#!/usr/bin/env python
# Copyright 2019 The Chromium Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.
"""Merges Snapdragon profiler data into a Chrome trace.

Snapdragon is a series of SoCs for mobile devices designed by Qualcomm.
Snapdragon Profiler is a software written by Qualcomm that knows how to extract
a wide range of information from Snapdragon chips, e.g. the GPU. This tool helps
to align Snapdragon Profiler information with internal Chrome traces to get a
better insight on how changes to Chrome affect the system.

To obtain a trace with Snapdragon profiler data,

1- Run the Snapdragon profiler, connect to a device, and start capturing
real-time data.

2- While Snapdragon profiler is capturing real-time data, capture a chrome trace
(or many traces), either from chrome://inspect/?tracing or using Telemetry.

3- Stop real-time capturing in Snapdragon profiler and save the result in a CSV
file.

4- Run this script. For example:
   ./snapdragon2trace sd.csv amazon_mobile.html merged_trace.html
"""

import argparse
import codecs
import sys
import os

tracing_path = os.path.abspath(os.path.join(
  os.path.dirname(os.path.realpath(__file__)), '..'))
sys.path.append(tracing_path)
from tracing_build import snapdragon2trace


def main():
  parser = argparse.ArgumentParser(description='add Snapdragon profiler data '
                                   'to a trace.', add_help=False)
  parser.add_argument('snapdragon_csv', metavar='SNAPDRAGON_CSV',
                      help='Snapdragon CSV file path (input).')
  parser.add_argument('chrome_trace', metavar='CHROME_TRACE',
                      help='Chrome trace file path (input). Supported '
                           'extensions are .gz, .html, and .json.')
  parser.add_argument('output', metavar='OUTPUT',
                      help='Output file path. Supported extensions are .gz, '
                           '.html, and .json.')
  parser.add_argument('-h', '--help', action='help',
                      help='Show this help message and exit.')
  args = parser.parse_args()

  traces = snapdragon2trace.LoadTraces(args.chrome_trace)
  csv = snapdragon2trace.LoadCSV(args.snapdragon_csv)
  snapdragon2trace.AddSnapdragonProfilerData(traces, csv)
  snapdragon2trace.WriteTraces(args.output, traces)


if __name__ == '__main__':
  sys.exit(main())

gha: HTML, lang: python
# this is the name of the package, not a list of spiders
SPIDER_MODULES = ['wine_example.spiders']
# indicates where to put newly generated spiders
NEWSPIDER_MODULE = SPIDER_MODULES[0]
COOKIES_ENABLED = False
COOKIES_DEBUG = True

# BEGIN: slow down request settings for class
CONCURRENT_REQUESTS = 1
CONCURRENT_REQUESTS_PER_DOMAIN = 1
# CONCURRENT_REQUESTS_PER_IP = 1
DOWNLOAD_DELAY = 1.0  # seconds
# END: slow down request settings for class

DUPEFILTER_DEBUG = True

HTTPCACHE_ENABLED = True

USER_AGENT = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:33.0) Gecko/20100101 Firefox/33.0'

gha: Python, lang: ini
package sample;
import javafx.application.Application;
import javafx.scene.Scene;
import javafx.stage.Stage;
import java.io.*;
import java.util.ArrayList;
import java.util.Scanner;


public class Game extends Application {

    public  int start;
    public int end;
    private Map map;
    private Player player;

    public void start(Stage stage){
        Scanner input = new Scanner(System.in);
        String st = "Map5.txt";
        String a ="";
        try{
            Scanner br = new Scanner(new FileReader(st)); String s;
            while (br.hasNextLine()){
                s=br.next();a+=s; } }
        catch (FileNotFoundException e){
            System.out.println("File not found!");
            System.exit(0);

        }
        System.out.print("Enter start number (1-18): ");
        this.start = input.nextInt();
        System.out.print("Enter goal number (1-18): ");
        this.end = input.nextInt();  //System.out.println(a);
        map = new Map(a,start,end);




        player = new MyPlayer(map);
        player.getBall();
            Scene scene = new Scene(map, map.getSize()*map.getUnit(),map.getSize()*map.getUnit() );
            stage.setTitle("GaMe");
            stage.setScene(scene);
        ArrayList<Integer> arr = map.path_way;

            scene.setOnKeyPressed(e -> {
                switch (e.getCode()) {
                    case DOWN: player.moveDown();break;
                    case UP:player. moveUp();break;
                    case LEFT: player.moveLeft();break;
                    case RIGHT: player.moveRight();break;
                    default: }

            });
            arr.remove(0);

        stage.setScene(scene);
        stage.show();

    }

    public static void main(String[] args) {
        launch(args);
    }
}

gha: Java, lang: groovy
<?php
/**
 * @author Thomas Müller <thomas.mueller@tmit.eu>
 *
 * @copyright Copyright (c) 2018, ownCloud GmbH
 * @license AGPL-3.0
 *
 * This code is free software: you can redistribute it and/or modify
 * it under the terms of the GNU Affero General Public License, version 3,
 * as published by the Free Software Foundation.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
 * GNU Affero General Public License for more details.
 *
 * You should have received a copy of the GNU Affero General Public License, version 3,
 * along with this program.  If not, see <http://www.gnu.org/licenses/>
 *
 */

namespace OCA\Federation;

use OC\BackgroundJob\TimedJob;
use OCA\Federation\AppInfo\Application;

class SyncJob extends TimedJob {
	public function __construct() {
		// Run once a day
		$this->setInterval(24 * 60 * 60);
	}

	protected function run($argument) {
		$app = new Application();
		$ss = $app->getSyncService();
		$ss->syncThemAll(function ($url, $ex) {
			if ($ex instanceof \Exception) {
				\OC::$server->getLogger()->error("Error while syncing $url : " . $ex->getMessage(), ['app' => 'fed-sync']);
			}
		});
	}
}

gha: JavaScript, lang: php
GO := go

GO_BUILDFLAGS ?= -v -ldflags "-s -w"
GO_TESTFLAGS ?= -v -cover
GO_GETFLAGS ?= -v
GO_VETFLAGS ?= -v -all -source -shadow=true -shadowstrict

GOFMT := gofmt
GOFMTFLAGS := -s -w -l

GOPATH := $(shell pwd)
PKGPATH := $(GOPATH)/src/local-ci
BINPATH := $(GOPATH)/bin

SRCS = $(PKGPATH)/main.go $(wildcard $(PKGPATH)/**/*.go)

.PHONY: verify
verify: fmt vet

.PHONY: build build/alpine build/darwin build/linux
build: build/alpine build/darwin build/linux build/windows
build/alpine: $(BINPATH)/alpine/local-ci
build/darwin: $(BINPATH)/darwin/local-ci
build/linux: $(BINPATH)/linux/local-ci
build/windows: $(BINPATH)/windows/local-ci
	mv $< $<.exe

.PHONY: clean
clean:
	rm -rf bin/ pkg/ src/github.com gopkk.in/

.PHONY: fmt
fmt:
	@$(GOFMT) $(GOFMTFLAGS) $(PKGPATH)

.PHONY: vet
vet:
	GOPATH=$(GOPATH) $(GO) vet $(GO_VETFLAGS) ./src/local-ci/...

.PHONY: test
test:
	GOPATH=$(GOPATH) $(GO) test $(GO_TESTFLAGS) local-ci/...

.PHONY: vendor
vendor:
	GOPATH=$(GOPATH) $(GO) get $(GO_GETFLAGS) ./src/local-ci/...

$(BINPATH)/%/local-ci: $(SRCS) vendor
	mkdir -p $(dir $@)
	GOPATH=$(GOPATH) GOOS=$(shell echo $* | sed s/alpine/linux/) $(GO) build $(GO_BUILDFLAGS) -o $@ $<

CHANGELOG.md: $(BINPATH)/clog .clog.toml
	$<

$(BINPATH)/clog:
	mkdir -p $(BINPATH)
ifeq ($(shell uname),Darwin)
	wget -q -O $@.tar.gz https://github.com/clog-tool/clog-cli/releases/download/v0.9.3/clog-v0.9.3-$(shell uname -m)-apple-darwin.tar.gz
else
	wget -q -O $@.tar.gz https://github.com/clog-tool/clog-cli/releases/download/v0.9.3/clog-v0.9.3-$(shell uname -m)-unknown-linux-gnu.tar.gz
endif
	tar xzvf $@.tar.gz -C bin/
	rm -f $@.tar.gz

gha: Go, lang: makefile
// Copyright (c) 2023, the Dart project authors.  Please see the AUTHORS file
// for details. All rights reserved. Use of this source code is governed by a
// BSD-style license that can be found in the LICENSE file.

/// @assertion It is a compile-time error if:
/// - A declaration depends directly on a sealed declaration from another
///   library.
///
/// @description Check that it is a compile-time error to implement the
/// interface of a class marked `sealed` outside of the library where it is
/// declared
/// @author sgrekhov22@gmail.com

import "class_modifiers_lib.dart";

class ImplementsSealed implements SealedClass {}
//                                ^^^^^^^^^^^
// [analyzer] unspecified
// [cfe] unspecified

abstract class AbstractImplementsSealed implements SealedClass {}
//                                                 ^^^^^^^^^^^
// [analyzer] unspecified
// [cfe] unspecified

abstract base class AbstractBaseImplementsSealed implements SealedClass {}
//                                                          ^^^^^^^^^^^
// [analyzer] unspecified
// [cfe] unspecified

abstract interface class AbstractInterfaceImplementsSealed implements SealedClass {}
//                                                                    ^^^^^^^^^^^
// [analyzer] unspecified
// [cfe] unspecified

abstract final class AbstractFinalImplementsSealed implements SealedClass {}
//                                                            ^^^^^^^^^^^
// [analyzer] unspecified
// [cfe] unspecified

final class FinalImplementsSealed implements SealedClass {}
//                                           ^^^^^^^^^^^
// [analyzer] unspecified
// [cfe] unspecified

base class BaseImplementsSealed implements SealedClass {}
//                                         ^^^^^^^^^^^
// [analyzer] unspecified
// [cfe] unspecified

sealed class SealedImplementsSealed implements SealedClass {}
//                                             ^^^^^^^^^^^
// [analyzer] unspecified
// [cfe] unspecified

interface class InterfaceImplementsSealed implements SealedClass {}
//                                                   ^^^^^^^^^^^
// [analyzer] unspecified
// [cfe] unspecified

mixin class MixinClassImplementsSealed implements SealedClass {}
//                                                ^^^^^^^^^^^
// [analyzer] unspecified
// [cfe] unspecified

base mixin class BaseMixinClassImplementsSealed implements SealedClass {}
//                                                         ^^^^^^^^^^^
// [analyzer] unspecified
// [cfe] unspecified

abstract mixin class AbstractMixinImplementsSealed implements SealedClass {}
//                                                            ^^^^^^^^^^^
// [analyzer] unspecified
// [cfe] unspecified

abstract base mixin class AbstractBaseMixinImplementsSealed implements SealedClass {}
//                                                                     ^^^^^^^^^^^
// [analyzer] unspecified
// [cfe] unspecified

mixin MixinImplementsSealed implements SealedClass {}
//                                     ^^^^^^^^^^^
// [analyzer] unspecified
// [cfe] unspecified

base mixin BaseMixinImplementsSealed implements SealedClass {}
//                                              ^^^^^^^^^^^
// [analyzer] unspecified
// [cfe] unspecified

enum EnumImplementsSealedClass implements SealedClass {e1, e2}
//                                        ^^^^^^^^^^^
// [analyzer] unspecified
// [cfe] unspecified

main() {
  print(ImplementsSealed);
  print(AbstractImplementsSealed);
  print(AbstractBaseImplementsSealed);
  print(AbstractInterfaceImplementsSealed);
  print(AbstractFinalImplementsSealed);
  print(FinalImplementsSealed);
  print(BaseImplementsSealed);
  print(SealedImplementsSealed);
  print(InterfaceImplementsSealed);
  print(MixinClassImplementsSealed);
  print(BaseMixinClassImplementsSealed);
  print(AbstractMixinImplementsSealed);
  print(AbstractBaseMixinImplementsSealed);
  print(MixinImplementsSealed);
  print(BaseMixinImplementsSealed);
  print(EnumImplementsSealedClass);
}

gha: Dart, lang: cpp
class Event < ActiveRecord::Base

  belongs_to :event_type
  belongs_to :location
  belongs_to :event_status
  has_many :event_signups
  has_many :members, :through => :event_signups
  has_many :attendances
  has_many :members, :through => :attendances
  has_one :trip
  has_and_belongs_to_many :ride_requests
  has_many :lhfe_flights
  has_many :lhfe_riders
  has_paper_trail

  validates :start, :end, :event_type_id, :event_statuses_id, :location_id, :presence => true, :on => :create

# upcoming events
scope :published, lambda {
  where ("events.start IS NOT NULL AND events.end > ?"), (Time.zone.now - 2.day)
  }

# gives a longer lookback than published
scope :recent, lambda {
  where ("events.start IS NOT NULL AND events.end > ?"), (Time.zone.now - 180.day)
  }

scope :ordered, order("events.start ASC")
scope :reverse, order("events.start DESC")
scope :cat_ordered, order("events.event_type_id ASC", "events.start ASC")
scope :confirmed, where("event_statuses_id = 1")
scope :tease, :limit => 3

scope :meeting, where("event_type_id = 1")
scope :air_show, where("event_type_id = 2")
scope :special, where("event_type_id = 3")
scope :maint, where("event_type_id = 4")
scope :flying_event, where("event_type_id = 2 OR event_type_id = 3")

scope :needs_roster, lambda {where("events.flight_roster = ?", true) }
scope :has_lhfe, lambda {where("events.rides_available = ?", true) }
scope :has_rsvp, lambda {where("events.rsvp = ?", true) }

def event_date
  "#{self.title} - #{self.start.strftime("%b %d, %Y")}"
end

end

gha: HTML, lang: ruby
export const AUTHENTICATE = "AUTHENTICATE"
export const LOGOUT = "LOGOUT"
gha: JavaScript, lang: ini
import * as Scrivito from "scrivito";
import addressWidgetIcon from "../../assets/images/address_widget.svg";

Scrivito.provideEditingConfig("AddressWidget", {
  title: "Address",
  thumbnail: addressWidgetIcon,
  attributes: {
    showBorderBottom: {
      title: "Show border at the bottom?",
      description: "Default: No",
    },
    showLogo: {
      title: "Show brand logo?",
      description: "Default: Yes",
    },
    locationName: {
      title: "Location name",
      description: "E.g. New York Convention Center",
    },
    locationStreetAddress: {
      title: "Street address",
      description: "E.g. 655 W. 34th Street",
    },
    locationLocality: {
      title: "Locality",
      description: "E.g. New York",
    },
    locationRegion: {
      title: "Region",
      description: "E.g. NY or CA",
    },
    locationPostalCode: {
      title: "Postal code",
      description: "E.g. 10001",
    },
    locationCountry: {
      title: "Country",
      description: "E.g. USA",
    },
    addressFormat: {
      title: "Address format",
      description: "Default: USA",
      values: [
        { value: "USA", title: "USA" },
        { value: "GER", title: "Germany" },
      ],
    },
    phone: {
      title: "Phone",
    },
    fax: {
      title: "Fax",
    },
    email: {
      title: "Email",
    },
  },
  properties: [
    "showLogo",
    "locationName",
    "locationStreetAddress",
    "locationLocality",
    "locationPostalCode",
    "locationRegion",
    "locationCountry",
    "addressFormat",
    "phone",
    "fax",
    "email",
    "showBorderBottom",
  ],
  initialContent: {
    showLogo: true,
    addressFormat: "USA",
  },
});

gha: JavaScript, lang: rust
#include "board.h"
#include "bishop.h"
#include <string>
// static helpers 
static bool onRight(int i){
	return (7 == (i % 8)) ? true : false;
}

static bool onLeft(int i){
	return (0 == (i % 8)) ? true : false;
}

// 2 Parameter ctor
Bishop::Bishop(int pos, bool isWhite) : Piece(pos, isWhite) {}

// returns if the Piece is empty or not
bool Bishop::isEmpty() const{
	return false;
}

// determines whether a Bishop can move to the end coordinates
bool Bishop::canMove(const std::string &start,const std::string &end, Piece ** b) const {
	int begin = getPos(start);
	int fin = getPos(end);

	// moving down on the right diagonal
	if (!(begin==0) && !(begin == 63) && (begin % 7 == fin % 7) && begin < fin) {
		while (true) {
			begin += 7;
			if (begin == fin && (b[begin]->isEmpty() || (isWhite() != b[begin]->isWhite()))) {
				return true;
			}
			else if (begin == fin && b[begin]->isEmpty()) {
				return true;
			}
			else if (!b[begin]->isEmpty()) {
				return false;
			}
		}
	}

	// moving up on the right diagonal
	else if (!(begin==0) && !(begin == 63) && (begin % 7 == fin % 7) && begin > fin) {
		while (true) {
			begin -= 7;
			if (begin == fin && (b[begin]->isEmpty() || (isWhite() != b[begin]->isWhite()))) {
				return true;
			}
			else if (begin == fin && b[begin]->isEmpty()) {
				return true;
			}
			else if(!b[begin]->isEmpty()) {
				return false;
			}
		} 
	}

	// moving down on the left diagonal
	else if (begin % 9 == fin % 9 && begin < fin) {
		if(onLeft(begin)){
				return false;
		}
		while (true) {
			begin += 9;
			if (begin == fin && (b[begin]->isEmpty() || (isWhite() != b[begin]->isWhite()))) {
				return true;
			}
			else if (begin == fin && b[begin]->isEmpty()) {
				return true;
			}
			else if (!b[begin]->isEmpty()) {
				return false;
			}
			else if(onRight(begin)){
				return false;
			}
		} 
	}

	// moving up on the left diagonal
	else if (begin % 9 == fin % 9 && begin > fin) {
		if (onRight(begin)){
				return false;
		}
		while (true) {
			begin -= 9;
			if (begin == fin && (b[begin]->isEmpty() || (isWhite() != b[begin]->isWhite()))) {
				return true;
			}
			else if (begin == fin && b[begin]->isEmpty()) {
				return true;
			}
			else if (!b[begin]->isEmpty()) {
				return false;
			}
			else if(onLeft(begin)){
				return false;
			}
		} 
	}
	else {
		return false;
	}
}

// returns uppercase or lowercase b, depending on which Player's turn it is
char Bishop::Type() const {
	return isWhite() ? 'B' : 'b';
}


gha: C++, lang: cpp
# The baseline for module testing used by Puppet Labs is that each manifest
# should have a corresponding test manifest that declares that class or defined
# type.
#
# Tests are then run by using puppet apply --noop (to check for compilation
# errors and view a log of events) or by fully applying the test in a virtual
# environment (to compare the resulting system state to the desired state).
#
# Learn more about module testing here:
# http://docs.puppetlabs.com/guides/tests_smoke.html
#
class { 'flowtools':
  capture  => true,
  flow_dir => '/flows',
}

flowtools::device { 'device1':
  ip_address => '192.168.1.1',
  port       => '9996',
  listen     => '0.0.0.0',
  options    => '-V 5'
}
gha: Ruby, lang: powershell
.navbar-lewagon {
  justify-content: space-between;
  background: rgba(255,255,255,1);
  top: 0;
  padding:12px 32px;
  margin:24px;
  z-index:9999;
  border-radius:6px;
  box-shadow: rgba(0, 0, 0, 0.07) -4px 9px 25px -6px;

  .nav-item {
    display:flex;
    }

  .id_photo {
    justify-content: center;
  }

  .fa-star {
    color:$blue-lavender;

  }

  .brand-name {
    font-size: 14px;
    font-family: 'Montserrat';
    font-weight: 800;
    color:$blue-lavender;
    margin-left: 12px;
  }

  .nav-link-favorites {
    font-size:14px;
    color:$black-blue;
    opacity:.7;
    transition:.2s;
    text-transform: uppercase;
    letter-spacing: 1px;
    transition:.2s;
    color: $blue-lavender;
    margin-right: 24px;
    &:hover {
      opacity:1;
      transition:.2s;
    }
  }

   .nav-link-comparator {
    font-size:14px;
    color:$black-blue;
    opacity:.7;
    transition:.2s;
    text-transform: uppercase;
    letter-spacing: 1px;
    transition:.2s;
    color: $grey-lavender;
    margin-right: 24px;
    &:hover {
      opacity:1;
      transition:.2s;
    }

  }
  .user-name {
    color:$black-blue;
    opacity:.5;
    font-size:12px;
  }
}

.navbar-lewagon .navbar-collapse {
  flex-grow: 0;
}

.navbar-lewagon .navbar-brand img {
  width: 40px;
}

.links {
  display: flex;
}

.logo {
  color:$black-blue;
 }

 .navbar-brand {
  align-items: center;
 }

 .search-navbar{
  display: flex;
  margin-left: 12px;
 }

 .searchbar-navbar {
  display: flex;
  align-items: center;
  justify-content: between;
  width: 300px;
 }

 .elements-navbar {
  padding-left: 10px;
  color: $light-grey;
  margin-top: 3px;
 }

 .btn-search {
  margin-left: 12px !important;
  background: transparent;
  border: none;
  box-shadow: none;
 }

gha: Ruby, lang: css
---
title: Support, Extend and Contribute to Aspose.BarCode in PHP
type: docs
weight: 30
url: /java/support-extend-and-contribute-to-aspose-barcode-in-php/
---

## **Support**
From the very first days of Aspose, we knew that just giving our customers good products would not be enough. We also needed to deliver good service. We are developers ourselves and understand how frustrating it is when a technical issue or a quirk in the software stops you from doing what you need to do. We're here to solve problems, not create them.

This is why we offer free support. Anyone who uses our product, whether they have bought them or are using an evaluation, deserves our full attention and respect.

You can log any issues or suggestions related to Aspose.Barcode Java for PHP using any of the following platforms:

- [Github](https://github.com/aspose-barcode/Aspose.BarCode-for-Java/issues)
- [CodePlex](https://asposebarcodejavaphp.codeplex.com/workitem/list/basic)
## **Extend and Contribute**
Aspose.Barcode Java for PHP is open source and its source code is available on the major social coding websites listed below. Developers are encouraged to download the source code and contribute by suggesting or adding new feature or improving the existing ones, so that others could also benefit from it.
## **Source Code**
You can get the latest source code from one of the following locations

- [Github](https://github.com/aspose-barcode/Aspose.BarCode-for-Java/tree/master/Plugins/Aspose_Barcode_Java_for_PHP)
- [CodePlex](https://asposebarcodejavaphp.codeplex.com/SourceControl/latest)

gha: Java, lang: markdown
// 1251. 단어 나누기
// 2021.06.09
// 브루트 포스
#include<iostream>
#include<string>
#include<algorithm>

using namespace std;

int main()
{
    string s;
    cin >> s;
    string ans = "";
    string a = "";
    string b = "";
    string c = "";
    for (int i = 1; i < s.size() - 1; i++)
    {
        for (int j = 1; j < s.size() - i; j++)
        {
            // 세 단어로 나누기
            a = s.substr(0, i);
            b = s.substr(i, j);
            c = s.substr(i + j, s.size() - i - j);

            // 각각 뒤집기
            reverse(a.begin(), a.end());
            reverse(b.begin(), b.end());
            reverse(c.begin(), c.end());

            // 합치기
            string tmp = a + b + c;

            if (ans == "")
            {
                ans = tmp;
            }
            else if (ans > tmp)
            {
                ans = tmp;
            }
        }
    }
    cout << ans << endl;
    return 0;
}

gha: C++, lang: cpp
# utasker_MODBUS
The crash occurs as it is not ensured that all `SerialHandle` entries are initialized before they are being used.

The crash itself happens in `fnRead`, where a NULL function pointer is dereferenced.
gha: Shell, lang: sql
Catkin-Sphinx
=============

Sphinx plugins for Catkin projects.
Currently provides the ROS theme, better shell prompt highlighting and a sphinx domain for cmake.

Using the ROS theme
-------------------

To use this plugin, add the following to the ``conf.py`` in your project
(which it should have as one of the files used by Sphinx to generate
documentation):

    # Below the definition of html_theme_path:
    import catkin_sphinx
    html_theme_path = [catkin_sphinx.get_theme_path()]

    # Use ROS theme
    html_theme = 'ros-theme'

Using an improved shell prompt highlighting
-------------------------------------------

Add the following to the ``conf.py`` in your project below the definition of the extensions list::

    extensions = extensions + ['catkin_sphinx.ShLexer']

This will slightly improve documentation highlighting for examples like::

    # this will make all following snippets be of type prompt
    .. highlight:: catkin-sh

    # this will create a single code block of type prompt (examples)
    .. code-block:: catkin-sh

      >>> python setup.py install
      # comment
      $ bash prompt

Using the cmake sphinx domain
-----------------------------

Add the following to the ``conf.py`` in your project below the definition of the extensions list::

    extensions = extensions + ['catkin_sphinx.cmake']

Then cmake modules and macros can be documented using the following syntax::

    * :cmake:mod:`foo` Module

    .. cmake:macro:: bar(bam)

      :param bam: foo docstring
      :type bam: string
      :returns: list

Blank lines and indentation are important.
No autodoc extention for cmake files yet.

gha: Python, lang: markdown
USE `asign_system`;
/* 文件表增加打印分配次数字段 */
ALTER TABLE `asign_system`.`sign_sys_file_resource` ADD COLUMN `print_dis_num` BIGINT(20) NULL COMMENT '最后一次打印分配次数' AFTER `gmt_mod`;

gha: Java, lang: sql
import React, { Component } from 'react';
import { View, Button } from 'react-native';

interface DefaultProps { 
    onLogout: () => void
}

class SettingsScreen extends Component<DefaultProps, object> {

    handleLogout = () => {
        this.props.onLogout();
    }

    render() {
        return (
            <View>
                <Button 
                    color='tomato'
                    title='Log out'
                    onPress={this.handleLogout}
                />
            </View>
        );
    }
}

export default SettingsScreen;
gha: TypeScript, lang: javascript
as yet unclassified
hasKeyboard
	^ self submorphs first hasKeyboard
gha: Smalltalk, lang: pascal
﻿
using Blitz.Rpc.Shared;
using Newtonsoft.Json;
using Newtonsoft.Json.Linq;
using System;
using System.Collections.Generic;
using System.IO;

namespace UsingServer
{
    public class MySerializer : ISerializer
    {

        JsonSerializer serializer;
        public MySerializer()
        {
            serializer = new JsonSerializer();
        }
        public List<string> AcceptMimeType { get; } = new List<string> { "application/json", "text/json" };

        public string ProduceMimeType { get; set; } = "application/json";

        public object FromStream(Stream stream, Type returnType)
        {
            return serializer.Deserialize(new StreamReader(stream), returnType);
        }

        public object[] FromStream(Stream stream, Type[] returnType)
        {
            var data = JToken.Load(new JsonTextReader(new StreamReader(stream)));
            if(!(data is JArray))
            {
                throw new Exception();
            }
            var list = new List<object>();
            int i = 0;
            foreach(var item in data as JArray)
            {
                list.Add(item.ToObject(returnType[i++]));
            }
            return list.ToArray();
        }


        public void ToStream(Stream outstream, object v)
        {
            StreamWriter textWriter = new StreamWriter(outstream);
            serializer.Serialize(textWriter, v);
            textWriter.Flush();
        }
    }


}

gha: C#, lang: c_sharp
#pragma once

#include <iostream>
#include <string>
#include <vector>

class Frame {
    char firstRoll;
    char secondRoll;

   public:
    Frame() : firstRoll(' '), secondRoll(' ') {}
    Frame(char first, char second) : firstRoll(first), secondRoll(second) {}
    bool operator==(const Frame& rhs) const { return firstRoll == rhs.firstRoll && secondRoll == rhs.secondRoll; }
    friend std::ostream& operator<<(std::ostream& os, const Frame& frame);
    char getFirstRoll() const { return firstRoll; };
    char getSecondRoll() const { return secondRoll; };
};

inline std::ostream& operator<<(std::ostream& os, const Frame& frame) {
    os << "{" << frame.firstRoll << ", " << frame.secondRoll << "}";
    return os;
}

class Game {
   public:
    enum class Status {
        NO_GAME,
        IN_PROGRESS,
        FINISHED,
    };

   private:
    struct PlayerData {
        std::string name;
        std::vector<Frame> rolls;
    };
    std::vector<PlayerData> players;
    void loadPlayerRolls(std::ifstream& file, std::vector<Frame>& playerRolls);
    bool isLastFrame(int frameCount) const;
    bool isStrike(char currentRoll) const;
    bool isStrike(const Frame& frame) const;
    bool isSpare(char nextRoll) const;
    bool isSpare(const Frame& frame) const;
    std::vector<Frame> conversionCharNumbersToInt(const std::vector <Frame>& rolls) const;
    size_t countFramesWithoutStrikeOrSpare(const std::vector<Frame>& rolls) const;
    size_t countOnlyStrikeFrames(const std::vector<Frame>& rolls) const;
    size_t countOnlySpareFrames(const std::vector<Frame>& rolls) const;
    std::string getOutputString(int laneNumber) const;

   public:
    Game(){};
    void loadFromFile(const std::string& filePath);
    const std::vector<PlayerData>& getPlayers() const { return players; };
    size_t countPoints(const std::vector<Frame>& rolls) const;
    Status getGameStatus() const;
    void printOutput(std::ostream& os, int laneNumber) const;
};

gha: C++, lang: cpp
#include "fps_limit.h"
#include "logger.h"
#include "timespec_util.h"
#include <stdint.h>
#include <time.h>
#include <unistd.h>
#include <assert.h>

#define FPS_MEASURE_PERIOD_SEC 5.0

void measure_fps(struct fps_limit_state *state, struct timespec *now);

void fps_limit_measure_start(struct fps_limit_state *state, double max_fps) {
	if (max_fps <= 0.0) {
		return;
	}

	clock_gettime(CLOCK_MONOTONIC, &state->frame_last_time);
}

uint64_t fps_limit_measure_end(struct fps_limit_state *state, double max_fps) {
	if (max_fps <= 0.0) {
		return 0;
	}

	// `fps_limit_measure_start` was not called?
	assert(!timespec_is_zero(&state->frame_last_time));

	struct timespec now;
	clock_gettime(CLOCK_MONOTONIC, &now);
	int64_t elapsed_ns = timespec_diff_ns(&now, &state->frame_last_time);

	measure_fps(state, &now);

	int64_t target_ns = (1.0 / max_fps) * TIMESPEC_NSEC_PER_SEC;
	int64_t delay_ns = target_ns - elapsed_ns;
	if (delay_ns > 0) {
		logprint(TRACE, "fps_limit: elapsed time since the last measurement: %u, "
			"target %u, should delay for %u (ns)", elapsed_ns, target_ns, delay_ns);
		return delay_ns;
	} else {
		logprint(TRACE, "fps_limit: elapsed time since the last measurement: %u, "
			"target %u, target not met (ns)", elapsed_ns, target_ns);
		return 0;
	}
}

void measure_fps(struct fps_limit_state *state, struct timespec *now) {
	if (timespec_is_zero(&state->fps_last_time)) {
		state->fps_last_time = *now;
		return;
	}

	state->fps_frame_count++;

	int64_t elapsed_ns = timespec_diff_ns(now, &state->fps_last_time);

	double elapsed_sec = (double) elapsed_ns / (double) TIMESPEC_NSEC_PER_SEC;
	if (elapsed_sec < FPS_MEASURE_PERIOD_SEC) {
		return;
	}

	double avg_frames_per_sec = state->fps_frame_count / elapsed_sec;

	logprint(DEBUG, "fps_limit: average FPS in the last %0.2f seconds: %0.2f",
		elapsed_sec, avg_frames_per_sec);

	state->fps_last_time = *now;
	state->fps_frame_count = 0;
}

gha: C, lang: cpp
using Windows.Media.Playback;

namespace Zafiro.Uwp.Core.Media
{
    public interface IMediaPlayerAdapterInjector
    {
        void Adapt(Windows.Media.Playback.MediaPlayer mediaPlayer);
    }
}
gha: C#, lang: c_sharp
﻿namespace WebManager.Utility
{
    public class RegistryCredential
    {
        public string Registry { get; set; }
        public string BasicAuth { get; set; }
    }
}

gha: TypeScript, lang: c_sharp
export const columns = (vm: any) => {
  return [
    {
      title: '课程名称',
      dataIndex: 'course_name'
    },
    {
      title: '上课时间',
      dataIndex: 'course_time'
    },
    {
      title: `${vm.$c('coach')}姓名`,
      dataIndex: 'coach_name'
    },
    {
      title: '可约人数',
      dataIndex: 'can_reserve_num'
    },
    {
      title: '预约人数',
      dataIndex: 'reserve_num'
    },
    {
      title: '签到人数',
      dataIndex: 'checkin_num'
    }
  ]
}

gha: Vue, lang: javascript
#include "range_attack.h"
#include <shot_action.h>
#include <ai.h>
#include <actor.h>
#include <equip_action.h>
#include <unequip_action.h>

namespace amarlon { namespace state {

RangeAttack::RangeAttack()
{
}

FSMStateType RangeAttack::getType() const
{
  return FSMStateType::ATTACK_RANGE;
}

int RangeAttack::update()
{
  if ( _ai )
  {
    ActorPtr enemy = _ai->getTarget().firstActor();
    ActorPtr me = _ai->getOwner().lock();

    if ( me && enemy )
    {
      me->performAction( std::make_shared<ShotAction>(enemy) );
    }
  }

  return 0;
}

bool RangeAttack::canEnter()
{
  _weapon = nullptr;
  _amunition = nullptr;

  ActorPtr me = _ai->getOwner().lock();
  if ( me )
  {
    me->performAction( new UnEquipAction(ItemSlotType::MainHand) );
    me->performAction( new UnEquipAction(ItemSlotType::Amunition) );
  }

  chooseWeapon();
  return _weapon && _amunition;
}

void RangeAttack::onEnter()
{
  equip();
}

void RangeAttack::chooseWeapon()
{
  auto wps = getWeapons();
  for ( ActorPtr w : wps )
  {
    auto ams = getAmunition(w->getFeature<Pickable>());
    if ( !ams.empty() )
    {
      _weapon = w;
      _amunition = ams.front();
      break;
    }
  }
}

void RangeAttack::equip()
{
  ActorPtr me = _ai->getOwner().lock();
  if ( me )
  {
    me->performAction( new UnEquipAction(ItemSlotType::MainHand) );
    me->performAction( new UnEquipAction(ItemSlotType::Amunition) );
    me->performAction( new EquipAction(_weapon) );
    me->performAction( new EquipAction(_amunition) );
  }
}

bool RangeAttack::isOutOfAmmo()
{
  bool ooa = true;
  if ( _amunition )
  {
    PickablePtr ammo = _amunition->getFeature<Pickable>();
    ooa = !ammo || ammo->getAmount() == 0;
  }
  return ooa;
}

std::vector<ActorPtr> RangeAttack::getWeapons()
{
  std::vector<ActorPtr> weapons;
  ActorPtr me = _ai->getOwner().lock();
  InventoryPtr inv = me ? me->getFeature<Inventory>() : nullptr;
  if ( me && inv )
  {
    weapons = inv->items([](PickablePtr p){
      return p->getItemType().isRangeWeapon();
    });
  }
  return weapons;
}

std::vector<ActorPtr> RangeAttack::getAmunition(PickablePtr weapon)
{
  std::vector<ActorPtr> amunition;
  ActorPtr me = _ai->getOwner().lock();
  InventoryPtr inv = me ? me->getFeature<Inventory>() : nullptr;
  if ( me && inv && weapon )
  {
    amunition = inv->items([&weapon](PickablePtr p){
      return p->getCategory() == PickableCategory::Amunition &&
             p->getItemType().amunition == weapon->getItemType().amunition;
    });
    std::sort(amunition.begin(), amunition.end(), [](ActorPtr l, ActorPtr r){
      PickablePtr pl = l ? l->getFeature<Pickable>() : nullptr;
      PickablePtr pr = r ? r->getFeature<Pickable>() : nullptr;
      return pl->getDamage() > pr->getDamage();
    });
  }
  return amunition;
}


}}

gha: C++, lang: cpp
<div class="container">
    <div class="row">
        <div class="col-md-4 col-md-offset-4">
            <div class="panel panel-default">
                <div class="panel-body">
                    <div class="row">
                        <div class="col-md-12 text-center">
                            <h2>Login</h2><hr>
                        </div>
                        <div class="col-md-12">
                            {{#if success_msg}}
                                <div class="alert alert-success alert-dismissible" role="alert">
                                    <button type="button" class="close" data-dismiss="alert" aria-label="Close"><span aria-hidden="true">&times;</span></button>
                                    <strong>{{success_msg}}</strong>
                                </div>
                            {{/if}}
                            {{#if error_msg}}
                                <div class="alert alert-danger alert-dismissible" role="alert">
                                    <button type="button" class="close" data-dismiss="alert" aria-label="Close"><span aria-hidden="true">&times;</span></button>
                                    <strong>{{error_msg}}</strong>
                                </div>
                            {{/if}}
                            {{#if error}}
                                <div class="alert alert-danger alert-dismissible" role="alert">
                                    <button type="button" class="close" data-dismiss="alert" aria-label="Close"><span aria-hidden="true">&times;</span></button>
                                    <strong>{{error}}</strong>
                                </div>
                            {{/if}}
                        </div>
                        <div class="col-md-12">
                            <form action="/users/login" method="post">
                                <div class="form-group">
                                    <label for="username">Username</label>
                                    <input type="text" class="form-control" id="username" name="username" placeholder="username" />
                                </div>
                                <div class="form-group">
                                    <label for="password">Password</label>
                                    <input type="password" class="form-control" id="password" name="password" placeholder="password" />
                                </div>
                                <div class="form-group text-right">
                                    <button type="submit" class="btn btn-success">Login</button>
                                </div>
                            </form>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>
gha: Handlebars, lang: html
<h1>商品管理画面</h1>
<p id="notice"><%= notice %></p>

<%= link_to '新しく商品を登録する', new_product_path, class: 'btn btn-primary btn-sm' %>
<div class='row screen_frame'>
  <% @products.each do |product| %>
    <div class='col-md-5 product_frame'>
      <table>
        <% product.product_images.each do |p_image| %>
          <tr>
            <th><%= t('activerecord.attributes.product_image.image') %></th>
            <td><%= image_tag(p_image.image.url, :size => "160x120") %></td>
          </tr>
        <% end %>
        <tr>
          <th><%= t('activerecord.attributes.product.name') %></th>
          <td><%= product.name %></td>
        </tr>
        <tr>
          <th><%= t('activerecord.attributes.product.number') %></th>
          <td><%= product.number.to_s(:delimited) %>個</td>
        </tr>
        <tr>
          <th><%= t('activerecord.attributes.product.price') %></th>
          <td><%= product.price.to_s(:delimited) %>円</td>
        </tr>
        <tr>
          <th><%= t('activerecord.attributes.product.content') %></th>
          <td><%= product.content %></td>
        </tr>
        <tr>
          <th><%= t('activerecord.attributes.product.preservation') %></th>
          <td><%= product.preservation %></td>
        </tr>
        <tr>
          <th><%= t('activerecord.attributes.product.how_to_eat') %></th>
          <td><%= product.how_to_eat %></td>
        </tr>
        <tr>
          <th><%= t('activerecord.attributes.product.expiration') %></th>
          <td><%= product.expiration %></td>
        </tr>
        <tr>
          <th><%= t('activerecord.attributes.product.shipping') %></th>
          <td><%= product.shipping %></td>
        </tr>
        <tr>
          <th><%= t('activerecord.attributes.product.remarks') %></th>
          <td><%= product.remarks %></td>
        </tr>
      </table>
      <%= link_to '編集', edit_product_path(product.id) %> | 
      <%= link_to '削除', product_path(product.id), method: :delete, data: { confirm: '本当に削除しますか？' } %>
    </div>
  <% end %>
</div>
gha: HTML, lang: coffeescript
node_modules
package.json
links

gha: JavaScript, lang: ini
---
title: Vault
link: https://github.com/pusher/vault
language: Rails, HTML, CSS
author: Pusher
---

Vault is a front-end pattern library, which holds patterns that are used across a site. Examples of patterns are navbars, buttons, and headings. It is a rails implementation of Rareloop's Primer tool.

gha: HTML, lang: yaml
import axios from 'axios';

export const authenticateUser = async () => {
	const token = await localStorage.getItem('token');
	try {
		await axios.get(`${process.env.BACKEND_API_ENDPOINT}/authenticate`, {
			headers: { Authorization: `Bearer ${token}` }
		});

		return true;
	} catch (error) {
		return false;
	}
};

gha: TypeScript, lang: javascript
import axios from "axios";
import localforage from "localforage";

import { BOOKS_DETAIL, BOOKS_CHAPTERS, BOOKS } from "../urls";
import { isLangTC, langTC } from "../helpers/util";

const readBookKey = "my-read-book-list";

let defaultChapterLimit = 5;
if (isLangTC()) {
  defaultChapterLimit = 2;
}

// detail 获取书籍详情
export async function detail(id) {
  const url = BOOKS_DETAIL.replace(":id", id);
  const params = {};
  if (isLangTC()) {
    params.lang = langTC;
  }
  const { data } = await axios.get(url, {
    params
  });
  return data;
}

// listChapters 获取书籍章节列表
export async function listChapters(id, params) {
  const url = BOOKS_CHAPTERS.replace(":id", id);
  if (isLangTC()) {
    params.lang = langTC;
  }
  const { data } = await axios.get(url, {
    params
  });
  if (!data.chapters) {
    data.chapters = [];
  }
  data.chapters.forEach(item => {
    if (!item.no) {
      item.no = 0;
    }
  });
  return data;
}

// updateByID 更新书籍
export async function updateByID(id, params) {
  const url = BOOKS_DETAIL.replace(":id", id);
  const { data } = await axios.patch(url, params);
  return data;
}

// list 获取书籍列表
export async function list(params) {
  if (isLangTC()) {
    params.lang = langTC;
  }
  const { data } = await axios.get(BOOKS, {
    params
  });
  if (!data.books) {
    data.books = [];
  }
  return data;
}

let chapterContentCache = null;
function getChapterContentFromCache(bookID, chapterIndex) {
  if (!chapterContentCache) {
    return null;
  }
  if (chapterContentCache.bookID !== bookID) {
    return null;
  }
  let found = null;
  chapterContentCache.chapters.forEach(item => {
    if (item.no === chapterIndex) {
      found = item;
    }
  });
  if (found) {
    // 如果出现多个空白字段，替换（一般为错误）
    found.content = found.content.replace(/\s{2,}/g, "");
  }
  return found;
}

// getChapterContent 获取章节内容
export async function getChapterContent(bookID, chapterIndex) {
  // 先从缓存读取
  const found = getChapterContentFromCache(bookID, chapterIndex);
  if (found) {
    return found;
  }
  const limit = defaultChapterLimit;
  const offset = Math.floor(chapterIndex / limit) * limit;
  // 失败则从服务器读取
  const data = await listChapters(bookID, {
    offset,
    limit,
    fields: "no,title,content"
  });
  const chapters = (data && data.chapters) || [];

  // 写入缓存
  chapterContentCache = {
    bookID,
    chapters
  };
  return getChapterContentFromCache(bookID, chapterIndex);
}

// clearRead 清除阅读记录
export async function clearRead() {
  await localforage.removeItem(readBookKey);
}

// listRead 获取阅读书籍
export async function listRead() {
  const data = await localforage.getItem(readBookKey);
  let bookList = [];
  if (data) {
    bookList = JSON.parse(data);
  }
  return bookList;
}

// setRead 设置书籍阅读信息
export async function setRead({ id, name, no, title, done }) {
  const bookList = await listRead();
  let found = -1;
  bookList.forEach((item, index) => {
    if (item.id === id) {
      found = index;
    }
  });
  if (found !== -1) {
    bookList.splice(found, 1);
  }
  bookList.push({
    id,
    name,
    title,
    no,
    done,
    updatedAt: new Date().toISOString()
  });
  // 最多只保存20个记录
  if (bookList.length > 20) {
    bookList.shift();
  }
  await localforage.setItem(readBookKey, JSON.stringify(bookList));
}

// getRead 获取书籍阅读信息
export async function getRead(bookID) {
  const bookList = await listRead();
  let found = null;
  bookList.forEach(item => {
    if (item.bookID === bookID) {
      found = item;
    }
  });
  return found;
}

gha: Go, lang: javascript
spring.datasource.url=jdbc:postgresql://localhost:5432/Hertzz
spring.datasource.username=froznar
spring.datasource.password=root
spring.datasource.driver-class-name=org.postgresql.Driver
spring.jpa.hibernate.ddl-auto=update
gha: JavaScript, lang: ini
<div>
    i am father
    <examples-widget-08_debug_data_pass-child></examples-widget-08_debug_data_pass-child>
    <examples-widget-08_debug_data_pass-child2></examples-widget-08_debug_data_pass-child2>
</div>
gha: JavaScript, lang: makefile
{
    "backup": {
        "container": null,
        "description": "Test backup",
        "name": "backup001",
        "volume_id": "%(volume_id)s",
        "incremental": false,
        "snapshot_id": null,
        "force": false
    }
}

gha: Python, lang: json


  <div align="center">

   <h2>{{ my_page.centre }} </h2>

  </div>

 <br>
 {%include "Web_Accounting_Summary_Exp_Table.html" with my_exp=my_page.exp1 %} <br>
 {%include "Web_Accounting_Summary_Exp_Table.html" with my_exp=my_page.exp2 %} <br>
 {%include "Web_Accounting_Summary_Exp_Table.html" with my_exp=my_page.exp3 %} <br>
 {%include "Web_Accounting_Summary_Exp_Table.html" with my_exp=my_page.exp4 %} <br>
 
  
 


gha: JavaScript, lang: html
---
date: 2021-11-09
title: Бесплатные книги по байесу!
published: 2021-11-10
lastModified: 2021-11-10
---

## Bayesian Optimization Book

Автор **Roman Garnett**

https://bayesoptbook.com/

## Probabilistic Programming & Bayesian Methods for Hackers

Автор **Cam Davidson-Pilon**

Баейсовские методы для хакеров - объсняется все на чистом питоне с примерами в юпитеровских блокнотиках.

https://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/


gha: JavaScript, lang: markdown
<template>
    <v-container class="text-xs-center">
        <cube loading></cube>
        <br />
        <br />
        <br />
    </v-container>
</template>

<script>
export default {
}
</script>
gha: Vue, lang: xml
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.

import { CbsClient, TokenType, defaultCancellableLock } from "../src";
import { AbortController } from "@azure/abort-controller";
import { Connection } from "rhea-promise";
import { assert } from "chai";
import { createConnectionStub } from "./utils/createConnectionStub";
import { isError } from "@azure/core-util";
import { stub } from "sinon";

describe("CbsClient", function () {
  const TEST_FAILURE = "Test failure";

  describe("init", function () {
    it("honors already aborted abortSignal", async function () {
      const cbsClient = new CbsClient(new Connection(), "lock");

      // Create an abort signal that is already aborted.
      const controller = new AbortController();
      controller.abort();
      const signal = controller.signal;

      try {
        await cbsClient.init({ abortSignal: signal });
        throw new Error(TEST_FAILURE);
      } catch (err) {
        assert.ok(isError(err));
        assert.equal((err as Error).name, "AbortError");
      }
    });

    it("honors abortSignal inside locking code", async function () {
      const lock = "lock";
      const cbsClient = new CbsClient(new Connection(), "lock");

      // Create an abort signal that will be aborted on a future tick of the event loop.
      const controller = new AbortController();
      const signal = controller.signal;

      // Make the existing `init` invocation wait until the abortSignal
      // is aborted before acquiring it's lock.
      await defaultCancellableLock.acquire(
        lock,
        () => {
          return new Promise<void>((resolve) => {
            setTimeout(() => {
              controller.abort();
              resolve();
            }, 0);
          });
        },
        { abortSignal: undefined, timeoutInMs: undefined }
      );

      try {
        await cbsClient.init({ abortSignal: signal });
        throw new Error(TEST_FAILURE);
      } catch (err) {
        assert.ok(isError(err));
        assert.equal((err as Error).name, "AbortError");
      }
    });

    it("honors abortSignal", async function () {
      const connectionStub = new Connection();
      // Stub 'open' because creating a real connection will fail.
      stub(connectionStub, "open").resolves({} as any);

      const cbsClient = new CbsClient(connectionStub, "lock");

      // Create an abort signal that will be aborted on a future tick of the event loop.
      const controller = new AbortController();
      const signal = controller.signal;
      setTimeout(() => controller.abort(), 0);

      try {
        await cbsClient.init({ abortSignal: signal });
        throw new Error(TEST_FAILURE);
      } catch (err) {
        assert.ok(isError(err));
        assert.equal((err as Error).name, "AbortError");
      }
    });
  });

  describe("negotiateClaim", function () {
    it("throws an error if the cbs link doesn't exist.", async function () {
      const connectionStub = createConnectionStub();
      const cbsClient = new CbsClient(connectionStub, "lock");

      try {
        await cbsClient.negotiateClaim("audience", "token", TokenType.CbsTokenTypeSas);
        throw new Error(TEST_FAILURE);
      } catch (err) {
        assert.ok(isError(err));
        assert.equal(
          (err as Error).message,
          "Attempted to negotiate a claim but the CBS link does not exist."
        );
      }
    });

    describe("cancellation", function () {
      it("honors already aborted abortSignal", async function () {
        const connectionStub = createConnectionStub();
        const cbsClient = new CbsClient(connectionStub, "lock");

        // Create an abort signal that is already aborted.
        const controller = new AbortController();
        controller.abort();
        const signal = controller.signal;

        try {
          // Pass the already aborted abortSignal to make sure negotiateClaim will exit quickly.
          await cbsClient.negotiateClaim("audience", "token", TokenType.CbsTokenTypeSas, {
            abortSignal: signal,
          });
          throw new Error(TEST_FAILURE);
        } catch (err) {
          assert.ok(isError(err));
          assert.equal((err as Error).name, "AbortError");
        }
      });

      it("honors abortSignal", async function () {
        const connectionStub = createConnectionStub();
        const cbsClient = new CbsClient(connectionStub, "lock");

        // Call `init()` to ensure the CbsClient has a RequestResponseLink.
        await cbsClient.init();

        // Create an abort signal that will be aborted on a future tick of the event loop.
        const controller = new AbortController();
        const signal = controller.signal;
        setTimeout(() => controller.abort(), 0);

        try {
          await cbsClient.negotiateClaim("audience", "token", TokenType.CbsTokenTypeSas, {
            abortSignal: signal,
          });
          throw new Error(TEST_FAILURE);
        } catch (err) {
          assert.ok(isError(err));
          assert.equal((err as Error).name, "AbortError");
        }
      });
    });
  });
});

gha: TypeScript, lang: javascript
---
modified_at:	2019-08-28 10:35:06
title:	'PostgreSQL - New version: 10.10'
---

[https://www.postgresql.org/docs/10/static/release-10-10.html](https://www.postgresql.org/docs/10/static/release-10-10.html)

gha: HTML, lang: yaml
---
layout: post
title: "科学上网且用且珍惜"
date: 2018-11-09  
description: "ssr"
tag: Linux  
---  

## 安装：

### 服务端安装

linux服务器服务端(在国外服务器上执行)  
<del>`wget --no-check-certificate https://freed.ga/github/shadowsocksR.sh; bash shadowsocksR.sh`</del>
安装链接貌似已经失效了,最近使用的比较好用的是v2ray,一键脚本执行方法：  
`bash <(curl -s -L https://git.io/v2ray.sh)`  
脚本下载下来看了一下,备注挺中二的...  

执行完成后监听端口为执行过程中的默认端口  
在客户端按脚本输出信息配置连接信息  

<br>

### 客户端安装

客户端下载地址:  
[windows](href="https://freed.ga/ShadowSocksR/ShadowsocksR-4.7.0.zip")  
[android](https://freed.ga/ShadowSocksR/shadowsocksr-release.apk)  
[mac](https://freed.ga/ShadowSocksR/macOS%20Sierra%2010.10.x.zip)  
ios的到appstore找一个,目前貌似大部分要收费了~  
<br>

## 原理：

转自: [https://vc2tea.com/whats-shadowsocks/](https://vc2tea.com/whats-shadowsocks/)  

- 很久前,访问google的方式  

![](/images/posts/netcont/1.png)  

- 被墙  

![](/images/posts/netcont/2.png)  

- 初代解决方法,利用海外服务器直接代理

![](/images/posts/netcont/3.png)  
1 首先用户和境外服务器基于ssh建立起一条加密的通道  
2-3 用户通过建立起的隧道进行代理,通过ssh server向真实的服务发起请求  
4-5 服务通过ssh server,再通过创建好的隧道返回给用户  
由于ssh本身就是基于RSA加密技术,所以GFW无法从数据传输的过程中的加密数据内容进行关键词分析,避免了被重置链接的问题,但由于创建隧道和数据传输的过程中,ssh本身的特征是明显的,所以GFW一度通过分析连接的特征进行干扰,导致ssh存在被定向进行干扰的问题

- Shadowsocks原理:  

![](/images/posts/netcont/4.png)  

简单理解的话,shadowsocks是将原来ssh创建的Socks5协议拆开成server端和client端,所以下面这个原理图基本上和利用ssh tunnel大致类似  
1&6 客户端发出的请求基于Socks5协议跟ss-local端进行通讯,由于这个ss-local一般是本机或路由器或局域网的其他机器,不经过GFW,所以解决了上面被GFW通过特征分析进行干扰的问题  
2&5 ss-local和ss-server两端通过多种可选的加密方法进行通讯,经过GFW的时候是常规的TCP包,没有明显的特征码而且GFW也无法对通讯数据进行解密  
3&4 ss-server将收到的加密数据进行解密,还原原来的请求,再发送到用户需要访问的服务,获取响应原路返回  

gha: HTML, lang: markdown
﻿using Microsoft.EntityFrameworkCore.Migrations;

namespace Whale.DAL.Migrations
{
    public partial class AddColumnsToScheduledMeetingsTable : Migration
    {
        protected override void Up(MigrationBuilder migrationBuilder)
        {
            migrationBuilder.AddColumn<string>(
                name: "FullURL",
                table: "ScheduledMeetings",
                nullable: true);

            migrationBuilder.AddColumn<string>(
                name: "Password",
                table: "ScheduledMeetings",
                nullable: true);

            migrationBuilder.AddColumn<string>(
                name: "ShortURL",
                table: "ScheduledMeetings",
                nullable: true);
        }

        protected override void Down(MigrationBuilder migrationBuilder)
        {
            migrationBuilder.DropColumn(
                name: "FullURL",
                table: "ScheduledMeetings");

            migrationBuilder.DropColumn(
                name: "Password",
                table: "ScheduledMeetings");

            migrationBuilder.DropColumn(
                name: "ShortURL",
                table: "ScheduledMeetings");
        }
    }
}

gha: C#, lang: c_sharp
export const skillConstants = {
    ADD_SKILL_REQUEST: 'ADD_SKILL_REQUEST',
    ADD_SKILL_SUCCESS: 'ADD_SKILL_SUCCESS',
    ADD_SKILL_FAILURE: 'ADD_SKILL_FAILURE',

    EDIT_SKILL_REQUEST: 'EDIT_SKILL_REQUEST',
    EDIT_SKILL_SUCCESS: 'EDIT_SKILL_SUCCESS',
    EDIT_SKILL_FAILURE: 'EDIT_SKILL_FAILURE',

    SHOW_SKILL_REQUEST: 'SHOW_SKILL_REQUEST',
    SHOW_SKILL_SUCCESS: 'SHOW_SKILL_SUCCESS',
    SHOW_SKILL_FAILURE: 'SHOW_SKILL_FAILURE',

    FETCH_SKILLS_REQUEST: 'FETCH_SKILLS_REQUEST',
    FETCH_SKILLS_SUCCESS: 'FETCH_SKILLS_SUCCESS',
    FETCH_SKILLS_FAILURE: 'FETCH_SKILLS_FAILURE'
}
gha: JavaScript, lang: shell
---
title: 操作系统
date: "2020-01-011T22:22:22.169Z"
path:  "/operating-system"
tags:
   - base
---

## 操作系统的进程通信方式

Linux 进程间通信方式
* 管道
* 信号
* 信号量
* 消息队列
* 共享内存
* 套接字

## 僵尸进程和孤儿进程

## Q & A

gha: JavaScript, lang: markdown
<?php
$debug_lvl = 0; /* Verbosity debug level */

include("../include/functions.inc");
include("../include/vars.inc");
include("../include/config.inc");
include("../include/mysql-connect.inc");
date_default_timezone_set('America/Los_Angeles');

$mysql_link_r = database_open($mysql_host, "w");

if (!is_object($mysql_link_r)) {
	if ($debug_lvl>0)
		mysqli_connect_error();
	die("Cannot connect to the database");
}

if (isset($_COOKIE['nocreports_uname'])) {
	$user = $user->getUserSettings($_COOKIE['nocreports_uname'], $mysql_link_r);
} else {
	$user->name = "jdoe";
}

/*
 * This function returns the list of rpt_users to use as user select options
 * @params is_search BOOL if true use logged in user as default user, if false ignore
 * @returns option string
 */
function getUsersOptions($is_search = false) {
	global $mysql_link_r;
	global $user;

	$sql_users = 'SELECT id, name FROM rpt_user ORDER BY name';
	$q_users   = database_query($sql_users, $mysql_link_r);
	$option    = '';

	while ($row = database_fetch_array($q_users)) {
		if ($user->id == $row['id'] && $is_search) {
			$option .= '<option value="'.$row['id'].'" selected="selected">'.$row['name'].'</option>';
		} else {
			$option .= '<option value="'.$row['id'].'">'.$row['name'].'</option>';
		}
	}

	return $option;
}

/*
 * This function returns all the puppet errors in the database.
 */
function getAll() {
	global $mysql_link_r;

	$sql = "SELECT p.*, u.name FROM puppet_errors p LEFT JOIN rpt_user u ON p.resolved_by = u.id ORDER BY error_date DESC, error_time DESC";
	$q = database_query($sql, $mysql_link_r);
	while ($row = database_fetch_object($q)) {
	?>
		<tr>
			<td><?php echo date('m/d/Y H:i:s', strtotime($row->error_date.' '.$row->error_time)); ?></td>
			<td><?php echo $row->host_name; ?></td>
			<td><?php echo $row->centos_os; ?></td>
			<td><?php echo $row->action; ?></td>
			<td><?php echo $row->name; ?></td>
		</tr>
	<?php }
}

gha: C, lang: php
<?php

namespace App;

use Illuminate\Database\Eloquent\Model;
use Illuminate\Database\Eloquent\Relations\BelongsTo;

class Job extends Model
{
    protected $fillable = ['service_id', 'contact_id', 'event_id', 'status_id', 'description', 'scope_of_work'];

    public function event ()
    {
        return $this->hasMany(Event::class, 'job_id', 'id');
    }

    public function service(): BelongsTo
    {
        return $this->belongsTo(Service::class,
                                'service_id',
                                'id');
    }

    public function contact(): BelongsTo
    {
        return $this->belongsTo(Contacts::class,
                                'contact_id',
                                'id');
    }

    public function status(): BelongsTo
    {
        return $this->belongsTo(StatusJob::class,
                                'status_id',
                                'id');
    }

    public function history(): \Illuminate\Database\Eloquent\Relations\HasMany
    {
        return $this->hasMany(JobHistory::class,
                              'job_id',
                              'id');
    }

    public function notes()
    {
        return $this->hasMany(Note::class, 'job_id', 'id');
    }

    public function images()
    {
        return $this->hasMany(ImageJob::class,'job_id','id');
    }


}

gha: CSS, lang: php
import { reduxBatch } from "@manaflair/redux-batch";
import { createStore, applyMiddleware } from "redux";
import {
  useSelector as useReduxSelector,
  TypedUseSelectorHook,
} from "react-redux";
import appReducer, { AppState } from "./reducers";
import createSagaMiddleware from "redux-saga";
import { rootSaga } from "sagas";
import { composeWithDevTools } from "redux-devtools-extension/logOnlyInProduction";
import * as Sentry from "@sentry/react";
import { ReduxActionTypes } from "constants/ReduxActionConstants";

const sagaMiddleware = createSagaMiddleware();
const sentryReduxEnhancer = Sentry.createReduxEnhancer({
  actionTransformer: (action) => {
    if (
      action.type === ReduxActionTypes.SET_EVALUATED_TREE ||
      action.type === ReduxActionTypes.EXECUTE_API_ACTION_SUCCESS
    ) {
      // Return null to not log the action to Sentry
      action.payload = null;
    }
    return action;
  },
});

export default createStore(
  appReducer,
  composeWithDevTools(
    reduxBatch,
    applyMiddleware(sagaMiddleware),
    reduxBatch,
    sentryReduxEnhancer,
  ),
);
sagaMiddleware.run(rootSaga);

export const useSelector: TypedUseSelectorHook<AppState> = useReduxSelector;

gha: TypeScript, lang: javascript
"=============================================================================
" File: efm_langserver_settings.vim
" Author: Tsuyoshi CHO
" Created: 2020-01-11
"=============================================================================

scriptencoding utf-8

if exists('g:loaded_lsp_efm_langserver_settings')
\ || !executable('efm-langserver')
\ || !exists('g:lsp_loaded')
  finish
endif
let g:loaded_lsp_efm_langserver_settings = 1

let s:args = ['efm-langserver']
if efm_langserver_settings#config_enable()
  let s:args = extend(s:args, ['-c', efm_langserver_settings#config_path()])
endif
if efm_langserver_settings#debug_enable()
  let s:args = extend(s:args, ['-logfile', efm_langserver_settings#debug_path()])
  let s:args = extend(s:args, ['-loglevel', efm_langserver_settings#debug_enable()])
endif

function! s:lsp_efm_langserver_setup() abort
  call lsp#register_server({
  \  'name': 'efm-langserver',
  \  'cmd': { server_info->s:args },
  \  'allowlist': efm_langserver_settings#whitelist(),
  \  'blocklist': efm_langserver_settings#blacklist(),
  \})
endfunction

augroup vim-lsp-efm-langserver-settings
  autocmd!
  autocmd User lsp_setup call s:lsp_efm_langserver_setup()
  \ | autocmd! vim-lsp-efm-langserver-settings
augroup END

" EOF

gha: Vim Script, lang: elixir
import { Identify, Types, createInstance } from '@amplitude/analytics-browser';
import { version } from '../package.json';
import { getAmplitudeEndpoint } from './common';
import {
	COOKIES_TTL_DAYS,
	USER_PROP_ANALYTICS_CLIENT_VERSION,
	USER_PROP_COMPONENT_NAME,
} from './config';

export interface Properties {
	[key: string]: any;
}

export interface UserProperties {
	set?: Properties;
	setOnce?: Properties;
}

/**
 * Client defines an interface for interaction wih balena analytics backend.
 */
export interface Client {
	/** Return the ID used to identify the current device. */
	deviceId(): string;

	/** Return the ID used to identify the current session. */
	sessionId(): number;

	/** Generate a new device identifier used for reporting. */
	regenerateDeviceId(): void;

	/** Associate all input device IDs with a user ID. */
	linkDevices(userId: string, deviceIds: string[]): void;

	/** Track event of the defined type with specified event properties. */
	track(eventType: string, props?: Properties): void;

	/** Set current device ID. */
	setDeviceId(deviceId: string): void;

	/** Set current session ID. */
	setSessionId(sessionId: number): void;

	/** Set current user ID. */
	setUserId(userId: string): void;

	setUserProperties(props: UserProperties): void;

	identify(identify: Identify): void;
}

/**
 * Analytics client configuration.
 */
export interface Config {
	/** Analytics backend base endpoint. e.g data.balena-cloud.com */
	endpoint?: string;

	/** Project name for the analytics client. */
	projectName: string;

	/** Name of the component that does the reporting. */
	componentName: string;

	/** Component version name. */
	componentVersion?: string;

	/** Optional config for Amplitude client. */
	amplitude?: Omit<Types.BrowserOptions, keyof AmplitudeOverride>;

	/** Optional device_id for Amplitude client. */
	deviceId?: string;
}

interface AmplitudeOverride {
	endpoint?: string;
	deviceId?: string;
	cookieExpiration?: number;
}

const getIdentifyObject = () => {
	const identifyObject = new Identify();
	identifyObject.set(USER_PROP_ANALYTICS_CLIENT_VERSION, version);
	return identifyObject;
};

class DefaultClient implements Client {
	private readonly amplitudeInstance: Types.BrowserClient;

	constructor(config: Config) {
		this.amplitudeInstance = createInstance();

		const amplConfig: Types.BrowserOptions = Object.assign(
			{},
			config.amplitude,
		);

		if (config.endpoint) {
			amplConfig.serverUrl = getAmplitudeEndpoint(config.endpoint);
		}
		if (config.deviceId) {
			amplConfig.deviceId = config.deviceId;
		}
		if (config.componentVersion) {
			amplConfig.appVersion = config.componentVersion;
		}

		// TODO: Move this to the web tracker.
		amplConfig.cookieExpiration = COOKIES_TTL_DAYS;

		this.amplitudeInstance.init(config.projectName, undefined, amplConfig);

		const identifyObject = getIdentifyObject();
		identifyObject.set(USER_PROP_COMPONENT_NAME, config.componentName);
		this.amplitudeInstance.identify(identifyObject);
	}

	deviceId(): string {
		return this.amplitudeInstance.getDeviceId()!;
	}

	sessionId(): number {
		return this.amplitudeInstance.getSessionId()!;
	}

	setDeviceId(deviceId: string): void {
		this.amplitudeInstance.setDeviceId(deviceId);
	}

	setSessionId(sessionId: number): void {
		this.amplitudeInstance.setSessionId(sessionId);
	}

	regenerateDeviceId(): void {
		const userId = this.amplitudeInstance.getUserId();
		this.amplitudeInstance.reset();
		this.amplitudeInstance.setUserId(userId);
	}

	linkDevices(userId: string, deviceIds: string[]): void {
		let finalDeviceId: string | null = this.deviceId();
		if (finalDeviceId === userId) {
			finalDeviceId = null;
		}
		this.setUserId(userId);

		const identifyData = getIdentifyObject();

		// Make sure the current device ID is associated.
		this.amplitudeInstance.identify(identifyData);

		for (const deviceId of deviceIds) {
			if (finalDeviceId == null && deviceId !== userId) {
				finalDeviceId = deviceId;
			}
			this.amplitudeInstance.setDeviceId(deviceId);
			this.amplitudeInstance.identify(identifyData);
		}

		// Continue reporting with the original device ID (if it's not equal to the user ID).
		if (finalDeviceId != null) {
			this.amplitudeInstance.setDeviceId(finalDeviceId);
		} else {
			this.regenerateDeviceId();
		}
	}

	track(eventType: string, props?: Properties): void {
		this.amplitudeInstance.track(eventType, props);
	}

	setUserId(userId: string): void {
		this.amplitudeInstance.setUserId(userId);
	}

	setUserProperties(props: UserProperties): void {
		const identify = new Identify();
		for (const key in props.set) {
			if (props.set.hasOwnProperty(key)) {
				identify.set(key, props.set[key]);
			}
		}
		for (const key in props.setOnce) {
			if (props.setOnce.hasOwnProperty(key)) {
				identify.setOnce(key, props.setOnce[key]);
			}
		}

		this.amplitudeInstance.identify(identify);
	}

	identify(identify: Identify): void {
		this.amplitudeInstance.identify(identify);
	}
}

/** NoopClient does nothing when  */
class NoopClient implements Client {
	constructor(private readonly logEvents: boolean) {}

	private log(...args: any[]) {
		if (this.logEvents) {
			console.log('Analytics client:', ...args);
		}
	}

	deviceId() {
		return '';
	}

	sessionId() {
		return -1;
	}

	linkDevices() {
		/* nothing */
	}
	regenerateDeviceId() {
		/* nothing */
	}
	setDeviceId(): void {
		/* nothing */
	}
	setSessionId(): void {
		/* nothing */
	}
	setUserId(): void {
		/* nothing */
	}
	setUserProperties() {
		/* nothing */
	}

	track(eventType: string, props?: Properties): void {
		this.log(`track [${eventType}]`, props);
	}

	identify(): void {
		/* nothing */
	}
}

export function createClient(config: Config): Client {
	return new DefaultClient(config);
}

export function createNoopClient(logEvents: boolean = false): Client {
	return new NoopClient(logEvents);
}

gha: TypeScript, lang: javascript
statsmodels.tsa.arima\_process.ArmaProcess.isinvertible
=======================================================

.. currentmodule:: statsmodels.tsa.arima_process

.. autoproperty:: ArmaProcess.isinvertible
gha: HTML, lang: ini
FHINI0B0	; ; 11-OCT-1995
	;;5.0;Dietetics;;Oct 11, 1995
	Q:'DIFQR(112)  F I=1:2 S X=$T(Q+I) Q:X=""  S Y=$E($T(Q+I+1),4,999),X=$E(X,4,999) S:$A(Y)=126 I=I+1,Y=$E(Y,2,999)_$E($T(Q+I+1),5,99) S:$A(Y)=61 Y=$E(Y,2,999) X NO E  S @X=Y
Q	Q
	;;^UTILITY(U,$J,112,7300,20)
	;;=Bowes & Church's Food Values, Sixteenth Edition.
	;;^UTILITY(U,$J,112,7301,0)
	;;=PUDDINGS,VANILLA TAPIOCA (REG MIX),JELL-O AMERICANA^BC-00574^1/2-cup^145
	;;^UTILITY(U,$J,112,7301,1)
	;;=2.759^2.828^18.897^110.345^74.69^^^101.379^.062^11.724^79.31^128.276^117.241^.331^.038^^^106.207^.69^.034
	;;^UTILITY(U,$J,112,7301,2)
	;;=.138^.069^.262^.034^4.138^.303^^^11.724^1.793^^.138
	;;^UTILITY(U,$J,112,7301,20)
	;;=Bowes & Church's Food Values, Sixteenth Edition.
	;;^UTILITY(U,$J,112,7302,0)
	;;=CAKE & COOKIE DECORATOR,PILSBURY^BC-00575^tbsp.^18
	;;^UTILITY(U,$J,112,7302,1)
	;;=0^11.111^76.111^400^13.889^^^0^0^^0^27.778^0^^^^^0^0^0
	;;^UTILITY(U,$J,112,7302,2)
	;;=0^0
	;;^UTILITY(U,$J,112,7302,20)
	;;=Bowes & Church's Food Values, Sixteenth Edition.
	;;^UTILITY(U,$J,112,7303,0)
	;;=CAKE & COOKIE DECORATOR (CHOC),PILSBURY^BC-00576^tbsp.^16
	;;^UTILITY(U,$J,112,7303,1)
	;;=1.25^11.25^76.25^400^18.125^^^0^.813^^68.75^31.25^0^^^^^0^0^0
	;;^UTILITY(U,$J,112,7303,2)
	;;=0^0
	;;^UTILITY(U,$J,112,7303,20)
	;;=Bowes & Church's Food Values, Sixteenth Edition.
	;;^UTILITY(U,$J,112,7304,0)
	;;=SAUCES,CARAMEL,KNORR^BC-00577^tbsp.^21
	;;^UTILITY(U,$J,112,7304,1)
	;;=0^0^70^285.714^25.714^^^^^^^^23.81
	;;^UTILITY(U,$J,112,7304,2)
	;;=^^^^^^^^0
	;;^UTILITY(U,$J,112,7304,20)
	;;=Bowes & Church's Food Values, Sixteenth Edition.
	;;^UTILITY(U,$J,112,7305,0)
	;;=SYRUPS,CHOC,HERSHEY^BC-00578^2-tbsp.^28
	;;^UTILITY(U,$J,112,7305,1)
	;;=3.214^1.429^58.571^260.714^^^^14.286^1.786^71.429^128.571^171.429^64.286^.786^.5^.4^^21.429^^.036
	;;^UTILITY(U,$J,112,7305,2)
	;;=.036^.357^^^^^^^0
	;;^UTILITY(U,$J,112,7305,20)
	;;=Bowes & Church's Food Values, Sixteenth Edition.
	;;^UTILITY(U,$J,112,7306,0)
	;;=ICING FROM MIX (CHOC),DUNCAN HINES^BC-00579^1/12-pkg.^38
	;;^UTILITY(U,$J,112,7306,1)
	;;=1.316^18.421^63.158^421.053^17.895^^^15.789^2.368^^^^236.842^^^^^^^.026
	;;^UTILITY(U,$J,112,7306,2)
	;;=.053^.263^^^^^^^0^5.263^12.105^1.053
	;;^UTILITY(U,$J,112,7306,20)
	;;=Bowes & Church's Food Values, Sixteenth Edition.
	;;^UTILITY(U,$J,112,7307,0)
	;;=ICING FROM MIX (CHOC FUDGE),GENERAL MILLS^BC-00580^1/12-pkg.^37
	;;^UTILITY(U,$J,112,7307,1)
	;;=0^16.216^81.081^486.486^^^^^^^^162.162^189.189
	;;^UTILITY(U,$J,112,7307,2)
	;;=^^^^^^^^0^5.405^8.108^2.703
	;;^UTILITY(U,$J,112,7307,20)
	;;=Bowes & Church's Food Values, Sixteenth Edition.
	;;^UTILITY(U,$J,112,7308,0)
	;;=ICING FROM MIX (COCONUT PECAN),GENERAL MILLS^BC-00581^1/12-pkg.^35
	;;^UTILITY(U,$J,112,7308,1)
	;;=0^22.857^54.286^428.571^^^^^^^^85.714^142.857
	;;^UTILITY(U,$J,112,7308,2)
	;;=^^^^^^^^0^8.571^8.571^5.714
	;;^UTILITY(U,$J,112,7308,20)
	;;=Bowes & Church's Food Values, Sixteenth Edition.
	;;^UTILITY(U,$J,112,7309,0)
	;;=ICING FROM MIX (CREAM CHEESE),DUNCAN HINES^BC-00582^1/12-pkg.^38
	;;^UTILITY(U,$J,112,7309,1)
	;;=.263^21.053^63.158^421.053^^^^^^^^^315.789
	;;^UTILITY(U,$J,112,7309,2)
	;;=^^^^^^^^0
	;;^UTILITY(U,$J,112,7309,20)
	;;=Bowes & Church's Food Values, Sixteenth Edition.
	;;^UTILITY(U,$J,112,7310,0)
	;;=ICING FROM MIX (DARK DUTCH FUDGE),DUNCAN HINES^BC-00583^1/12-pkg.^38
	;;^UTILITY(U,$J,112,7310,1)
	;;=1.579^18.421^63.158^421.053^18.947^^^18.421^2.053^^^^250^^^^^^^0
	;;^UTILITY(U,$J,112,7310,2)
	;;=.026^.263^^^^^^^18.421^5.263^12.105^1.053
	;;^UTILITY(U,$J,112,7310,20)
	;;=Bowes & Church's Food Values, Sixteenth Edition.
	;;^UTILITY(U,$J,112,7311,0)
	;;=ICING FROM MIX (MILK CHOC POLKA DOT),DUNCAN HINES^BC-00584^1/12-pkg.^38
	;;^UTILITY(U,$J,112,7311,1)
	;;=1.579^21.053^65.789^447.368^^^^^^^^^250
	;;^UTILITY(U,$J,112,7311,2)
	;;=^^^^^^^^0
	;;^UTILITY(U,$J,112,7311,20)
	;;=Bowes & Church's Food Values, Sixteenth Edition.
	;;^UTILITY(U,$J,112,7312,0)
	;;=ICING FROM MIX (RAINBOW CHIP),GENERAL MILLS^BC-00585^1/12-pkg.^40
	;;^UTILITY(U,$J,112,7312,1)
	;;=0^17.5^80^475^^^^^^^^37.5^125
	;;^UTILITY(U,$J,112,7312,2)
	;;=^^^^^^^^0^5^10^2.5
	;;^UTILITY(U,$J,112,7312,20)
	;;=Bowes & Church's Food Values, Sixteenth Edition.
	;;^UTILITY(U,$J,112,7313,0)
	;;=ICING FROM MIX (SOUR CREAM CHOC FUDGE),GENERAL MILLS^BC-00586^1/12-pkg.^37
	;;^UTILITY(U,$J,112,7313,1)
	;;=2.703^16.216^81.081^486.486^^^^^^^^202.703^202.703
	;;^UTILITY(U,$J,112,7313,2)
	;;=^^^^^^^^0^5.405^8.108^2.703
	;;^UTILITY(U,$J,112,7313,20)
	;;=Bowes & Church's Food Values, Sixteenth Edition.
	;;^UTILITY(U,$J,112,7314,0)
	;;=ICING FROM MIX (SOUR CREAM WHITE),GENERAL MILLS^BC-00587^1/12-pkg.^37
	;;^UTILITY(U,$J,112,7314,1)
	;;=0^13.514^83.784^459.459^^^^^^^^27.027^270.27
	;;^UTILITY(U,$J,112,7314,2)
	;;=^^^^^^^^0^2.703^8.108^2.703
	;;^UTILITY(U,$J,112,7314,20)
	;;=Bowes & Church's Food Values, Sixteenth Edition.

gha: M, lang: assembly
---
layout: post 
title:  "파스퇴르 건강한 저온살균 우유 후레쉬, 2.3L, 1개" 
description: 파스퇴르  ..
date: 2020-02-02 06:12:05 
img: https://static.coupangcdn.com/image/product/image/vendoritem/2018/10/19/3922489847/97300bda-f0ad-4549-8ab4-decf1e3c1647.jpg 
linkUrl: https://coupa.ng/bnQITX 
categories: [1012] 
color: BF360C 
price: 5860 
author: Ask View Shop 
cont:  "(2020년 5월 1일 주문해서<br/> 상품 특징 <br/> 영양 정보 <br/> 최대 19가지 품질 검사 <br/> 혹 구매 하시는데 도움이 되셨다면,<br/><br/> - 냉해 / 품온 준수<br/><br/> - 원산지 / 표시 사항 / 인증 확인<br/><br/> - 이물질 / 위생 상태 확인<br/><br/> - 저온 살균<br/><br/> - 포장 / 파손 확인<br/>1만 5천원 이상 구매해야<br/>1인 가족이지만 우유를 평소 자주 마시거나<br/>2인 이상 가족에게 완전 강추 ! 강추합니다  )<br/>4천원대로 판매하길래 바로 주문했지요ㅎㅎ<br/>5월 2일 받은 제품 기준입니다)<br/><br/><br/>[ 구매 계기 ]<br/>[ 구매 후기 ]<br/>[ 배송 ]<br/>[ 별  점수]<br/>[ 제품 설명 ]<br/><br/>가격  4,460원<br/>가격도 너무 저렴하고 빠른 배송으로<br/>각각 어떤 맛인지 궁금하기도 했고<br/>고소한 맛보다는 단백한 맛이 더 느껴졌어요<br/>골다공증에 걸리면 살살 넘어져도 쉽게 뼈가 부러집니다  칼슘은 뼈와 골격의  성장과 내구성, 기능 등에 제일 중요한 미네랄이기에 우유를 통한 칼슘 섭취는 골다공증 예방에도 효과가 있으니 우유는 마시는게 좋습니다<br/>괜히 더 기분이 좋더라고요ㅎㅎ<br/>구매에 참고가 되면 좋겠습니다<br/>구해하실때 참고가 되면 좋겠습니다;;<br/>그래도 파스퇴르 만큼 맛있는 우유를 하나 찾았으니 다행이지욤 ㅋㅋ파스퇴르 우유는 63도에서 30분간 천천히 저온 살균한 우유이기 때문에 맛은 후레쉬한 우유 본연의 신선한 맛과 향이 납니다.<br/><br/>그래서 1인 가구임에도 불구하고<br/>나트륨  100 mg / 5 %<br/>내용량  2300ml<br/>다른 새로운 우유들이 있어서 맛을 보느라 한동안 안 먹었던 파스퇴르 후레쉬 우유를 주문하였습니다역쉬 베스트3안에 듭니다 ㅋㅋ 저혼자만의 순위이고 안 궁금하겄지만 나중에 공개할께요.<br/>크흐흐흫<br/>단백질 6g 11%<br/>단백질  6 g / 11 %<br/>당류 10g 10%<br/>당류  10 g  / 10 %<br/>두꺼운 초록색의 뽁뽁이 (?) 에<br/>만들어 먹기도 하다보니<br/>많은 비용과 노력이 필요하니 가격이 다른 우유에 비해 비쌀수밖에 없지요!!! 원유의 품질이 보장 되지 않으면 저온살균을 할수 없습니다.<br/> 그러니 파스퇴르는 신선하고 질이 좋은 원유를 사용하는 것입니다!!<br/>말하면 입 아프지만 신선한 프레쉬한 맛입니다.<br/> 저온살균우유중에서도 특이한 맛이 납니다 ㅎㅎ 영양가도 훌륭하지요 우유속의 좋은 유산균이 살아 있어서 한잔을 마시더라도 더더 좋숩니돠 이젠 나이가 들어서 근가 좋은음식을 찾아 먹게 됩니다!!<br/>맛있게 먹었을 파스퇴르 우유입니다  )<br/>매번 먹을때마다 구수한 끝맛을 느끼려고 노력하면서 먹곤 하는데 정말 이런 맛은 파스퇴르 밖에없습니다 ;;<br/>무 ! 엇 ! 보 ! 다 !<br/>무료 배송해주기 때문에<br/>뭘 타먹지 않아도 그 자체로도 맛있고<br/>바로 다음 날 새벽에 도착해서 넘 좋았어요ㅎㅎ<br/>밖에 잘 못나가다보니 먹거리를<br/>배송은 역시나 쿠팡의 로켓 배송 덕분에<br/>배송일자; 2020/04/28 새벽<br/>벌써 얼마 남지 않은 우유의 양<br/>벌컥벌컥 마시게 되더라고요ㅎㅎ<br/>별 5개 중 5개를 주었어요  )<br/>보관 방법  냉장 보관 ( 0  10도 )<br/>사실 저는 우유에 뭘 타서 잘 마시는데<br/>살균 방법  63도 이상에서 30분간 저온 살균<br/>살균 방식; 63도에서 30분간 저온 살균<br/>새벽 배송으로 빨리 배송을 받고 너무 좋아<br/>솔직하게 작성하는 구매리뷰입니다<br/>솔직한 구매 후기입니다<br/>송아지가 커서도 어미젖을 먹냐고.<br/>.<br/> 앙탈을 부립니다;;; 그러면서 빵 먹을땐 왜 먹는건데... <br/> 뭔데... <br/> ㅋㅋㅋ<br/>시중가 보다 가성비가 너무너무 착한 쿠팡,<br/>신선함을 유지 시키기 위한<br/>아 ! 이 제품은 ‘로켓프레시’ 제품으로<br/>양이 넉넉한 우유를 찾다가<br/>열량  200 ml 당 135kcal<br/>영양성분; 나트륨 100mg 5%<br/>완전 빨리 도착한거 있죠  )<br/>완전 할인 엄청 했을 때 사서 그런지<br/>왜 값 비싼지 알겠더라고요ㅎㅎ<br/>요즘 코로나 19 바이러스로 인해<br/>용량2.<br/>3리터<br/>우유가 엄청 빨리 없어지더라고요ㅎㅎ<br/>우유는 액체지만 고형분이 12 프로가 있기 때문에 천천히 씹어 먹으면 유당 분해 효소인 락타아제가 작용해 소화가 잘 되고 더 고소한 맛을 느끼게 됩니다<br/>우유를 마시고 햇빛을 쪼이면 비타민 D가 생성되서 체내 칼슘흡수율을 도와줍니다.<br/>  저는 파스퇴르 우유를 좋아합니다.<br/><br/>우유를 천천히 씹으면서 먹으면 대뇌의 손상을 낮춰 뇌졸중 위험을 감소시켜 주게 됩니다.<br/>  칼슘이 부족하면 나타나는 대표적인 증세로는 빈혈, 골다공증 등이 있습니다.<br/> 우유는 가장 좋은 칼슘 공급원지욤!!!<br/>우유속 성분이 세균이나 바이러스로부터 지켜내기 위해 인체의 저항력을 높여줍니다.<br/>  감기에 걸핏하면  잘 걸린다거나 수면이 부족 하면 우유를 마시면 좋습니돠요!!!<br/>우유에 포함되어 있는 영양분은 단백질, 지방, 칼슘, 리보플라빈, 비타민 등 인체에 필수적인 성분이 들어 있어서 어린이, 성인 등 모두에게 유익한 식품입니돠<br/>우유와 함께 배송되는 동안<br/>원래는 저지방 or 무지방 우유를 주로 마셨는데<br/>원성분; 1급A 원유 100%<br/>원재료명 및 함량  1급 A 원유 100% / 우유 함유<br/>유통 기한  2020년 5월 9일 9시 34분 까지<br/>유통기한; 2020/05/06<br/>이 부분 참고하셔서 구매하시면 좋을 것 같아요 ㅎㅎ<br/>이번에도 역시나 믿고 잘 구매 했습니다 !!<br/>일년동안 아이들이 감기가 안 걸린이유가 우유를 잘 마셔서 도움을 받은거 같숩니다 ㅎㅎ 앗 글고 우유는 고형분이 있으므로 씹어서 마시면 좋아욤!!<br/>일주일 이상이라 넉넉하네요 !!<br/>저는 파스퇴르 우유의 가격이<br/>전날 오후에 주문했는데<br/>제가 받은 우유는 유통 기한도<br/>제가 우유 주문하려고 봤을 때가<br/>제가 우유에 대한 미식가라면 미식가여서 ㅋㅋㅋ맛있는 우유를 찾아서  삼만리 했지만 결국 답장너였숩니돠;;<br/>제품명  파스퇴르 우유 후레쉬<br/>종이 재질의 팩 안에 물이 얼려져 있어요 !<br/>주문일자; 2020/04/27<br/>지방 8g 15%<br/>지방  8 g / 15 %<br/>집 현관문까지 배달해주는 쿠팡<br/>총 내용량  2.<br/>3 L<br/>칼슘 220mg 31%<br/>칼슘  220 mg / 31 %<br/>콜레스테롤 25g 8%<br/>콜레스테롤  25 mg / 8 %<br/>쿠팡 통해서 자주 주문해 먹고 있어요  )<br/>쿠팡에서 여러가지 종류의 우유가 있길래<br/>탄수화물 10g 3%<br/>탄수화물  10 g / 3 %<br/>택배 상자를 열어보면<br/>트랜스 지방  0 g<br/>파스퇴르 우유는 60도에서 30분간 저온살균으로 우유속에 유산균이 사롸 있습니다 그래서 우유중에 제일 맛있고 영양도 우수하지요!!<br/>파스퇴르 우유는 그냥 우유만으로도<br/>파스퇴르 우유는 신선하고 특유의 진한 맛이 살아 있습니다;;  언제나 먹어도 질리지 않고 고소하고 맛있습니다!!  파스퇴르 우유는 무겁지 않은 구수함에 끝맛이 정말 특이하고 맛있습니다;;<br/>파스퇴르 우유는 우리집 입맛에 잘 맞고 맛도 맛이지만 건강에도 좀더 도움이 되는거 같습니다 우리집에서 우유를 안 먹는 사람은 신랑인데요<br/>파스퇴르 우유는 우유통 재질이 HDPE인데요  환경 호르몬이 검출되지 않는 친환경 플라스틱입니다.<br/> 그리고 전자렌지 사용이 가능합니다;;;<br/>파스퇴르 우유를 2300ml 주문했어요 !!<br/>파스퇴르 우유를 맛 보니<br/>파스퇴르 우유를 발견했어요 !!<br/>파스퇴르 원유는 1급A보다 더 까다로운 기준의 세균수 8천미만의 원유를 사용합니다.<br/> 파스퇴르 우유는 저온살균을 할때 우유에 유해균이  많이 남지 않더록 하기 위해 처음부터 세균수가 적은 좋은 원유를 사용합니다.<br/><br/>파스퇴르 후레쉬 우유는 저의 원픽 원탑인 만큼 맛도 짱 좋고 영양적으로도 우수하고 건강에도 좋아서 계속 먹으려고 합니돠.<br/>;;<br/>파스퇴르가 원래 6천원대로 판매하는데<br/>평소에 우유를 자주 마시고<br/>평소에 우유와 과일을 갈아 마시기도 하고<br/>포장 재질  폴리에틸렌<br/>포화 지방  5 g / 33 %<br/>포화지방 5g 33%<br/>할인 안 하고 제 돈 주고 사 먹어도<br/>홍차 티백과 함께 밀크티도 만들어 먹어서<br/>홍차 티백과 함께 밀크티를<br/>" 
---

gha: HTML, lang: shell
FROM continuumio/anaconda3:5.0.1

# install sys requirements
RUN apt-get update
RUN apt-get install -y build-essential git

# clone in repo
RUN git clone https://github.com/{{cookiecutter.github_user_name}}/{{cookiecutter.github_project_name}}

# update conda
RUN conda update --yes conda

# go into repo
RUN cd {{cookiecutter.github_project_name}} && conda env create -f {{cookiecutter.package_name}}-dev-requirements.yml

# activate
RUN echo "source activate {{cookiecutter.package_name}}-dev-requirements" > ~/.bash
ENV PATH /opt/conda/envs/{{cookiecutter.package_name}}-dev-requirements/bin:$PATH

# activate
#RUN conda activate {{cookiecutter.github_project_name}}-dev-requirements

# make build dir
RUN cd {{cookiecutter.github_project_name}} && mkdir build

# run cmake
RUN  cd {{cookiecutter.github_project_name}}/build && \
    cmake .. -DCMAKE_INSTALL_PREFIX=$(conda info --base)/envs/{{cookiecutter.github_project_name}}-dev-requirements

# build and install project
RUN cd {{cookiecutter.github_project_name}}/build && \
    make -j2 install
gha: CMake, lang: dockerfile
# PlanDetails

## Properties

Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**BaseFeeMonthly** | **int64** | BaseFeeMonthly is the monthly base fee for the plan. | 
**BaseFeeYearly** | **int64** | BaseFeeYearly is the yearly base fee for the plan. | 
**Custom** | **bool** | Custom is true if the plan is custom. This means it will be hidden from the pricing page. | 
**Description** | **string** | Description is the description of the plan. | 
**Features** | [**map[string]GenericUsage**](GenericUsage.md) | Features are the feature definitions included in the plan. | 
**Name** | **string** | Name is the name of the plan. | 
**Version** | **int64** | Version is the version of the plan. The combination of &#x60;name@version&#x60; must be unique. | 

## Methods

### NewPlanDetails

`func NewPlanDetails(baseFeeMonthly int64, baseFeeYearly int64, custom bool, description string, features map[string]GenericUsage, name string, version int64, ) *PlanDetails`

NewPlanDetails instantiates a new PlanDetails object
This constructor will assign default values to properties that have it defined,
and makes sure properties required by API are set, but the set of arguments
will change when the set of required properties is changed

### NewPlanDetailsWithDefaults

`func NewPlanDetailsWithDefaults() *PlanDetails`

NewPlanDetailsWithDefaults instantiates a new PlanDetails object
This constructor will only assign default values to properties that have it defined,
but it doesn't guarantee that properties required by API are set

### GetBaseFeeMonthly

`func (o *PlanDetails) GetBaseFeeMonthly() int64`

GetBaseFeeMonthly returns the BaseFeeMonthly field if non-nil, zero value otherwise.

### GetBaseFeeMonthlyOk

`func (o *PlanDetails) GetBaseFeeMonthlyOk() (*int64, bool)`

GetBaseFeeMonthlyOk returns a tuple with the BaseFeeMonthly field if it's non-nil, zero value otherwise
and a boolean to check if the value has been set.

### SetBaseFeeMonthly

`func (o *PlanDetails) SetBaseFeeMonthly(v int64)`

SetBaseFeeMonthly sets BaseFeeMonthly field to given value.


### GetBaseFeeYearly

`func (o *PlanDetails) GetBaseFeeYearly() int64`

GetBaseFeeYearly returns the BaseFeeYearly field if non-nil, zero value otherwise.

### GetBaseFeeYearlyOk

`func (o *PlanDetails) GetBaseFeeYearlyOk() (*int64, bool)`

GetBaseFeeYearlyOk returns a tuple with the BaseFeeYearly field if it's non-nil, zero value otherwise
and a boolean to check if the value has been set.

### SetBaseFeeYearly

`func (o *PlanDetails) SetBaseFeeYearly(v int64)`

SetBaseFeeYearly sets BaseFeeYearly field to given value.


### GetCustom

`func (o *PlanDetails) GetCustom() bool`

GetCustom returns the Custom field if non-nil, zero value otherwise.

### GetCustomOk

`func (o *PlanDetails) GetCustomOk() (*bool, bool)`

GetCustomOk returns a tuple with the Custom field if it's non-nil, zero value otherwise
and a boolean to check if the value has been set.

### SetCustom

`func (o *PlanDetails) SetCustom(v bool)`

SetCustom sets Custom field to given value.


### GetDescription

`func (o *PlanDetails) GetDescription() string`

GetDescription returns the Description field if non-nil, zero value otherwise.

### GetDescriptionOk

`func (o *PlanDetails) GetDescriptionOk() (*string, bool)`

GetDescriptionOk returns a tuple with the Description field if it's non-nil, zero value otherwise
and a boolean to check if the value has been set.

### SetDescription

`func (o *PlanDetails) SetDescription(v string)`

SetDescription sets Description field to given value.


### GetFeatures

`func (o *PlanDetails) GetFeatures() map[string]GenericUsage`

GetFeatures returns the Features field if non-nil, zero value otherwise.

### GetFeaturesOk

`func (o *PlanDetails) GetFeaturesOk() (*map[string]GenericUsage, bool)`

GetFeaturesOk returns a tuple with the Features field if it's non-nil, zero value otherwise
and a boolean to check if the value has been set.

### SetFeatures

`func (o *PlanDetails) SetFeatures(v map[string]GenericUsage)`

SetFeatures sets Features field to given value.


### GetName

`func (o *PlanDetails) GetName() string`

GetName returns the Name field if non-nil, zero value otherwise.

### GetNameOk

`func (o *PlanDetails) GetNameOk() (*string, bool)`

GetNameOk returns a tuple with the Name field if it's non-nil, zero value otherwise
and a boolean to check if the value has been set.

### SetName

`func (o *PlanDetails) SetName(v string)`

SetName sets Name field to given value.


### GetVersion

`func (o *PlanDetails) GetVersion() int64`

GetVersion returns the Version field if non-nil, zero value otherwise.

### GetVersionOk

`func (o *PlanDetails) GetVersionOk() (*int64, bool)`

GetVersionOk returns a tuple with the Version field if it's non-nil, zero value otherwise
and a boolean to check if the value has been set.

### SetVersion

`func (o *PlanDetails) SetVersion(v int64)`

SetVersion sets Version field to given value.



[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)



gha: C#, lang: markdown
#include <XLib.Vectors.Math.h>
#include <XLib.System.File.h>
#include <XEngine.Render.Device.h>
#include <XEngine.Render.Vertices.h>

#include "XEngine.Core.GeometryResource.h"

#include "XEngine.Core.Engine.h"

using namespace XLib;
using namespace XEngine::Core;
using namespace XEngine::Render;

/*GeometryResource::~GeometryResource()
{

}

bool GeometryResource::Create(const CreationArgs& args, CreationTask& task)
{
	switch (args.type)
	{
		case CreationType::Cube:

			break;

		case CreationType::CubicSphere:

			break;

		case CreationType::FromFile:

			break;

		default:
			// TODO: log warning
			return false;
	}
}

bool GeometryResource::CreationTask::cancel()
{

}*/

#pragma pack(push, 1)
class XEGeometryFile abstract final
{
public:
	static constexpr uint32 Magic = 0xAABBCCDD; // TODO: replace
	static constexpr uint16 SupportedVersion = 1;

	struct Header
	{
		uint32 magic;
		uint16 version;
		uint16 vertexStride;
		uint32 vertexCount;
		uint32 indexCount;
	};
};
#pragma pack(pop)

bool GeometryResource::createFromFile(const char* filename)
{
	File file;
	if (!file.open(filename, FileAccessMode::Read))
		return false;

	XEGeometryFile::Header header;
	if (!file.read(header))
		return false;

	if (header.magic != XEGeometryFile::Magic ||
		header.version != XEGeometryFile::SupportedVersion)
	{
		return false;
	}

	uint64 expectedFileSize = uint64(header.vertexStride) * uint64(header.vertexCount) +
		uint64(header.indexCount) * sizeof(uint32) + sizeof(header);
	if (expectedFileSize != file.getSize())
		return false;

	uint32 verticesSize = header.vertexCount * header.vertexStride;
	uint32 indicesSize = header.indexCount * 4;

	HeapPtr<byte> vertices(verticesSize);
	if (!file.read(vertices, verticesSize))
		return false;

	HeapPtr<uint32> indices(header.indexCount);
	if (!file.read(indices, indicesSize ))
		return false;

	vertexCount = header.vertexCount;
	indexCount = header.indexCount;
	vertexStride = uint8(header.vertexStride);
	indexIs32Bit = true;

	Render::Device& renderDevice = Engine::GetRenderDevice();
	buffer = renderDevice.createBuffer(verticesSize + indicesSize);
	renderDevice.updateBuffer(buffer, 0, vertices, verticesSize);
	renderDevice.updateBuffer(buffer, verticesSize, indices, indicesSize);

	return true;
}

void GeometryResource::createCube()
{
	static VertexBase vertices[] =
	{
		{ { -1.0f, -1.0f, -1.0f }, { 0.0f, 0.0f, -1.0f } },
		{ {  1.0f,  1.0f, -1.0f }, { 0.0f, 0.0f, -1.0f } },
		{ {  1.0f, -1.0f, -1.0f }, { 0.0f, 0.0f, -1.0f } },
		{ { -1.0f,  1.0f, -1.0f }, { 0.0f, 0.0f, -1.0f } },

		{ { -1.0f, -1.0f,  1.0f }, { 0.0f, 0.0f, 1.0f } },
		{ {  1.0f,  1.0f,  1.0f }, { 0.0f, 0.0f, 1.0f } },
		{ {  1.0f, -1.0f,  1.0f }, { 0.0f, 0.0f, 1.0f } },
		{ { -1.0f,  1.0f,  1.0f }, { 0.0f, 0.0f, 1.0f } },

		{ { -1.0f,  1.0f, -1.0f }, { 0.0f, 1.0f, 0.0f } },
		{ {  1.0f,  1.0f,  1.0f }, { 0.0f, 1.0f, 0.0f } },
		{ { -1.0f,  1.0f,  1.0f }, { 0.0f, 1.0f, 0.0f } },
		{ {  1.0f,  1.0f, -1.0f }, { 0.0f, 1.0f, 0.0f } },

		{ { -1.0f, -1.0f, -1.0f }, { 0.0f, -1.0f, 0.0f } },
		{ {  1.0f, -1.0f,  1.0f }, { 0.0f, -1.0f, 0.0f } },
		{ {  1.0f, -1.0f, -1.0f }, { 0.0f, -1.0f, 0.0f } },
		{ { -1.0f, -1.0f,  1.0f }, { 0.0f, -1.0f, 0.0f } },

		{ { -1.0f, -1.0f, -1.0f }, { -1.0f, 0.0f, 0.0f } },
		{ { -1.0f,  1.0f,  1.0f }, { -1.0f, 0.0f, 0.0f } },
		{ { -1.0f, -1.0f,  1.0f }, { -1.0f, 0.0f, 0.0f } },
		{ { -1.0f,  1.0f, -1.0f }, { -1.0f, 0.0f, 0.0f } },

		{ {  1.0f, -1.0f, -1.0f }, { 1.0f, 0.0f, 0.0f } },
		{ {  1.0f,  1.0f,  1.0f }, { 1.0f, 0.0f, 0.0f } },
		{ {  1.0f,  1.0f, -1.0f }, { 1.0f, 0.0f, 0.0f } },
		{ {  1.0f, -1.0f,  1.0f }, { 1.0f, 0.0f, 0.0f } },
	};

	static uint16 indices[] =
	{
		 0,  1,  2,
		 0,  3,  1,

		 4,  6,  5,
		 4,  5,  7,

		 8, 10,  9,
		 8,  9, 11,

		12, 14, 13,
		12, 13, 15,

		16, 18, 17,
		16, 17, 19,

		20, 22, 21,
		20, 21, 23,
	};

	vertexCount = countof(vertices);
	indexCount = countof(indices);
	vertexStride = sizeof(VertexBase);
	indexIs32Bit = false;

	Render::Device& renderDevice = Engine::GetRenderDevice();
	buffer = renderDevice.createBuffer(sizeof(vertices) + sizeof(indices));
	renderDevice.updateBuffer(buffer, 0, vertices, sizeof(vertices));
	renderDevice.updateBuffer(buffer, sizeof(vertices), indices, sizeof(indices));
}

void GeometryResource::createPlane_texture()
{
	static VertexTexture vertices[] =
	{
		{ { -1.0f, -1.0f, 0.0f },	{ 0.0f, 0.0f, 1.0f },	{ 0.0f, 0.0f } },
		{ { 1.0f, 1.0f, 0.0f },		{ 0.0f, 0.0f, 1.0f },	{ 1.0f, 1.0f } },
		{ { -1.0f, 1.0f, 0.0f },	{ 0.0f, 0.0f, 1.0f },	{ 0.0f, 1.0f } },
		{ { 1.0f, -1.0f, 0.0f },	{ 0.0f, 0.0f, 1.0f },	{ 1.0f, 0.0f } },
	};

	static uint16 indices[] =
	{
		0, 1, 2,
		0, 3, 1,
	};

	vertexCount = countof(vertices);
	indexCount = countof(indices);
	vertexStride = sizeof(VertexTexture);
	indexIs32Bit = false;

	Render::Device& renderDevice = Engine::GetRenderDevice();
	buffer = renderDevice.createBuffer(sizeof(vertices) + sizeof(indices));
	renderDevice.updateBuffer(buffer, 0, vertices, sizeof(vertices));
	renderDevice.updateBuffer(buffer, sizeof(vertices), indices, sizeof(indices));
}

void GeometryResource::createPlane_tangentTexture()
{
	static VertexTangentTexture vertices[] =
	{
		{ { -1.0f, -1.0f, 0.0f },	{ 0.0f, 0.0f, 1.0f },	{ 1.0f, 0.0f, 0.0f },	{ 0.0f, 0.0f } },
		{ { 1.0f, 1.0f, 0.0f },		{ 0.0f, 0.0f, 1.0f },	{ 1.0f, 0.0f, 0.0f },	{ 1.0f, 1.0f } },
		{ { -1.0f, 1.0f, 0.0f },	{ 0.0f, 0.0f, 1.0f },	{ 1.0f, 0.0f, 0.0f },	{ 0.0f, 1.0f } },
		{ { 1.0f, -1.0f, 0.0f },	{ 0.0f, 0.0f, 1.0f },	{ 1.0f, 0.0f, 0.0f },	{ 1.0f, 0.0f } },
	};

	static uint16 indices[] =
	{
		0, 1, 2,
		0, 3, 1,
	};

	vertexCount = countof(vertices);
	indexCount = countof(indices);
	vertexStride = sizeof(VertexTangentTexture);
	indexIs32Bit = false;

	Render::Device& renderDevice = Engine::GetRenderDevice();
	buffer = renderDevice.createBuffer(sizeof(vertices) + sizeof(indices));
	renderDevice.updateBuffer(buffer, 0, vertices, sizeof(vertices));
	renderDevice.updateBuffer(buffer, sizeof(vertices), indices, sizeof(indices));
}

void GeometryResource::createCubicSphere(uint32 detalizationLevel)
{
	// TODO: check max detalization value

	uint16 quadsPerEdge = uint16(detalizationLevel) + 1;
	uint16 vertexPerEdge = quadsPerEdge + 1;
	uint16 vertexPerFace = sqr(vertexPerEdge);
	uint16 indexPerFace = sqr(quadsPerEdge) * 6;

	HeapPtr<byte> temp((sizeof(VertexBase) * vertexPerFace + sizeof(uint16) * indexPerFace) * 6);
	VertexBase *vertexBuffer = to<VertexBase*>(temp);
	uint16 *indexBuffer = to<uint16*>(vertexBuffer + vertexPerFace * 6);

	// Vertices generation
	{
		VertexBase *faceVertices[6];
		for (uint16 i = 0; i < 6; i++)
			faceVertices[i] = vertexBuffer + i * vertexPerFace;

		for (uint16 row = 0; row < vertexPerEdge; row++)
		{
			for (uint16 column = 0; column < vertexPerEdge; column++)
			{
				float32x3 flatPosition =
				{
					1.0f,
					lerp(-1.0f, 1.0f, column, quadsPerEdge),
					lerp(-1.0f, 1.0f, row, quadsPerEdge)
				};

				float32x3 p = VectorMath::Normalize(flatPosition);
				uint16 offset = row * vertexPerEdge + column;
				faceVertices[0][offset].normal = faceVertices[0][offset].position = { -p.x,  p.y,  p.z };
				faceVertices[1][offset].normal = faceVertices[1][offset].position = {  p.x, -p.y,  p.z };
				faceVertices[2][offset].normal = faceVertices[2][offset].position = {  p.y,  p.x,  p.z };
				faceVertices[3][offset].normal = faceVertices[3][offset].position = { -p.y, -p.x,  p.z };
				faceVertices[4][offset].normal = faceVertices[4][offset].position = {  p.z,  p.y,  p.x };
				faceVertices[5][offset].normal = faceVertices[5][offset].position = {  p.z, -p.y, -p.x };
			}
		}
	}

	// Indices generation
	for (uint16 face = 0; face < 6; face++)
	{
		uint16 *faceIndices = indexBuffer + face * indexPerFace;

		for (uint16 row = 0; row < quadsPerEdge; row++)
		{
			for (uint16 column = 0; column < quadsPerEdge; column++)
			{
				uint16 leftTop = vertexPerFace * face + row * vertexPerEdge + column;
				uint16 leftBottom = leftTop + vertexPerEdge;
				uint16 rightTop = leftTop + 1;
				uint16 rightBottom = leftBottom + 1;

				uint16 *quadIndices = &faceIndices[(row * quadsPerEdge + column) * 6];
				quadIndices[0] = leftTop;
				quadIndices[1] = leftBottom;
				quadIndices[2] = rightTop;
				quadIndices[3] = rightBottom;
				quadIndices[4] = rightTop;
				quadIndices[5] = leftBottom;
			}
		}
	}

	vertexCount = vertexPerFace * 6;
	indexCount = indexPerFace * 6;
	vertexStride = sizeof(VertexBase);
	indexIs32Bit = false;

	uint32 verticesSize = vertexCount * sizeof(VertexBase);
	uint32 indicesSize = indexCount * sizeof(uint16);

	Render::Device& renderDevice = Engine::GetRenderDevice();
	buffer = renderDevice.createBuffer(verticesSize + indicesSize);
	renderDevice.updateBuffer(buffer, 0, vertexBuffer, verticesSize);
	renderDevice.updateBuffer(buffer, verticesSize, indexBuffer, indicesSize);
}
gha: C++, lang: cpp
﻿using DataCore.Model;
using MongoDB.Bson;
using MongoDB.Bson.Serialization.Attributes;

namespace MongoService.Models
{
    public class MongodbBattery
    {
        [BsonId]
        public ObjectId InternalId { get; set; }
        public long Id { get; set; }

        public long Timestamp { get; set; }

        public int Level { get; set; }

        public float Temperature { get; set; }

        public MongodbBattery()
        {
        }
        public MongodbBattery(Battery b)
        {
            Id = b.Id;
            Timestamp = b.Timestamp;
            Level = b.Level;
            Temperature = b.Temperature;
        }
    }
}

gha: C#, lang: c_sharp
# store-api
Create API together!

Some code refactoring done; 
Added nodemon, dotenv, morgan, prettier to dependencies; 
Added orders, products, categories routes and handlers; 
Added catchAsync for further db queries; 
Added simple AppError class for handling exceptions; 
Implemented simlpe IO for some routes (req.params.id and req.body)"

gha: JavaScript, lang: ini
/**********************************************************/
/* Lesson4 - MySquare.cpp                                 */
/* 関数をDLLに分離してみよう                              */
/**********************************************************/
//#define MYSQUARE_EXPORTS

#include "MySquare.h"

//
// mySquareメソッドの定義
//
int __stdcall mySquare(int in_val)
{
	return (in_val * in_val * in_val);      // ver1.0
	//return (in_val * in_val);             // ver1.1(bug fix)
}

gha: C++, lang: cpp
import { toAscii, fromAscii } from 'web3-utils'
import expectRevert from '../helpers/expectRevert'
import expectEvent from '../helpers/expectEvent'
import { encodeCall } from 'zos-lib'

const BasicOracle = artifacts.require('BasicOracleMock')

require('chai').should()

const RESULT = 'hello oracle'

contract('BasicOracle', (accounts) => {
  const dataSource = accounts[1]

  let oracle
  beforeEach(async ()=> {
    oracle = await BasicOracle.new(dataSource)
  })

  it('can set result by owner', async () => {
    await oracle.setResult(RESULT, { from: dataSource })

    const result = await oracle.resultFor(0)
    toAscii(result).replace(/\u0000/g, '').should.equal(RESULT)

    const isResultSet = await oracle.isResultSet(0)
    isResultSet.should.equal(true)
  })

  it('cannot be set by a different data source', async () => {
    await expectRevert(oracle.setResult(RESULT, { from: accounts[2] }))

    const isResultSet = await oracle.isResultSet(0)
    isResultSet.should.equal(false)
  })

  it('cannot be set twice', async () => {
    await oracle.setResult(RESULT, { from: dataSource })
    await expectRevert(oracle.setResult(RESULT, { from: dataSource }))
  })

  it('should emit ResultSet event', async () => {
    const bytes32Result = fromAscii(RESULT)
    await expectEvent.inTransaction(
      oracle.setResult(RESULT, { from: dataSource }),
      'ResultSet',
      { _result: bytes32Result, _sender: dataSource }
    )
  })
})

gha: Solidity, lang: javascript
---
title: "lkjijioj"
date: "01/01/2019"
slug: "/guides/handbook/add-edit"
---

👆 slug = where in the table of contents should this content be placed

**Replace the text in the following paragraphs with your text.**

## Content

**Add page content in [markdown format](https://guides.github.com/features/mastering-markdown/) here**

# lkjijioj

gha: JavaScript, lang: markdown
---
layout: post 
title:  "블랙야크 워크웨어 다용도 힙색, 블랙" 
description: 블랙야크 워크웨어 다용도 힙 ..
date: 2023-05-30 11:43:10+0900 
img: https://image5.coupangcdn.com/image/rs_quotation_api/1zdhfr3n/bbf6a3aea87c4bc3bf8c60f8a2da6d84.jpg 
linkUrl: https://link.coupang.com/re/AFFSDP?lptag=AF3600438&subid=ahnPublicAsk&pageKey=5408673264&itemId=8126333812&vendorItemId=75414599390&traceid=V0-113-31cac9105dcefc23 
categories: [1002] 
color: BF360C 
price: 19900 
author: Ask View Shop 
---
 
gha: HTML, lang: yaml
[Profile]
Device = evdev/0/Microsoft X-Box 360 pad
Buttons/A = `Button 0`
Buttons/B = `Button 1`
Buttons/1 = `Button 2`
Buttons/2 = `Button 3`
Buttons/- = `Button 6`
Buttons/+ = `Button 7`
Buttons/Home = !`Alt_L` & Return
IR/Up = `Axis 1-`
IR/Down = `Axis 1-+`
IR/Left = `Axis 0-`
IR/Right = `Axis 0+`
Shake/X = Click 2
Shake/Y = Click 2
Shake/Z = Click 2
Extension = Classic
Nunchuk/Buttons/C = Control_L
Nunchuk/Buttons/Z = Shift_L
Nunchuk/Stick/Up = W
Nunchuk/Stick/Down = S
Nunchuk/Stick/Left = A
Nunchuk/Stick/Right = D
Classic/Buttons/A = `Button 0`
Classic/Buttons/B = `Button 1`
Classic/Buttons/X = `Button 2`
Classic/Buttons/Y = `Button 3`
Classic/Buttons/ZL = `Button 4`
Classic/Buttons/ZR = `Button 5`
Classic/Buttons/- = `Button 6`
Classic/Buttons/+ = `Button 7`
Classic/Buttons/Home = `Button 8`
Classic/Left Stick/Up = `Axis 1-`
Classic/Left Stick/Down = `Axis 1+`
Classic/Left Stick/Left = `Axis 0-`
Classic/Left Stick/Right = `Axis 0+`
Classic/Left Stick/Modifier = `Button 9`
Classic/Right Stick/Up = `Axis 4-`
Classic/Right Stick/Down = `Axis 4-+`
Classic/Right Stick/Left = `Axis 3-`
Classic/Right Stick/Right = `Axis 3+`
Classic/Right Stick/Modifier = `Button 10`
Classic/Triggers/L = `Axis 2-+`
Classic/Triggers/R = `Axis 5-+`
Classic/Triggers/L-Analog = `Axis 2-+`
Classic/Triggers/R-Analog = `Axis 5-+`
Classic/D-Pad/Up = `Axis 7-`
Classic/D-Pad/Down = `Axis 7+`
Classic/D-Pad/Left = `Axis 6-`
Classic/D-Pad/Right = `Axis 6+`
D-Pad/Up = `Axis 7-`
D-Pad/Down = `Axis 7+`
D-Pad/Left = `Axis 6-`
D-Pad/Right = `Axis 6+`

gha: Shell, lang: markdown
<?php

namespace App\Http\Controllers\Access;

use App\Http\Controllers\Controller;
use App\Models\User;
use Illuminate\Http\Request;
use App\Exceptions\InvalidRequestException;
use DataTables;
use Validator;
use Spatie\Permission\Models\Role;
use DB;

class UserController extends Controller
{
    public function index(){
        return view('access.user.index');
    }

    public function tableGet(){
        $userList  = User::select('*')->with('roles');
        return DataTables::of($userList)
            ->editColumn('roles', function ($list) {
                return $list->roles->pluck('name')->toArray();
            })
            ->make(true);        
    }

    public function store(Request $request){
        $validator = Validator::make($request->all(), [
            'name' => 'bail|required|string|max:255',
            'email' => 'required|string|email|max:255|unique:users',
            'password' => 'required|string|min:6',
        ]);
        if($validator->fails()){
            $errors = $validator->errors()->toArray();
            $errors = array_reduce($errors, function($carry, $item){ return $carry.$item[0].'<br>';  },'' );
            throw new InvalidRequestException($errors);
        }
        User::create([
            'name' => $request->input('name'),
            'email' => $request->input('email'),
            'password' => bcrypt($request->input('password') ),
        ]);
        return ['code'=>200,'msg'=>'添加成功'];
    }

    public function edit($id){
        $user  = User::find($id);
        if(empty($user)){
            return redirect()->route('access.user.index')->withFlashWarning('此角色不存在');
        }
        $roles     = $user->roles->pluck('id')->toArray();
        $all_roles = Role::query()->get()->toArray();
        return view('access.user.edit',compact('user','roles','all_roles'));
    }

    public function delete(Request $request){
        $id   = $request->input('id');
        DB::transaction(function ()use($id) {
            $user = User::find($id);
            $user->roles()->detach();
            $user->delete();

        });
        return ['code'=>200,'msg'=>'删除成功']; 
    }

    public function update(Request $request){
        $this->validate($request, [
            'name'    => 'required|max:255',
            'roles'   => 'required',
        ]);
        $name        = $request->input('name');
        $roles       = $request->input('roles');
        $id          = $request->input('id');
        try {
            $user    = User::find($id);
            $user->name  =  $name;
            $user->save();
    
            $user->roles()->sync($roles);
        }catch (\Exception $ex) {
            throw new InvalidRequestException($ex->getMessage());
        }
        return redirect()->route('access.user.index')->withFlashSuccess('操作成功');
    }
}

gha: HTML, lang: php
<template>
  <v-dialog v-model="dialog" persistent width="430">
    <!-- 背包 -->
    <v-card>
      <v-card-title>
        Choose your seed to plant
      </v-card-title>

      <Repository class="mx-4" @selected="doSowing"></Repository>

      <v-card-actions>
        <v-spacer> </v-spacer>
        <v-btn color="primary" @click="dialog = false"> close </v-btn>
      </v-card-actions>
    </v-card>
  </v-dialog>
</template>

<script>
import Dapp from "@/util/pixfarmon-dapp";
import { mapState } from "vuex";
import { indexToCoor } from "@/util";
import Repository from "../repository.vue";

export default {
  components: { Repository },
  data() {
    return {
      dialog: false,
      field: -1,
      repository: []
    };
  },
  methods: {
    sowing(fieldIndex) {
      this.field = fieldIndex;
      this.dialog = true;
    },
    doSowing(item) {
      this.$debug(item);
      const { x, y } = indexToCoor(this.field);
      this.$log(x, y);
      const { itemTag } = item;
      Dapp.field.sowing(this.address, { x, y, seedTag: itemTag }, error => {
        this.$log("Sowing:", itemTag);
        if (error) {
          this.$error(error);
        } else {
          this.$log("Success");
        }
      });
    },
    updateRepository() {
      Dapp.repository.getItemList(
        this.address,
        { type: 0, user: this.address, target: this.address },
        (err, list) => {
          if (err) {
            this.$error(err);
          } else {
            this.$log(list);
          }
        }
      );
    }
  },
  computed: {
    ...mapState("account", {
      address: state => state.address
    })
  }
};
</script>

<style></style>

gha: Vue, lang: javascript
//drivers...SIMULAUNCHER

#include "ButtonDriver.hpp"

using namespace std;

AButtonDriver * AButtonDriver::create()
{
	return new ButtonDriver();
}

ButtonDriver::ButtonDriver()
{

}

ButtonDriver::~ButtonDriver()
{
}

bool ButtonDriver::pressed(ButtonTouch button)
{
	switch (button)
	{
	case BUTTON_ENTER_KEY:
		break;
	case BUTTON_BACK_KEY:
			break;
	case BUTTON_UP_KEY:
			break;
	case BUTTON_DOWN_KEY:
			break;
	case BUTTON_LEFT_KEY:
			break;
	case BUTTON_RIGHT_KEY:
			break;
	}

	return 0;
}

gha: C++, lang: cpp
#include "TestHelpers.h"
#include "TestOutput.h"
#include "TSystem.h"
#include "TList.h"
#include "TRegexp.h"
#include "TObjString.h"
#include <utility>

void fillListOfDir(TList &l) {
   
   TString directory = ".";
   void *dir = gSystem->OpenDirectory(directory);

   const char *file = 0;
   if (dir) {

      //create a TList to store the file names (not yet sorted)
      TString basename = ".-..-..";
      TRegexp re(basename,kFALSE);

      while ((file = gSystem->GetDirEntry(dir))) {
         if (!strcmp(file,".") || !strcmp(file,"..")) continue;
         // Skip 'latest' as it is a symlink
         if (strcmp(file,"latest")==0) continue;

         TString s = file;
//          cout << "found the directory " << file << endl;
         if ( (basename!=file) && s.Index(re) == kNPOS) continue;

         TString vfile = gSystem->ConcatFileName(file,"vector.root");
         if (gSystem->GetPathInfo(vfile,(Long_t*)0,(Long_t*)0,(Long_t*)0,0)==0) {
//             cout << "found vector in " << file << endl;
            l.Add(new TObjString(file));
         } else {
//             cout << "did not find vector in " << file << endl;
         }

      }
      gSystem->FreeDirectory(dir);

      //sort the files in alphanumeric order
      l.Sort();

      TIter next(&l);
      TObjString *obj;
      while ((obj = (TObjString*)next())) {
         file = obj->GetName();
//          cout << "found the directory " << obj->GetName() << endl;
      }
   }
}
#ifdef __MAKECINT__
#pragma link C++ function DebugTest;
//#pragma link C++ class pair<float,int>+;
//#pragma link C++ class pair<std::string,double>+;'
//#pragma create TClass pair<std::string,double>+;
#pragma link C++ class GHelper<float>+;
#pragma link C++ class GHelper<GHelper<float> >+;
#pragma link C++ class GHelper<GHelper<GHelper<float> > >+;
#endif

gha: C++, lang: cpp
export default '2.1.1-beta.2'

gha: JavaScript, lang: batchfile
package no.imr.geoexplorer.admindatabase.mybatis.pojo;

public class HovedtemaEnNo {
	private long hovedtemaerId;
	private String title;
	private String alternateTitle; 
	private String abstracts;
	
	public long getHovedtemaerId() {
		return hovedtemaerId;
	}
	public void setHovedtemaerId(long hovedtemaerId) {
		this.hovedtemaerId = hovedtemaerId;
	}
	public String getTitle() {
		return title;
	}
	public void setTitle(String title) {
		this.title = title;
	}
	public String getAlternateTitle() {
		return alternateTitle;
	}
	public void setAlternateTitle(String alternateTitle) {
		this.alternateTitle = alternateTitle;
	}
	public String getAbstracts() {
		return abstracts;
	}
	public void setAbstracts(String abstracts) {
		this.abstracts = abstracts;
	}
}

gha: CSS, lang: groovy
import {
  updateEntry as updateEntryLF
} from '@/api/localforage'

import {
  deleteEntry as deleteEntryFire,
  deleteFile
} from '@/api/firebase'

const namespace = 'gallery'
const rootFolder = 'plants'
const folder = 'gallery'

export async function deleteGalleryItem ({ state, commit, dispatch }, data) {
  commit('DELETE_GALLERY_ITEM_PROGRESS')

  const updated = Date.now()
  await updateEntryLF('updated', updated)

  if (state.storage.type === 'cloud') {
    try {
      const path = [
        ['users', state.user.id],
        [rootFolder, state.plants.selected.guid],
        [folder, data.item.guid]
      ]
      await Promise.all([
        await deleteEntryFire(path),
        await deleteFile(path)
      ])
    } catch (error) {
      commit('DELETE_GALLERY_ITEM_FAILURE')
    }
  } else {
    await updateEntryLF(namespace, state.gallery.data)
    console.warn('GALLERY SHOULD NOT BE STORED LOCALLY') // eslint-disable-line
  }

  if (!state.storage.migrationMode) {
    commit('DELETE_GALLERY_ITEM_SUCCESS', data)
    dispatch('updateGalleryModule', {
      guid: data.guid,
      item: data.item.guid,
      type: 'delete'
    })
  }
}

gha: Vue, lang: javascript
import React, { useState } from "react";
import ReactDOM from "react-dom";
const equalities = [
  true,
  false,
  1,
  0,
  -1,
  "true",
  "false",
  "1",
  "0",
  "-1",
  "",
  null,
  undefined,
  Infinity,
  -Infinity,
  [],
  {},
  [[]],
  [0],
  [1],
  NaN,
];
function App() {
  const [selectedItem, setSelectedItem] = useState("");
  const table = (strictEquality: boolean = false) => {
    const table = [];
    for (let i = 0; i < equalities.length; i++) {
      for (let j = 0; j < equalities.length; j++) {
        table.push(
          <div
            className={`${selectedItem === equalities[i]}`}
            style={{
              width: 10,
              height: 10,
              border: "1px solid gray",
              backgroundColor: strictEquality
                ? equalities[i] === equalities[j]
                  ? "dodgerblue"
                  : "white"
                : equalities[i] == equalities[j]
                ? "dodgerblue"
                : "white",
            }}
          ></div>
        );
      }
    }
    return (
      <>
        <div
          style={{
            display: "grid",
            width: 450,
            padding: 10,
            gridTemplateColumns: `repeat(${equalities.length}, 1fr)`,
          }}
        >
          {equalities.map((eq) => {
            return (
              <span
                style={{ writingMode: "vertical-lr", textAlign: "right" }}
              >{`${eq}`}</span>
            );
          })}
        </div>
        <div>
          <div
            style={{
              display: "grid",
              gridTemplateColumns: `repeat(${equalities.length}, 1fr)`,
              gap: 10,
              border: "1px solid gray",
              padding: 10,
              width: 450,
            }}
          >
            {table}
          </div>
        </div>
      </>
    );
  };

  return (
    <div
      style={{
        display: "flex",
        flexDirection: "column",
        justifyContent: "space-around",
        alignItems: "center",
        height: "100vh",
      }}
    >
      {table()}
      {table(true)}
    </div>
  );
}

ReactDOM.render(<App />, document.querySelector("#root"));

gha: CSS, lang: javascript
## About entity-framework

The ADO.NET Entity Framework is a set of Object-Relational-Mapping (ORM) tools for the .NET Framework, since version 3.5 SP1.

The [ADO.NET Entity Framework](http://en.wikipedia.org/wiki/ADO.NET_Entity_Framework) (EF) is .NET's built-in Object-Relational Mapping (ORM) tool that enables .NET developers to work with relational data using domain-specific objects. It eliminates the need for most of the data-access code that developers usually need to write. Either natively or through third-party libraries, it supports most major RDBM products including SQL Server, MySQL, Oracle, PostgreSQL and SQLite. It also supports Microsoft's "LINQ" syntax and lambda-expressions via the [LINQ to Entities](http://en.wikipedia.org/wiki/ADO.NET_Entity_Framework#LINQ_to_Entities) library.

Visual Studio provides design-time support for EF. It includes GUI tools for model-to-database and database-to-model generation. The .NET [Text Template Transformation Toolkit](http://en.wikipedia.org/wiki/Text_Template_Transformation_Toolkit) (T4) or text-templating libraries are leveraged to generate entity classes, and this code generation is customizable in various ways from within Visual Studio.

### Initial Release:

`August 11, 2008`

### Stable Release:

`6.1.3` (March 10, 2015)

### References

*   [Entity Framework on MSDN](http://msdn.com/data/ef)
*   [Entity Framework API Reference](https://msdn.microsoft.com/en-us/library/dn223258.aspx)
*   [Entity Framework Source Code on Codeplex](http://entityframework.codeplex.com)

### Books

*   [Programming EF, 2nd ed.](http://rads.stackoverflow.com/amzn/click/0596807260)
*   [Programming EF: Code First](http://rads.stackoverflow.com/amzn/click/1449312942)
*   [EF 4.0 Recipes: A Problem-Solution Approach](http://rads.stackoverflow.com/amzn/click/1430227036)

Code Language (used for [syntax highlighting](http://google-code-prettify.googlecode.com/svn/trunk/README.html)): default

  default
gha: JavaScript, lang: markdown
<!-- Default home page -->
KEEP ALIVE

gha: JavaScript, lang: batchfile
[Uno.Compiler.UxGenerated]
public partial class LordsPrayerContemporary: Fuse.Controls.WrapPanel
{
    static LordsPrayerContemporary()
    {
    }
    [global::Uno.UX.UXConstructor]
    public LordsPrayerContemporary()
    {
        InitializeUX();
    }
    void InitializeUX()
    {
        var temp = new global::iphod.Regular();
        var temp1 = new global::iphod.Regular();
        var temp2 = new global::iphod.Regular();
        var temp3 = new global::iphod.Regular();
        var temp4 = new global::iphod.Regular();
        var temp5 = new global::iphod.Regular();
        var temp6 = new global::Indent();
        this.Margin = float4(5f, 0f, 5f, 0f);
        temp.Value = "Our Father in heaven, hallowed be your Name.";
        temp1.Value = "Your kingdom come, your will be done, on earth as it is in heaven.";
        temp2.Value = "Give us today our daily bread.";
        temp3.Value = "And forgive us our sins as we forgive those who sin against us.";
        temp4.Value = "Save us from the time of trial, and deliver us from evil.";
        temp5.Value = "For the kingdom, the power, and the glory are yours,";
        temp6.Value = "now and forever. Amen";
        this.Children.Add(temp);
        this.Children.Add(temp1);
        this.Children.Add(temp2);
        this.Children.Add(temp3);
        this.Children.Add(temp4);
        this.Children.Add(temp5);
        this.Children.Add(temp6);
    }
}

gha: C++, lang: c_sharp
#include <cstring>
#include <algorithm>
using std::memcpy;

#include <powerslaves.h>

#include "../device.h"

class R4i_Gold_3DS : Flashcart {
    protected:
        static const uint8_t cmdReadFlash[8];
        static const uint8_t cmdEraseFlash[8];
        static const uint8_t cmdWriteByteFlash[8];
        static const uint8_t cmdGetHWRevision[8];
        static const uint8_t cmdWaitFlashBusy[8];

    public:
        virtual bool setup() {
            uint32_t hw_revision;
            // TODO: check chipid?
            powerslaves_sendreceive(NTR, cmdGetHWRevision, 4, (uint8_t*)&hw_revision); // Get HW Revision
            if (hw_revision != 0xA6A6A6A6) return false;

            // Doesn't use any locking or unlocking functions?
            return true;
        }

        virtual void waitFlashBusy() {
            uint8_t state[4];
            while (true) {
                powerslaves_sendreceive(NTR, cmdWaitFlashBusy, 4, state);
                if((state[3] & 1) == 0) break;
            }
        }

        virtual void formatReadCommand(uint8_t *cmdbuf, uint32_t address) {
            memcpy(cmdbuf, cmdReadFlash, 8);
            cmdbuf[1] = (address >> 16) & 0xFF;
            cmdbuf[2] = (address >>  8) & 0xFF;
            cmdbuf[3] = (address >>  0) & 0xFF;
        }

        virtual void formatEraseCommand(uint8_t *cmdbuf, uint32_t address) {
            memcpy(cmdbuf, cmdEraseFlash, 8);
            cmdbuf[1] = (address >> 16) & 0xFF;
            cmdbuf[2] = (address >>  8) & 0xFF;
            cmdbuf[3] = (address >>  0) & 0xFF;
        }

        virtual void formatWriteCommand(uint8_t *cmdbuf, uint32_t address, uint8_t value) {
            memcpy(cmdbuf, cmdWriteByteFlash, 8);
            cmdbuf[1] = (address >> 16) & 0xFF;
            cmdbuf[2] = (address >>  8) & 0xFF;
            cmdbuf[3] = (address >>  0) & 0xFF;
            cmdbuf[4] = value;
        }

        virtual void cleanup() {
            // Nothing needed?
        };
};

const uint8_t R4i_Gold_3DS::cmdReadFlash[8] = {0xA5, 0x00, 0x00, 0x00, 0x00, 0x5A, 0x00, 0x00};
const uint8_t R4i_Gold_3DS::cmdEraseFlash[8] = {0xDA, 0x00, 0x00, 0x00, 0x00, 0xA5, 0x00, 0x00};
const uint8_t R4i_Gold_3DS::cmdWriteByteFlash[8] = {0xDA, 0x00, 0x00, 0x00, 0x00, 0x5A, 0x00, 0x00};
const uint8_t R4i_Gold_3DS::cmdWaitFlashBusy[8] = {0xC0, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00};
const uint8_t R4i_Gold_3DS::cmdGetHWRevision[8] = {0xD1, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00};

R4i_Gold_3DS r4igold3ds;

gha: C++, lang: cpp
#!/bin/sh

if [ "${TERM%%-*}" = "screen" ] || [ "${TERM%%-*}" = "tmux" ]; then
  if [ -n "$TMUX" ]; then
    printf "\033Ptmux;\033\033]4;236;rgb:26/24/23\007\033\\"
    printf "\033Ptmux;\033\033]4;234;rgb:16/18/19\007\033\\"

    printf "\033Ptmux;\033\033]4;235;rgb:1e/1e/1e\007\033\\"
    printf "\033Ptmux;\033\033]4;237;rgb:2e/2a/29\007\033\\"
    printf "\033Ptmux;\033\033]4;239;rgb:3f/39/35\007\033\\"
    printf "\033Ptmux;\033\033]4;241;rgb:53/4a/42\007\033\\"
    printf "\033Ptmux;\033\033]4;243;rgb:68/5c/51\007\033\\"

    printf "\033Ptmux;\033\033]4;244;rgb:7f/70/61\007\033\\"
    printf "\033Ptmux;\033\033]4;245;rgb:7f/70/61\007\033\\"

    printf "\033Ptmux;\033\033]4;228;rgb:ef/df/ae\007\033\\"
    printf "\033Ptmux;\033\033]4;230;rgb:f8/f4/cd\007\033\\"

    printf "\033Ptmux;\033\033]4;229;rgb:fa/ee/bb\007\033\\"
    printf "\033Ptmux;\033\033]4;223;rgb:e6/d4/a3\007\033\\"
    printf "\033Ptmux;\033\033]4;250;rgb:cb/b8/90\007\033\\"
    printf "\033Ptmux;\033\033]4;248;rgb:af/9f/81\007\033\\"
    printf "\033Ptmux;\033\033]4;246;rgb:97/87/71\007\033\\"

    printf "\033Ptmux;\033\033]4;167;rgb:f7/30/28\007\033\\"
    printf "\033Ptmux;\033\033]4;142;rgb:aa/b0/1e\007\033\\"
    printf "\033Ptmux;\033\033]4;214;rgb:f7/b1/25\007\033\\"
    printf "\033Ptmux;\033\033]4;109;rgb:71/95/86\007\033\\"
    printf "\033Ptmux;\033\033]4;175;rgb:c7/70/89\007\033\\"
    printf "\033Ptmux;\033\033]4;108;rgb:7d/b6/69\007\033\\"
    printf "\033Ptmux;\033\033]4;208;rgb:fb/6a/16\007\033\\"

    printf "\033Ptmux;\033\033]4;88;rgb:89/00/09\007\033\\"
    printf "\033Ptmux;\033\033]4;100;rgb:66/62/0d\007\033\\"
    printf "\033Ptmux;\033\033]4;136;rgb:a5/63/11\007\033\\"
    printf "\033Ptmux;\033\033]4;24;rgb:0e/53/65\007\033\\"
    printf "\033Ptmux;\033\033]4;96;rgb:7b/2b/5e\007\033\\"
    printf "\033Ptmux;\033\033]4;65;rgb:35/6a/46\007\033\\"
    printf "\033Ptmux;\033\033]4;130;rgb:9d/28/07\007\033\\"
  else
    printf "\033P\033]4;236;rgb:26/24/23\007\033\\"
    printf "\033P\033]4;234;rgb:16/18/19\007\033\\"

    printf "\033P\033]4;235;rgb:1e/1e/1e\007\033\\"
    printf "\033P\033]4;237;rgb:2e/2a/29\007\033\\"
    printf "\033P\033]4;239;rgb:3f/39/35\007\033\\"
    printf "\033P\033]4;241;rgb:53/4a/42\007\033\\"
    printf "\033P\033]4;243;rgb:68/5c/51\007\033\\"

    printf "\033P\033]4;244;rgb:7f/70/61\007\033\\"
    printf "\033P\033]4;245;rgb:7f/70/61\007\033\\"

    printf "\033P\033]4;228;rgb:ef/df/ae\007\033\\"
    printf "\033P\033]4;230;rgb:f8/f4/cd\007\033\\"

    printf "\033P\033]4;229;rgb:fa/ee/bb\007\033\\"
    printf "\033P\033]4;223;rgb:e6/d4/a3\007\033\\"
    printf "\033P\033]4;250;rgb:cb/b8/90\007\033\\"
    printf "\033P\033]4;248;rgb:af/9f/81\007\033\\"
    printf "\033P\033]4;246;rgb:97/87/71\007\033\\"

    printf "\033P\033]4;167;rgb:f7/30/28\007\033\\"
    printf "\033P\033]4;142;rgb:aa/b0/1e\007\033\\"
    printf "\033P\033]4;214;rgb:f7/b1/25\007\033\\"
    printf "\033P\033]4;109;rgb:71/95/86\007\033\\"
    printf "\033P\033]4;175;rgb:c7/70/89\007\033\\"
    printf "\033P\033]4;108;rgb:7d/b6/69\007\033\\"
    printf "\033P\033]4;208;rgb:fb/6a/16\007\033\\"

    printf "\033P\033]4;88;rgb:89/00/09\007\033\\"
    printf "\033P\033]4;100;rgb:66/62/0d\007\033\\"
    printf "\033P\033]4;136;rgb:a5/63/11\007\033\\"
    printf "\033P\033]4;24;rgb:0e/53/65\007\033\\"
    printf "\033P\033]4;96;rgb:7b/2b/5e\007\033\\"
    printf "\033P\033]4;65;rgb:35/6a/46\007\033\\"
    printf "\033P\033]4;130;rgb:9d/28/07\007\033\\"
  fi
else
  printf "\033]4;236;rgb:26/24/23\033\\"
  printf "\033]4;234;rgb:16/18/19\033\\"

  printf "\033]4;235;rgb:1e/1e/1e\033\\"
  printf "\033]4;237;rgb:2e/2a/29\033\\"
  printf "\033]4;239;rgb:3f/39/35\033\\"
  printf "\033]4;241;rgb:53/4a/42\033\\"
  printf "\033]4;243;rgb:68/5c/51\033\\"

  printf "\033]4;244;rgb:7f/70/61\033\\"
  printf "\033]4;245;rgb:7f/70/61\033\\"

  printf "\033]4;228;rgb:ef/df/ae\033\\"
  printf "\033]4;230;rgb:f8/f4/cd\033\\"

  printf "\033]4;229;rgb:fa/ee/bb\033\\"
  printf "\033]4;223;rgb:e6/d4/a3\033\\"
  printf "\033]4;250;rgb:cb/b8/90\033\\"
  printf "\033]4;248;rgb:af/9f/81\033\\"
  printf "\033]4;246;rgb:97/87/71\033\\"

  printf "\033]4;167;rgb:f7/30/28\033\\"
  printf "\033]4;142;rgb:aa/b0/1e\033\\"
  printf "\033]4;214;rgb:f7/b1/25\033\\"
  printf "\033]4;109;rgb:71/95/86\033\\"
  printf "\033]4;175;rgb:c7/70/89\033\\"
  printf "\033]4;108;rgb:7d/b6/69\033\\"
  printf "\033]4;208;rgb:fb/6a/16\033\\"

  printf "\033]4;88;rgb:89/00/09\033\\"
  printf "\033]4;100;rgb:66/62/0d\033\\"
  printf "\033]4;136;rgb:a5/63/11\033\\"
  printf "\033]4;24;rgb:0e/53/65\033\\"
  printf "\033]4;96;rgb:7b/2b/5e\033\\"
  printf "\033]4;65;rgb:35/6a/46\033\\"
  printf "\033]4;130;rgb:9d/28/07\033\\"
fi

gha: Vim Script, lang: ocaml
//
//     Generated by class-dump 3.5 (64 bit) (Debug version compiled Mar 11 2021 20:53:35).
//
//  Copyright (C) 1997-2019 Steve Nygard.
//

#import <Ozone/OZTransform3DHUDButton.h>

@class TXGlyphToolHUDController;

@interface TXGlyphTransform3DHUDButton : OZTransform3DHUDButton
{
    TXGlyphToolHUDController *_txcontroller;
}

- (struct OZChannelRotation3D *)getRotationChannel:(const shared_ptr_e0e110e1 *)arg1;
- (struct OZChannelScale *)getScaleChannel:(const shared_ptr_e0e110e1 *)arg1;
- (struct OZChannelPosition3D *)getOffsetChannel:(const shared_ptr_e0e110e1 *)arg1;
- (unsigned int)getGlyphSelectionSize;
- (id)controller;
- (void)setController:(id)arg1;
- (void)mouseUp:(id)arg1;
- (void)mouseDragged:(id)arg1;
- (void)mouseDown:(id)arg1;

@end


gha: Objective-C, lang: cpp
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <time.h>

char revertStr[20];
char *strScore;

typedef struct bank{
    char question[120];
    char choiceA[70];
    char choiceB[70];
    char choiceC[70];
    char choiceD[70];
    char answer[5];
}Bank;                                  //Array size for getting questions per level

typedef struct question
{
    char word[1000];
    char answer[5];
}Question;

Bank setEasy[30];
Bank setHard[30];
Bank setMod[30];

Question questionEasy[30];
Question questionHard[30];
Question questionMod[30];


typedef struct score
{
    char level[5];
    char aName[20];
    int  aScore;
    struct score *next;
}score;

score *head = NULL;

void insertScore(char level[5], char aName[20], int aScore){
	score *temp;
	temp=(score *)malloc(sizeof(score));
	strcpy(temp->level, level);
	strcpy(temp->aName, aName);
	temp->aScore = aScore;
	temp->next = head;
	head = temp;
}

void printAll()
{
    score *temp;
    temp = head;
    while(temp)
    {
    	printf("%5s %20s %d",temp->level, temp->aName, temp->aScore);
        printf("\n");
        temp=temp->next;
    }
    printf("\n");
}

void openFileScore(){
	score *user;
	char *level;
	char *aName;
	int score;
	char c;
	int u = 0, p = 0, blank = 0;
	level = (char *)malloc(5);
	aName = (char *)malloc(20);
    FILE *fptr;
	if((fptr=fopen("score.txt","r+"))==NULL){
		printf("Not find%s\n","score.txt");
		return;
	}
	while(1){
		fscanf(fptr,"%s",level);
		fscanf(fptr,"%s",aName);
		fscanf(fptr,"%d",&score);
		if(feof(fptr)) break;
		insertScore(level, aName, score);
	}
	free(level); free(aName);
	fclose(fptr);
}

void writeFileScore(){
	FILE *fptr;
	score *temp;
    temp = head;
    fptr=fopen("score.txt","w+");
    while(temp){
    	fprintf(fptr, "%s %s %d", temp->level, temp->aName, temp->aScore);
    	fprintf(fptr, "\n");
    	temp=temp->next;
    }
    fclose(fptr);
}

void save(){
    score *temp;
    temp = head;
	while(temp != NULL)
    {
    	strcpy(strScore, temp->level);
        strcat(strScore, "\t");
		strcat(strScore, temp->aName);
        snprintf(revertStr,sizeof(revertStr), "%d", temp->aScore);
        strcat(strScore, "\t");
		strcat(strScore, revertStr);
        temp = temp->next;
    }
}

char *special_char_remplace(){

    size_t len, bytesRead;
    char *readedContent;
    FILE* f2;

    f2 = fopen("score.txt", "rb");

    fseek(f2, 0, SEEK_END);
    len = ftell(f2);
    rewind(f2);

    readedContent = (char*) malloc(sizeof(char) * len + 1);
    readedContent[len] = '\0';                      // Is needed only for printing to stdout with printf

    bytesRead = fread(readedContent, sizeof(char), len, f2);
    fclose(f2);
    return readedContent;
}


FILE*eBank;
FILE*mBank;
FILE*hBank;
FILE*sBank;
FILE*sBank2;

void doEASYROUND(){ // Gets and stores questions for Easy Round
    if((eBank = fopen("easybank.txt", "r"))==NULL){
        printf("Not find%s\n","easybank.txt");
		return;
    }
    else{
        while(!feof(eBank)){
            for(int x=0; x<30; x++){ // Reads the questions from file
                fgets(setEasy[x].question, 120, eBank);
                fgets(setEasy[x].choiceA, 70, eBank);
                fgets(setEasy[x].choiceB, 70, eBank);
                fgets(setEasy[x].choiceC, 70, eBank);
                fgets(setEasy[x].choiceD, 70, eBank);
                fgets(setEasy[x].answer, 70, eBank);
            }
        }
    }
  
    fclose(eBank);
}

void doMODERATEROUND(){ // Gets and stores questions for Moderate Round
    if((mBank = fopen("moderatebank.txt", "r"))==NULL){
        printf("Not find%s\n","moderatebank.txt");
		return;
    }
    else{
        while(!feof(mBank)){
            for(int x=0; x<30; x++){ // Reads the questions from file
                fgets(setMod[x].question, 120, mBank);
                fgets(setMod[x].choiceA, 70, mBank);
                fgets(setMod[x].choiceB, 70, mBank);
                fgets(setMod[x].choiceC, 70, mBank);
                fgets(setMod[x].choiceD, 70, mBank);
                fgets(setMod[x].answer, 70, mBank);
            }
        }
    }
    fclose(mBank);
}

void doHARDROUND(){ // Gets and stores questions for Hard Round
    if((hBank = fopen("hardbank.txt", "r"))==NULL){
        printf("Not find%s\n","hradbank.txt");
		return;
    }else{
        while(!feof(hBank)){
            for(int x=0;x<30; x++){ // Reads the questions from file
                fgets(setHard[x].question, 120, hBank);
                fgets(setHard[x].choiceA, 70, hBank);
                fgets(setHard[x].choiceB, 70, hBank);
                fgets(setHard[x].choiceC, 70, hBank);
                fgets(setHard[x].choiceD, 70, hBank);
                fgets(setHard[x].answer, 70, hBank);
            }
        }
    }
    fclose(hBank);
    
}

void makeQuesEasy(){
    Question *buff;
    doEASYROUND();
    for (int i = 0; i < 30; i++)
    {
        buff = (Question *)malloc(sizeof(Question));
        strcpy((*buff).word, setEasy[i].question);
        strcat((*buff).word, setEasy[i].choiceA);
        strcat((*buff).word, setEasy[i].choiceB);
        strcat((*buff).word, setEasy[i].choiceC);
        strcat((*buff).word, setEasy[i].choiceD);
        (*buff).word[strlen((*buff).word) - 1] = '\0';
        strcpy((*buff).answer, setEasy[i].answer);
        strcpy(questionEasy[i].word, (*buff).word);
        strcpy(questionEasy[i].answer, (*buff).answer);
        free(buff);
        
    }
}

void makeQuesHard(){
    Question *buff;
    doHARDROUND();
    for (int i = 0; i < 30; i++)
    {
        buff = (Question *)malloc(sizeof(Question));
        strcpy((*buff).word, setHard[i].question);
        strcat((*buff).word, setHard[i].choiceA);
        strcat((*buff).word, setHard[i].choiceB);
        strcat((*buff).word, setHard[i].choiceC);
        strcat((*buff).word, setHard[i].choiceD);
        (*buff).word[strlen((*buff).word) - 1] = '\0';
        strcpy((*buff).answer, setHard[i].answer);
        strcpy(questionHard[i].word, (*buff).word);
        strcpy(questionHard[i].answer, (*buff).answer);
        free(buff);
        
    }
}

void makeQuesMod(){
    Question *buff;
    doMODERATEROUND();
    for (int i = 0; i < 30; i++)
    {
        buff = (Question *)malloc(sizeof(Question));
        strcpy((*buff).word, setMod[i].question);
        strcat((*buff).word, setMod[i].choiceA);
        strcat((*buff).word, setMod[i].choiceB);
        strcat((*buff).word, setMod[i].choiceC);
        strcat((*buff).word, setMod[i].choiceD);
        (*buff).word[strlen((*buff).word) - 1] = '\0';
        strcpy((*buff).answer, setMod[i].answer);
        strcpy(questionMod[i].word, (*buff).word);
        strcpy(questionMod[i].answer, (*buff).answer);
        free(buff);
        
    }
}

int ranDomAns(int a){
    int intRandom;
    srand(time(NULL));
    do{
        intRandom = (rand()%5);

    }while (intRandom == 0 || intRandom == a);
    
    return intRandom;
    
} 

void swap (Question *a, Question *b) 
{ 
    Question temp = *a; 
    *a = *b; 
    *b = temp; 
} 
  
  
// A function to generate a random permutation of arr[] 
void randomize ( Question arr[], int n ) 
{ 
    // Use a different seed value so that we don't get same 
    // result each time we run this program 
    srand ( time(NULL) ); 
  
    // Start from the last element and swap one by one. We don't 
    // need to run for the first element that's why i > 0 
    for (int i = n-1; i > 0; i--) 
    { 
        // Pick a random index from 0 to i 
        int j = rand() % (i+1); 
  
        // Swap arr[i] with the element at random index 
        swap(&arr[i], &arr[j]); 
    } 
}

int main(){
    char level[5];
    char aName[20];
    int aScore;
    int num;
    char str[10] = "abc";
    openFileScore();
    strScore = special_char_remplace();
    printf("%s", strScore);
    num = ranDomAns(1);
    printf("%d\n", num);
    str[0] = '\0';
    printf("%s", str);

}
gha: C, lang: cpp
Basic Ansible playbook for installing NEAT and the PM service on Debian systems from the Github repo.

    ansible-playbook -i hosts setup_neat.yml

or with python3 and no ssh keys:

    ansible-playbook -i hosts setup_neat.yml --ask-pass -e 'ansible_python_interpreter=/usr/bin/python3'

gha: C, lang: dockerfile
export { default as Code } from './Code.svelte'
export { default as ExternalLink } from './ExternalLink.svelte'
export { default as Scale } from './Scale.svelte'
export { default as SortAscending } from './SortAscending.svelte'
export { default as Spinner } from './Spinner.svelte'
export { default as Star } from './Star.svelte'

gha: Svelte, lang: javascript
#!/usr/bin/python

#creator: Jeffrey A. Detras
#date: 09/19/2016
#usage: creates list of samples for rerunning on
#snp discovery pipeline

import os
from shutil import copyfile

#read input file and the log file
input_list=open('input.info','r').readlines()
log_list=open('log.txt','r').read().splitlines()

#copy original input.info to old
copyfile('input.info','input.info.old')

#overwrite input.info list for rerun list
rerun_list=open('input.info','w')

for i in input_list:
    for j in log_list:
        if j in i:
            rerun_list.write(i)

gha: Perl, lang: python
class prometheus::server (
  String $image = 'prom/prometheus',
  String $version = '2.3.2',
  String $reloader_image = 'jimmidyson/configmap-reload',
  String $reloader_version = '0.1',
  String $retention = '720h',  # 30 days
  Integer[1025,65535] $port = 9090,
  String $external_url = '',
  Boolean $persistent_volume = false,
  Integer $persistent_volume_size = 15,
  String $kubernetes_token_file = '/var/run/secrets/kubernetes.io/serviceaccount/token',
  String $kubernetes_ca_file = '/var/run/secrets/kubernetes.io/serviceaccount/ca.crt',
  Hash[String,String] $external_labels = {},
)
{
  require ::kubernetes
  include ::prometheus

  if $::prometheus::mode == 'Full' or $::prometheus::mode == 'ExternalScrapeTargetsOnly' {
    $namespace = $::prometheus::namespace

    $authorization_mode = $::kubernetes::_authorization_mode
    if member($authorization_mode, 'RBAC'){
      $rbac_enabled = true
    } else {
      $rbac_enabled = false
    }

    if versioncmp($::kubernetes::version, '1.6.0') >= 0 {
      $version_before_1_6 = false
    } else {
      $version_before_1_6 = true
    }

    kubernetes::apply{'prometheus-server':
      ensure    => $::prometheus::ensure,
      manifests => [
        template('prometheus/prometheus-ns.yaml.erb'),
        template('prometheus/prometheus-deployment.yaml.erb'),
        template('prometheus/prometheus-svc.yaml.erb'),
      ],
    }

    kubernetes::apply{'prometheus-config':
      ensure => $::prometheus::ensure,
      type   => 'concat',
    }

    kubernetes::apply_fragment { 'prometheus-config-header':
      ensure  => $::prometheus::ensure,
      content => template('prometheus/prometheus-config-header.yaml.erb'),
      order   => 0,
      target  => 'prometheus-config',
    }

    kubernetes::apply_fragment { 'prometheus-config-prometheus-file':
      ensure  => $::prometheus::ensure,
      content => '  prometheus.yaml: |-',
      order   => 100,
      target  => 'prometheus-config',
    }

    kubernetes::apply_fragment { 'prometheus-config-prometheus-rules':
      ensure  => $::prometheus::ensure,
      content => template('prometheus/prometheus-config-rules.yaml.erb'),
      order   => 200,
      target  => 'prometheus-config',
    }

    kubernetes::apply_fragment { 'prometheus-config-global':
      ensure  => $::prometheus::ensure,
      content => template('prometheus/prometheus-config-global.yaml.erb'),
      order   => 300,
      target  => 'prometheus-config',
    }

    kubernetes::apply_fragment { 'prometheus-config-global-pre-scrape-config':
      ensure  => $::prometheus::ensure,
      content => '    scrape_configs:',
      order   => 400,
      target  => 'prometheus-config',
    }

    if $::prometheus::mode == 'Full' {
      # Scrape config for API servers.
      #
      # Kubernetes exposes API servers as endpoints to the default/kubernetes
      # service so this uses `endpoints` role and uses relabelling to only keep
      # the endpoints associated with the default/kubernetes service using the
      # default named port `https`. This works for single API server deployments as
      # well as HA API server deployments.
      prometheus::scrape_config { 'kubernetes-apiservers':
        order  =>  100,
        config => {
          'kubernetes_sd_configs' => [{
            'role' => 'endpoints',
          }],
          'tls_config'            => {
            'ca_file' => $kubernetes_ca_file,
          },
          'bearer_token_file'     => $kubernetes_token_file,
          'scheme'                => 'https',
          'relabel_configs'       => [{
            'source_labels' => ['__meta_kubernetes_namespace', '__meta_kubernetes_service_name', '__meta_kubernetes_endpoint_port_name'],
            'action'        => 'keep',
            'regex'         => 'default;kubernetes;https',
          }],
        }
      }

      # Scrape config for master's schedulers and controller manager (kubelet).
      #
      # Rather than connecting directly to the node, the scrape is proxied though the
      # Kubernetes apiserver.  This means it will work if Prometheus is running out of
      # cluster, or can't connect to nodes for some other reason (e.g. because of
      # firewalling).
      prometheus::scrape_config { 'kubernetes-schedulers':
        order  =>  110,
        config => {
          'kubernetes_sd_configs' => [{
            'role' => 'node',
          }],
          'tls_config'            => {
            'ca_file' => $kubernetes_ca_file,
          },
          'bearer_token_file'     => $kubernetes_token_file,
          'scheme'                => 'https',
          'relabel_configs'       => [{
              'source_labels' => ['__meta_kubernetes_node_label_role'],
              'action'        => 'keep',
              'regex'         => 'master',
          },{
            'action' => 'labelmap',
            'regex'  => '__meta_kubernetes_node_label_(.+)',
          },{
            'target_label' => '__address__',
            'replacement'  => 'kubernetes.default.svc:443',
          }, {
            'source_labels' => ['__meta_kubernetes_node_name'],
            'regex'         => '(.+)',
            'target_label'  => '__metrics_path__',
            'replacement'   => '/api/v1/nodes/${1}:10251/proxy/metrics',
          }],
        }
      }
      prometheus::scrape_config { 'kubernetes-controller-managers':
        order  =>  110,
        config => {
          'kubernetes_sd_configs' => [{
            'role' => 'node',
          }],
          'tls_config'            => {
            'ca_file' => $kubernetes_ca_file,
          },
          'bearer_token_file'     => $kubernetes_token_file,
          'scheme'                => 'https',
          'relabel_configs'       => [{
            'source_labels' => ['__meta_kubernetes_node_label_role'],
            'action'        => 'keep',
            'regex'         => 'master',
          },{
            'action' => 'labelmap',
            'regex'  => '__meta_kubernetes_node_label_(.+)',
          },{
            'target_label' => '__address__',
            'replacement'  => 'kubernetes.default.svc:443',
          }, {
            'source_labels' => ['__meta_kubernetes_node_name'],
            'regex'         => '(.+)',
            'target_label'  => '__metrics_path__',
            'replacement'   => '/api/v1/nodes/${1}:10252/proxy/metrics',
          }],
        }
      }

      # Scrape config for nodes (kubelet).
      #
      # Rather than connecting directly to the node, the scrape is proxied though the
      # Kubernetes apiserver.  This means it will work if Prometheus is running out of
      # cluster, or can't connect to nodes for some other reason (e.g. because of
      # firewalling).
      prometheus::scrape_config { 'kubernetes-nodes':
        order  =>  110,
        config => {
          'kubernetes_sd_configs' => [{
            'role' => 'node',
          }],
          'tls_config'            => {
            'ca_file' => $kubernetes_ca_file,
          },
          'bearer_token_file'     => $kubernetes_token_file,
          'scheme'                => 'https',
          'relabel_configs'       => [{
            'action' => 'labelmap',
            'regex'  => '__meta_kubernetes_node_label_(.+)',
          },{
            'target_label' => '__address__',
            'replacement'  => 'kubernetes.default.svc:443',
          }, {
            'source_labels' => ['__meta_kubernetes_node_name'],
            'regex'         => '(.+)',
            'target_label'  => '__metrics_path__',
            'replacement'   => '/api/v1/nodes/${1}/proxy/metrics',
          }],
        }
      }


      # Scrape config for Kubelet cAdvisor.
      #
      # This is required for Kubernetes 1.7.3 and later, where cAdvisor metrics
      # (those whose names begin with 'container_') have been removed from the
      # Kubelet metrics endpoint.  This job scrapes the cAdvisor endpoint to
      # retrieve those metrics.
      #
      # In Kubernetes 1.7.0-1.7.2, these metrics are only exposed on the cAdvisor
      # HTTP endpoint; use "replacement: /api/v1/nodes/${1}:4194/proxy/metrics"
      # in that case (and ensure cAdvisor's HTTP server hasn't been disabled with
      # the --cadvisor-port=0 Kubelet flag).
      #
      # This job is not necessary and should be removed in Kubernetes 1.6 and
      # earlier versions, or it will cause the metrics to be scraped twice.
      prometheus::scrape_config { 'kubernetes-nodes-cadvisor':
        order  =>  120,
        config => {
          'kubernetes_sd_configs' => [{
            'role' => 'node',
          }],
          'tls_config'            => {
            'ca_file' => $kubernetes_ca_file,
          },
          'bearer_token_file'     => $kubernetes_token_file,
          'scheme'                => 'https',
          'relabel_configs'       => [{
            'action' => 'labelmap',
            'regex'  => '__meta_kubernetes_node_label_(.+)',
          },{
            'target_label' => '__address__',
            'replacement'  => 'kubernetes.default.svc:443',
          }, {
            'source_labels' => ['__meta_kubernetes_node_name'],
            'regex'         => '(.+)',
            'target_label'  => '__metrics_path__',
            'replacement'   => '/api/v1/nodes/${1}/proxy/metrics/cadvisor',
          }],
        }
      }

      # Scrape config for service endpoints.
      #
      # The relabeling allows the actual service scrape endpoint to be configured
      # via the following annotations:
      #
      # * `prometheus.io/scrape`: Only scrape services that have a value of `true`
      # * `prometheus.io/scheme`: If the metrics endpoint is secured then you will need
      # to set this to `https` & most likely set the `tls_config` of the scrape config.
      # * `prometheus.io/path`: If the metrics path is not `/metrics` override this.
      # * `prometheus.io/port`: If the metrics are exposed on a different port to the
      # service then set this appropriately.
      prometheus::scrape_config { 'kubernetes-service-endpoints':
        order  =>  200,
        config => {
          'kubernetes_sd_configs' => [{
            'role' => 'endpoints',
          }],

          'relabel_configs'       => [
            {
              'source_labels' => ['__meta_kubernetes_service_annotation_prometheus_io_scrape'],
              'action'        => 'keep',
              'regex'         => true,
            },
            {
              'source_labels' => ['__meta_kubernetes_service_annotation_prometheus_io_scheme'],
              'action'        => 'replace',
              'target_label'  => '__scheme__',
              'regex'         => '(https?)',
            },
            {
              'source_labels' => ['__meta_kubernetes_service_annotation_prometheus_io_path'],
              'action'        => 'replace',
              'target_label'  => '__metrics_path__',
              'regex'         => '(.+)',
            },
            {
              'source_labels' => ['__address__', '__meta_kubernetes_service_annotation_prometheus_io_port'],
              'action'        => 'replace',
              'target_label'  => '__address__',
              'regex'         => '(.+)(?::\d+);(\d+)',
              'replacement'   => '$1:$2',
            },
            {
              'action' => 'labelmap',
              'regex'  => '__meta_kubernetes_service_label_(.+)',
            },
            {
              'source_labels' => ['__meta_kubernetes_namespace'],
              'action'        => 'replace',
              'target_label'  => 'kubernetes_namespace',
            },
            {
              'source_labels' => ['__meta_kubernetes_service_name'],
              'action'        => 'replace',
              'target_label'  => 'kubernetes_name',
            }
          ]
        }
      }

      # Example scrape config for probing services via the Blackbox Exporter.
      #
      # The relabeling allows the actual service scrape endpoint to be configured
      # via the following annotations:
      #
      # * `prometheus.io/probe`: Only probe services that have a value of `true`
      prometheus::scrape_config { 'kubernetes-services':
        order  =>  210,
        config => {
          'kubernetes_sd_configs' => [{
            'role' => 'service'
          }],
          'metrics_path'          => '/probe',
          'params'                => {
            'module' => ['http_2xx'],
          },
          'relabel_configs'       => [
            {
              'source_labels' => ['__meta_kubernetes_service_annotation_prometheus_io_probe'],
              'action'        => 'keep',
              'regex'         => true,
            },
            {
              'source_labels' => ['__address__'],
              'target_label'  => '__param_target',
            },
            {
              'target_label' => '__address__',
              'replacement'  => 'blackbox-exporter',
            },
            {
              'source_labels' => ['__param_target'],
              'target_label'  => 'instance',
            },
            {
              'action' => 'labelmap',
              'regex'  => '__meta_kubernetes_service_label_(.+)',
            },
            {
              'source_labels' => ['__meta_kubernetes_service_namespace'],
              'target_label'  => 'kubernetes_namespace',
            },
            {
              'source_labels' => ['__meta_kubernetes_service_name'],
              'target_label'  => 'kubernetes_name',
            },
          ]
        },
      }


      # Example scrape config for probing ingresses via the Blackbox Exporter.
      #
      # The relabeling allows the actual ingress scrape endpoint to be configured
      # via the following annotations:
      #
      # * `prometheus.io/probe`: Only probe ingresses that have a value of `true`
      prometheus::scrape_config { 'kubernetes-ingresses':
        order  =>  220,
        config => {
          'kubernetes_sd_configs' => [{
            'role' => 'ingress'
          }],
          'metrics_path'          => '/probe',
          'params'                => {
            'module' => ['http_2xx'],
          },
          'relabel_configs'       => [
            {
              'source_labels' => ['__meta_kubernetes_ingress_annotation_prometheus_io_probe'],
              'action'        => 'keep',
              'regex'         => true,
            },
            {
              'source_labels' => ['__meta_kubernetes_ingress_scheme','__address__','__meta_kubernetes_ingress_path'],
              'target_label'  => '__param_target',
              'regex'         => '(.+);(.+);(.+)',
              'replacement'   => '${1}://${2}${3}',
            },
            {
              'target_label' => '__address__',
              'replacement'  => 'blackbox-exporter',
            },
            {
              'source_labels' => ['__param_target'],
              'target_label'  => 'instance',
            },
            {
              'action' => 'labelmap',
              'regex'  => '__meta_kubernetes_ingress_label_(.+)',
            },
            {
              'source_labels' => ['__meta_kubernetes_ingress_namespace'],
              'target_label'  => 'kubernetes_namespace',
            },
            {
              'source_labels' => ['__meta_kubernetes_ingress_name'],
              'target_label'  => 'kubernetes_name',
            },
          ]
        },
      }

      # Example scrape config for pods
      #
      # The relabeling allows the actual pod scrape endpoint to be configured via the
      # following annotations:
      #
      # * `prometheus.io/scrape`: Only scrape pods that have a value of `true`
      # * `prometheus.io/path`: If the metrics path is not `/metrics` override this.
      # * `prometheus.io/port`: Scrape the pod on the indicated port instead of the
      # pod's declared ports (default is a port-free target if none are declared).
      prometheus::scrape_config { 'kubernetes-pods':
        order  =>  230,
        config => {
          'kubernetes_sd_configs' => [{
            'role' => 'pod'
          }],
          'relabel_configs'       => [
            {
              'source_labels' => ['__meta_kubernetes_pod_annotation_prometheus_io_scrape'],
              'action'        => 'keep',
              'regex'         => true,
            },
            {
              'source_labels' => ['__meta_kubernetes_pod_annotation_prometheus_io_path'],
              'action'        => 'replace',
              'target_label'  => '__metrics_path__',
              'regex'         => '(.+)',
            },
            {
              'source_labels' => ['__address__', '__meta_kubernetes_pod_annotation_prometheus_io_port'],
              'action'        => 'replace',
              'regex'         => '([^:]+)(?::\d+)?;(\d+)',
              'replacement'   => '${1}:${2}',
              'target_label'  => '__address__',
            },
            {
              'action' => 'labelmap',
              'regex'  => '__meta_kubernetes_pod_label_(.+)',
            },
            {
              'source_labels' => ['__meta_kubernetes_namespace'],
              'action'        => 'replace',
              'target_label'  => 'kubernetes_namespace',
            },
            {
              'source_labels' => ['__meta_kubernetes_pod_name'],
              'action'        => 'replace',
              'target_label'  => 'kubernetes_pod_name',
            }
          ]
        }
      }
    }

    kubernetes::apply{'prometheus-rules':
      ensure => $::prometheus::ensure,
      type   => 'concat',
    }

    kubernetes::apply_fragment { 'prometheus-rules-header':
      ensure  => $::prometheus::ensure,
      content => template('prometheus/prometheus-rules-header.yaml.erb'),
      order   => 0,
      target  => 'prometheus-rules',
    }


    prometheus::rule { 'ScrapeEndpointDown':
      expr        => '(up == 0 AND up {job != "kubernetes-apiservers"})',
      for         => '2m',
      summary     => '{{$labels.instance}}: Scrape target is down',
      description => '{{$labels.instance}}: Target down for job {{$labels.job}}',
    }

    prometheus::rule { 'ContainerScrapeError':
      expr        => '(container_scrape_error) != 0',
      for         => '2m',
      summary     => '{{$labels.instance}}: Container scrape error',
      description => '{{$labels.instance}}: Failed to scrape container, metrics will not be updated',
    }
  }
}

gha: Go, lang: powershell
/*
 * SPDX-License-Identifier:	GPL-2.0+
 *
 * Based on bitrev from the Linux kernel, by Akinobu Mita
 */


#include <linux/types.h>
#include <linux/bitrev.h>

const u8 byte_rev_table[256] = {
	0x00, 0x80, 0x40, 0xc0, 0x20, 0xa0, 0x60, 0xe0,
	0x10, 0x90, 0x50, 0xd0, 0x30, 0xb0, 0x70, 0xf0,
	0x08, 0x88, 0x48, 0xc8, 0x28, 0xa8, 0x68, 0xe8,
	0x18, 0x98, 0x58, 0xd8, 0x38, 0xb8, 0x78, 0xf8,
	0x04, 0x84, 0x44, 0xc4, 0x24, 0xa4, 0x64, 0xe4,
	0x14, 0x94, 0x54, 0xd4, 0x34, 0xb4, 0x74, 0xf4,
	0x0c, 0x8c, 0x4c, 0xcc, 0x2c, 0xac, 0x6c, 0xec,
	0x1c, 0x9c, 0x5c, 0xdc, 0x3c, 0xbc, 0x7c, 0xfc,
	0x02, 0x82, 0x42, 0xc2, 0x22, 0xa2, 0x62, 0xe2,
	0x12, 0x92, 0x52, 0xd2, 0x32, 0xb2, 0x72, 0xf2,
	0x0a, 0x8a, 0x4a, 0xca, 0x2a, 0xaa, 0x6a, 0xea,
	0x1a, 0x9a, 0x5a, 0xda, 0x3a, 0xba, 0x7a, 0xfa,
	0x06, 0x86, 0x46, 0xc6, 0x26, 0xa6, 0x66, 0xe6,
	0x16, 0x96, 0x56, 0xd6, 0x36, 0xb6, 0x76, 0xf6,
	0x0e, 0x8e, 0x4e, 0xce, 0x2e, 0xae, 0x6e, 0xee,
	0x1e, 0x9e, 0x5e, 0xde, 0x3e, 0xbe, 0x7e, 0xfe,
	0x01, 0x81, 0x41, 0xc1, 0x21, 0xa1, 0x61, 0xe1,
	0x11, 0x91, 0x51, 0xd1, 0x31, 0xb1, 0x71, 0xf1,
	0x09, 0x89, 0x49, 0xc9, 0x29, 0xa9, 0x69, 0xe9,
	0x19, 0x99, 0x59, 0xd9, 0x39, 0xb9, 0x79, 0xf9,
	0x05, 0x85, 0x45, 0xc5, 0x25, 0xa5, 0x65, 0xe5,
	0x15, 0x95, 0x55, 0xd5, 0x35, 0xb5, 0x75, 0xf5,
	0x0d, 0x8d, 0x4d, 0xcd, 0x2d, 0xad, 0x6d, 0xed,
	0x1d, 0x9d, 0x5d, 0xdd, 0x3d, 0xbd, 0x7d, 0xfd,
	0x03, 0x83, 0x43, 0xc3, 0x23, 0xa3, 0x63, 0xe3,
	0x13, 0x93, 0x53, 0xd3, 0x33, 0xb3, 0x73, 0xf3,
	0x0b, 0x8b, 0x4b, 0xcb, 0x2b, 0xab, 0x6b, 0xeb,
	0x1b, 0x9b, 0x5b, 0xdb, 0x3b, 0xbb, 0x7b, 0xfb,
	0x07, 0x87, 0x47, 0xc7, 0x27, 0xa7, 0x67, 0xe7,
	0x17, 0x97, 0x57, 0xd7, 0x37, 0xb7, 0x77, 0xf7,
	0x0f, 0x8f, 0x4f, 0xcf, 0x2f, 0xaf, 0x6f, 0xef,
	0x1f, 0x9f, 0x5f, 0xdf, 0x3f, 0xbf, 0x7f, 0xff,
};

u16 bitrev16(u16 x)
{
	return (bitrev8(x & 0xff) << 8) | bitrev8(x >> 8);
}

/**
 * bitrev32 - reverse the order of bits in a u32 value
 * @x: value to be bit-reversed
 */
u32 bitrev32(u32 x)
{
	return (bitrev16(x & 0xffff) << 16) | bitrev16(x >> 16);
}

gha: C, lang: cpp
/*
* Copyright 2020 Google LLC
*
* Licensed under the Apache License, Version 2.0 (the "License");
* you may not use this file except in compliance with the License.
* You may obtain a copy of the License at
*
*      http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
*/

select
     tab.owner as schema_name,
     schema.created as schema_create_time,
     tab.table_name as table_name,
     obj.object_type as table_type,
     obj.created table_create_time,
     obj.last_ddl_time as table_update_time,
     tab.num_rows as table_rows,
     tab_comm.comments as table_comments,
     col.column_name,
     col.data_type,
     decode(char_length,
            0, data_type,
            data_type || '(' || char_length || ')')
            as data_type_ext,
     col.data_length,
     col.data_precision,
     col.data_scale,
     col_comm.comments as col_comments,
     col.nullable
from all_tables tab
     inner join all_objects obj
         on obj.owner = tab.owner
        and obj.object_name = tab.table_name
     inner join all_users schema
         on schema.username = tab.owner
     left outer join all_tab_comments tab_comm
         on tab.table_name = tab_comm.table_name
        and tab.owner = tab_comm.owner
     inner join all_tab_columns col
        on col.owner = tab.owner
        and col.table_name = tab.table_name
     left join all_col_comments col_comm
         on col.owner = col_comm.owner
         and col.table_name = col_comm.table_name
         and col.column_name = col_comm.column_name
where tab.owner in
  (select username from all_users
   where oracle_maintained = 'N')
order by tab.owner,
     tab.table_name,
     col.column_name
gha: Python, lang: sql
import { DataTypes, Model, Sequelize } from 'sequelize';

export interface LimitRateAttributes {
  email: string;
  totalWords: number;
  rateDate?: Date;
}

export class LimitRate
  extends Model<LimitRateAttributes>
  implements LimitRateAttributes
{
  email!: string;
  totalWords!: number;
}

export function LimitRateBuilder(sequelize: Sequelize): typeof LimitRate {
  LimitRate.init(
    {
      email: {
        type: DataTypes.STRING,
        primaryKey: true,
      },
      totalWords: {
        type: DataTypes.NUMBER,
        allowNull: false,
        defaultValue: 0,
      },
      rateDate: {
        type: DataTypes.DATEONLY,
        primaryKey: true,
        defaultValue: new Date()
      },
    },
    {
      sequelize,
      tableName: 'limit_rates',
      underscored: true,
    },
  );

  return LimitRate;
}

gha: TypeScript, lang: javascript
<% case course.outcome %>
<% when 'QTS' %>
  <%= render partial: 'courses/qualification/qts' %>
<% when 'PGCE with QTS' %>
  <%= render partial: 'courses/qualification/pgce_with_qts' %>
<% when 'PGDE with QTS' %>
  <%= render partial: 'courses/qualification/pgde_with_qts' %>
<% when 'PGCE' %>
  <%= render partial: 'courses/qualification/pgce' %>
<% when 'PGDE' %>
  <%= render partial: 'courses/qualification/pgde' %>
<% end %>

gha: Ruby, lang: coffeescript
---
layout: post
title : 「Kotlin」 Kotlin与AndroidSDK环境配置
date: 2020-06-27
tags: [Kotlin]
categories: [Kotlin]
---

# Kotlin基础
[toc]

## Kotlin 介绍

Kotlin 是一个用于现代多平台应用的静态编程语言, 由 JetBrains 开发.
Kotlin可以编译成Java字节码, 也可以编译成JavaScript, 方便在没有JVM的设备上运行.
Kotlin已正式成为Android官方支持开发语言.

## 开发环境

### 总览

* IntelliJ IDEA(社区版足够)
* JDK 1.6+
* Android SDK(如果需要开发安卓的话)

### Android SDK

如果本身没有 android sdk, 事情就简单了.
打开Idea主界面, Configure-> Setting
里面选择 Android SDK , 点edit, 选择路径后 idea可以给你自动下载一个. 然后采用下文23的步骤, 就可以轻松配置.

理论上的方式:

1. 先下载一个sdk
2. 打开Idea主界面, Configure-> Structure for New Project
3. 设置jdk, 然后打开左侧的SDKs, 点加号, 添加 Android SDK , 选中.

这里很可能出现一个报错

Cannot find any Android targets in this SDK

根据多方查询
[stackoverflow的回答](https://stackoverflow.com/questions/38212868/cannot-find-any-android-targets-in-this-sdk-in-intellij-2016/40984451?r=SearchResults#40984451)

这个指出, 出现这个问题是因为

> This error message means that IntelliJ didn't find any virtual device to run your project in.
> You need to create a new Android Virtual Device (AVD) using the AVD manager tool.
> Next time you'll try to create a new project you select the same SDK path as before and IntelliJ will automatically find your newly created AVD.

根据我的猜想, 是点击弹出框中的 package mannager 然后会回到和上面的 Setting 相同的界面, 然后在edit中设置路径, 然后在选择你安装的sdk的路径, idea会自动给你下几个其他的工具, platform之类的, 然后就等待安装完成即可.

还有个猜想没有验证, 就是下载后的sdk里面有两个exe, 一个是 AVD manager.exe 一个是SDK manager.exe 后者在Idea里有, 前者我认为就是上文答案中所说的控制AVD的东西. 但是我尝试打开了, 并不懂如何操作, 或许还要等更深入的理解之后才可以.

gha: HTML, lang: markdown
import {NgModule} from "@angular/core";
import {RouterModule, Routes} from "@angular/router";
import {IndexComponent} from "../index/index.component";
import {ArticleComponent} from "../article/article.component";
import {CategoryComponent} from "../category/category.component";

export const routes: Routes = [
    {path: '', redirectTo: '/index', pathMatch: 'full'},
    {path: 'index', component: IndexComponent, data: {name: 'index'}},
    {path: 'article', component: ArticleComponent, data: {name: 'article'}},
    {path: 'category', component: CategoryComponent, data: {name: 'category'}},
];

@NgModule({
    imports: [RouterModule.forRoot(routes, {useHash: true})],
    exports: [RouterModule]
})
export class AppRoutingModule {
}

gha: TypeScript, lang: javascript
﻿using System;
using System.Collections.Generic;
using System.Linq;

namespace _08.MentorGroup
{
    class Student
    {
        public string Name { get; set; }
        public List<DateTime> Dates { get; set; }
        public List<string> Comments { get; set; }
    }

    class MentorGroup
    {
        static void Main(string[] args)
        {
            string[] nameAndDates = Console.ReadLine().Split(' ').ToArray();
            string[] nameAndComments = Console.ReadLine().Split('-').ToArray();

            List<DateTime> dates = new List<DateTime>();
            List<Student> students = new List<Student>();

            SetStudents(nameAndDates, dates, students);
            GetComments(nameAndComments, nameAndDates, students);
            
            PrintResult(students);
        }

        private static void SetStudents(string[] nameAndDates, List<DateTime> dates, List<Student> students)
        {
            while (nameAndDates[0] != "end")
            {

                string name = nameAndDates[0];
                if (nameAndDates.Length > 0)
                    dates = nameAndDates[1].Split(',').Select(DateTime.Parse).ToList();

                Student student = new Student
                {
                    Name = name,
                    Dates = dates
                };

                bool hasTheSameName = CheckIfHasTheSameName(students, name, dates);
                
                if (!hasTheSameName)
                    students.Add(student);

                nameAndDates = Console.ReadLine().Split(' ').ToArray();
            }

        }

        private static bool CheckIfHasTheSameName(List<Student> students, string name, List<DateTime> dates)
        {
            bool hasTheSameName = false;
            foreach (var stu in students)
            {
                if (stu.Name == name)
                {
                    dates.AddRange(stu.Dates);
                    stu.Dates = dates;
                    hasTheSameName = true;
                }
            }
            return hasTheSameName;
        }

        private static void GetComments(string[] nameAndComments, string[] nameAndDates, List<Student> students)
        {
            List<string> comments = new List<string>();
            while (nameAndComments[0] != "end")
            {
                string name = nameAndComments[0];
                string comment = nameAndComments[1];

                Student currStud = students.Where(s => s.Name == name).FirstOrDefault();

                if (currStud != null)
                {
                    currStud.Comments = comments;
                    comments.Add(comment);
                }

                nameAndComments = Console.ReadLine().Split(' ').ToArray();
            }
        }

        private static void PrintResult(List<Student> students)
        {
            foreach (var stud in students.OrderBy(s => s.Name))
            {
                string name = stud.Name;
                Console.WriteLine(name);
                Console.WriteLine("Comments:");

                if (stud.Comments != null)
                {
                    foreach (var comm in stud.Comments)
                    {
                        Console.WriteLine($"- {comm}");
                    }
                }

                Console.WriteLine("Dates attended:");

                if (stud.Dates != null)
                {
                    foreach (var date in stud.Dates.OrderBy(d => d))
                    {
                        Console.WriteLine($"-- {date.Day:D2}/{date.Month:D2}/{date.Year}");
                    }
                }
            }

        }
    }
}

gha: PHP, lang: c_sharp
////////////////////////////////////////////
/*
Image Name: imgDroneMD.bmp
MonoChrome Image 1 Bit Per Pixel
Width: 16
Height: 16
Pixel Format: Format32bppArgb
*/
///////////////////////////////////////////////////



#include <stdlib.h>
#include "bitmap.h"

static const uint8_t _acimgDroneMDBmp[] =
{
0x00, 0x00, 0x07, 0xE0, 0x08, 0x10, 0x10, 0x08, 0x20, 0x04,
0x44, 0x24, 0x41, 0x02, 0x41, 0x82, 0x40, 0x82, 0x41, 0x82,
0x44, 0x24, 0x26, 0x64, 0x11, 0x88, 0x0C, 0x30, 0x03, 0xC0,
0x00, 0x00};


const ImageData bmimgDroneMDBmp = {
16, //xSize
16, //ySize
2, //bytesPerLine
1, //bits per pixel
(uint8_t*)_acimgDroneMDBmp,
};
/////////////////// End of File  ///////////////////////////
gha: C, lang: cpp
<?php

namespace App\Models;

use Illuminate\Database\Eloquent\Model;
use Backpack\CRUD\CrudTrait;

class Estate extends Model
{
    use CrudTrait;

    /*
    |--------------------------------------------------------------------------
    | GLOBAL VARIABLES
    |--------------------------------------------------------------------------
    */

    protected $table = 'estates';
    // protected $primaryKey = 'id';
    // public $timestamps = false;
    // protected $guarded = ['id'];
    protected $fillable = ['approved','abonent_id','images','view','title','description',
        'locationP','locationC','estate_type','room','phone','announcement_type'];
    // protected $hidden = [];
    // protected $dates = [];

    /*
    |--------------------------------------------------------------------------
    | FUNCTIONS
    |--------------------------------------------------------------------------
    */

    /*
    |--------------------------------------------------------------------------
    | RELATIONS
    |--------------------------------------------------------------------------
    */

    public function client(){
        return $this->belongsTo(Abonent::class,'abonent_id');
    }
    public function location(){
        return $this->belongsTo(Location::class,'locationP');
    }

    public function location_child(){
        return $this->belongsTo(Location::class,'locationC');
    }

    public function type(){
        return $this->belongsTo(Estate_type::class,'estate_type');
    }
    /*
    |--------------------------------------------------------------------------
    | SCOPES
    |--------------------------------------------------------------------------
    */

    /*
    |--------------------------------------------------------------------------
    | ACCESORS
    |--------------------------------------------------------------------------
    */

    /*
    |--------------------------------------------------------------------------
    | MUTATORS
    |--------------------------------------------------------------------------
    */
}

gha: CSS, lang: php
import {
  STRING,
  BOOLEAN,
  INTEGER,
  Sequelize,
  Model,
  BuildOptions
} from 'sequelize';

export interface ILessonModel extends Model {
  id: number;
  url: string;
  description: string;
  duration: number;
  seqNo: number;
  courseId: number;
  pro: boolean;
  tags: string;
  gitHubUrl: string;
}

type LessonModelStatic = typeof Model & {
  new (values?: object, options?: BuildOptions): ILessonModel;
};

export function initLessonModel(sequelize: Sequelize) {
  return <LessonModelStatic>sequelize.define('Lesson', {
    url: STRING,
    description: STRING,
    duration: INTEGER,
    seqNo: INTEGER,
    courseId: INTEGER,
    pro: BOOLEAN,
    tags: STRING,
    gitHubUrl: STRING
  });
}

gha: TSQL, lang: javascript
#include <fx2usb.h>

extern usb_descriptor_set_c usb_descriptor_set;

bool handle_usb_set_interface(uint8_t interface, uint8_t alt_setting) {
  interface;
  if(alt_setting == 0) {
    usb_reset_data_toggles(&usb_descriptor_set, interface, alt_setting);
    return true;
  }

  return false;
}

gha: C, lang: cpp
﻿// This Source Code Form is subject to the terms of the MIT License.
// If a copy of the MIT was not distributed with this file, You can obtain one at https://opensource.org/licenses/MIT.
// Copyright (C) Leszek Pomianowski and WPF UI Contributors.
// All Rights Reserved.

using System;
using System.Windows;
using System.Windows.Media;
using Microsoft.Win32;

namespace Wpf.Ui.Appearance;

internal static class SystemTheme
{
    /// <summary>
    /// Gets the current main color of the system.
    /// </summary>
    /// <returns></returns>
    public static Color GlassColor => SystemParameters.WindowGlassColor;

    /// <summary>
    /// Determines whether the system is currently set to hight contrast mode.
    /// </summary>
    /// <returns><see langword="true"/> if <see cref="SystemParameters.HighContrast"/>.</returns>
    public static bool HighContrast => SystemParameters.HighContrast;

    /// <summary>
    /// Gets currently set system theme based on <see cref="Registry"/> value.
    /// </summary>
    public static SystemThemeType GetTheme()
    {
        var currentTheme =
            Registry.GetValue("HKEY_CURRENT_USER\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Themes",
                "CurrentTheme", "aero.theme") as string ?? String.Empty;

        if (String.IsNullOrEmpty(currentTheme))
            return SystemThemeType.Unknown;

        currentTheme = currentTheme.ToLower().Trim();

        // This may be changed in the next versions, check the Insider previews

        if (currentTheme.Contains("basic.theme"))
            return SystemThemeType.Light;

        if (currentTheme.Contains("aero.theme"))
            return SystemThemeType.Light;

        if (currentTheme.Contains("dark.theme"))
            return SystemThemeType.Dark;

        if (currentTheme.Contains("themea.theme"))
            return SystemThemeType.Glow;

        if (currentTheme.Contains("themeb.theme"))
            return SystemThemeType.CapturedMotion;

        if (currentTheme.Contains("themec.theme"))
            return SystemThemeType.Sunrise;

        if (currentTheme.Contains("themed.theme"))
            return SystemThemeType.Flow;

        //if (currentTheme.Contains("custom.theme"))
        //    return ; custom can be light or dark

        var rawAppsUseLightTheme = Registry.GetValue(
        "HKEY_CURRENT_USER\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Themes\\Personalize",
        "AppsUseLightTheme", 1) ?? 1;

        if (rawAppsUseLightTheme is int and 0)
            return SystemThemeType.Dark;

        var rawSystemUsesLightTheme = Registry.GetValue(
            "HKEY_CURRENT_USER\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Themes\\Personalize",
            "SystemUsesLightTheme", 1) ?? 1;

        return rawSystemUsesLightTheme is int and 0 ? SystemThemeType.Dark : SystemThemeType.Light;
    }
}

gha: C#, lang: c_sharp
/api/rest/v1/products:
  $ref: ./resources/products/routes/products.yaml
/api/rest/v1/products/{code}:
  $ref: ./resources/products/routes/products_code.yaml
/api/rest/v1/products/{code}/proposal:
  $ref: ./resources/products/routes/products_code_proposal.yaml
/api/rest/v1/products/{code}/draft:
  $ref: ./resources/products/routes/products_code_draft.yaml

/api/rest/v1/products-uuid:
  $ref: ./resources/products_uuid/routes/products_uuid.yaml
/api/rest/v1/products-uuid/{uuid}:
  $ref: ./resources/products_uuid/routes/products_uuid_uuid.yaml
/api/rest/v1/products-uuid/{uuid}/proposal:
  $ref: ./resources/products_uuid/routes/products_uuid_uuid_proposal.yaml
/api/rest/v1/products-uuid/{uuid}/draft:
  $ref: ./resources/products_uuid/routes/products_uuid_uuid_draft.yaml

/api/rest/v1/product-models:
  $ref: ./resources/product_models/routes/product_models.yaml
/api/rest/v1/product-models/{code}:
  $ref: ./resources/product_models/routes/product_models_code.yaml
/api/rest/v1/product-models/{code}/proposal:
  $ref: ./resources/product_models/routes/product_models_code_proposal.yaml
/api/rest/v1/product-models/{code}/draft:
  $ref: ./resources/product_models/routes/product_models_code_draft.yaml

/api/rest/v1/published-products:
  $ref: ./resources/published_products/routes/published_products.yaml
/api/rest/v1/published-products/{code}:
  $ref: ./resources/published_products/routes/published_products_code.yaml

/api/rest/v1/media-files:
  $ref: ./resources/media_files/routes/media_files.yaml
/api/rest/v1/media-files/{code}:
  $ref: ./resources/media_files/routes/media_files_code.yaml
/api/rest/v1/media-files/{code}/download:
  $ref: ./resources/media_files/routes/media_files_code_download.yaml

/api/rest/v1/families:
  $ref: ./resources/families/routes/families.yaml
/api/rest/v1/families/{code}:
  $ref: ./resources/families/routes/families_code.yaml
/api/rest/v1/families/{family_code}/variants:
  $ref: ./resources/families/routes/families_code_variants.yaml
/api/rest/v1/families/{family_code}/variants/{code}:
  $ref: ./resources/families/routes/families_code_variants_code.yaml

/api/rest/v1/attributes:
  $ref: ./resources/attributes/routes/attributes.yaml
/api/rest/v1/attributes/{code}:
  $ref: ./resources/attributes/routes/attributes_code.yaml
/api/rest/v1/attributes/{attribute_code}/options:
  $ref: ./resources/attributes/routes/attributes_code_options.yaml
/api/rest/v1/attributes/{attribute_code}/options/{code}:
  $ref: ./resources/attributes/routes/attributes_code_options_code.yaml

/api/rest/v1/attribute-groups:
  $ref: ./resources/attribute_groups/routes/attribute_groups.yaml
/api/rest/v1/attribute-groups/{code}:
  $ref: ./resources/attribute_groups/routes/attribute_groups_code.yaml

/api/rest/v1/association-types:
  $ref: ./resources/association_types/routes/association_types.yaml
/api/rest/v1/association-types/{code}:
  $ref: ./resources/association_types/routes/association_types_code.yaml

/api/rest/v1/channels:
  $ref: ./resources/channels/routes/channels.yaml
/api/rest/v1/channels/{code}:
  $ref: ./resources/channels/routes/channels_code.yaml

/api/rest/v1/locales:
  $ref: ./resources/locales/routes/locales.yaml
/api/rest/v1/locales/{code}:
  $ref: ./resources/locales/routes/locales_code.yaml

/api/rest/v1/categories:
  $ref: ./resources/categories/routes/categories.yaml
/api/rest/v1/categories/{code}:
  $ref: ./resources/categories/routes/categories_code.yaml
/api/rest/v1/category-media-files/{file_path}/download:
  $ref: ./resources/categories/routes/category_media_files_code_download.yaml

/api/rest/v1/currencies:
  $ref: ./resources/currencies/routes/currencies.yaml
/api/rest/v1/currencies/{code}:
  $ref: ./resources/currencies/routes/currencies_code.yaml

/api/rest/v1/measure-families:
  $ref: ./resources/measure_families/routes/measure_families.yaml
/api/rest/v1/measure-families/{code}:
  $ref: ./resources/measure_families/routes/measure_families_code.yaml

/api/rest/v1/measurement-families:
  $ref: ./resources/measurement_families/routes/measurement_families.yaml

/api/rest/v1/reference-entities:
  $ref: ./resources/reference_entities/routes/reference_entities.yaml
/api/rest/v1/reference-entities/{code}:
  $ref: ./resources/reference_entities/routes/reference_entities_code.yaml

/api/rest/v1/reference-entities/{reference_entity_code}/attributes:
  $ref: ./resources/reference_entity_attributes/routes/reference_entity_attributes.yaml
/api/rest/v1/reference-entities/{reference_entity_code}/attributes/{code}:
  $ref: ./resources/reference_entity_attributes/routes/reference_entity_attributes_code.yaml
/api/rest/v1/reference-entities/{reference_entity_code}/attributes/{attribute_code}/options:
  $ref: ./resources/reference_entity_attributes/routes/reference_entity_attributes_code_options.yaml
/api/rest/v1/reference-entities/{reference_entity_code}/attributes/{attribute_code}/options/{code}:
  $ref: ./resources/reference_entity_attributes/routes/reference_entity_attributes_code_options_code.yaml

/api/rest/v1/reference-entities/{reference_entity_code}/records:
  $ref: ./resources/reference_entity_records/routes/reference_entity_records.yaml
/api/rest/v1/reference-entities/{reference_entity_code}/records/{code}:
  $ref: ./resources/reference_entity_records/routes/reference_entity_records_code.yaml

/api/rest/v1/reference-entities-media-files:
  $ref: ./resources/reference_entity_media_files/routes/reference_entity_media_files.yaml
/api/rest/v1/reference-entities-media-files/{code}:
  $ref: ./resources/reference_entity_media_files/routes/reference_entity_media_files_code.yaml

/api/rest/v1/asset-families:
  $ref: ./resources/asset_families/routes/asset_families.yaml
/api/rest/v1/asset-families/{code}:
  $ref: ./resources/asset_families/routes/asset_families_code.yaml
/api/rest/v1/asset-families/{asset_family_code}/attributes:
  $ref: ./resources/asset_attributes/routes/asset_attributes.yaml
/api/rest/v1/asset-families/{asset_family_code}/attributes/{code}:
  $ref: ./resources/asset_attributes/routes/asset_attributes_code.yaml
/api/rest/v1/asset-families/{asset_family_code}/attributes/{attribute_code}/options:
  $ref: ./resources/asset_attributes/routes/asset_attributes_code_options.yaml
/api/rest/v1/asset-families/{asset_family_code}/attributes/{attribute_code}/options/{code}:
  $ref: ./resources/asset_attributes/routes/asset_attributes_code_options_code.yaml

/api/rest/v1/asset-media-files:
  $ref: ./resources/asset_media_files/routes/asset_media_files.yaml
/api/rest/v1/asset-media-files/{code}:
  $ref: ./resources/asset_media_files/routes/asset_media_files_code.yaml

/api/rest/v1/asset-families/{asset_family_code}/assets:
  $ref: ./resources/assets/routes/assets.yaml
/api/rest/v1/asset-families/{asset_family_code}/assets/{code}:
  $ref: ./resources/assets/routes/assets_code.yaml

/api/rest/v1/assets:
  $ref: ./resources/deprecated/assets/routes/assets.yaml
/api/rest/v1/assets/{code}:
  $ref: ./resources/deprecated/assets/routes/assets_code.yaml
/api/rest/v1/assets/{asset_code}/reference-files/{locale_code}:
  $ref: ./resources/deprecated/assets/routes/assets_code_reference_files_channel_code_locale_code.yaml
/api/rest/v1/assets/{asset_code}/reference-files/{locale_code}/download:
  $ref: ./resources/deprecated/assets/routes/assets_code_reference_files_channel_code_locale_code_download.yaml
/api/rest/v1/assets/{asset_code}/variation-files/{channel_code}/{locale_code}:
  $ref: ./resources/deprecated/assets/routes/assets_code_variation_files_channel_code_locale_code.yaml
/api/rest/v1/assets/{asset_code}/variation-files/{channel_code}/{locale_code}/download:
  $ref: ./resources/deprecated/assets/routes/assets_code_variation_files_channel_code_locale_code_download.yaml
/api/rest/v1/asset-categories:
  $ref: ./resources/deprecated/asset_categories/routes/asset_categories.yaml
/api/rest/v1/asset-categories/{code}:
  $ref: ./resources/deprecated/asset_categories/routes/asset_categories_code.yaml
/api/rest/v1/asset-tags:
  $ref: ./resources/deprecated/asset_tags/routes/asset_tags.yaml
/api/rest/v1/asset-tags/{code}:
  $ref: ./resources/deprecated/asset_tags/routes/asset_tags_code.yaml

/api/rest/v1/catalogs:
  $ref: ./resources/app_catalogs/routes/app_catalogs.yaml
/api/rest/v1/catalogs/{id}:
  $ref: ./resources/app_catalogs/routes/app_catalogs_id.yaml
/api/rest/v1/catalogs/{id}/product-uuids:
  $ref: ./resources/app_catalogs/routes/app_catalogs_id_product_uuids.yaml
/api/rest/v1/catalogs/{id}/products:
  $ref: ./resources/app_catalogs/routes/app_catalogs_id_products.yaml
/api/rest/v1/catalogs/{id}/products/{uuid}:
  $ref: ./resources/app_catalogs/routes/app_catalogs_id_products_uuid.yaml
/api/rest/v1/catalogs/{id}/mapping-schemas/product:
  $ref: ./resources/app_catalogs/routes/app_catalogs_mapping_schema_product.yaml
/api/rest/v1/catalogs/{id}/mapped-products:
  $ref: ./resources/app_catalogs/routes/app_catalogs_id_mapped_products.yaml

/api/rest/v1:
  $ref: ./resources/list_endpoints.yaml

/api/oauth/v1/token:
  $ref: ./resources/token.yaml

/api/rest/v1/system-information:
  $ref: ./resources/system_information.yaml

gha: Handlebars, lang: yaml
---
title: Ambedkar Reading List for&nbsp;Beginners
published: 2015-04-19
author: Surabhi
---

## Introduction

[Dr. Bhimrao Ambedkar][ambedkar] led what was possibly South Asia’s biggest social revolution in 2500 years. Yet, if you read the textbooks used to teach modern history in Indian schools, he appears to be little more than a sidekick to the more towering figures of Gandhi and Nehru. He is usually mentioned, quite briefly, as having played an important role in the framing of the constitution, and as a leader of the people belonging to the lowest rung of the caste system - the ‘untouchables’ or [dalits][]. What is never brought out is his seminal role, through decades of tireless endeavour, in restoring some humanity in a society which had been defined by despicable forms of discrimination and violence for close to two millennia. The achievements of the Congress-led national movement undoubtedly pale in comparison.

[ambedkar]:http://en.wikipedia.org/wiki/B._R._Ambedkar
[dalits]:http://en.wikipedia.org/wiki/Dalit

Ambedkar’s battle was for something much more fundamental than the Congress' objective of forming a politically independent nation state. Being a dalit himself, he knew that a victory for the national movement would mean nothing if India's majority lower-caste population continued to slave under the hegemony of upper-caste elites in the 'free' nation of India. In fact, he compared it with wanting to “build a palace on a dung heap”. As a result, he made it his life’s mission to work towards breaking the fetters of caste, and in the process inspired millions of people belonging to India's 'Depressed Classes' to fight and take control of their destiny. His battle was, in his own words, "a battle for the reclamation of human personality".

Ambedkar was also one of the most erudite and articulate scholars of his time, who received training in Economics, Sociology, History, Philosophy and Anthropology at Columbia University, and later studied Law at Gray’s Inn, London while working on his doctoral thesis at the London School of Economics. He has written on a wide range of topics concerning Indian social, political, economic, cultural and religious life. Most of what he wrote, including numerous books, academic papers, magazine articles and speeches are freely available online. To begin to read Ambedkar for an upper-caste Indian such as myself, is to start a long and difficult process of unlearning – unlearning so much of what I thought I understood about India’s history, politics, culture and religions; about poverty, exploitation and inequality; about feminism, communism and Gandhism; and even about myself.

## Books

### Annihilation of Caste
The best introduction to Ambedkar's writings is, no doubt, the seminal text [Annihilation of Caste][aoc]. Written in the form of a speech, which was meant to be delivered at a conference that never happened (the irreverence of what Ambedkar was planning to say made the organisers uncomfortable enough to cancel the event outright), it is a scathing indictment of the caste system and a call for a revolution within Hindu society. Ambedkar covers a range of issues, from the problems and failures of the upper-caste Hindu reform movement, to the root causes of social inequality and discrimination among Hindus. His arguments are sharp, logical and incisive, and he invokes several creative analogies and examples to illustrate his points, which make the text expectionally powerful and engaging.

[aoc]:http://ccnmtl.columbia.edu/projects/mmt/ambedkar/web/index.html

### Castes in India: Their Genesis, Mechanisms and Development
Ambedkar presented an academic paper titled [Castes in India: Their Genesis, Mechanisms and Development][cii], while he was still a young student at Columbia. This paper is remarkable because it presents what is possibly the very first feminist analysis of caste system. Putting the upper-caste Hindu woman at the centre of his thesis, Ambedkar argues that the caste system was created, preserved and propagated primarily through the oppression and control of women. Since endogamy is the defining feature of caste, it is essential that women be controlled sexually and physically, in order to preserve it. This is what led to the emergence of a range of misogynistic social practices among upper-caste Hindus, such as sati, child marriage and forced widowhood.

[cii]:http://www.columbia.edu/itc/mealac/pritchett/00ambedkar/txt_ambedkar_castes.html

### The Untouchables: Who They Were and How They Became Untouchable
Ambedkar also wrote a number of books on Indian history, challenging the Brahminical and colonialist interpretations posited by the influential historians of his time. He gives an interesting account of how untouchability may have originated in his book: [The Untouchables: Who They Were and How They Became Untouchable][the-untouchables]. In it he presents what is called the *Broken Man Theory*, which states that untouchables were originally members of nomadic tribes who were forced to settle outside sedentary villages when their tribes were defeated in battle. The theory goes on to connect the consumption of dead cattle and the spread of Buddhism among these people, with the imposition of untouchability on them by the upper-castes. Pre-empting criticism that his theory is not backed by sufficient historical evidence, Ambedkar said:

> "The present attempt to explain the origin of Untouchability...[is a] task...analogous to that of the archaeologist who constructs a city from broken stones...In this sense the book is a work of art even more than of history. The origin of Untouchability lies buried in a dead past which nobody knows. To make it alive is like an attempt to reclaim to history a city which has been dead since ages past and present it as it was in its original condition. It cannot but be that imagination and hypothesis should pay a large part in such a work."

By presenting untouchability as something which was imposed on an innocent people through cunning and deceit, and out of a lust for power, Ambedkar sought to bring a radical change in the mindset of communities which, due to centuries of servitude, accepted their low status in society as their fate. His assertion was that they had not always been slaves, and there was no reason why they should continue to be.

[the-untouchables]:http://www.ambedkar.org/ambcd/39A.Untouchables%20who%20were%20they_why%20they%20became%20PART%20I.htm

### What the Congress and Gandhi have Done to the Untouchables
Ambedkar’s relationship with the Indian National Congress, which was dominated by [savarna][] Hindus, was strained at best and antagonistic at worst. In the 1920’s when Ambedkar first entered the political arena, the Congress, led by Mohandas Gandhi, had begun to aggressively pursue its ideal of *Swaraj* or self-rule, and was gaining mass support. Ambedkar was one of the very few influential people of his time who dared to openly criticise the actions of Gandhi and the Congress at the height of their powers. According to him they were opportunists and hypocrites, who only pretended to care about the untouchables, while being primarily concerned with acquiring political power. In his book [What the Congress and Gandhi have Done to the Untouchables][congress-gandhi-untouchables], Ambedkar doesn’t mince words, and often leaves you reeling from the utter irreverence of his statements. He compares the Congress to a “tyrant who is held down and who pleads for liberty because he wants to regain his right to oppress”, and says that “the very idea of political power to the Untouchables is hateful to Mr. Gandhi”. These opinions are not left unsubstantiated. The book carefully traces the history of the Congress’ engagement with pressing social issues such as caste and untouchability, offering ample evidence of the hypocritical shifts in its attitude towards them, and the wide chasm between their words and actions when it came to the upliftment of the untouchables.

[savarna]:http://en.wikipedia.org/wiki/Savarna
[congress-gandhi-untouchables]:http://www.ambedkar.org/ambcd/41A.What%20Congress%20and%20Gandhi%20Preface.htm

*This is a work in progress. Comments and suggestions are welcome.*

gha: CSS, lang: tex
CREATE TABLE double_spend_proofs (
    hash BINARY(32) NOT NULL,
    transaction_id INT UNSIGNED NOT NULL,
    output_index INT UNSIGNED NOT NULL,
    data BLOB,
    PRIMARY KEY (hash),
    UNIQUE KEY dsproof_previous_output_ix (transaction_id, output_index)
) ENGINE=InnoDB DEFAULT CHARSET=LATIN1;
gha: Java, lang: sql
# Generated by Django 2.2.3 on 2021-02-18 04:52

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('blog', '0005_auto_20210216_2211'),
    ]

    operations = [
        migrations.AddField(
            model_name='activitygallery',
            name='thumbnail_complete_url',
            field=models.CharField(default='#', max_length=200, verbose_name='略缩图原图地址'),
        ),
        migrations.AlterField(
            model_name='activitygallery',
            name='thumbnail_url',
            field=models.CharField(default='#', max_length=200, verbose_name='略缩图地址'),
        ),
    ]

gha: Smarty, lang: python

var vari = new n_class("0");
vari.nFunction();

function n_class(invar){
  this.localVariable = invar;

  this.nFunction = function(){
    console.log("a function");
  }
}


gha: PHP, lang: javascript
/*  RetroArch - A frontend for libretro.
 *  Copyright (C) 2010-2014 - Hans-Kristian Arntzen
 *  Copyright (C) 2011-2016 - Daniel De Matteis
 *  Copyright (C) 2012-2015 - Michael Lelli
 *  Copyright (C) 2013-2014 - Steven Crowe
 *
 *  RetroArch is free software: you can redistribute it and/or modify it under the terms
 *  of the GNU General Public License as published by the Free Software Found-
 *  ation, either version 3 of the License, or (at your option) any later version.
 *
 *  RetroArch is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;
 *  without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR
 *  PURPOSE.  See the GNU General Public License for more details.
 *
 *  You should have received a copy of the GNU General Public License along with RetroArch.
 *  If not, see <http://www.gnu.org/licenses/>.
 */

#include <unistd.h>
#include <dlfcn.h>

#include <android/keycodes.h>

#include <dynamic/dylib.h>
#include <retro_inline.h>
#include <string/stdstring.h>

#include "../../frontend/drivers/platform_linux.h"
#include "../input_autodetect.h"
#include "../input_config.h"
#include "../input_joypad_driver.h"
#include "../drivers_keyboard/keyboard_event_android.h"
#include "../../performance_counters.h"
#include "../../general.h"
#include "../../driver.h"

#ifdef HAVE_MENU
#include "../../menu/menu_display.h"
#endif

#define MAX_TOUCH 16
#define MAX_NUM_KEYBOARDS 3

typedef struct
{
   float x;
   float y;
   float z;
} sensor_t;

struct input_pointer
{
   int16_t x, y;
   int16_t full_x, full_y;
};

static int pad_id1 = -1;
static int pad_id2 = -1;
static int kbd_id[MAX_NUM_KEYBOARDS];
static int kbd_num = 0;

enum
{
   AXIS_X = 0,
   AXIS_Y = 1,
   AXIS_Z = 11,
   AXIS_RZ = 14,
   AXIS_HAT_X = 15,
   AXIS_HAT_Y = 16,
   AXIS_LTRIGGER = 17,
   AXIS_RTRIGGER = 18,
   AXIS_GAS = 22,
   AXIS_BRAKE = 23
};

typedef struct state_device
{
   int id;
   int port;
   char name[256];
} state_device_t;

typedef struct android_input_data
{
   state_device_t pad_states[MAX_PADS];
   int16_t analog_state[MAX_PADS][MAX_AXIS];
   int8_t hat_state[MAX_PADS][2];

   unsigned pads_connected;
   sensor_t accelerometer_state;
   struct input_pointer pointer[MAX_TOUCH];
   unsigned pointer_count;
} android_input_data_t;

typedef struct android_input
{
   bool blocked;
   android_input_data_t thread, copy;
   const input_device_driver_t *joypad;
} android_input_t;

static void frontend_android_get_version_sdk(int32_t *sdk);
static void frontend_android_get_name(char *s, size_t len);

bool (*engine_lookup_name)(char *buf,
      int *vendorId, int *productId, size_t size, int id);

void (*engine_handle_dpad)(android_input_data_t *, AInputEvent*, int, int);

static bool android_input_set_sensor_state(void *data, unsigned port,
      enum retro_sensor_action action, unsigned event_rate);

extern float AMotionEvent_getAxisValue(const AInputEvent* motion_event,
      int32_t axis, size_t pointer_idx);

static typeof(AMotionEvent_getAxisValue) *p_AMotionEvent_getAxisValue;

#define AMotionEvent_getAxisValue (*p_AMotionEvent_getAxisValue)

static void *libandroid_handle;

static bool android_input_lookup_name_prekitkat(char *buf,
      int *vendorId, int *productId, size_t size, int id)
{
   jobject name      = NULL;
   jmethodID getName = NULL;
   jobject device    = NULL;
   jmethodID method  = NULL;
   jclass    class   = 0;
   const char *str   = NULL;
   JNIEnv     *env   = (JNIEnv*)jni_thread_getenv();

   if (!env)
      goto error;

   VLOG(@"Using old lookup");

   FIND_CLASS(env, class, "android/view/InputDevice");
   if (!class)
      goto error;

   GET_STATIC_METHOD_ID(env, method, class, "getDevice",
         "(I)Landroid/view/InputDevice;");
   if (!method)
      goto error;

   CALL_OBJ_STATIC_METHOD_PARAM(env, device, class, method, (jint)id);
   if (!device)
   {
      ELOG(@"Failed to find device for ID: %d\n", id);
      goto error;
   }

   GET_METHOD_ID(env, getName, class, "getName", "()Ljava/lang/String;");
   if (!getName)
      goto error;

   CALL_OBJ_METHOD(env, name, device, getName);
   if (!name)
   {
      ELOG(@"Failed to find name for device ID: %d\n", id);
      goto error;
   }

   buf[0] = '\0';

   str = (*env)->GetStringUTFChars(env, name, 0);
   if (str)
      strlcpy(buf, str, size);
   (*env)->ReleaseStringUTFChars(env, name, str);

   VLOG(@"device name: %s\n", buf);

   return true;
error:
   return false;
}

static bool android_input_lookup_name(char *buf,
      int *vendorId, int *productId, size_t size, int id)
{
   jmethodID getVendorId  = NULL;
   jmethodID getProductId = NULL;
   jmethodID getName      = NULL;
   jobject device         = NULL;
   jobject name           = NULL;
   jmethodID method       = NULL;
   jclass class           = NULL;
   const char *str        = NULL;
   JNIEnv     *env        = (JNIEnv*)jni_thread_getenv();

   if (!env)
      goto error;

   VLOG(@"Using new lookup");

   FIND_CLASS(env, class, "android/view/InputDevice");
   if (!class)
      goto error;

   GET_STATIC_METHOD_ID(env, method, class, "getDevice",
         "(I)Landroid/view/InputDevice;");
   if (!method)
      goto error;

   CALL_OBJ_STATIC_METHOD_PARAM(env, device, class, method, (jint)id);
   if (!device)
   {
      ELOG(@"Failed to find device for ID: %d\n", id);
      goto error;
   }

   GET_METHOD_ID(env, getName, class, "getName", "()Ljava/lang/String;");
   if (!getName)
      goto error;

   CALL_OBJ_METHOD(env, name, device, getName);
   if (!name)
   {
      ELOG(@"Failed to find name for device ID: %d\n", id);
      goto error;
   }

   buf[0] = '\0';

   str = (*env)->GetStringUTFChars(env, name, 0);
   if (str)
      strlcpy(buf, str, size);
   (*env)->ReleaseStringUTFChars(env, name, str);

   VLOG(@"device name: %s\n", buf);

   GET_METHOD_ID(env, getVendorId, class, "getVendorId", "()I");
   if (!getVendorId)
      goto error;

   CALL_INT_METHOD(env, *vendorId, device, getVendorId);

   VLOG(@"device vendor id: %d\n", *vendorId);

   GET_METHOD_ID(env, getProductId, class, "getProductId", "()I");
   if (!getProductId)
      goto error;

   *productId = 0;
   CALL_INT_METHOD(env, *productId, device, getProductId);

   VLOG(@"device product id: %d\n", *productId);

   return true;
error:
   return false;
}

static void android_input_poll_main_cmd(void)
{
   int8_t cmd;
   struct android_app *android_app = (struct android_app*)g_android;

   if (read(android_app->msgread, &cmd, sizeof(cmd)) != sizeof(cmd))
      cmd = -1;

   switch (cmd)
   {
      case APP_CMD_REINIT_DONE:
         slock_lock(android_app->mutex);

         android_app->reinitRequested = 0;

         scond_broadcast(android_app->cond);
         slock_unlock(android_app->mutex);
         break;

      case APP_CMD_INPUT_CHANGED:
         slock_lock(android_app->mutex);

         if (android_app->inputQueue)
            AInputQueue_detachLooper(android_app->inputQueue);

         android_app->inputQueue = android_app->pendingInputQueue;

         if (android_app->inputQueue)
         {
            VLOG(@"Attaching input queue to looper");
            AInputQueue_attachLooper(android_app->inputQueue,
                  android_app->looper, LOOPER_ID_INPUT, NULL,
                  NULL);
         }

         scond_broadcast(android_app->cond);
         slock_unlock(android_app->mutex);

         break;

      case APP_CMD_INIT_WINDOW:
         slock_lock(android_app->mutex);
         android_app->window = android_app->pendingWindow;
         android_app->reinitRequested = 1;
         scond_broadcast(android_app->cond);
         slock_unlock(android_app->mutex);

         break;

      case APP_CMD_SAVE_STATE:
         slock_lock(android_app->mutex);
         android_app->stateSaved = 1;
         scond_broadcast(android_app->cond);
         slock_unlock(android_app->mutex);
         break;

      case APP_CMD_RESUME:
      case APP_CMD_START:
      case APP_CMD_PAUSE:
      case APP_CMD_STOP:
         slock_lock(android_app->mutex);
         android_app->activityState = cmd;
         scond_broadcast(android_app->cond);
         slock_unlock(android_app->mutex);
         break;

      case APP_CMD_CONFIG_CHANGED:
         AConfiguration_fromAssetManager(android_app->config,
               android_app->activity->assetManager);
         break;
      case APP_CMD_TERM_WINDOW:
         slock_lock(android_app->mutex);

         /* The window is being hidden or closed, clean it up. */
         /* terminate display/EGL context here */

         android_app->window = NULL;
         scond_broadcast(android_app->cond);
         slock_unlock(android_app->mutex);
         break;

      case APP_CMD_GAINED_FOCUS:
         {
            bool boolean = false;

            runloop_ctl(RUNLOOP_CTL_SET_PAUSED, &boolean);
            runloop_ctl(RUNLOOP_CTL_SET_IDLE,   &boolean);
#ifdef HAVE_MENU
            video_driver_unset_stub_frame();
#endif

            if ((android_app->sensor_state_mask
                     & (UINT64_C(1) << RETRO_SENSOR_ACCELEROMETER_ENABLE))
                  && android_app->accelerometerSensor == NULL)
               input_sensor_set_state(0,
                     RETRO_SENSOR_ACCELEROMETER_ENABLE,
                     android_app->accelerometer_event_rate);
         }
         slock_lock(android_app->mutex);
         android_app->unfocused = false;
         scond_broadcast(android_app->cond);
         slock_unlock(android_app->mutex);
         break;
      case APP_CMD_LOST_FOCUS:
         {
            bool boolean = true;

            runloop_ctl(RUNLOOP_CTL_SET_PAUSED, &boolean);
            runloop_ctl(RUNLOOP_CTL_SET_IDLE,   &boolean);
#ifdef HAVE_MENU
            video_driver_set_stub_frame();
#endif

            /* Avoid draining battery while app is not being used. */
            if ((android_app->sensor_state_mask
                     & (UINT64_C(1) << RETRO_SENSOR_ACCELEROMETER_ENABLE))
                  && android_app->accelerometerSensor != NULL
                  )
               input_sensor_set_state(0,
                     RETRO_SENSOR_ACCELEROMETER_DISABLE,
                     android_app->accelerometer_event_rate);
         }
         slock_lock(android_app->mutex);
         android_app->unfocused = true;
         scond_broadcast(android_app->cond);
         slock_unlock(android_app->mutex);
         break;

      case APP_CMD_DESTROY:
         VLOG(@"APP_CMD_DESTROY\n");
         android_app->destroyRequested = 1;
         break;
   }
}

static void engine_handle_dpad_default(android_input_data_t *android_data,
      AInputEvent *event, int port, int source)
{
   size_t motion_ptr = AMotionEvent_getAction(event) >>
      AMOTION_EVENT_ACTION_POINTER_INDEX_SHIFT;
   float x           = AMotionEvent_getX(event, motion_ptr);
   float y           = AMotionEvent_getY(event, motion_ptr);

   android_data->analog_state[port][0] = (int16_t)(x * 32767.0f);
   android_data->analog_state[port][1] = (int16_t)(y * 32767.0f);
}

static void engine_handle_dpad_getaxisvalue(android_input_data_t *android_data,
      AInputEvent *event, int port, int source)
{
   size_t motion_ptr = AMotionEvent_getAction(event) >>
      AMOTION_EVENT_ACTION_POINTER_INDEX_SHIFT;
   float x           = AMotionEvent_getAxisValue(event, AXIS_X, motion_ptr);
   float y           = AMotionEvent_getAxisValue(event, AXIS_Y, motion_ptr);
   float z           = AMotionEvent_getAxisValue(event, AXIS_Z, motion_ptr);
   float rz          = AMotionEvent_getAxisValue(event, AXIS_RZ, motion_ptr);
   float hatx        = AMotionEvent_getAxisValue(event, AXIS_HAT_X, motion_ptr);
   float haty        = AMotionEvent_getAxisValue(event, AXIS_HAT_Y, motion_ptr);
   float ltrig       = AMotionEvent_getAxisValue(event, AXIS_LTRIGGER, motion_ptr);
   float rtrig       = AMotionEvent_getAxisValue(event, AXIS_RTRIGGER, motion_ptr);
   float brake       = AMotionEvent_getAxisValue(event, AXIS_BRAKE, motion_ptr);
   float gas         = AMotionEvent_getAxisValue(event, AXIS_GAS, motion_ptr);

   android_data->hat_state[port][0] = (int)hatx;
   android_data->hat_state[port][1] = (int)haty;

   /* XXX: this could be a loop instead, but do we really want to
    * loop through every axis? */
   android_data->analog_state[port][0] = (int16_t)(x * 32767.0f);
   android_data->analog_state[port][1] = (int16_t)(y * 32767.0f);
   android_data->analog_state[port][2] = (int16_t)(z * 32767.0f);
   android_data->analog_state[port][3] = (int16_t)(rz * 32767.0f);
#if 0
   android_data->analog_state[port][4] = (int16_t)(hatx * 32767.0f);
   android_data->analog_state[port][5] = (int16_t)(haty * 32767.0f);
#endif
   android_data->analog_state[port][6] = (int16_t)(ltrig * 32767.0f);
   android_data->analog_state[port][7] = (int16_t)(rtrig * 32767.0f);
   android_data->analog_state[port][8] = (int16_t)(brake * 32767.0f);
   android_data->analog_state[port][9] = (int16_t)(gas * 32767.0f);
}


static bool android_input_init_handle(void)
{
   if (libandroid_handle != NULL) /* already initialized */
      return true;

   if ((libandroid_handle = dlopen("/system/lib/libandroid.so",
               RTLD_LOCAL | RTLD_LAZY)) == 0)
      return false;

   if ((p_AMotionEvent_getAxisValue = dlsym(RTLD_DEFAULT,
               "AMotionEvent_getAxisValue")))
   {
      VLOG(@"Set engine_handle_dpad to 'Get Axis Value' (for reading extra analog sticks)");
      engine_handle_dpad = engine_handle_dpad_getaxisvalue;
   }
   pad_id1 = -1;
   pad_id2 = -1;

   return true;
}

static void *android_input_init(void)
{
   int32_t sdk;
   settings_t *settings = config_get_ptr();
   struct android_app *android_app = (struct android_app*)g_android;
   android_input_t *android = (android_input_t*)
      calloc(1, sizeof(*android));

   if (!android)
      return NULL;

   android->thread.pads_connected = 0;
   android->copy.pads_connected = 0;
   android->joypad         = input_joypad_init_driver(
         settings->input.joypad_driver, android);
 
   input_keymaps_init_keyboard_lut(rarch_key_map_android);
 
   frontend_android_get_version_sdk(&sdk);

   VLOG(@"sdk version: %d\n", sdk);

   if (sdk >= 19)
      engine_lookup_name = android_input_lookup_name;
   else
      engine_lookup_name = android_input_lookup_name_prekitkat;

   engine_handle_dpad         = engine_handle_dpad_default;

   if (!android_input_init_handle())
   {
      WLOG(@"Unable to open libandroid.so\n");
   }

   android_app->input_alive = true;

   return android;
}

static INLINE int android_input_poll_event_type_motion(
      android_input_data_t *android_data, AInputEvent *event,
      int port, int source)
{
   int getaction, action;
   size_t motion_ptr;
   bool keyup;

   if (source & ~(AINPUT_SOURCE_TOUCHSCREEN | AINPUT_SOURCE_MOUSE))
      return 1;

   getaction  = AMotionEvent_getAction(event);
   action     = getaction & AMOTION_EVENT_ACTION_MASK;
   motion_ptr = getaction >> AMOTION_EVENT_ACTION_POINTER_INDEX_SHIFT;
   keyup      = (
         action == AMOTION_EVENT_ACTION_UP ||
         action == AMOTION_EVENT_ACTION_CANCEL ||
         action == AMOTION_EVENT_ACTION_POINTER_UP) ||
      (source == AINPUT_SOURCE_MOUSE &&
       action != AMOTION_EVENT_ACTION_DOWN);

   if (keyup && motion_ptr < MAX_TOUCH)
   {
      memmove(android_data->pointer + motion_ptr,
            android_data->pointer + motion_ptr + 1,
            (MAX_TOUCH - motion_ptr - 1) * sizeof(struct input_pointer));
      if (android_data->pointer_count > 0)
         android_data->pointer_count--;
   }
   else
   {
      float x, y;
      int pointer_max = MIN(AMotionEvent_getPointerCount(event), MAX_TOUCH);

      for (motion_ptr = 0; motion_ptr < pointer_max; motion_ptr++)
      {
         x = AMotionEvent_getX(event, motion_ptr);
         y = AMotionEvent_getY(event, motion_ptr);

         input_translate_coord_viewport(x, y,
               &android_data->pointer[motion_ptr].x,
               &android_data->pointer[motion_ptr].y,
               &android_data->pointer[motion_ptr].full_x,
               &android_data->pointer[motion_ptr].full_y);

         android_data->pointer_count = MAX(
               android_data->pointer_count,
               motion_ptr + 1);
      }
   }

   return 0;
}

bool is_keyboard_id(int id)
{
   for(int i=0; i<kbd_num; i++)
      if (id == kbd_id[i]) return true;

   return false;
}

static INLINE void android_input_poll_event_type_keyboard(
      AInputEvent *event, int keycode, int *handled)
{
   int keydown = (AKeyEvent_getAction(event) == AKEY_EVENT_ACTION_DOWN);
   unsigned keyboardcode = input_keymaps_translate_keysym_to_rk(keycode);
                     
   // Set keyboard modifier based on shift,ctrl and alt state
   uint16_t mod = 0;
   int meta = AKeyEvent_getMetaState(event);
   if(meta & AMETA_ALT_ON) mod |= RETROKMOD_ALT;
   if(meta & AMETA_CTRL_ON) mod |= RETROKMOD_CTRL;
   if(meta & AMETA_SHIFT_ON) mod |= RETROKMOD_SHIFT;

   input_keyboard_event(keydown, keyboardcode, keyboardcode, mod, RETRO_DEVICE_KEYBOARD);

   if ((keycode == AKEYCODE_VOLUME_UP || keycode == AKEYCODE_VOLUME_DOWN))
      *handled = 0;
}

static INLINE void android_input_poll_event_type_key(
      struct android_app *android_app,
      AInputEvent *event, int port, int keycode, int source,
      int type_event, int *handled)
{
   uint8_t *buf = android_keyboard_state_get(port);
   int action  = AKeyEvent_getAction(event);

   /* some controllers send both the up and down events at once
    * when the button is released for "special" buttons, like menu buttons
    * work around that by only using down events for meta keys (which get
    * cleared every poll anyway)
    */
   switch (action)
   {
      case AKEY_EVENT_ACTION_UP:
         BIT_CLEAR(buf, keycode);
         break;
      case AKEY_EVENT_ACTION_DOWN:
         BIT_SET(buf, keycode);
         break;
   }

   if ((keycode == AKEYCODE_VOLUME_UP || keycode == AKEYCODE_VOLUME_DOWN))
      *handled = 0;
}

static int android_input_get_id_port(android_input_data_t *android_data, int id,
      int source)
{
   unsigned i;
   int ret = -1;
   if (source & (AINPUT_SOURCE_TOUCHSCREEN | AINPUT_SOURCE_MOUSE |
            AINPUT_SOURCE_TOUCHPAD))
         ret = 0; /* touch overlay is always user 1 */

   for (i = 0; i < android_data->pads_connected; i++)
      if (android_data->pad_states[i].id == id)
         ret = i;

   return ret;
}

/* Returns the index inside android->pad_state */
static int android_input_get_id_index_from_name(android_input_data_t *android_data,
      const char *name)
{
   int i;
   for (i = 0; i < android_data->pads_connected; i++)
   {
      if (string_is_equal(name, android_data->pad_states[i].name))
         return i;
   }

   return -1;
}

static void handle_hotplug(android_input_data_t *android_data,
      struct android_app *android_app, int *port, int id,
      int source)
{
   char device_name[256]        = {0};
   char device_model[256]       = {0};
   char name_buf[256]           = {0};
   int vendorId                 = 0;
   int productId                = 0;
   bool back_mapped             = false;
   settings_t         *settings = config_get_ptr();

   frontend_android_get_name(device_model, sizeof(device_model));

   VLOG(@"Device model: (%s).\n", device_model);

   if (*port > MAX_PADS)
   {
      ELOG(@"Max number of pads reached.\n");
      return;
   }

   if (!engine_lookup_name(device_name, &vendorId,
            &productId, sizeof(device_name), id))
   {
      ELOG(@"Could not look up device name or IDs.\n");
      return;
   }

   /* FIXME - per-device hacks for NVidia Shield, Xperia Play and
    * similar devices
    *
    * These hacks depend on autoconf, but can work with user
    * created autoconfs properly
    */

   /* NVIDIA Shield Console
    * This is the most complicated example, the built-in controller
    * has an extra button that can't be used and a remote.
    *
    * We map the remote for navigation and overwrite whenever a
    * real controller is connected.
    * Also group the NVIDIA button on the controller with the
    * main controller inputs so it's usable. It's mapped to
    * menu by default
    *
    * The NVIDIA button is identified as "Virtual" device when first
    * pressed. CEC remote input is also identified as "Virtual" device.
    * If a virtual device is detected before a controller then it will
    * be assigned to port 0 as "SHIELD Virtual Controller". When a real
    * controller is detected it will overwrite the virtual controller
    * and be grouped with the NVIDIA button of the virtual device.
    *
    */
   if(strstr(device_model, "SHIELD Android TV") && (
      strstr(device_name, "Virtual") ||
      strstr(device_name, "NVIDIA Corporation NVIDIA Controller v01.03")))
   {
      /* only use the hack if the device is one of the built-in devices */
      VLOG(@"Special Device Detected: %s\n", device_model);
      {
#if 0
         VLOG(@"- Pads Mapped: %d\n- Device Name: %s\n- IDS: %d, %d, %d",
               android_data->pads_connected, device_name, id, pad_id1, pad_id2);
#endif
         /* remove the remote or virtual controller device if it is mapped */
         if (strstr(android_data->pad_states[0].name,"SHIELD Remote") || 
            strstr(android_data->pad_states[0].name,"SHIELD Virtual Controller"))
         {
            pad_id1 = -1;
            pad_id2 = -1;
            android_data->pads_connected = 0;
            *port = 0;
            strlcpy(name_buf, device_name, sizeof(name_buf));
         }

         /* if the actual controller has not been mapped yet, 
          * then configure Virtual device for now */
         if (strstr(device_name, "Virtual") && android_data->pads_connected==0)
            strlcpy (name_buf, "SHIELD Virtual Controller", sizeof(name_buf));
         else
            strlcpy (name_buf, "NVIDIA SHIELD Controller", sizeof(name_buf));

         /* apply the hack only for the first controller
          * store the id for later use
         */
         if (strstr(device_name, "NVIDIA Corporation NVIDIA Controller v01.03") 
               && android_data->pads_connected==0)
            pad_id1 = id;
         else if (strstr(device_name, "Virtual") && pad_id1 != -1)
         {
            id = pad_id1;
            return;
         }
      }
   }

   /* NVIDIA Shield Portable
    * This is a simple hack, basically groups the "back"
    * button with the rest of the gamepad
    */
   else if(strstr(device_model, "SHIELD") && (
      strstr(device_name, "Virtual") || strstr(device_name, "gpio") ||
      strstr(device_name, "NVIDIA Corporation NVIDIA Controller v01.01")))
   {
      /* only use the hack if the device is one of the built-in devices */
      VLOG(@"Special Device Detected: %s\n", device_model);
      {
         if ( pad_id1 < 0 )
            pad_id1 = id;
         else
            pad_id2 = id;

         if ( pad_id2 > 0)
            return;

         strlcpy (name_buf, "NVIDIA SHIELD Portable", sizeof(name_buf));
      }
   }

   /* GPD XD
    * This is a simple hack, basically groups the "back"
    * button with the rest of the gamepad
    */
   else if(strstr(device_model, "XD") && (
      strstr(device_name, "Virtual") || strstr(device_name, "rk29-keypad") ||
      strstr(device_name,"Playstation3") || strstr(device_name,"XBOX")))
   {
      /* only use the hack if the device is one of the built-in devices */
      VLOG(@"Special Device Detected: %s\n", device_model);
      {
         if ( pad_id1 < 0 )
            pad_id1 = id;
         else
            pad_id2 = id;

         if ( pad_id2 > 0)
            return;

         strlcpy (name_buf, "GPD XD", sizeof(name_buf));
         *port = 0;
      }
   }

   /* XPERIA Play
    * This device is composed of two hid devices
    * We make it look like one device
    */
   else if(strstr(device_model, "R800") && 
         (
          strstr(device_name, "keypad-game-zeus") || 
          strstr(device_name, "keypad-zeus")
         )
         )
   {
      /* only use the hack if the device is one of the built-in devices */
      VLOG(@"Special Device Detected: %s\n", device_model);
      {
         if ( pad_id1 < 0 )
            pad_id1 = id;
         else
            pad_id2 = id;

         if ( pad_id2 > 0)
            return;

         strlcpy (name_buf, "XPERIA Play", sizeof(name_buf));
         *port = 0;
      }
   }

   /* ARCHOS Gamepad
    * This device is composed of two hid devices
    * We make it look like one device
    */
   else if(strstr(device_model, "ARCHOS GAMEPAD") && (
      strstr(device_name, "joy_key") || strstr(device_name, "joystick")))
   {
      /* only use the hack if the device is one of the built-in devices */
      VLOG(@"ARCHOS GAMEPAD Detected: %s\n", device_model);
      {
         if ( pad_id1 < 0 )
            pad_id1 = id;
         else
            pad_id2 = id;

         if ( pad_id2 > 0)
            return;

         strlcpy (name_buf, "ARCHOS GamePad", sizeof(name_buf));
         *port = 0;
      }
   }

   /* Other uncommon devices
    * These are mostly remote control type devices, bind them always to port 0
    * And overwrite the binding whenever a controller button is pressed
    */
   else if (strstr(device_name, "Amazon Fire TV Remote")
         || strstr(device_name, "Nexus Remote")
         || strstr(device_name, "SHIELD Remote"))
   {
      android_data->pads_connected = 0;
      *port = 0;
      strlcpy(name_buf, device_name, sizeof(name_buf));
   }

   else if (strstr(device_name, "iControlPad-"))
      strlcpy(name_buf, "iControlPad HID Joystick profile", sizeof(name_buf));

   else if (strstr(device_name, "TTT THT Arcade console 2P USB Play"))
   {
      if (*port == 0)
         strlcpy(name_buf, "TTT THT Arcade (User 1)", sizeof(name_buf));
      else if (*port == 1)
         strlcpy(name_buf, "TTT THT Arcade (User 2)", sizeof(name_buf));
   }
   else if (strstr(device_name, "MOGA"))
      strlcpy(name_buf, "Moga IME", sizeof(name_buf));

   /* If device is keyboard only and didn't match any of the devices above
    * then assume it is a keyboard, register the id, and return unless the
    * maximum number of keyboards are already registered. */
   else if(source == AINPUT_SOURCE_KEYBOARD && kbd_num < MAX_NUM_KEYBOARDS)
   {
      kbd_id[kbd_num] = id;
      kbd_num++;
      return;
   }

   /* if device was not keyboard only, yet did not match any of the devices
    * then try to autoconfigure as gamepad based on device_name. */
   else if (!string_is_empty(device_name))
      strlcpy(name_buf, device_name, sizeof(name_buf));

   if (strstr(android_app->current_ime, "net.obsidianx.android.mogaime"))
      strlcpy(name_buf, android_app->current_ime, sizeof(name_buf));
   else if (strstr(android_app->current_ime, "com.ccpcreations.android.WiiUseAndroid"))
      strlcpy(name_buf, android_app->current_ime, sizeof(name_buf));
   else if (strstr(android_app->current_ime, "com.hexad.bluezime"))
      strlcpy(name_buf, android_app->current_ime, sizeof(name_buf));

   if (*port < 0)
      *port = android_data->pads_connected;

   if (settings->input.autodetect_enable)
   {
      bool      autoconfigured;
      autoconfig_params_t params   = {{0}};

      VLOG(@"Pads Connected: %d Port: %d\n %s VID/PID: %d/%d\n",
            android_data->pads_connected, *port, name_buf,
            params.vid, params.pid);

      strlcpy(params.name, name_buf, sizeof(params.name));
      params.idx = *port;
      params.vid = vendorId;
      params.pid = productId;
      settings->input.pid[*port] = params.pid;
      settings->input.vid[*port] = params.vid;

      strlcpy(params.driver, android_joypad.ident, sizeof(params.driver));
      autoconfigured = input_config_autoconfigure_joypad(&params);

      if (autoconfigured)
      {
         if (settings->input.autoconf_binds[*port]
               [RARCH_MENU_TOGGLE].joykey != 0)
            back_mapped = true;
      }
   }

   if (!string_is_empty(name_buf))
   {
      strlcpy(settings->input.device_names[*port],
            name_buf, sizeof(settings->input.device_names[*port]));
   }

   if (!back_mapped && settings->input.back_as_menu_toggle_enable)
      settings->input.autoconf_binds[*port]
         [RARCH_MENU_TOGGLE].joykey = AKEYCODE_BACK;

   android_data->pad_states[android_data->pads_connected].id = id;
   android_data->pad_states[android_data->pads_connected].port = *port;
   strlcpy(android_data->pad_states[*port].name, name_buf,
         sizeof(android_data->pad_states[*port].name));

   android_data->pads_connected++;
}

static int android_input_get_id(AInputEvent *event)
{
   int id = AInputEvent_getDeviceId(event);

   if (id == pad_id2)
      id = pad_id1;

   return id;
}

static void android_input_poll_input(void *data)
{
   AInputEvent *event = NULL;
   struct android_app *android_app = (struct android_app*)g_android;
   android_input_t    *android     = (android_input_t*)data;
   android_input_data_t    *android_data     = (android_input_data_t*)&android->thread;

   /* Read all pending events. */
   while (AInputQueue_hasEvents(android_app->inputQueue))
   {
      while (AInputQueue_getEvent(android_app->inputQueue, &event) >= 0)
      {
         int32_t   handled = 1;
         int predispatched = AInputQueue_preDispatchEvent(android_app->inputQueue, event);
         int        source = AInputEvent_getSource(event);
         int    type_event = AInputEvent_getType(event);
         int            id = android_input_get_id(event);
         int          port = android_input_get_id_port(android_data, id, source);

         if (port < 0 && !is_keyboard_id(id))
            handle_hotplug(android_data, android_app,
            &port, id, source);
 
         switch (type_event)
         {
            case AINPUT_EVENT_TYPE_MOTION:
               if (android_input_poll_event_type_motion(android_data, event,
                        port, source))
                  engine_handle_dpad(android_data, event, port, source);
               break;
            case AINPUT_EVENT_TYPE_KEY:
               {
                  int keycode = AKeyEvent_getKeyCode(event);

                  if (is_keyboard_id(id))
                  {
                     if (!predispatched)
                     {
                        android_input_poll_event_type_keyboard(event, keycode, &handled);
                        android_input_poll_event_type_key(android_app, event, ANDROID_KEYBOARD_PORT, keycode, source, type_event, &handled);
                     }
                  }
                  else
                     android_input_poll_event_type_key(android_app,
                        event, port, keycode, source, type_event, &handled);
               }
               break;
         }

         if (!predispatched)
            AInputQueue_finishEvent(android_app->inputQueue, event,
                  handled);
      }
   }
}

static void android_input_poll_user(void *data)
{
   struct android_app *android_app = (struct android_app*)g_android;
   android_input_t    *android     = (android_input_t*)data;
   android_input_data_t *android_data = (android_input_data_t*)&android->thread;

   if ((android_app->sensor_state_mask & (UINT64_C(1) <<
               RETRO_SENSOR_ACCELEROMETER_ENABLE))
         && android_app->accelerometerSensor)
   {
      ASensorEvent event;
      while (ASensorEventQueue_getEvents(android_app->sensorEventQueue, &event, 1) > 0)
      {
         android_data->accelerometer_state.x = event.acceleration.x;
         android_data->accelerometer_state.y = event.acceleration.y;
         android_data->accelerometer_state.z = event.acceleration.z;
      }
   }
}

static void android_input_poll_memcpy(void *data)
{
   unsigned i, j;
   android_input_t    *android     = (android_input_t*)data;
   struct android_app *android_app = (struct android_app*)g_android;
   
   memcpy(&android->copy, &android->thread, sizeof(android->copy));
   
   for (i = 0; i < MAX_PADS; i++)
   {
      for (j = 0; j < 2; j++)
         android_app->hat_state[i][j]    = android->copy.hat_state[i][j];
      for (j = 0; j < MAX_AXIS; j++)
         android_app->analog_state[i][j] = android->copy.analog_state[i][j];
   }
}

/* Handle all events. If our activity is in pause state,
 * block until we're unpaused.
 */
static void android_input_poll(void *data)
{
   int ident;
   unsigned key                    = RARCH_PAUSE_TOGGLE;
   struct android_app *android_app = (struct android_app*)g_android;

   while ((ident =
            ALooper_pollAll((input_driver_key_pressed(&key))
               ? -1 : 1,
               NULL, NULL, NULL)) >= 0)
   {
      switch (ident)
      {
         case LOOPER_ID_INPUT:
            android_input_poll_input(data);
            break;
         case LOOPER_ID_USER:
            android_input_poll_user(data);
            break;
         case LOOPER_ID_MAIN:
            android_input_poll_main_cmd();
            break;
      }
      
      if (android_app->destroyRequested != 0)
      {
         runloop_ctl(RUNLOOP_CTL_SET_SHUTDOWN, NULL);
         return;
      }

      if (android_app->reinitRequested != 0)
      {
         if (runloop_ctl(RUNLOOP_CTL_IS_PAUSED, NULL))
            command_event(CMD_EVENT_REINIT, NULL);
         android_app_write_cmd(android_app, APP_CMD_REINIT_DONE);
         return;
      }
   }

   if (android_app->input_alive)
      android_input_poll_memcpy(data);
}

bool android_run_events(void *data)
{
   struct android_app *android_app = (struct android_app*)g_android;

   if (ALooper_pollOnce(-1, NULL, NULL, NULL) == LOOPER_ID_MAIN)
      android_input_poll_main_cmd();

   /* Check if we are exiting. */
   if (android_app->destroyRequested != 0)
   {
      runloop_ctl(RUNLOOP_CTL_SET_SHUTDOWN, NULL);
      return false;
   }

   if (android_app->reinitRequested != 0)
   {
      if (runloop_ctl(RUNLOOP_CTL_IS_PAUSED, NULL))
         command_event(CMD_EVENT_REINIT, NULL);
      android_app_write_cmd(android_app, APP_CMD_REINIT_DONE);
   }

   return true;
}

static int16_t android_input_state(void *data,
      const struct retro_keybind **binds, unsigned port, unsigned device,
      unsigned idx, unsigned id)
{
   settings_t *settings = config_get_ptr();
   android_input_t *android = (android_input_t*)data;
   android_input_data_t *android_data = (android_input_data_t*)&android->copy;

   switch (device)
   {
      case RETRO_DEVICE_JOYPAD:
         return input_joypad_pressed(android->joypad, port, binds[port], id) ||
                android_keyboard_port_input_pressed(binds[port],id);
      case RETRO_DEVICE_ANALOG:
         return input_joypad_analog(android->joypad, port, idx, id,
               binds[port]);
      case RETRO_DEVICE_POINTER:
         switch (id)
         {
            case RETRO_DEVICE_ID_POINTER_X:
               return android_data->pointer[idx].x;
            case RETRO_DEVICE_ID_POINTER_Y:
               return android_data->pointer[idx].y;
            case RETRO_DEVICE_ID_POINTER_PRESSED:
               return (idx < android_data->pointer_count) &&
                  (android_data->pointer[idx].x != -0x8000) &&
                  (android_data->pointer[idx].y != -0x8000);
            case RARCH_DEVICE_ID_POINTER_BACK:
               if(settings->input.autoconf_binds[0][RARCH_MENU_TOGGLE].joykey == 0)
                  return android_keyboard_input_pressed(AKEYCODE_BACK);
         }
         break;
      case RARCH_DEVICE_POINTER_SCREEN:
         switch (id)
         {
            case RETRO_DEVICE_ID_POINTER_X:
               return android_data->pointer[idx].full_x;
            case RETRO_DEVICE_ID_POINTER_Y:
               return android_data->pointer[idx].full_y;
            case RETRO_DEVICE_ID_POINTER_PRESSED:
               return (idx < android_data->pointer_count) &&
                  (android_data->pointer[idx].full_x != -0x8000) &&
                  (android_data->pointer[idx].full_y != -0x8000);
            case RARCH_DEVICE_ID_POINTER_BACK:
               if(settings->input.autoconf_binds[0][RARCH_MENU_TOGGLE].joykey == 0)
                  return android_keyboard_input_pressed(AKEYCODE_BACK);
         }
         break;
   }

   return 0;
}

static bool android_input_key_pressed(void *data, int key)
{
   android_input_t *android = (android_input_t*)data;
   settings_t *settings     = config_get_ptr();

   if(android_keyboard_port_input_pressed(settings->input.binds[0],key))
      return true;

   if (input_joypad_pressed(android->joypad,
         0, settings->input.binds[0], key))
      return true;

   return false;
}

static bool android_input_meta_key_pressed(void *data, int key)
{
   return false;
}

static void android_input_free_input(void *data)
{
   android_input_t *android = (android_input_t*)data;
   struct android_app *android_app = (struct android_app*)g_android;
   if (!android)
      return;

   if (android_app->sensorManager)
      ASensorManager_destroyEventQueue(android_app->sensorManager,
            android_app->sensorEventQueue);

   if (android->joypad)
      android->joypad->destroy();
   android->joypad = NULL;

   android_app->input_alive = false;

   dylib_close((dylib_t)libandroid_handle);
   libandroid_handle = NULL;

   android_keyboard_free();
   free(data);
}

static uint64_t android_input_get_capabilities(void *data)
{
   (void)data;

   return
      (1 << RETRO_DEVICE_JOYPAD)  |
      (1 << RETRO_DEVICE_POINTER) |
      (1 << RETRO_DEVICE_ANALOG);
}

static void android_input_enable_sensor_manager(struct android_app *android_app)
{
   android_app->sensorManager = ASensorManager_getInstance();
   android_app->accelerometerSensor =
      ASensorManager_getDefaultSensor(android_app->sensorManager,
         ASENSOR_TYPE_ACCELEROMETER);
   android_app->sensorEventQueue =
      ASensorManager_createEventQueue(android_app->sensorManager,
         android_app->looper, LOOPER_ID_USER, NULL, NULL);
}

static bool android_input_set_sensor_state(void *data, unsigned port,
      enum retro_sensor_action action, unsigned event_rate)
{
   struct android_app *android_app = (struct android_app*)g_android;

   if (event_rate == 0)
      event_rate = 60;

   switch (action)
   {
      case RETRO_SENSOR_ACCELEROMETER_ENABLE:
         if (!android_app->accelerometerSensor)
            android_input_enable_sensor_manager(android_app);

         if (android_app->accelerometerSensor)
            ASensorEventQueue_enableSensor(android_app->sensorEventQueue,
                  android_app->accelerometerSensor);

         /* Events per second (in microseconds). */
         if (android_app->accelerometerSensor)
            ASensorEventQueue_setEventRate(android_app->sensorEventQueue,
                  android_app->accelerometerSensor, (1000L / event_rate)
                  * 1000);

         BIT64_CLEAR(android_app->sensor_state_mask, RETRO_SENSOR_ACCELEROMETER_DISABLE);
         BIT64_SET(android_app->sensor_state_mask, RETRO_SENSOR_ACCELEROMETER_ENABLE);
         return true;

      case RETRO_SENSOR_ACCELEROMETER_DISABLE:
         if (android_app->accelerometerSensor)
            ASensorEventQueue_disableSensor(android_app->sensorEventQueue,
                  android_app->accelerometerSensor);

         BIT64_CLEAR(android_app->sensor_state_mask, RETRO_SENSOR_ACCELEROMETER_ENABLE);
         BIT64_SET(android_app->sensor_state_mask, RETRO_SENSOR_ACCELEROMETER_DISABLE);
         return true;
      default:
         return false;
   }

   return false;
}

static float android_input_get_sensor_input(void *data,
      unsigned port,unsigned id)
{
   android_input_t      *android      = (android_input_t*)data;
   android_input_data_t *android_data = (android_input_data_t*)&android->copy;

   switch (id)
   {
      case RETRO_SENSOR_ACCELEROMETER_X:
         return android_data->accelerometer_state.x;
      case RETRO_SENSOR_ACCELEROMETER_Y:
         return android_data->accelerometer_state.y;
      case RETRO_SENSOR_ACCELEROMETER_Z:
         return android_data->accelerometer_state.z;
   }

   return 0;
}

static const input_device_driver_t *android_input_get_joypad_driver(void *data)
{
   android_input_t *android = (android_input_t*)data;
   if (!android)
      return NULL;
   return android->joypad;
}

static bool android_input_keyboard_mapping_is_blocked(void *data)
{
   android_input_t *android = (android_input_t*)data;
   if (!android)
      return false;
   return android->blocked;
}

static void android_input_keyboard_mapping_set_block(void *data, bool value)
{
   android_input_t *android = (android_input_t*)data;
   if (!android)
      return;
   android->blocked = value;
}

static void android_input_grab_mouse(void *data, bool state)
{
   (void)data;
   (void)state;
}

static bool android_input_set_rumble(void *data, unsigned port,
      enum retro_rumble_effect effect, uint16_t strength)
{
   (void)data;
   (void)port;
   (void)effect;
   (void)strength;

   return false;
}

input_driver_t input_android = {
   android_input_init,
   android_input_poll,
   android_input_state,
   android_input_key_pressed,
   android_input_meta_key_pressed,
   android_input_free_input,
   android_input_set_sensor_state,
   android_input_get_sensor_input,
   android_input_get_capabilities,
   "android",

   android_input_grab_mouse,
   NULL,
   android_input_set_rumble,
   android_input_get_joypad_driver,
   NULL,
   android_input_keyboard_mapping_is_blocked,
   android_input_keyboard_mapping_set_block,
};

gha: C, lang: cpp
<div align="center">
<h3 style="color: #dd3f3c">Simple-Music</h3>

[![forthebadge](https://forthebadge.com/images/badges/made-with-vue.svg)](https://forthebadge.com)
[![forthebadge](https://forthebadge.com/images/badges/makes-people-smile.svg)](https://forthebadge.com)

<p>Vue练手项目</p>
</div>


## Build Setup

``` bash
# install dependencies
npm install

# serve with hot reload at localhost:8080
npm run dev

# type url in browser
localhost:8080
```

## 项目一览 ![70](https://img.lishengcn.cn/progress?percent=65&color=c92d36)

<img src="https://github.com/JiangWeixian/simple-music/blob/dev/protoPicture/pages/README/friends.gif" width="200"/> <img src="https://github.com/JiangWeixian/simple-music/blob/dev/protoPicture/pages/README/mine.gif" width="200"/><img src="https://github.com/JiangWeixian/simple-music/blob/dev/protoPicture/pages/README/recommed.gif" width="200"/><img src="https://github.com/JiangWeixian/simple-music/blob/dev/protoPicture/pages/README/singer.gif" width="200"/><img src="https://github.com/JiangWeixian/simple-music/blob/dev/protoPicture/pages/README/userh.gif" width="200"/>

## Thanks

Thanks[@CheckLee](https://github.com/CheckLee/simple-music)

Thanks[@JiangWeixian](https://github.com/JiangWeixian/simple-music/)

gha: JavaScript, lang: markdown
import { CacheContainerOptions, CacheReturnType } from '../..';

import { MemoryCacheObject } from '../../cache/memory/object/memory-cache.object';
import { SessionCacheObject } from '../../cache/persistent/session/object/session-cache.object';

describe('Cache Object', () => {
  const key: string = 'key';
  const args: string = 'args';
  const cache: string = 'cache';
  const ttl: number = 50;

  describe('default', () => {
    const cacheObject: MemoryCacheObject = new MemoryCacheObject({ key });

    it('should have cache after set', () => {
      cacheObject.setCache(args, cache);
      expect(cacheObject.hasCache(args)).toBeTruthy();
    });

    it('should have the same cache as set', () => {
      cacheObject.setCache(args, cache);
      expect(cacheObject.getCache(args)).toEqual(cache);
    });

    it('should have no cache after clear', () => {
      cacheObject.setCache(args, cache);
      cacheObject.clearArgs(args);
      expect(cacheObject.hasCache(args)).toBeFalsy();

      cacheObject.setCache(args, cache);
      cacheObject.clear();
      expect(cacheObject.hasCache(args)).toBeFalsy();
    });

    it('should not be expired', () => {
      cacheObject.setCache(args, cache);
      expect(cacheObject.isExpired(args)).toBeFalsy();
    });
  });

  describe('TTL', () => {
    describe('using seconds', () => {
      const cacheObject: MemoryCacheObject = new MemoryCacheObject({ key, ttl: ttl / 1000 });

      beforeEach(() => {
        cacheObject.setCache(args, cache);
      });

      it('should not be expired', () => {
        expect(cacheObject.isExpired(args)).toBeFalsy();
      });

      it('should be expired', done => {
        setTimeout(() => {
          expect(cacheObject.isExpired(args)).toBeTruthy();
          done();
        }, ttl + 1);
      });
    });

    describe('using date object', () => {
      let cacheObject: MemoryCacheObject;

      beforeEach(() => {
        cacheObject = new MemoryCacheObject({ key, ttl: new Date(Date.now() + ttl) });
        cacheObject.setCache(args, cache);
      });

      it('should not be expired', () => {
        expect(cacheObject.isExpired(args)).toBeFalsy();
      });

      it('should be expired', done => {
        setTimeout(() => {
          expect(cacheObject.isExpired(args)).toBeTruthy();
          done();
        }, ttl + 1);
      });
    });

    describe('using date string', () => {
      let timestamp: number = Date.now() + ttl;
      let cacheObject: MemoryCacheObject;

      beforeEach(() => {
        timestamp = Date.now() + ttl;
        const dateString: string = new Date(timestamp).toLocaleString();
        cacheObject = new MemoryCacheObject({ key, ttl: dateString });
        cacheObject.setCache(args, cache);
      });

      it('should have close to the same timestamp as the date string given', () => {
        expect(cacheObject['ttl'][args] - timestamp).toBeLessThan(2000);
      });

      it('should not be expired', () => {
        expect(cacheObject.isExpired(args)).toBeFalsy();
      });

      it('should be expired', done => {
        setTimeout(() => {
          expect(cacheObject.isExpired(args)).toBeTruthy();
          done();
        }, ttl + 1);
      });
    });
  });

  describe('inherit Cache Container Options', () => {
    const options: CacheContainerOptions = {
      key,
      returnType: CacheReturnType.Promise,
      ttl
    };

    it('should inherit the returnType', () => {
      const cacheObject: MemoryCacheObject = new MemoryCacheObject({ key });
      cacheObject.inheritContainerOptions(options);
      expect(cacheObject.options.returnType).toEqual(CacheReturnType.Promise);
    });

    it('should inherit the ttl', () => {
      const cacheObject: MemoryCacheObject = new MemoryCacheObject({ key });
      cacheObject.inheritContainerOptions(options);
      expect(cacheObject.options.ttl).toEqual(ttl);
    });

    it('should not override the returnType', () => {
      const cacheObject: SessionCacheObject = new SessionCacheObject({ key, returnType: CacheReturnType.Promise });
      cacheObject.inheritContainerOptions(options);
      expect(cacheObject.options.returnType).toEqual(CacheReturnType.Promise);
    });

    it('should not override the ttl', () => {
      const cacheObject: MemoryCacheObject = new MemoryCacheObject({ key, ttl: ttl * 10 });
      cacheObject.inheritContainerOptions(options);
      expect(cacheObject.options.ttl).toEqual(ttl * 10);
    });
  });
});

gha: TypeScript, lang: javascript
/// handles all pause menu logic - ran when clicking any pause menu object

if text = 'Resume'
{
    with (parent_button_pause) instance_destroy()
    instance_activate_all()
}

if text = 'Exit' // exit to main menu
{
    instance_activate_all()
    room_goto(room_menu)
}


gha: Game Maker Language, lang: groovy
import uniqid from 'uniqid';
import { clone } from './clone';

export const assignIds = (data: any): any => {
  data = { children: clone(data) };

  const run = (d: any): any => {
    if (typeof d.children !== 'undefined') {
      d.children = d.children.map((item: any) => {
        item.id = uniqid();
        return run(item);
      });
    }

    return d;
  };

  return run(data).children;
};

gha: TypeScript, lang: javascript
---
layout: post 
title:  "진격의 거인-후회없는 1 2 세트(전2권)(15세미만구독불가), 학산문화사(주)" 
description: 진격의 거인-후회없는 1 2 ..
date: 2021-01-21 08:03:32 
img: https://static.coupangcdn.com/image/vendor_inventory/33c5/bd565c2261fe12c2e0b8452fe200bededff257b56fb57fc20febec9de0a0.jpg 
linkUrl: https://link.coupang.com/re/AFFSDP?lptag=AF3600438&subid=ahnPublicAsk&pageKey=2034422519&itemId=3459487829&vendorItemId=71445864108&traceid=V0-113-57360ed3d7e6f7c0 
categories: [1019] 
color: FF6F00 
price: 6480 
author: Ask View Shop 
---
 
gha: HTML, lang: yaml


# PaymentDeviceSaleTransaction

## Properties

Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**paymentMethod** | [**PaymentDevicePaymentMethod**](PaymentDevicePaymentMethod.md) |  | 
**createToken** | [**CreatePaymentToken**](CreatePaymentToken.md) |  |  [optional]
**storedCredentials** | [**StoredCredential**](StoredCredential.md) |  |  [optional]




gha: Java, lang: markdown
const devProdUrl = window.location.host.includes("localhost")
    ? "http://localhost:5000/"
    : "https://mybuzzin.herokuapp.com/";

export default devProdUrl;

gha: JavaScript, lang: batchfile
﻿using System;
using System.Collections.Generic;
using System.Text;

namespace Azure.Functions.Cli.Telemetry
{
    class TelemetryEvent
    {
        public TelemetryEvent()
        {
            Parameters = new List<string>();
            CommandEvents = new Dictionary<string, string>();
            GlobalSettings = new Dictionary<string, string>();
        }

        public string CommandName { get; set; }

        public string IActionName { get; set; }

        public IEnumerable<string> Parameters { get; set; }

        public bool PrefixOrScriptRoot { get; set; }

        public bool IsSuccessful { get; set; }

        public bool ParseError { get; set; }

        public long TimeTaken { get; set; }

        public IDictionary<string, string> CommandEvents { get; set; }

        public IDictionary<string, string> GlobalSettings { get; set; }
    }
}

gha: C#, lang: c_sharp
<template>
  <v-container grid-list-md text-xs-center>
    <v-form
      ref="form"
      v-model="valid">
    <v-text-field
      v-model="selectedYear"
      :rules="yearErrors"
      :counter="4"
      label="Year"
      required
    ></v-text-field>
    <v-select
      v-model="selectedSeason"
      :items="seasonItems"
      label="Season"
      required
    ></v-select>
      <nuxt-link :to="selectedSeasonPath"
      :disabled="!valid">
        <v-btn nuxt color="primary" 
          :disabled="!valid">
        Go
        </v-btn>
      </nuxt-link>
      <v-btn color="error" 
        @click="resetForm">
        Current
      </v-btn>
    </v-form>
    <v-layout align-center justify-center fill-height row wrap>
      <v-flex xs6 sm3 v-for="(cardSeason, i) in cardSeasons" :key="i">
        <season-card 
          :season="cardSeason"
        />
      </v-flex>
    </v-layout>
  </v-container>
</template>

<script>
import SeasonCard from '@/components/season/SeasonCard.vue';


export default {
  name: 'SeasonSearchPage',
  components: {
    'season-card': SeasonCard,
  },
  data() {
    return {
      valid: true,
      selectedYear: '2019',
      currentYear: '2019',
      yearErrors: [
        v => !!v || 'Year is required.',
        v => (v && Number.isInteger(Number(v))) || 'Year must be a number between 1917 and ' + new Date().getFullYear(),
        v => (Number(v) <= new Date().getFullYear() && Number(v) >= 1917) || 'Year must be a number between 1917 and ' + new Date().getFullYear()
      ],
      selectedSeason: 'Winter',
      currentSeason: 'Winter',
      seasonItems: [
        'Winter',
        'Spring',
        'Summer',
        'Fall'
      ]
    }
  },
  computed: {
    selectedSeasonPath() {
      return 'season/' + this.selectedYear + '/' + this.selectedSeason.toLowerCase(); 
    },
    cardSeasons() {
      return [
        { name: this.seasonItems[this.mod(this.seasonItems.indexOf(this.currentSeason) - 2, 4)], year: this.currentSeason === 'Winter' || this.currentSeason === 'Spring' ? this.currentYear - 1 : this.currentYear},
        { name: this.seasonItems[this.mod(this.seasonItems.indexOf(this.currentSeason) - 1, 4)], year: this.currentSeason === 'Winter' ? this.currentYear - 1 : this.currentYear},
        { name: this.currentSeason, year: this.currentYear},
        { name: this.seasonItems[this.mod(this.seasonItems.indexOf(this.currentSeason) + 1, 4)], year: this.currentSeason === 'Fall' ? this.currentYear + 1 : this.currentYear}
      ]
    }
  },
  methods: {
    resetForm() {
      var currentDate = new Date();
      this.currentYear = currentDate.getFullYear();
      this.currentSeason = this.seasonItems[Math.floor(currentDate.getMonth() / 3)];
      this.selectedYear = this.currentYear;
      this.selectedSeason = this.currentSeason
    }
  },
  mounted() {
    this.resetForm();
  }
}
</script>

gha: C#, lang: javascript
import Vue from "vue";
import Router from "vue-router";
import Home from "@/components/pages/Home";
import User from "@/components/pages/User";
import Repositories from "@/components/pages/Repositories";

Vue.use(Router);

export default new Router({
  mode: "history",
  routes: [
    {
      path: "/",
      name: "home",
      component: Home
    },
    {
      path: "/users/:username",
      name: "user",
      component: User,
      props: true
    },
    {
      path: "/users/:username/repositories",
      name: "repositories",
      component: Repositories,
      props: true
    }
  ]
});

gha: Vue, lang: javascript
# Dockerfile for {{ cookiecutter.project_name }}. Build it using:
#
#     $ docker build -t {{ cookiecutter.repo_name }} .
#
# You can then run it as a container:
#
#     $ docker run --rm {{ cookiecutter.repo_name }}

FROM python:3.8.5-slim

# Install Python dependencies with pip
COPY requirements.txt .
RUN python -m pip install -r requirements.txt --no-cache-dir --disable-pip-version-check

# Create working directory
WORKDIR /{{ cookiecutter.repo_name }}

# Install {{ cookiecutter.repo_name }}
COPY MANIFEST.in setup.cfg setup.py ./
COPY {{ cookiecutter.repo_name }} ./{{ cookiecutter.repo_name }}
RUN python -m pip install -e . --no-cache-dir --disable-pip-version-check

# The container runs this commands, options can be set as environment variables
ENV {{ cookiecutter.exe_name|upper }}_PIPELINE={{cookiecutter.default_pipeline}}
ENV {{ cookiecutter.exe_name|upper }}_OPTIONS=
CMD {{ cookiecutter.exe_name }} ${{ cookiecutter.exe_name|upper }}_PIPELINE ${{ cookiecutter.exe_name|upper }}_OPTIONS

gha: Python, lang: dockerfile
# Metadatas

All tracking tables maintains the state of each row. 
Especially for deleted rows.   
So, over time, we can have an increase of these tracking tables, with a lot of rows that are not useful anymore.
These **metadatas rows** are present on the server side of course, and also on the **client side**.

## Client side

On the client side, once the client has made a synchronization with success, we can easily purge the metadata rows from all the local tracking tables.  

The `CleanMetadatas` option (boolean true / false available through the `SyncOptions` object) allows you to clean automatically the `_tracking` tables metadata rows from your client databases.  

If enabled, the client database will basically delete all the metadata rows from the tracking tables, after every successful sync.  
Be careful, the metadata rows purge will:
* Work only if the client has downloaded *something* from the server. If there is no changes downloaded and applied on the client, `DeleteMetadasAsync()` is not called
* Work only on T-2 metadata rows. To be more secure, the T-1 values stays in the tracking tables.

So far, the client side is easy to maintain, since it's by default, automatic.

## Server side

There is no automatic mechanism on the server side. Mainly because **DMS** does not know *when* he should clean the metadata rows.   

> Indeed we can launch the metadata rows cleanup routine after *every* client synchronization, but it will lead to an non-necessary overhead and will extend the time needed for each sync

Basically, the most important is to keep the metadata rows as long as one client needs them to retrieve the deleted / updated rows.   
Once all clients have made a sync and are up to date at time **T**, we can theoricaly supposing that the metadata rows from **0** to **T-1** are not needed anymore.

The easiest way to achieve that, on the server side, is to create a schedule task and call the `DeleteMetadatasAsync` method (from a console application, service windows, whatever...) with this kind of code:

``` csharp
var remoteOrchestrator = new RemoteOrchestrator(serverProvider, options, setup);
remoteOrchestrator.DeleteMetadatasAsync();

```

**DMS** will delete the metadata rows in the safest way to ensure no client become *out-dated*.

### How does it work

What happens under the hood ?

**DMS** will try to get the *min* timestamp available from the `scope_info_history` table to ensure that no clients becomes *out-dated*.

Basically, if you have this kind of `scope_info_history` table :

``` sql
SELECT [sync_scope_id] ,[sync_scope_name] ,[scope_last_sync_timestamp], [scope_last_sync]
FROM [AdventureWorks].[dbo].[scope_info_history]
```
**Server database:**   
sync_scope_id | sync_scope_name | scope_last_sync_timestamp | scope_last_sync   
------------- | ----------| ------------ | -----------------   
9E9722CD-... | DefaultScope | 2090 | 2020-04-01   
AB4122AE-... | DefaultScope | 2100 | 2020-04-10   
DB6EEC7E-... | DefaultScope | **2000** | 2020-03-20   
E9CBB51D-... | DefaultScope | 2020 | 2020-03-21   
CC8A9184-... | DefaultScope | 2030 | 2020-03-22   
D789288E-... | DefaultScope | 2040 | 2020-03-23   
95425970-... | DefaultScope | 2050 | 2020-03-24   
5B6ACCC0-... | DefaultScope | 2060 | 2020-03-25   

the `Min(scope_last_sync_timestamp)` will be **2000** and then **DMS** will internally call `remoteOrchestrator.DeleteMetadatasAsync(2000);`

### Going further

Now imagine we have one client that did a first sync, and then **never did a sync again for 3 years** ... 
This situation will lead to this kind of rows in the `scope_info_history` table:

``` sql
SELECT [sync_scope_id] ,[sync_scope_name] ,[scope_last_sync_timestamp], [scope_last_sync]
FROM [AdventureWorks].[dbo].[scope_info_history]
```
**Server database:**    
sync_scope_id | sync_scope_name | scope_last_sync_timestamp | scope_last_sync   
------------- | ----------| ------------ | -----------------   
9E9722CD-... | DefaultScope | **100** | **2017-01-01**   
AB4122AE-... | DefaultScope | 2100 | 2020-04-10   
DB6EEC7E-... | DefaultScope | 2000 | 2020-03-20   
E9CBB51D-... | DefaultScope | 2020 | 2020-03-21   
CC8A9184-... | DefaultScope | 2030 | 2020-03-22   
D789288E-... | DefaultScope | 2040 | 2020-03-23   
95425970-... | DefaultScope | 2050 | 2020-03-24   
5B6ACCC0-... | DefaultScope | 2060 | 2020-03-25   

Once again, if you call the `remoteOrchestrator.DeleteMetadatasAsync()` from your schedule task, internally **DMS** will delete all rows where timestamp is inferior to **100** (and so far, all metadata rows existing before year 2017)

It's not really interesting to keep **all** the metadata rows from **2017** to **2020**, just because of **One** client who never did a sync since 2017...
Eventually we can assume this client has removed the app or changed his mobile device or whatever. We can argue that this client can be considered as *out-dated* and will have to **reinitialize** everything if he tries to sync again.

Then how to create a scheduled taks with that will workaround this situation ?

Well, can make this assumption
- We will run the `DeleteMetadatasAsync()` every month (or weeks, choose the best interval for you)
- Each run will take the `Min(scope_last_sync_timestamp)` from the `scope_info_history` table for all client that have, at least, sync during the last **30** days.

The code became:

``` csharp
// get all history lines from `scope_info_history`
var histories = await remoteOrchestrator.GetServerHistoryScopes();

// select only clients that have synced at least 30 days earlier
var historiesTwoWeeksAgo = histories.Where(h => h.LastSync.HasValue && h.LastSync.Value >= DateTime.Now.AddDays(-30));

// Get the min timestamp
var minTimestamp = historiesTwoWeeksAgo.Min(h => h.LastSyncTimestamp);

// Call the delete metadatas with this timestamp
await remoteOrchestrator.DeleteMetadatasAsync(minTimestamp);
```

Grab this code, create a *routine* to execute every month, and your server database won't growth too much because of the tracking tables metadata rows.
gha: C#, lang: markdown
import { Location } from '@angular/common';
import { Component, OnInit, ViewEncapsulation } from '@angular/core';
import { DomSanitizer } from '@angular/platform-browser';
import { ActivatedRoute } from '@angular/router';
import { LoginService } from 'src/app/services/login.service';
import { ProxyService } from 'src/app/services/proxy.service';
import firebase from 'firebase/app';
import { Observable } from 'rxjs';

@Component({
  selector: 'app-details-page',
  templateUrl: './details-page.component.html',
  styleUrls: ['./details-page.component.scss'],
  encapsulation: ViewEncapsulation.None
})
export class DetailsPageComponent implements OnInit {

  authUser!: Observable<firebase.User>;
  routeSub: any;
  currentAttraction: any;
  favorited: boolean = false;

  constructor(
    public location: Location,
    public sanitizer: DomSanitizer,
    private loginService: LoginService,
    private activatedRoute: ActivatedRoute,
    private proxyService: ProxyService) { }

  ngOnInit(): void {

    this.authUser = this.loginService.getLoggedInUser();
    this.routeSub = this.activatedRoute.params.subscribe(params => {
      let attractionId = params['id'];
      this.currentAttraction = this.proxyService.getAttractionById(attractionId);
      this.currentAttraction.video = 'https://www.youtube.com/embed/' + this.currentAttraction.video;
    });
  }

  onBackClick(): void {
    this.location.back();
  }

  onAttractionFavorited() {
    this.proxyService.markAttractionAsSelected(
      this.currentAttraction.id, !this.currentAttraction.isSelected);
  }
}

gha: TypeScript, lang: javascript
CREATE EXTENSION test_copy_callbacks;
CREATE TABLE public.test (a INT, b INT, c INT);
INSERT INTO public.test VALUES (1, 2, 3), (12, 34, 56), (123, 456, 789);
SELECT test_copy_to_callback('public.test'::pg_catalog.regclass);

gha: C, lang: sql
import React from 'react';

import './styles.css'

const HeaderLinks: React.FC = () => (
  <ul className='head-links'>

    <li>
      <a href={`/login`}>
        login
      </a>
    </li>

    <li>
      <a href={`/patient`}>
        patient
      </a>
    </li>

    <li>
      <a href={`/specialist`}>
        specialist
      </a>
    </li>

    <li>
      <a href={`/occupation`}>
        occupation
      </a>
    </li>

    <li>
      <a href={`/calls`}>
        calendar
      </a>
    </li>

    <li>
      <a href={`/record`}>
        prontuario
      </a>
    </li>

    <li>
      <a href={`/history`}>
        historico
      </a>
    </li>
  </ul>
);

export default HeaderLinks
gha: TypeScript, lang: coffeescript
#include <iostream>
#include <vector>
using namespace std;
vector<int>adj[10001];
int p[10001][17];
int depth[10001];
void go(int now, int p) {
    depth[now] = depth[p] + 1;
    for (int next : adj[now]) {
        go(next, now);
    }
}
int lca(int u, int v) {
    if (depth[u] < depth[v]) u ^= v ^= u ^= v;
    
    for (int i = 16; i >= 0; --i) {
        if (depth[u] - depth[v] >= (1 << i)) {
            u = p[u][i];
        }
    }
    if (u == v) return u;
    for (int i = 16; i >= 0; --i) {
        if (p[u][i] != p[v][i]) {
            u = p[u][i];
            v = p[v][i];
        }
    }
    return p[u][0];
}
int main() {
    ios_base::sync_with_stdio(false), cin.tie(0);
    int T; cin >> T;
    while (T--) {
        int n; cin >> n;
        for (int i = 1; i <= n; ++i) adj[i].clear(), p[i][0] = i, depth[i] = 0;
        for (int i = 1, u, v; i < n; ++i) {
            cin >> u >> v;
            adj[u].push_back(v);
            p[v][0] = u;
        }
        int root = -1;
        for (int i = 1; i <= n; ++i) {
            if (p[i][0] == i) root = i;
        }
        go(root, root);
        for (int j = 1; (1 << j) <= n; ++j) {
            for (int i = 1; i <= n; ++i) {
                p[i][j] = p[p[i][j - 1]][j - 1];
            }
        }
        int x, y; cin >> x >> y; cout << lca(x, y) << '\n';
    }
}
gha: C++, lang: cpp
# OryClient::NormalizedProjectRevisionHook

## Properties

| Name | Type | Description | Notes |
| ---- | ---- | ----------- | ----- |
| **config_key** | **String** | The Hooks Config Key |  |
| **created_at** | **Time** | The Project&#39;s Revision Creation Date | [optional][readonly] |
| **hook** | **String** | The Hook Type |  |
| **id** | **String** | ID of the entry | [optional] |
| **project_revision_id** | **String** | The Revision&#39;s ID this schema belongs to | [optional] |
| **updated_at** | **Time** | Last Time Project&#39;s Revision was Updated | [optional][readonly] |
| **web_hook_config_auth_api_key_in** | **String** | Whether to send the API Key in the HTTP Header or as a HTTP Cookie | [optional] |
| **web_hook_config_auth_api_key_name** | **String** | The name of the api key | [optional] |
| **web_hook_config_auth_api_key_value** | **String** | The value of the api key | [optional] |
| **web_hook_config_auth_basic_auth_password** | **String** | The password to be sent in the HTTP Basic Auth Header | [optional] |
| **web_hook_config_auth_basic_auth_user** | **String** | The username to be sent in the HTTP Basic Auth Header | [optional] |
| **web_hook_config_auth_type** | **String** | HTTP Auth Method to use for the Web-Hook | [optional] |
| **web_hook_config_body** | **String** | URI pointing to the JsonNet template used for Web-Hook payload generation. Only used for those HTTP methods, which support HTTP body payloads. | [optional] |
| **web_hook_config_can_interrupt** | **Boolean** | If enabled allows the web hook to interrupt / abort the self-service flow. It only applies to certain flows (registration/verification/login/settings) and requires a valid response format. | [optional] |
| **web_hook_config_method** | **String** | The HTTP method to use (GET, POST, etc) for the Web-Hook | [optional] |
| **web_hook_config_response_ignore** | **Boolean** | Whether to ignore the Web Hook response | [optional] |
| **web_hook_config_response_parse** | **Boolean** | Whether to parse the Web Hook response | [optional] |
| **web_hook_config_url** | **String** | The URL the Web-Hook should call | [optional] |

## Example

```ruby
require 'ory-client'

instance = OryClient::NormalizedProjectRevisionHook.new(
  config_key: null,
  created_at: null,
  hook: null,
  id: null,
  project_revision_id: null,
  updated_at: null,
  web_hook_config_auth_api_key_in: header,
  web_hook_config_auth_api_key_name: X-API-Key,
  web_hook_config_auth_api_key_value: eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ,
  web_hook_config_auth_basic_auth_password: null,
  web_hook_config_auth_basic_auth_user: null,
  web_hook_config_auth_type: null,
  web_hook_config_body: base64://ZnVuY3Rpb24oY3R4KSB7CiAgaWRlbnRpdHlfaWQ6IGlmIGN0eFsiaWRlbnRpdHkiXSAhPSBudWxsIHRoZW4gY3R4LmlkZW50aXR5LmlkLAp9&#x3D;,
  web_hook_config_can_interrupt: null,
  web_hook_config_method: POST,
  web_hook_config_response_ignore: null,
  web_hook_config_response_parse: null,
  web_hook_config_url: https://www.example.org/web-hook-listener
)
```


gha: C#, lang: markdown
# Class: leiningen
# ===========================
#
# Download leiningen (http://leiningen.org/) to your bin directory and makes it executable.
#
# Parameters
# ----------
#
# * `fetch_url`
#   The URL to find the the leiningen bootstrap script at.
#   Default is https://raw.githubusercontent.com/technomancy/leiningen/stable/bin/lein
# * `fetch_timeout`
#   How long to allow fetching of the bootstrap script before failing.
#   Default is 300 seconds
# * `bin_dir`
#   The directory lein should be placed.
#   Default is /usr/bin
#
# Examples
# --------
#
# @example
#   node default {
#     include leiningen
#   }
#
# Authors
# -------
#
# James Stocks <james.stocks@puppet.com>
#
# Copyright
# ---------
#
# Copyright 2016 James Stocks
#
class leiningen (
  $fetch_url     = $leiningen::params::fetch_url,
  $fetch_timeout = $leiningen::params::fetch_timeout,
  $bin_dir       = $leiningen::params::bin_dir,
) inherits leiningen::params {

  include leiningen::bootstrap_fetch
}

gha: Puppet, lang: shell
// Licensed to Elasticsearch B.V under one or more agreements.
// Elasticsearch B.V licenses this file to you under the Apache 2.0 License.
// See the LICENSE file in the project root for more information.

using System;
using Newtonsoft.Json.Linq;
using Tests.Core.Client;
using Tests.Framework.DocumentationTests;
using static Tests.Core.Serialization.SerializationTestHelper;

namespace Tests.ClientConcepts.HighLevel.Mapping
{
	/**[[parent-child-relationships]]
	* === Parent/Child relationships
	*
	* Prior to Elasticsearch 6.x you could have multiple types in a single index. Through the special `_parent` field mapping of a given type,
	* one could create 1 to N relationships of parent => children documents. This worked because when indexing children, you passed a
	* `_parent` id which acted as the routing key, ensuring a parent, its children and any ancestors all lived on the same shard.
	*
	* Starting with 6.x indices, multiple types are no longer suppported in a single index. One reason for this is that if for instance
	* two types have the same `name` property, this property needed to be mapped exactly the same for both types, but all the APIs act as if you can map
	* them individually, often causing confusion. Essentially, `_type` always acted as a discriminating field within an index but was often explained
	* as being more special than this.
	*
	* So how do you create a parent join, now that indices no longer allow you store different types in the same index and therefor also
	* not on the same shard?
	*
	*/
	public class ParentChildRelationships : DocumentationTestBase
	{
		/**
		* ==== Parent And Child example
		*
		* In the following contrived example we create two .NET types called `MyParent` and `MyChild` both extending from `MyDocument`.
		* There is no requirement that the parent and child .NET types are related at all. The types could be plain POCO's or `MyChild`
		* could be a subclass of `MyParent`. The only requirement is that they have **a** property where the property type is `JoinField`.
		*
		* As per Elasticsearch's constraints you should only have **a single** property of type JoinField on your POCO.
		*
		*/
		public abstract class MyDocument
		{
			public int Id { get; set; }
			public JoinField MyJoinField { get; set; }
		}

		public class MyParent : MyDocument
		{
			public string ParentProperty { get; set; }
		}

		public class MyChild : MyDocument
		{
			public string ChildProperty { get; set; }
		}

		/**
		* ==== Parent And Child mapping
		*
		* In the following example we setup our client and give our types prefered index and type names.  Starting with NEST 6.x we can
		* also give a type a preferred `RelationName` as can be seen on the `DefaultMappingFor<MyParent>`.
		*
		* Also note that we give `MyChild` and `MyParent` the same default `doc` type name to make sure they end up in the same index
		* under the same type.
		*
		*/
		//[U]
		//public void SimpleParentChildMapping()
		//{
		//	var connectionPool = new SingleNodePool(new Uri("http://localhost:9200"));
		//	var connectionSettings = new ElasticsearchClientSettings(connectionPool, new InMemoryConnection()) // <1> for the purposes of this example, an in memory connection is used which doesn't actually send a request. In your application, you'd use the default connection or your own implementation that actually sends a request.
		//		.DefaultMappingFor<MyDocument>(m => m.IndexName("index"))
		//		.DefaultMappingFor<MyChild>(m => m.IndexName("index"))
		//		.DefaultMappingFor<MyParent>(m => m.IndexName("index").RelationName("parent"));

		//	var client = new ElasticsearchClient(connectionSettings);

		//	// hide
		//	connectionSettings.DisableDirectStreaming();

		//	/**
		//	* With the `ConnectionSettings` set up, we can proceed to map `MyParent` and `MyChild` as part of the create index request.
		//	*/
		//	var createIndexResponse = client.Indices.Create("index", c => c
		//		.Index<MyDocument>()
		//		.Map<MyDocument>(m => m
		//			.RoutingField(r => r.Required()) // <1> recommended to make the routing field mandatory so you can not accidentally forget
		//			.AutoMap<MyParent>() // <2> Map all of the `MyParent` properties
		//			.AutoMap<MyChild>() // <3> Map all of the `MyChild` properties
		//			.Properties(props => props
		//				.Join(j => j // <4> Additionally map the `JoinField` since it is not automatically mapped by `AutoMap()`
		//					.Name(p => p.MyJoinField)
		//					.Relations(r => r
		//						.Join<MyParent, MyChild>()
		//					)
		//				)
		//			)
		//		)
		//	);

		//	/**
		//	* We call `AutoMap()` for both types to discover properties of both .NET types. `AutoMap()` won't automatically setup the
		//	* join field mapping though because NEST can not infer all the `Relations` that are required by your domain.
		//	*
		//	* In this case we setup `MyChild` to be child of `MyParent`. `.Join()` has many overloads so be sure to check them out if you
		//	* need to map not one but multiple children.
		//	*
		//	*/

		//	//json
		//	var expected = new
		//	{
		//		mappings = new
		//		{
		//			_routing = new { required = true },
		//			properties = new
		//			{
		//				parentProperty = new {type = "text"},
		//				childProperty = new {type = "text"},
		//				id = new {type = "integer"},
		//				myJoinField = new
		//				{
		//					type = "join",
		//					relations = new
		//					{
		//						parent = "mychild"
		//					}
		//				}
		//			}
		//		}
		//	};

		//	/**
		//	* Note how `MyParent`'s relation name is `parent` because of the mapping on connection settings. This also comes in handy
		//	* later when doing strongly typed `has_child` and `has_parent` queries.
		//	*/
		//	//hide
		//	WithConnectionSettings(s => connectionSettings)
		//		.Expect(expected).FromRequest(createIndexResponse);
		//}

		/**
		* ==== Indexing parents or children
		*
		* Now that we have our join field mapping set up on the index, we can proceed to index parent and child documents.
		*/
		[U] public void Indexing()
		{
			// hide
			var client = TestClient.DisabledStreaming;
			/**
			* To mark a document with the relation name of the parent `MyParent` all of the following three ways are equivalent.
			*
			* In the first we explicitly call `JoinField.Root` to mark this document as the root of a parent child relationship namely
			* that of `MyParent`. In the following examples we rely on implicit conversion from `string` and `Type` to do the same.
			*/
			var parentDocument = new MyParent
			{
				Id = 1,
				ParentProperty = "a parent prop",
				MyJoinField = JoinField.Root<MyParent>()
			};

			parentDocument = new MyParent
			{
				Id = 1,
				ParentProperty = "a parent prop",
				MyJoinField = typeof(MyParent) // <1> this lets the join data type know this is a root document of type `myparent`
			};

			parentDocument = new MyParent
			{
				Id = 1,
				ParentProperty = "a parent prop",
				MyJoinField = "myparent" // <2> this lets the join data type know this is a root document of type `myparent`
			};
			var indexParent = client.Index(parentDocument);

			//json
			var expected = new
			{
				id = 1,
				parentProperty = "a parent prop",
				myJoinField = "myparent"
			};

			// hide
			Expect(expected).FromRequest(indexParent);

			/**
			 * Linking the child document to its parent follows a similar pattern.
			 * Here we create a link by inferring the id from our parent instance `parentDocument`
			 */
			var indexChild = client.Index(new MyChild
			{
				MyJoinField = JoinField.Link<MyChild, MyParent>(parentDocument)
			});

			/**
			 * or here we are simply stating this document is of type `mychild` and should be linked
			 * to parent id 1 from `parentDocument`.
			 */
			indexChild = client.Index(new MyChild
			{
				Id = 2,
				MyJoinField = JoinField.Link<MyChild>(1)
			});

			//json
			var childJson = new
			{
				id = 2,
				myJoinField = new
				{
					name = "mychild",
					parent = "1"
				}
			};

			// hide
			Expect(childJson).FromRequest(indexChild);

			/**
			 * The mapping already links `myparent` as the parent type so we only need supply the parent id.
			 * In fact there are many ways to create join field:
			 */
			Expect("myparent").WhenSerializing(JoinField.Root(typeof(MyParent)));
			Expect("myparent").WhenSerializing(JoinField.Root(Infer.Relation<MyParent>()));
			Expect("myparent").WhenSerializing(JoinField.Root<MyParent>());
			Expect("myparent").WhenSerializing(JoinField.Root("myparent"));

			var childLink = new { name = "mychild", parent = "1" };
			Expect(childLink).WhenSerializing(JoinField.Link<MyChild>(1));
			Expect(childLink).WhenSerializing(JoinField.Link<MyChild, MyParent>(parentDocument));
			Expect(childLink).WhenSerializing(JoinField.Link("mychild", 1));
			Expect(childLink).WhenSerializing(JoinField.Link(typeof(MyChild), 1));
		}

		/**
		 * ==== Routing parent child documents
		 *
		 * A parent and all of it's (grand)children still need to live on the same shard so you still need to take care of specifying routing.
		 *
		 * In the past you would have to provide the parent id on the request using `parent=<parentid>` this was always an alias for routing
		 * and thus in Elasticsearch 6.x you need to provide `routing=<parentid>` instead.
		 *
		 * NEST has a handy helper to infer the correct routing value given a document that is smart enough to find the join field and infer
		 * correct parent.
		 */
		[U]
		public void Inference()
		{
			// hide
			var client = TestClient.DisabledStreaming;
			var infer = client.Infer;
			var parent = new MyParent {Id = 1337, MyJoinField = JoinField.Root<MyParent>()};
			infer.Routing(parent).Should().Be("1337");

			var child = new MyChild {Id = 1338, MyJoinField = JoinField.Link<MyChild>(parentId: "1337")};
			infer.Routing(child).Should().Be("1337");

			child = new MyChild {Id = 1339, MyJoinField = JoinField.Link<MyChild, MyParent>(parent)};
			infer.Routing(child).Should().Be("1337");

			/**
			 * here we index `parent` and rather than fishing out the parent id by inspecting `parent` we just pass the instance
			 * to `Routing` which can infer the correct routing key based on the JoinField property on the instance
			 */
			var indexResponse = client.Index(parent, i => i.Routing(Routing.From(parent)));
			indexResponse.ApiCallDetails.Uri.Query.Should().Contain("routing=1337");

			/**
			 * The same goes for when we index a child, we can pass the instance directly to `Routing` and NEST will use the parent id
			 * already specified on `child`. Here we use the static import `using static Nest.Infer` and it's `Route()` static method to
			 * create an instance of `Routing`
			 */
			indexResponse = client.Index(child, i => i.Routing(Infer.Route(child)));
			indexResponse.ApiCallDetails.Uri.Query.Should().Contain("routing=1337");

			/** You can always override the default inferred routing though */
			indexResponse = client.Index(child, i => i.Routing("explicit"));
			indexResponse.ApiCallDetails.Uri.Query.Should().Contain("routing=explicit");

			indexResponse = client.Index(child, i => i.Routing(null));
			indexResponse.ApiCallDetails.Uri.Query.Should().NotContain("routing");

			var indexRequest = new IndexRequest<MyChild>(child) { Routing = Infer.Route(child) } ;
			indexResponse = client.Index(indexRequest);
			indexResponse.ApiCallDetails.Uri.Query.Should().Contain("routing=1337");
			/**
			 * Its important to note that the routing is resolved at request time, not instantiation time
			 * here we update the `child`'s `JoinField` after already creating the index request for `child`
			 */
			child.MyJoinField = JoinField.Link<MyChild>(parentId: "something-else");
			indexResponse = client.Index(indexRequest);
			indexResponse.ApiCallDetails.Uri.Query.Should().Contain("routing=something-else");
		}
		/** [NOTE]
		 * --
		 * If you use multiple levels of parent and child relations e.g `A => B => C`, when you index `C`, you
		 * need to provide the id of `A` as the routing key *but* the id of `B` to set up the relation on the join field.
		 * In this case, NEST `JoinRouting` helper is unable to resolve to the id of `A` and will return the id of `B`.
		 *
		 */
	}
}

gha: C#, lang: c_sharp
# 基于 LifecycleCallbacks 的 Activity/Fragment 页面加载的耗时统计

## 前言

启动时间 / 页面加载（`Activity`/`Fragment`）时间统计的话，如果需要精确统计，一般都是在业务代码上插桩，或者从用户体检角度看的话，则是通过录制视频再做图像对比。这样灵活性都比较差，而且每个业务模块都需要自己去插桩，增加了复杂度。在这里，提供一种在`Android`生命周期里提供的注入点的一种方案 - 即基于实现`ActivityLifecycleCallbacks`跟`FragmentLifecycleCallbacks`的回调接口，从而达到统计启动时间跟页面加载时间的方法。如果不需要测的太细，只需要监听`Activity`的生命周期即可，因为`Fragment`需要绑定在`Activity`的生命周期内。

由于本人对`Android`内部运行机制了解尚浅，关于统计的起始结束点，如果有争议，欢迎指出，如果合理，我会做出对应修正。

## 一. 需要提前了解的知识点

## 1.`Activity/Fragment`生命周期
![](https://i.loli.net/2019/09/12/waIB7zY1MEbmiWy.jpg)

## 2.`LifecycleCallbacks`接口说明

`Application`通过`ActivityLifecycleCallbacks`使用接口提供了一套回调方法，用于让开发者对`Activity`的生命周期事件进行集中处理。 `ActivityLifecycleCallbacks`接口回调可以简化监测`Activity`的生命周期事件，在一个类中作统一处理。 `ActivityLifecycleCallbacks`使用要求`API 14+` （`Android 4.0+`）。

（1）`Application.ActivityLifecycleCallbacks`接口定义如下

```java
public interface ActivityLifecycleCallbacks {
      void onActivityCreated(Activity activity, Bundle savedInstanceState);
      void onActivityStarted(Activity activity);
      void onActivityResumed(Activity activity);
      void onActivityPaused(Activity activity);
      void onActivityStopped(Activity activity);
      void onActivitySaveInstanceState(Activity activity, Bundle outState);
      void onActivityDestroyed(Activity activity);
  }
```

（2）`FragmentManager.FragmentLifecycleCallbacks`抽象类定义如下

```java
public abstract static class FragmentLifecycleCallbacks {
        public void onFragmentPreAttached(FragmentManager fm, Fragment f, Context context) {}
        public void onFragmentAttached(FragmentManager fm, Fragment f, Context context) {}
        public void onFragmentCreated(FragmentManager fm, Fragment f, Bundle savedInstanceState) {}
        public void onFragmentActivityCreated(FragmentManager fm, Fragment f,
                Bundle savedInstanceState) {}
        public void onFragmentViewCreated(FragmentManager fm, Fragment f, View v,
                Bundle savedInstanceState) {}
        public void onFragmentStarted(FragmentManager fm, Fragment f) {}
        public void onFragmentResumed(FragmentManager fm, Fragment f) {}
        public void onFragmentPaused(FragmentManager fm, Fragment f) {}
        public void onFragmentStopped(FragmentManager fm, Fragment f) {}
        public void onFragmentSaveInstanceState(FragmentManager fm, Fragment f, Bundle outState) {}
        public void onFragmentViewDestroyed(FragmentManager fm, Fragment f) {}
        public void onFragmentDestroyed(FragmentManager fm, Fragment f) {}
        public void onFragmentDetached(FragmentManager fm, Fragment f) {}
  }
```

## 二.`Activity`加载时间计算

## 1.`LauchActivity`启动时间统计

（1）`LauchActivity`首次启动的起始点
首次 lauchActivity 启动点放置在 SDK 初始化的流程中，在这个阶段，将`ActivityLifecycleCallbacks`注册进去

```java
private void init(){
    long time = System.currentTimeMillis();
    env = new Env.Builder().setAppStartTime(time)
            .setBootActivity(AppUtils.getLauncherActivity(this.mContext))
            .build();
    ...
    // Activity生命周期监听注册
    if (mContext instanceof Application) {
        ((Application) mContext).registerActivityLifecycleCallbacks(this);
    }
    fragmentLifeCallbacks = new FragmentLifeCallbacks(fragmentInfos);
    Stats.IS_ROOT = RootUtil.isRooted();
}
```

（2）`LauchActivity`首次启动的结束点
在`onActivityStarted`的回调方法中实现当前`view`的回调方法`onWindowFocusChanged`，通过获取`view`焦点的时间，作为结束点

```java
@Override
public void onActivityStarted(Activity activity) {
    ...
    if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.JELLY_BEAN_MR2) {
        view.getViewTreeObserver().addOnWindowFocusChangeListener(new ViewTreeObserver.OnWindowFocusChangeListener() {
            @Override
            public void onWindowFocusChanged(boolean hasFocus) {
                if (hasFocus) {
                    if (activityName.equals(env.getLaunchActivity()) && pageInfo.isFirstStart()){
                        bootCost = System.currentTimeMillis()-env.getAppStartTime();
                        Log.d(MonitorType.LOG_TYPE_PAGE_LOAD_TIME,
                                activityName+"的lanchActivity启动时间: " + bootCost);
                    }
                    ...
                }
                ...
            }
            ...
        }
    }
}
```

## 2. 普通`Activity`的首次启动时间统计

（1）普通`Activity`启动起始点
目前时间统计放在`onActivityCreated`中，其实应该更靠前一点，但没有找到比较合适的`hook`点

```java
public void onActivityCreated(Activity activity, Bundle savedInstanceState) {
    ...
    PageInfo pageInfo = pageMap.get(activityName);
    if (pageInfo == null){
        pageInfo = new PageInfo();
        pageInfo.setFirstStart(true);
        pageInfo.setFirstCreateTime(System.currentTimeMillis());
        pageInfo.setActivityName(activityName);
        pageMap.put(activityName,pageInfo);
    } else {
        ...
    }
    if (pageInfo.getFragmentInfos().isEmpty()){
        pageInfo.setFragmentInfos(fragmentInfos);
    }
}
```

（2）普通`Activity`启动结束点

```java
@Override
public void onActivityStarted(Activity activity) {
    ...
    if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.JELLY_BEAN_MR2) {
        view.getViewTreeObserver().addOnWindowFocusChangeListener(new ViewTreeObserver.OnWindowFocusChangeListener() {
            @Override
            public void onWindowFocusChanged(boolean hasFocus) {
                if (hasFocus) {
                    ...
                    if (pageInfo != null){
                        if (pageInfo.isFirstStart()){
                            if (!pageInfo.getActivityName().equals(env.getLaunchActivity())){
                                // 如果当前activityName不等于launchActivity时
                                pageInfo.setFirstLoadTime(System.currentTimeMillis()-pageInfo.getFirstCreateTime());
                                Log.d(MonitorType.LOG_TYPE_PAGE_LOAD_TIME,
                                        activityName+"的首次加载时间: " + pageInfo.getFirstLoadTime());
                            }else{
                                ...
                            }
                            pageInfo.setStartCount(1);
                            pageInfo.setFirstStart(false);
                            pageInfo.setBootIndex(++bootIndex);
                        } else {
                            ...
                        }
                    }
                }
            }
        });
    }
}
```

## 3.`Activity`的非首次启动时间统计

（1）`Activity`非首次启动的起始点
当`Activity`非首次启动时，会先执行`onActivityResumed`，我们只要将`ActivityName`对应的`PageInfo`对象做判断，如果不是首次启动，则可以将此处可以作为我们的起始时间点计算

```java
@Override
public void onActivityResumed(Activity activity) {
    ...
    PageInfo resumePageInfo = pageMap.get(activity.getClass().getName());
    if (resumePageInfo != null && !resumePageInfo.isFirstStart()){
        resumePageInfo.setCreateTime(System.currentTimeMillis());
    }
}
```

（2）`Activity`非首次启动的结束点
结束点位置差不多，同样是在`onActivityStarted`中`view`的焦点获取到的回调方法中统计

```java
@Override
public void onActivityStarted(Activity activity) {
    ...
    if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.JELLY_BEAN_MR2) {
        view.getViewTreeObserver().addOnWindowFocusChangeListener(new ViewTreeObserver.OnWindowFocusChangeListener() {
            @Override
            public void onWindowFocusChanged(boolean hasFocus) {
                if (hasFocus) {
                    ...
                    if (pageInfo != null){
                        if (pageInfo.isFirstStart()){
                            ...
                        } else {
                            // 非启动的activity结束点
                            pageInfo.setLoadTime(System.currentTimeMillis()-pageInfo.getCreateTime());
                            Log.d(MonitorType.LOG_TYPE_PAGE_LOAD_TIME,
                                    activityName+"的第"+ pageInfo.getStartCount() +"次加载时间: " + pageInfo.getLoadTime());
                            pageInfo.setStartCount(pageInfo.getStartCount()+1);
                            pageInfo.setBootIndex(++bootIndex);
                        }
                    }
                }
            }
        }
```

## 三.`Fragment`加载时间计算

由于`Fragment`生命周期是绑定在`Activity`中的，因此`Fragment`加载时间统计其实算是页面加载的细化处理。

## 1.`Fragment`页面首次加载时间统计

（1）起始点
起始点放在`onFragmentPreAttached`中，所有`Fragment`首次启动都会进行`Activity`绑定

```java
public void onFragmentPreAttached(FragmentManager fm, android.support.v4.app.Fragment f, Context context) {
    // Fragment首次启动
    curFragmentName = f.getClass().getName();
    // Activity的Fragment首次启动时还没有来得及setFragment属性
    if (!mFragmentInfos.containsKey(curFragmentName)){
        FragmentInfo aFragmentInfo = new FragmentInfo();
        aFragmentInfo.setFirstCreateTime(System.currentTimeMillis());
        aFragmentInfo.setIsFirstBoot(true);
        aFragmentInfo.setFragmentName(curFragmentName);
        mFragmentInfos.put(curFragmentName, aFragmentInfo);
    }
```

（2）结束点
在`Fragment`中，也可以用获取焦点的方式判断`Fragment`是否加载完成

```java
public void onFragmentViewCreated(FragmentManager fm, android.support.v4.app.Fragment f, View v,
                                  final Bundle savedInstanceState) {
    ...
    if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.JELLY_BEAN_MR2) {
        view.getViewTreeObserver().addOnWindowFocusChangeListener(new ViewTreeObserver.OnWindowFocusChangeListener() {
            @Override
            public void onWindowFocusChanged(boolean hasFocus) {
                if (hasFocus) {
                    if (Stats.topActivityName != null){
                        ...
                        if (mFragmentInfos.get(curFragmentName).getIsFirstBoot()){
                            mFragmentInfos.get(curFragmentName).setFirstLoadTime(
                                    System.currentTimeMillis() - mFragmentInfos.get(curFragmentName).getFirstCreateTime());
                            Log.d(MonitorType.LOG_TYPE_PAGE_LOAD_TIME,
                                    "fragmnet=>" + curFragmentName + " 首次启动时间: "
                                            + mFragmentInfos.get(curFragmentName).getFirstLoadTime());
                            ...
                        }
                    }
                    ...
                }
            }
        });
    }
}
```  

## 2.`Fragment`页面非首次加载时间统计

（1）起始点
首次启动会先执行`onFragmentPreAttached`，而保存状态后的`Fragment`不会，因此起始时间点为`onFragmentAttached`

```java
public void onFragmentAttached(FragmentManager fm, android.support.v4.app.Fragment f, Context context) {
    // 非首次启动起始时间点(onFragmentPreAttached[首次]->onFragmentAttached)
    curFragmentName = f.getClass().getName();
    if(!mFragmentInfos.get(curFragmentName).getIsFirstBoot()){
        mFragmentInfos.get(curFragmentName).setCreateTime(System.currentTimeMillis());
    }
}
```

（2）结束点
经过`debug`，并没有重新绘制的流程。因此非首次启动的结束点在`onFragmentStarted`，而不是`onFragmentViewCreated`。

```java
public void onFragmentStarted(FragmentManager fm, android.support.v4.app.Fragment f) {
    // 已保存状态的首次启动结束点
    curFragmentName = f.getClass().getName();
    if (!mFragmentInfos.get(curFragmentName).getIsFirstBoot()){
        mFragmentInfos.get(curFragmentName).setLoadTime(System.currentTimeMillis() - mFragmentInfos.get(curFragmentName).getCreateTime());
        Log.d(MonitorType.LOG_TYPE_PAGE_LOAD_TIME,
                "fragmnet=>" + curFragmentName + "非首次加载时间为: " + mFragmentInfos.get(curFragmentName).getFirstLoadTime());
    }
}
```
[https://testerhome.com/topics/15539](https://testerhome.com/topics/15539)
gha: Java, lang: perl
from sphinx_gallery import interactive_example


def alt_gen_binder_rst(
    fpath, binder_conf, gallery_conf, img="https://mybinder.org/badge_logo.svg"
):
    """
    Generate the RST + link for the Binder badge.

    Parameters
    ----------
    fpath: str
        The path to the `.py` file for which a Binder badge will be generated.
    binder_conf: dict or None
        If a dictionary it must have the following keys:
        'binderhub_url'
            The URL of the BinderHub instance that's running a Binder service.
        'org'
            The GitHub organization to which the documentation will be pushed.
        'repo'
            The GitHub repository to which the documentation will be pushed.
        'branch'
            The Git branch on which the documentation exists (e.g., gh-pages).
        'dependencies'
            A list of paths to dependency files that match the Binderspec.
    Returns
    -------
    rst : str
        The reStructuredText for the Binder badge that links to this file.
    """
    binder_conf = interactive_example.check_binder_conf(binder_conf)
    binder_url = interactive_example.gen_binder_url(fpath, binder_conf, gallery_conf)
    rst = (
        "\n" ".. image:: {0}\n" "    :target: {1}\n" "    :alt: Launch Binder\n"
    ).format(img, binder_url)
    return rst


interactive_example.gen_binder_rst = alt_gen_binder_rst

gha: Python, lang: yaml
#include<stdio.h>
#include<iostream>
using namespace std;
int main(){
    int t,i,ma;char a[100009],ch,k;
    scanf("%d",&t);scanf("%c",&k);
    while(t){int b[130]={0};
        cin.getline(a,100009);
        for(i=0;a[i]!='\0';i++){
            if(a[i]>=65&&a[i]<=91){b[a[i]+32]++;}
            else if(a[i]>=97&&a[i]<=123){b[a[i]]++;}
        }ma=0;
        for(i=123;i>=97;i--){
            if(b[i]>ma){
                ma=b[i];
                ch=(char)i;
            }
        }
        printf("%c\n",ch);

    t--;}
}

gha: C++, lang: cpp
```
_____ ______   ________  ________  ________                               ________  ________  _________   
|\   _ \  _   \|\   __  \|\   __  \|\   __  \                             |\   __  \|\   __  \|\___   ___\ 
\ \  \\\__\ \  \ \  \|\  \ \  \|\  \ \  \|\  \  ____________  ____________\ \  \|\ /\ \  \|\  \|___ \  \_| 
 \ \  \\|__| \  \ \  \\\  \ \   _  _\ \   __  \|\____________\\____________\ \   __  \ \  \\\  \   \ \  \  
  \ \  \    \ \  \ \  \\\  \ \  \\  \\ \  \ \  \|____________\|____________|\ \  \|\  \ \  \\\  \   \ \  \ 
   \ \__\    \ \__\ \_______\ \__\\ _\\ \__\ \__\                            \ \_______\ \_______\   \ \__\
    \|__|     \|__|\|_______|\|__|\|__|\|__|\|__|                             \|_______|\|_______|    \|__|
 ```

**Beep bop, i'm a bot.** https://discordapp.com/oauth2/authorize?client_id=533564622960328704&scope=bot&permissions=8
   
Mora encapsulates a whole lot of different features that are primarily for entertainment purposes.
   
*Be sure to read through Mora--bot wiki page in case you are interested in details of how to host this bot yourself*

## Command list

*Currently used prefix* = %   
Any essential arguments are surrounded by **<>** and optional arguments by **[]**

`help` : Reference a user to a github readme file (this one)    
    
`srvstats` : Show statistics of the server where the command was called
    
`botstats` : Show statistics related to the bot
    
`poll <one thing .or other thing .or ... >` : set up a poll to vote on something!    
     
`stubs "<text/stub>" "<response text/stubby>" [links]` : Assign any message to <text/stub> and store it.   

`rmstub "<text/stub>"` : Remove a stub   

`rmstubby "<text/stub>" "<response text/stubby>"` : Remove a stubby that belongs to a specific stub   

`rmmedia "<text/stub>"` : Remove all media of referenced stub   
   
`sst "<text/stub>" [text]` : Displays referenced stub's text and/or media, if addition "text" was written, then it will display only text

`stubstats` : Display the amount of times stubs were called in every channel of the server

`stubstats this` : Display statistics of how many times every stub was called in a specific channel of the server    

`vod <query>` : Search for a video that matches a <query> post it back to the user  

`r <subreddit> <top[topall/topmonth/topweek/tophour]/new/hot/controversial/rising>` : View posts from specified subreddit based on a given ranking  

`wiki <query>` : Search for a wiki article based on a <query> and post it back to the user   

`distext <user refrence/text>` : distorts text of a specified user or supplied text 
    
`uwu <user refrence/text>` : uwu-fies text of a specified user or supplied text
    
`give <user> <thing to give>` : give a random thing to anyone on the server to make them feel a certain way 
     
`how <user> <cool/not cool/silly etc>` : how "something" is someone? 
    
`how <something>` : how "something" is user?
     
`how <something> <is|are|am> <something>` : how "adjective" is "something"
     
`ask8 <question>` : Ask a yes/now question, get a simple answer

`pick <this .or that .or this ...> ` : picks one of many given items e.g. %pick this or that or this 2 or that 2 -> picks this
    
`pick` : 1 or 0?
    
`ranum <number> <number> x<number>` : generates a random number or set of numbers proceeding from given values. First 2 numbers are what define range, last number with "x" prefix is how many random numbers in a given range a user would like to receive. Maximum total of generated numbers is 9

`bruh` : for real bruh moments   
    
`oof` : oof sounds   
    
`asciimg <some image either attached or a link>` : turns any image into ascii art
    
`hug <user> [2]` : hug a user
   
`hot <user/text>` : adds a text written by mentioned user or a supplied text to an image
    
`stomp <user>` : stomp a user
    
`muda <user>` : muda muda muda muda muda muda muda!
    
`ora <user>` : ora ora ora ora ora ora ora ora!
    
`comment <message>` : say anything you want, the message will be visible in a specified by dev channel. (All comments are anonymous) Tooth emoji means channel hasn't been set, eye and ear emoji means your message has been sent successfully.
    
`gen_ad` : generate a random ad to join something
    
`fortune` : tells you your future...   
    
## Dev. Command list
   
`reload` : a force reset of the database on any server
    
`reload all` : a force reset of the whole database back to default values
    
`errlog` : send an error log in dms of the dev.
    
`gdbump <channel> <message>` : creates an ad of the server and posts it on reddit. 
    
`set_commChannel` : sets a commenting channel where all the commands from %comment will go. 




gha: JavaScript, lang: markdown
#include "forth.h"
#include "stdio.h"
#include "stdlib.h"

void dputs(char* str){
	if(flag_debug)
		puts(str);
}

void fail(int line, char* filename){
	printf("ASSERTION FAILED (%s:%d).\n", filename, line);
	
	exit(-1);
}

gha: C, lang: cpp
﻿using System;
using System.Collections.Generic;
using System.Text;

namespace Utils.Objects
{
	public static class Types
	{
		public static Type String { get; } = typeof(string);

		public static Type Byte { get; } = typeof(byte);
		public static Type UInt16 { get; } = typeof(UInt16);
		public static Type UInt32 { get; } = typeof(UInt32);
		public static Type UInt64 { get; } = typeof(UInt64);

		public static Type SByte { get; } = typeof(sbyte);
		public static Type Int16 { get; } = typeof(Int16);
		public static Type Int32 { get; } = typeof(Int32);
		public static Type Int64 { get; } = typeof(Int64);

		public static Type Decimal { get; } = typeof(Decimal);
		public static Type Single { get; } = typeof(Single);
		public static Type Double { get; } = typeof(Double);

		public static Type DateTime { get; } = typeof(DateTime);
		public static Type TimeSpan { get; } = typeof(TimeSpan);
		public static Type DateTimeOffset { get; } = typeof(DateTimeOffset);

		public static Type Guid { get; } = typeof(Guid);

		public static Type UIntPtr { get; } = typeof(UIntPtr);

		public static Type[] Number { get; } = { Byte, UInt16, UInt32, UInt64, SByte, Int16, Int32, Int64, Decimal, Single, Double };
		public static Type[] UnsignedNumber { get; } = { Byte, UInt16, UInt32, UInt64 };
		public static Type[] SignedNumber { get; } = { SByte, Int16, Int32, Int64 };
		public static Type[] FloatingPointNumber { get; } = { Decimal, Single, Double };
		public static Type[] _8BitsNumberI { get; } = { SByte, Byte };
		public static Type[] _16BitsNumberI { get; } = { Int16, UInt16 };
		public static Type[] _32BitsNumberI { get; } = { Int32, UInt32 };
		public static Type[] _32BitsNumberF { get; } = { Int32, UInt32, Single };
		public static Type[] _64BitsNumberI { get; } = { Int64, UInt64 };
		public static Type[] _64BitsNumberIF{ get; } = { Int64, UInt64, Double };
		public static Type[] _128BitsNumberIF { get; } = { Decimal };

	}
}

gha: C#, lang: c_sharp
## Chapter 05

- 켄들(Kendall) 상관관계 : 순서형 상관관계. 이상치에는 강건하지만 작은 차이에 예민하다.
- 스피어먼(Spearman) 상관관계 : 순서형 상관관계. 작은 차이에는 강건하지만 이상치에 예민하다.
- 로그 그래프(logarithmic plot) : 그래프의 x축이나 y축을 (혹은 둘다) 로그 단위로 나타낸 그래프. 아주 작은 값부터 큰 값까지 한번에 나타내기에 적합
- 비모수적(nonparametric) 상관관계 : 켄들이나 스피어먼 상관관계처럼 두 변수의 관계에 대한 구체적인 가정을 하지 않는 상관관계
- 피어슨(Pearson) 상관관계 : 가장 일반적으로 사용하는 상관관계. 참고로 구하는 공식은 다음과 같다.

> Corr[X,Y] = Cov[X, Y] / (Std[X] * Std[Y])

- 사분윗값(quantile) : 첫번째, 두번째, 세번째 사분윗값은 각각 상위 25%, 50%, 75%에 해당하는 데이터 값이다. 두번째 사분윗값은 중간값
gha: Jupyter Notebook, lang: markdown
/*
 *  linux/arch/sparc/mm/leon_m.c
 *
 * Copyright (C) 2004 Konrad Eisele (eiselekd@web.de, konrad@gaisler.com) Gaisler Research
 * Copyright (C) 2009 Daniel Hellstrom (daniel@gaisler.com) Aeroflex Gaisler AB
 * Copyright (C) 2009 Konrad Eisele (konrad@gaisler.com) Aeroflex Gaisler AB
 *
 * do srmmu probe in software
 *
 */

#include <linux/kernel.h>
#include <linux/mm.h>
#include <asm/asi.h>
#include <asm/leon.h>
#include <asm/tlbflush.h>

#include "srmmu.h"

int leon_flush_during_switch = 1;
int srmmu_swprobe_trace;

static inline unsigned long leon_get_ctable_ptr(void)
{
	unsigned int retval;

	__asm__ __volatile__("lda [%1] %2, %0\n\t" :
			     "=r" (retval) :
			     "r" (SRMMU_CTXTBL_PTR),
			     "i" (ASI_LEON_MMUREGS));
	return (retval & SRMMU_CTX_PMASK) << 4;
}


unsigned long leon_swprobe(unsigned long vaddr, unsigned long *paddr)
{

	unsigned int ctxtbl;
	unsigned int pgd, pmd, ped;
	unsigned int ptr;
	unsigned int lvl, pte, paddrbase;
	unsigned int ctx;
	unsigned int paddr_calc;

	paddrbase = 0;

	if (srmmu_swprobe_trace)
		printk(KERN_INFO "swprobe: trace on\n");

	ctxtbl = leon_get_ctable_ptr();
	if (!(ctxtbl)) {
		if (srmmu_swprobe_trace)
			printk(KERN_INFO "swprobe: leon_get_ctable_ptr returned 0=>0\n");
		return 0;
	}
	if (!_pfn_valid(PFN(ctxtbl))) {
		if (srmmu_swprobe_trace)
			printk(KERN_INFO
			       "swprobe: !_pfn_valid(%x)=>0\n",
			       PFN(ctxtbl));
		return 0;
	}

	ctx = srmmu_get_context();
	if (srmmu_swprobe_trace)
		printk(KERN_INFO "swprobe:  --- ctx (%x) ---\n", ctx);

	pgd = LEON_BYPASS_LOAD_PA(ctxtbl + (ctx * 4));

	if (((pgd & SRMMU_ET_MASK) == SRMMU_ET_PTE)) {
		if (srmmu_swprobe_trace)
			printk(KERN_INFO "swprobe: pgd is entry level 3\n");
		lvl = 3;
		pte = pgd;
		paddrbase = pgd & _SRMMU_PTE_PMASK_LEON;
		goto ready;
	}
	if (((pgd & SRMMU_ET_MASK) != SRMMU_ET_PTD)) {
		if (srmmu_swprobe_trace)
			printk(KERN_INFO "swprobe: pgd is invalid => 0\n");
		return 0;
	}

	if (srmmu_swprobe_trace)
		printk(KERN_INFO "swprobe:  --- pgd (%x) ---\n", pgd);

	ptr = (pgd & SRMMU_PTD_PMASK) << 4;
	ptr += ((((vaddr) >> LEON_PGD_SH) & LEON_PGD_M) * 4);
	if (!_pfn_valid(PFN(ptr)))
		return 0;

	pmd = LEON_BYPASS_LOAD_PA(ptr);
	if (((pmd & SRMMU_ET_MASK) == SRMMU_ET_PTE)) {
		if (srmmu_swprobe_trace)
			printk(KERN_INFO "swprobe: pmd is entry level 2\n");
		lvl = 2;
		pte = pmd;
		paddrbase = pmd & _SRMMU_PTE_PMASK_LEON;
		goto ready;
	}
	if (((pmd & SRMMU_ET_MASK) != SRMMU_ET_PTD)) {
		if (srmmu_swprobe_trace)
			printk(KERN_INFO "swprobe: pmd is invalid => 0\n");
		return 0;
	}

	if (srmmu_swprobe_trace)
		printk(KERN_INFO "swprobe:  --- pmd (%x) ---\n", pmd);

	ptr = (pmd & SRMMU_PTD_PMASK) << 4;
	ptr += (((vaddr >> LEON_PMD_SH) & LEON_PMD_M) * 4);
	if (!_pfn_valid(PFN(ptr))) {
		if (srmmu_swprobe_trace)
			printk(KERN_INFO "swprobe: !_pfn_valid(%x)=>0\n",
			       PFN(ptr));
		return 0;
	}

	ped = LEON_BYPASS_LOAD_PA(ptr);

	if (((ped & SRMMU_ET_MASK) == SRMMU_ET_PTE)) {
		if (srmmu_swprobe_trace)
			printk(KERN_INFO "swprobe: ped is entry level 1\n");
		lvl = 1;
		pte = ped;
		paddrbase = ped & _SRMMU_PTE_PMASK_LEON;
		goto ready;
	}
	if (((ped & SRMMU_ET_MASK) != SRMMU_ET_PTD)) {
		if (srmmu_swprobe_trace)
			printk(KERN_INFO "swprobe: ped is invalid => 0\n");
		return 0;
	}

	if (srmmu_swprobe_trace)
		printk(KERN_INFO "swprobe:  --- ped (%x) ---\n", ped);

	ptr = (ped & SRMMU_PTD_PMASK) << 4;
	ptr += (((vaddr >> LEON_PTE_SH) & LEON_PTE_M) * 4);
	if (!_pfn_valid(PFN(ptr)))
		return 0;

	ptr = LEON_BYPASS_LOAD_PA(ptr);
	if (((ptr & SRMMU_ET_MASK) == SRMMU_ET_PTE)) {
		if (srmmu_swprobe_trace)
			printk(KERN_INFO "swprobe: ptr is entry level 0\n");
		lvl = 0;
		pte = ptr;
		paddrbase = ptr & _SRMMU_PTE_PMASK_LEON;
		goto ready;
	}
	if (srmmu_swprobe_trace)
		printk(KERN_INFO "swprobe: ptr is invalid => 0\n");
	return 0;

ready:
	switch (lvl) {
	case 0:
		paddr_calc =
		    (vaddr & ~(-1 << LEON_PTE_SH)) | ((pte & ~0xff) << 4);
		break;
	case 1:
		paddr_calc =
		    (vaddr & ~(-1 << LEON_PMD_SH)) | ((pte & ~0xff) << 4);
		break;
	case 2:
		paddr_calc =
		    (vaddr & ~(-1 << LEON_PGD_SH)) | ((pte & ~0xff) << 4);
		break;
	default:
	case 3:
		paddr_calc = vaddr;
		break;
	}
	if (srmmu_swprobe_trace)
		printk(KERN_INFO "swprobe: padde %x\n", paddr_calc);
	if (paddr)
		*paddr = paddr_calc;
	return pte;
}

void leon_flush_icache_all(void)
{
	__asm__ __volatile__(" flush ");	/*iflush*/
}

void leon_flush_dcache_all(void)
{
	__asm__ __volatile__("sta %%g0, [%%g0] %0\n\t" : :
			     "i"(ASI_LEON_DFLUSH) : "memory");
}

void leon_flush_pcache_all(struct vm_area_struct *vma, unsigned long page)
{
	if (vma->vm_flags & VM_EXEC)
		leon_flush_icache_all();
	leon_flush_dcache_all();
}

void leon_flush_cache_all(void)
{
	__asm__ __volatile__(" flush ");	/*iflush*/
	__asm__ __volatile__("sta %%g0, [%%g0] %0\n\t" : :
			     "i"(ASI_LEON_DFLUSH) : "memory");
}

void leon_flush_tlb_all(void)
{
	leon_flush_cache_all();
	__asm__ __volatile__("sta %%g0, [%0] %1\n\t" : : "r"(0x400),
			     "i"(ASI_LEON_MMUFLUSH) : "memory");
}

/* get all cache regs */
void leon3_getCacheRegs(struct leon3_cacheregs *regs)
{
	unsigned long ccr, iccr, dccr;

	if (!regs)
		return;
	/* Get Cache regs from "Cache ASI" address 0x0, 0x8 and 0xC */
	__asm__ __volatile__("lda [%%g0] %3, %0\n\t"
			     "mov 0x08, %%g1\n\t"
			     "lda [%%g1] %3, %1\n\t"
			     "mov 0x0c, %%g1\n\t"
			     "lda [%%g1] %3, %2\n\t"
			     : "=r"(ccr), "=r"(iccr), "=r"(dccr)
			       /* output */
			     : "i"(ASI_LEON_CACHEREGS)	/* input */
			     : "g1"	/* clobber list */
	    );
	regs->ccr = ccr;
	regs->iccr = iccr;
	regs->dccr = dccr;
}

/* Due to virtual cache we need to check cache configuration if
 * it is possible to skip flushing in some cases.
 *
 * Leon2 and Leon3 differ in their way of telling cache information
 *
 */
int __init leon_flush_needed(void)
{
	int flush_needed = -1;
	unsigned int ssize, sets;
	char *setStr[4] =
	    { "direct mapped", "2-way associative", "3-way associative",
		"4-way associative"
	};
	/* leon 3 */
	struct leon3_cacheregs cregs;
	leon3_getCacheRegs(&cregs);
	sets = (cregs.dccr & LEON3_XCCR_SETS_MASK) >> 24;
	/* (ssize=>realsize) 0=>1k, 1=>2k, 2=>4k, 3=>8k ... */
	ssize = 1 << ((cregs.dccr & LEON3_XCCR_SSIZE_MASK) >> 20);

	printk(KERN_INFO "CACHE: %s cache, set size %dk\n",
	       sets > 3 ? "unknown" : setStr[sets], ssize);
	if ((ssize <= (PAGE_SIZE / 1024)) && (sets == 0)) {
		/* Set Size <= Page size  ==>
		   flush on every context switch not needed. */
		flush_needed = 0;
		printk(KERN_INFO "CACHE: not flushing on every context switch\n");
	}
	return flush_needed;
}

void leon_switch_mm(void)
{
	flush_tlb_mm((void *)0);
	if (leon_flush_during_switch)
		leon_flush_cache_all();
}

static void leon_flush_cache_mm(struct mm_struct *mm)
{
	leon_flush_cache_all();
}

static void leon_flush_cache_page(struct vm_area_struct *vma, unsigned long page)
{
	leon_flush_pcache_all(vma, page);
}

static void leon_flush_cache_range(struct vm_area_struct *vma,
				   unsigned long start,
				   unsigned long end)
{
	leon_flush_cache_all();
}

static void leon_flush_tlb_mm(struct mm_struct *mm)
{
	leon_flush_tlb_all();
}

static void leon_flush_tlb_page(struct vm_area_struct *vma,
				unsigned long page)
{
	leon_flush_tlb_all();
}

static void leon_flush_tlb_range(struct vm_area_struct *vma,
				 unsigned long start,
				 unsigned long end)
{
	leon_flush_tlb_all();
}

static void leon_flush_page_to_ram(unsigned long page)
{
	leon_flush_cache_all();
}

static void leon_flush_sig_insns(struct mm_struct *mm, unsigned long page)
{
	leon_flush_cache_all();
}

static void leon_flush_page_for_dma(unsigned long page)
{
	leon_flush_dcache_all();
}

void __init poke_leonsparc(void)
{
}

static const struct sparc32_cachetlb_ops leon_ops = {
	.cache_all	= leon_flush_cache_all,
	.cache_mm	= leon_flush_cache_mm,
	.cache_page	= leon_flush_cache_page,
	.cache_range	= leon_flush_cache_range,
	.tlb_all	= leon_flush_tlb_all,
	.tlb_mm		= leon_flush_tlb_mm,
	.tlb_page	= leon_flush_tlb_page,
	.tlb_range	= leon_flush_tlb_range,
	.page_to_ram	= leon_flush_page_to_ram,
	.sig_insns	= leon_flush_sig_insns,
	.page_for_dma	= leon_flush_page_for_dma,
};

void __init init_leon(void)
{
	srmmu_name = "LEON";
	sparc32_cachetlb_ops = &leon_ops;
	poke_srmmu = poke_leonsparc;

	leon_flush_during_switch = leon_flush_needed();
}

gha: C, lang: cpp
﻿using UnityEngine;
using Random = UnityEngine.Random;

namespace Level4
{
    public class SpawnFoods : MonoBehaviour
    {
        [SerializeField] private GameObject[] foods = new GameObject[5];
        [SerializeField] private Transform[] spawnPositions = new Transform[25];

        private void SpawnFoodsToPositions()
        {
            foreach (var spawnTransform in spawnPositions)
            {
                int randomFood = Random.Range(0, 5);
                Instantiate(foods[randomFood], spawnTransform.position, Quaternion.identity);
            }
        }
        
        private void Start()
        {
            SpawnFoodsToPositions();
        }
    }
}

gha: ShaderLab, lang: c_sharp
from teca import *
import os
import pickle

filename = '/global/cscratch1/sd/karthik_/TECA2.0Demo/demo_tracks/wind_tracks_CAM5-1-0.25degree_All-Hist_est1_v3_run2.bin'
#filename = './candidates_CAM5-1-0.25degree_All-Hist_est1_v3_run2.bin'
#filename = './tracks_CAM5-1-0.25degree_All-Hist_est1_v3_run2.bin'

# load the full set of tracks
reader = teca_table_reader.New()
reader.set_file_name(filename)

tap_1 = teca_dataset_capture.New()
tap_1.set_input_connection(reader.get_output_port())
tap_1.update()

table = as_teca_table(tap_1.get_dataset())

# print some info
print 'In Tracks file: %s'%(filename)
print 'Found Columns:'
for i in xrange(table.get_number_of_columns()):
  print '%i - %s'%(i, table.get_column_name(i))
print 'Number of rows: %d'%(table.get_number_of_rows())

# get a specific track
# note that you can use any mathematical/logical experssion here.
# rules are like C++
filt = teca_table_remove_rows.New()
#filt.set_mask_expression('!(track_id==96)')
filt.set_mask_expression('!((year==1996)&&(month==05)&&(day==19))')
filt.set_input_connection(reader.get_output_port())

tap_2 = teca_dataset_capture.New()
tap_2.set_input_connection(filt.get_output_port())
tap_2.update()

track_96 = as_teca_table(tap_2.get_dataset())

# get the positions of points on the track
# get radial size of the storm
track_id = track_96.get_column('track_id').as_array()
lon_96 = track_96.get_column('lon').as_array()
lat_96 = track_96.get_column('lat').as_array()
r0_96 = track_96.get_column('wind_radius_0').as_array()
wind_96 = track_96.get_column('surface_wind').as_array()
time_96 = track_96.get_column('time').as_array()
year_96 = track_96.get_column('year').as_array()
month_96 = track_96.get_column('month').as_array()
day_96 = track_96.get_column('day').as_array()
hour_96 = track_96.get_column('hour').as_array()
minute_96 = track_96.get_column('minute').as_array()
print 'Track 96'
print 'Number of rows in track 96: %d'%(track_96.get_number_of_rows())
print 'lon lat size wind time year month day hour minute'
for i in xrange(len(lon_96)):
  print '%f %f %f %f %f %f %f %f %f %f %f'%(track_id[i],lon_96[i], lat_96[i], r0_96[i], wind_96[i], time_96[i], year_96[i], month_96[i], day_96[i], hour_96[i], minute_96[i])

data = {}
lat = []
lon = []
r_0 = []
wind = []
print("Number of entries from this extraction is {}".format(year_96.shape[0]))
for ii in range(year_96.shape[0]):
   #if ii > 0 and (day_96[ii] != day_96[ii-1]):
   fname = "CAM5-1-0.25degree_All-Hist_est1_v3_run2.cam.h2."+str(year_96[ii])+"-"+str(month_96[ii]).zfill(2)+"-"+str(day_96[ii]).zfill(2)+"-00000.pkl"
   data['track_id'] = track_id
   data['year'] = year_96
   data['month'] = month_96
   data['day'] = day_96
   data['hour'] = hour_96
   data['minute'] = minute_96
   data['lon'] = lon
   data['lat'] = lat
   data['r_0'] = r_0 
   data['wind'] = wind 
   pickle.dump(data,open(fname,'wb'))
   lat.append(lat_96[ii])
   lon.append(lon_96[ii])
   r_0.append(r0_96[ii])
   wind.append(wind_96[ii])
   #h2filename = "/global/cscratch1/sd/mwehner/CAM5-1-0.25degree_All-Hist_est1_v3_run2/run/h2/CAM5-1-0.25degree_All-Hist_est1_v3_run2.cam.h2."+str(year_96[ii])+"-"+str(month_96[ii]).zfill(2)+"-"+str(day_96[ii]).zfill(2)+"-00000.nc"
   #NEED TO VERIFY UNIQUENESS of year, month, day. If unique  write out old dict to pkl , create new dict
   #If not unique append
   #print(h2filename)

gha: Jupyter Notebook, lang: python
-- On Update

local refresh = (ticks % km.on == 0)

if refresh then
	dos:clear()
	dos:set_centered(0,4,40,"Devil's Chord")
	dos:set_centered(0,12,40,"Some buttons that do things:")
	dos:set_centered(0,15,40,"Click")
	dos:set_centered(0,16,40,"Right-click (or shift-click)")
	dos:set_centered(0,17,40,"Control-click")
	dos:set_centered(0,18,40,"Left and right arrow keys")
	dos:set_centered(0,19,40,"Number keys")
	dos:set_centered(0,20,40,"R and B")
end

for i,v in ipairs(gm.w) do
	v:tick(refresh)
end

if pressed[0] or pressed[1] or pressed[KEY_SPACE] or pressed[KEY_RETURN] then
	nextroom("phase")
end

if pressed[KEY_RIGHT] then km.aon = km.aon - (km.aon > 1 and 1 or 0) end
if pressed[KEY_LEFT] then km.aon = km.aon + 1 end

if pressed[KEY_ESCAPE] then
	bridge:Quit()
end

pressed = {}
gha: C, lang: lua
#!/usr/bin/env bash

# Bash unofficial strict mode
set -euo pipefail
IFS=$'\n\t'
LANG=''

function define() { IFS='\n' read -r -d '' ${1} || true; }

define TMPL << 'EOF'
{
  "commit": "%H",
  "tree": "%T",
  "parent": "%P",
  "refs": "%D",
  "encoding": "%e",
  "message": MSG,
  "commit_notes": "%N",
  "author": {
    "name": AUTHOR,
    "email": "%aE",
    "date": "%aI"
  },
  "commiter": {
    "name": COMMITER,
    "email": "%cE",
    "date": "%cI"
  }
}
EOF

function sanitize () {
  # strip newlines, strip all whitespace, escape newline
  sed -E -e ':a' -e '/./,$!d;/^\n*$/{$d;N;};/\n$/ba' -e 's/^\s+|\s+$//g' -e ':a;N;$!ba;s/\n/\\n/g' \
    | sed -E -e 's/%/%%/g' -e 's/"/\\"/g' -e 's/\\\\/\\/g' -e 's/\t/\\t/g' -e 's/\\([^nt"])/\\\\\1/g' -e 's/[\x00-\x1f]//g' | tr -d '\r\0\t'
  # escape percent sign for template, escape quotes, escape backslash, escape tabs, fix double escapes, delete control characters
}

function field () {
  #git show -s --format="$1" "$2" | sanitize
  #git show -s --format="$1" "$2" | jq -Rsa .
  #git show -s --format="$1" "$2" | sed -Ez '$ s/\n+$//' | jq --slurp --raw-input
  git show -s --format="$1" "$2" | perl -ne 'if (/./) { print "\n" x $n, $_; $n = 0 } else { $n++ }' | jq -Rsa .
}

git log --pretty=format:'%H' | while IFS='' read -r hash; do
  TMP="$TMPL"
  msg=$(field "%B" $hash)
  author=$(field "%aN" $hash)
  commiter=$(field "%cN" $hash)
  TMP="${TMP/MSG/$msg}"
  TMP="${TMP/AUTHOR/$author}"
  TMP="${TMP/COMMITER/$commiter}"
  git show $hash -s --format="$TMP"
done

gha: Emacs Lisp, lang: shell
﻿using System;
using System.Collections.Generic;
using System.IO;
using System.Linq;
using System.Text;
using System.Threading.Tasks;

namespace F4Utils.Campaign.Tests
{
    internal class TestDatalLocations
    {
        public const string BMSBasePath = @"C:\Falcon BMS 4.33 RC6 (Internal)\";
        public const string BMSDataFolder = @"Data\";
        public const string TerrainBaseFolder = BMSBasePath + BMSDataFolder + @"Terrdata\";
        public const string TerrainObjectsFolder = TerrainBaseFolder + @"Objects\";
        public const string AcdFile= TerrainObjectsFolder + @"FALCON4.ACD";
        public const string DdpFile = TerrainObjectsFolder + @"FALCON4.DDP";
        public const string ClassTable = TerrainObjectsFolder + @"FALCON4.CT";
        public const string TestDataOutputFolder = @"C:\lightningtools_testjunk\";
    }
}

gha: C#, lang: c_sharp
﻿using System;
using System.Collections.Generic;
using System.ComponentModel.DataAnnotations.Schema;
using Dwapi.Hts.SharedKernel.Custom;
using Dwapi.Hts.SharedKernel.Model;

namespace Dwapi.Hts.Core.Domain
{
    public class HtsClient : Entity<Guid>
    {

        public virtual string HtsNumber { get; set; }
        public virtual string Emr { get; set; }
        public virtual string Project { get; set; }


        public int PatientPk { get; set; }
        public int SiteCode { get; set; }
        public string FacilityName { get; set; }
        public string Serial { get; set; }
        public DateTime DateExtracted { get; set; }
        public virtual bool? Processed { get; set; }
        public virtual string QueueId { get; set; }
        public virtual string Status { get; set; }
        public virtual DateTime? StatusDate { get; set; }
        public DateTime DateCreated { get; set; } = DateTime.Now;

        public int? EncounterId { get; set; }
        public DateTime? VisitDate { get; set; }
        public DateTime? Dob { get; set; }
        public string Gender { get; set; }
        public string MaritalStatus { get; set; }
        public string KeyPop { get; set; }
        public string TestedBefore { get; set; }
        public int? MonthsLastTested { get; set; }
        public string ClientTestedAs { get; set; }
        public string StrategyHTS { get; set; }
        public string TestKitName1 { get; set; }
        public string TestKitLotNumber1 { get; set; }
        public DateTime? TestKitExpiryDate1 { get; set; }
        public string TestResultsHTS1 { get; set; }
        public string TestKitName2 { get; set; }
        public string TestKitLotNumber2 { get; set; }
        public string TestKitExpiryDate2 { get; set; }
        public string TestResultsHTS2 { get; set; }
        public string FinalResultHTS { get; set; }
        public string FinalResultsGiven { get; set; }
        public string TBScreeningHTS { get; set; }
        public string ClientSelfTested { get; set; }
        public string CoupleDiscordant { get; set; }
        public string TestType { get; set; }

        public string KeyPopulationType { get; set; }
        public string PopulationType{ get; set; }
        public string PatientDisabled{ get; set; }
        public string DisabilityType { get; set; }
        public string PatientConsented{ get; set; }
        public  string County	 { get; set; }
        public  string  SubCounty	 { get; set; }
        public  string Ward	 { get; set; }
        public string NUPI { get; set; }
        public string Pkv { get; set; }
        public string Occupation { get; set; }
        public string PriorityPopulationType { get; set; }
        public string HtsRecencyId { get; set; }

        public DateTime? Date_Created { get; set; }
        public DateTime? Date_Last_Modified { get; set; }

        public Guid FacilityId { get; set; }



        public HtsClient()
        {
        }

        public override void UpdateRefId()
        {
            RefId = Id;
            Id = Guid.NewGuid();
        }
    }
}

gha: C#, lang: c_sharp
package com.lujian.orc;

import java.util.HashMap;

import org.json.JSONArray;
import org.json.JSONException;
import org.json.JSONObject;

import com.baidu.aip.ocr.AipOcr;

/**
 * 识别图片中的文字
 * 
 * @author Administrator
 *
 */
public class ApiOrcUtil {

	 //设置APPID/AK/SK
	private static String APP_ID = "16774949";
	private static String API_KEY = "psBgBHA1PYocGRNWfbt7Dbc6";
	private static String SECRET_KEY = "e03dh6oTlQPF1YW0Dfe20G51vuAMRce3";

	/**
	 * 识别身份证
	 * 
	 * @param photoPath
	 * @return
	 */
    public static String getPictureString(String photoPath){

        // 初始化一个AipOcr
        AipOcr client = new AipOcr(APP_ID, API_KEY, SECRET_KEY);

        // 可选：设置网络连接参数
        client.setConnectionTimeoutInMillis(2000);
        client.setSocketTimeoutInMillis(60000);

        // 传入可选参数调用接口
        HashMap<String, String> options = new HashMap<String, String>();
        // 是否检测朝向
        options.put("detect_direction", "false");
        // 是否检测风险
        options.put("detect_risk", "false");

        // 正反面front /back
        String idCardSide = "front";

        // 参数为本地图片二进制数组
        /*byte[] file = new byte[0];
        try {
            file = Util.readFileByBytes(photoPath);
        } catch (IOException e) {
            e.printStackTrace();
        }
        JSONObject res = client.idcard(file, idCardSide, options);
        System.out.println(res.toString(2));*/


        // 参数为本地图片路径
        try {
            JSONObject res = client.idcard(photoPath, idCardSide, options);
            System.out.println(res.toString(2));
            if (res != null) {
                JSONObject idCard = new JSONObject();
                JSONObject words_result = res.getJSONObject("words_result");

                idCard.put("name", words_result.getJSONObject("姓名").get("words"));
                idCard.put("nation", words_result.getJSONObject("民族").get("words"));
                idCard.put("address", words_result.getJSONObject("住址").get("words"));
                idCard.put("sex", words_result.getJSONObject("性别").get("words"));
                idCard.put("birth", words_result.getJSONObject("出生").get("words"));
                idCard.put("number", words_result.getJSONObject("公民身份号码").get("words"));
                return idCard.toString(2);
            } else {
                return "";
            }
        }catch (JSONException e){
            e.printStackTrace();
        }
        return null;
    }

	/**
	 * 识别车牌
	 * 
	 * @param photoPath
	 * @return
	 */
	public static String getPlateLicense(String photoPath) {

		// 初始化一个AipOcr
		AipOcr client = new AipOcr(APP_ID, API_KEY, SECRET_KEY);

		// 可选：设置网络连接参数
		client.setConnectionTimeoutInMillis(2000);
		client.setSocketTimeoutInMillis(60000);

		// 传入可选参数调用接口
		HashMap<String, String> options = new HashMap<String, String>();
		// multi_detect 是否检测多张车牌
		options.put("multi_detect", "true");

		// 参数为本地图片二进制数组
		/*
		 * byte[] file = new byte[0]; try { file =
		 * Util.readFileByBytes(photoPath); } catch (IOException e) {
		 * e.printStackTrace(); } JSONObject res = client.idcard(file,
		 * idCardSide, options); System.out.println(res.toString(2));
		 */

		// 参数为本地图片路径
		try {
			JSONObject res = client.plateLicense(photoPath, options);
			System.out.println(res.toString(2));
			if (res != null) {
				JSONObject plateLicense = new JSONObject();
				JSONArray words_result1 = res.getJSONArray("words_result");
				for (int i = 0; i < words_result1.length(); i++) {
					int j = i + 1;
					JSONObject myjObject = words_result1.getJSONObject(i);
					plateLicense.put(j + "号车牌", myjObject.get("number"));
				}
				return plateLicense.toString(2);
			} else {
				return "";
			}
		} catch (JSONException e) {
			e.printStackTrace();
		}
		return null;
	}

    public static void main(String[] args) {
		System.out.println(getPictureString("D:/sfz.png"));
    }

}

gha: CSS, lang: groovy
package com.tcs.myApp.model;

import java.util.ArrayList;

public class Library2 
{
	private String location;
	private ArrayList<Book>books=new ArrayList();
	public String getLocation() {
		return location;
	}
	public void setLocation(String location) {
		this.location = location;
	}
	public ArrayList<Book> getBooks() {
		return books;
	}
	public void setBooks(ArrayList<Book>books) {
		this.books = books;
	}
	public Library2(String location, ArrayList<Book> books2) {
		super();
		this.location = location;
		this.books = books2;
	}
	
	public void printAllBookDetails()
	{
		System.out.println("Using Normal for loop...");
		for (int i=0;i<books.size();i++)
		{
			System.out.println("Book ID - "+books.get(i).getBookId());
			System.out.println("Name of Book -"+books.get(i).getBookName());
			System.out.println("Name of Author -"+books.get(i).getBookAuthor());
			System.out.println("Price of Book -"+books.get(i).getBookPrice());
			System.out.println();
			
		}
	}
	
	public void printAllBookDetailsForEach()
	{
		System.out.println("Using FOR EACH loop");
		for(Book b:books)
		{
			System.out.println("Book ID - "+b.getBookId());
			System.out.println("Name of Book - "+b.getBookName());
			System.out.println("Name of Author - "+b.getBookAuthor());
			System.out.println("Price of Book - "+b.getBookPrice());
			System.out.println();
		}
	}
}

gha: Java, lang: groovy
# Sympletron

## What is it?
Sympletron is a very simple programming language with embedded interpreter, which has the indivisibility of memory (instructions and data are stored in the same memory) and can do some very simple operations.
It can read an integer from the keyboard and place it at the specified address in its memory, it can display an integer or instruction number placed in the specified memory cell.
Sympletron also can add, subtract and multiply the numbers in the specified cell with the value placed in the accumulator (just like in assembly).
The list of commands is really small, but this project can be expanded, for example, to add the ability to work with floating point numbers, to change the memory representation to hexadecimal, to expand the memory, to save the memory state after the last execution, etc.

## How to build and run?
The executable file located in `bin/Debug/Project_Sympletron.exe.` All you need to do is just to run it.

## How to use?
### Subtracting with keyboard input
At the beginning the Sympletron will greet you. Then it will show you a list of commands and their codes after which it will offer you a "terminal" to work with it.

<img src="/screenshots/sympletron_greeting.png" alt="Greeting_of_Sympletron"/>

Then you can choose the type of input: enter 1 to select keyboard input, enter 2 to select input from the file. We choose the 1st option in this example.
After that you can start to input the commands. To finish entering commands you must enter 4300. Then you must enter -99999 to start the program execution.
After the program execution Sympletron displays all information about its state on the screen.

An example of subtracting two numbers is shown in the screenshot below.

`00? 1002`   - enter a number into the 2nd memory cell  
`01? 4003`   - go to the instruction on the 3rd memory cell  
`02? 0000`   - reserve the 2nd memory cell for data  
`03? 1005`   - enter a number into the 5th memory cell  
`04? 4006`   - go to the instruction on the 6th memory cell  
`05? 0000`   - reserve the 5th memory cell for data  
`06? 2002`   - put the number from the 2nd memory cell to the accumulator  
`07? 3105`   - subtract from the number in the accumulator the number in the 5th cell  
`08? 2110`   - output the number from the accumulator to the 10th memory cell  
`09? 4011`   - go to the instruction on the 11th memory cell  
`10? 0000`   - reserve the 10th memory cell for data  
`11? 4300`   - end the entering of commands  
`12? -99999` - start the program execution  

<img src="/screenshots/subtracting_with_keyboard.png" alt="Subrtacting"/>

### Loop implementation with input from the file
To input your program from the file you must put this file in `bin/Debug/` and name it `commands.txt`.

To show the implementation of conditional operators and loops let's solve a simple problem. 
If the user enters a negative number or equal to zero, this number will be displayed on the screen.
If the user enters a positive number, numbers down to 1 will be displayed.
The user is asked to enter two numbers, the first of which should always be 1, because it is an decrement, the second number is a condition for solving the problem.

`00? 1002` - enter a number into the 2nd memory cell  
`01? 4003` - go to the instruction on the 3rd memory cell  
`02? 0000` - reserve the 2nd memory cell for data  
`03? 1005` - enter a number into the 5th memory cell  
`04? 4006` - go to the instruction on the 6th memory cell  
`05? 0000` - reserve the 5th memory cell for data  
`06? 2005` - put the number from the 5th memory cell to the accumulator  
`07? 1105` - output to screen the number from the 5th memory cell  
`08? 4117` - go to the instruction on the 17th memory cell if accumulator less then 0  
`09? 4217` - go to the instruction on the 17nd memory cell if accumulator equals 0  
`10? 3102` - subtract from the number in the accumulator the number in the 2nd cell  
`11? 2113` - output the number from the accumulator to the 13th memory cell  
`12? 4014` - go to the instruction on the 14th memory cell  
`13? 0000` - reserve the 11th memory cell for data  
`14? 1113` - output to screen the number from the 13th memory cell  
`15? 4118` - go to the instruction on the 18nd memory cell if accumulator less then 0  
`16? 4218` - go to the instruction on the 18nd memory cell if accumulator equals 0  
`17? 4010` - go to the instruction on the 10th memory cell  
`18? 4300` - end the entering of commands in this branch  
`19? -99999` - start the program execution  

<img src="/screenshots/code_of_program.png" alt="Code"/>

The implementation of the loop is shown by the 10th-16th commands.

<img src="/screenshots/execution.png" alt="Execution"/>

## Updates
### Verion 1.1 (18.10.2021)
* New functionality: conditional statements and loops.
* The ability to read programs from a file has been added.
* Memory processing were improved.
* Code structure was redesigned.

## P. S. 
This is my first pet-project and first README file also. 
The project was written on C. And the main purpose of writting it is to improve my skills in using github and to try to write good description of this simple project.

## Support
You can contact me using email vitalymayer1706@gmail.com. I'd be happy to help you.
gha: C, lang: markdown
// 関数f(x)
var f = function(x){
  return x*x - 4.0;
};

// 導関数f'(x)
var df = function(x){
  return 2.0*x;
};

// ニュートン法
var newtonMethod = function(a, eps){
    var i = 0;
    while(i<1000){
        i++;
        // 漸化式
        ah = a - f(a)/df(a)
        // 収束条件(近似解の変化が十分小さい)を満たせば計算終了
        if (Math.abs(ah - a) < eps) break;
        //　近似解の更新
        a = ah    
    }  
    return a;
    
};


window.onload=function () {
    alert(newtonMethod(1.0, 0.0001)); // 2.0000000929222947
};

gha: C, lang: javascript
import React, { FC } from 'react';

interface PictureProps {
  alt?: string;
  jpeg?: string;
  jpg?: string;
  png?: string;
  webp?: string;
}

const Picture: FC<PictureProps> = ({ alt = '', jpeg, jpg, png, webp }: PictureProps) => (
  <picture>
    {webp && <source srcSet={webp} type='image/webp' />}
    {jpeg && <source srcSet={jpeg} type='image/jpeg' />}
    {png && <source srcSet={png} type='image/png' />}
    <img src={jpg || png} alt={alt} />
  </picture>
);

export default Picture;
gha: TypeScript, lang: javascript
> 







## 最小表示法

> 找出字符串S的循环同构串中字典序最小的那个

![](https://wat1r-1311637112.cos.ap-shanghai.myqcloud.com/imgs/20220530224453.png)

```c++
#include <iostream>
#include <algorithm>

using namespace std;
const int N = 1e5 + 10;
int n;
char s[N];

int get_min(char *s)
{
    n = strlen(s + 1);
    for (int i = 1; i <= n; i++)
    {
        s[n + i] = s[i];
    }
    int i = 1, j = 2, k = 0;
    while (i <= n && j <= n)
    {
        for (k = 0; k < n && s[i + k] == s[j + k]; k++)
            ;
        s[i + k] > s[j + k] ? i = i + k + 1 : j = j + k + 1;
        if (i == j)
        {
            j++;
        }
    }
    return min(i, j);
}
```



### [796. 旋转字符串](https://leetcode.cn/problems/rotate-string/)

> 最小表示法的思路：

- 1.当前字符复制一倍，单链成环

- 2.初始化指针i =0 ,j =1 ,匹配长度k=0

- 3.比较`s[i+k]`与`s[j+k]`的大小

  - `s[i+k]`=`s[j+k]`时k++
  - `s[i+k]`>`s[j+k]`时i=i+k+1
  - `s[i+k]`<`s[j+k]`时j=j+k+1

  - 如果i=j时，表明在同一个位置上，需要岔开一位，让j++

- 4.重复上面的过程，取到最小值即min(i,j)

> 本题的思路

- 拿到两个字符的s和goal的最小表示法下的字符串，即字典序最小的那个，如果是一样的，说明s可以翻转得到goal

```java
//最小表示法
public boolean rotateString(String s, String goal) {
    if (s.length() != goal.length()) return false;
    return getMin(s).equals(getMin(goal));
}


public String getMin(String s) {
    int n = s.length();
    s = s + s;
    int i = 0, j = 1, k = 0;
    while (i < n && j < n) {
        for (k = 0; k < n && s.charAt(i + k) == s.charAt(j + k); k++) ;
        if (s.charAt(i + k) > s.charAt(j + k)) {
            i = i + k + 1;
        } else {
            j = j + k + 1;
        }
        if (i == j) {
            j++;
        }
    }
    int t = Math.min(i, j);
    return s.substring(t, t + n);
}
```



## [158.项链](https://www.acwing.com/problem/content/160/)

```java
static class Main {

    static Main main = new Main();

    public static void main(String[] args) {
        main.process();
    }


    private void process() {
        Scanner in = new Scanner(System.in);
        String a = in.next(), b = in.next();
        String aa = getMin(a), bb = getMin(b);
        if (aa.equals(bb)) {
            System.out.println("Yes");
            System.out.println(aa);
        } else {
            System.out.println("No");
        }

    }

    public String getMin(String s) {
        int n = s.length();
        s = s + s;
        char[] ch = s.toCharArray();
        int i = 0, j = 1;
        while (i < n && j < n) {
            int k = 0;//while的写法把k放在内侧
            while (k < n && ch[i + k] == ch[j + k]) k++;
            if (ch[i + k] > ch[j + k]) {
                i += k + 1;
            } else {
                j += k + 1;
            }
            if (i == j) j++;
        }
        int t = Math.min(i, j);
        return s.substring(t, t + n);
    }
}
```



## [899. 有序队列](https://leetcode.cn/problems/orderly-queue/)

- 当k=1时，即求字符串的最小表示法

- 当k>1时，每次可以调整开头的的至少两个字符的位置，如bazzz->  bzzza -> zzzab  ...->abzzz，对于在排序算法中，值需要交换相邻的两个字符可以实现序列有序，所以这种情况下只需要字符串排序即可

- 当 K = 2 时，可以发现，我们能够交换字符串中任意两个相邻的字母。具体地，设字符串 S 为 S[1], S[2], ..., S[i], S[i + 1], ..., S[N]，我们需要交换 S[i] 和 S[j]。首先我们依次将 S[i] 之前的所有字符依次移到末尾，得到

  S[i], S[i + 1], ..., S[N], S[1], S[2], ..., S[i - 1]

  随后我们先将 S[i + 1] 移到末尾，再将 S[i] 移到末尾，得到

  S[i + 2], ..., S[N], S[1], S[2], ..., S[i - 1], S[i + 1], S[i]

  最后将 S[i + 1] 之后的所有字符依次移到末尾，得到

  S[1], S[2], ..., S[i - 1], S[i + 1], S[i], S[i + 2], ..., S[N]

  这样就交换了 S[i] 和 S[i + 1]，而没有改变其余字符的位置。

  当我们可以交换任意两个相邻的字母后，就可以使用冒泡排序的方法，仅通过交换相邻两个字母，使得字符串变得有序。因此当 K = 2 时，我们可以将字符串移动得到最小的字典序。

  当 K > 2 时，我们可以完成 K = 2 时的所有操作。

```java
        public String orderlyQueue(String s, int k) {
            if (k == 1) return getMin(s);
            char[] ch = s.toCharArray();
            Arrays.sort(ch);
            return String.valueOf(ch);
        }

        public String getMin(String s) {
            int n = s.length();
            s = s + s;
            int i = 0, j = 1;
            while (i < n && j < n) {
                int p = 0;
                while (p < n && s.charAt(i + p) == s.charAt(j + p)) p++;
                if (s.charAt(i + p) > s.charAt(j + p)) {
                    i += p + 1;
                } else {
                    j += p + 1;
                }
                if (i == j) j++;
            }
            int q = Math.min(i, j);
            return s.substring(q, q + n);
        }
```



## 字典树

- 208. 实现 Trie (前缀树) —— 中等
- 211. 添加与搜索单词 - 数据结构设计 —— 中等
- 421. 数组中两个数的最大异或值 —— 中等
- 648. 单词替换 —— 中等
- 676. 实现一个魔法字典 —— 中等
- 692. 前K个高频单词 —— 中等
- 212. 单词搜索 II —— 困难
- 336. 回文对 —— 困难













## 最大异或对



### [421. 数组中两个数的最大异或值](https://leetcode.cn/problems/maximum-xor-of-two-numbers-in-an-array/)

```java
public int findMaximumXOR(int[] nums) {
    for (int x : nums) insert(x);
    int maxx = 0;
    for (int x : nums) {
        maxx = Math.max(maxx, query(x));
    }
    return maxx;
}


Trie root = new Trie();

public void insert(int x) {
    Trie cur = root;
    for (int i = 30; i >= 0; i--) {
        int u = x >> i & 1;//找打二进制的第i位上判断是0还是1
        if (cur.children[u] == null) {
            cur.children[u] = new Trie();
        }
        cur = cur.children[u];
    }
}


public int query(int x) {
    Trie cur = root;
    int res = 0;
    for (int i = 30; i >= 0; i--) {
        int u = x >> i & 1;//找打二进制的第i位上判断是0还是1
        if (cur.children[u ^ 1] != null) {//如果当前位u的另外一个分支可以走的，那就走这个分支
            res += (1 << i);//相当于当前的值左移i位叠加到res上
            cur = cur.children[u ^ 1];
        } else {//另外一个分支是空，只能和当前的分支一起前行
            cur = cur.children[u];
        }
    }
    return res;
}


class Trie {
    Trie[] children = new Trie[2];
}
```



### [剑指 Offer II 067. 最大的异或](https://leetcode.cn/problems/ms70jA/)

```java
public int findMaximumXOR(int[] nums) {
    for (int x : nums) insert(x);
    int maxx = 0;
    for (int x : nums) {
        maxx = Math.max(maxx, query(x));
    }
    return maxx;
}


Trie root = new Trie();

public void insert(int x) {
    Trie cur = root;
    for (int i = 30; i >= 0; i--) {
        int u = x >> i & 1;//找打二进制的第i位上判断是0还是1
        if (cur.children[u] == null) {
            cur.children[u] = new Trie();
        }
        cur = cur.children[u];
    }
}


public int query(int x) {
    Trie cur = root;
    int res = 0;
    for (int i = 30; i >= 0; i--) {
        int u = x >> i & 1;//找打二进制的第i位上判断是0还是1
        if (cur.children[u ^ 1] != null) {//如果当前位u的另外一个分支可以走的，那就走这个分支
            res += (1 << i);//相当于当前的值左移i位叠加到res上
            cur = cur.children[u ^ 1];
        } else {//另外一个分支是空，只能和当前的分支一起前行
            cur = cur.children[u];
        }
    }
    return res;
}


class Trie {
    Trie[] children = new Trie[2];
}
```

###  [1707. 与数组中元素的最大异或值](https://leetcode.cn/problems/maximum-xor-with-an-element-from-array/)

```java
    static class _1st {
        public static void main(String[] args) {
            _1st handler = new _1st();


        }


        public int[] maximizeXor(int[] nums, int[][] _queries) {
            Arrays.sort(nums);
            int n = _queries.length;
            int[][] queries = new int[n][3];
            for (int i = 0; i < n; i++) {
                queries[i][0] = _queries[i][0];
                queries[i][1] = _queries[i][1];
                queries[i][2] = i;
            }
            Arrays.sort(queries, (a, b) -> a[1] - b[1]);
            int[] res = new int[n];
            int idx = 0;
            n = nums.length;
            for (int[] q : queries) {
                int x = q[0], m = q[1], qid = q[2];
                while (idx < n && nums[idx] <= m) {
                    insert(nums[idx]);
                    idx++;
                }
                if (idx == 0) {
                    res[qid] = -1;
                } else {
                    res[qid] = query(x);
                }
            }
            return res;
        }


        public int query(int x) {
            int res = 0;
            Trie cur = root;
            for (int i = 30; i >= 0; --i) {
                int u = x >> i & 1;
                if (cur.children[u ^ 1] != null) {
                    res |= 1 << i;
                    u ^= 1;
                }
                cur = cur.children[u];
            }
            return res;
        }


        public void insert(int x) {
            Trie cur = root;
            for (int i = 30; i >= 0; --i) {
                int u = x >> i & 1;
                if (cur.children[u] == null) {
                    cur.children[u] = new Trie();
                }
                cur = cur.children[u];
            }
        }

        Trie root = new Trie();


        class Trie {
            Trie[] children = new Trie[2];
        }

    }
```





1163

> https://www.bilibili.com/video/av64366938
gha: Java, lang: cpp
import { HTTPError } from "./../utils/HTTPError";
import { User } from "../db/models";
import { CreateUser, UserEditable } from "../types/user";
import { injectable } from "inversify";
import { hash } from "bcrypt";
import { DB } from "../db/utils/DB";

@injectable()
export class UserRepository {
	constructor(public readonly db: DB) {}

	public all() {
		return User.query();
	}

	public create(data: CreateUser) {
		return User.query().insertGraphAndFetch(data);
	}

	public findById(id: number | string) {
		return User.query().findById(id);
	}

	public findOne(column: keyof User, value: string | number) {
		return User.query().findOne(column, value);
	}

	public async updateById(id: number, data: UserEditable) {
		if (data.password) {
			data.password = await hash(data.password, 10);
		}

		return User.query().updateAndFetchById(id, data);
	}

	public async deleteById(id: number | string) {
		const user = await this.findById(id);
		if (!user) {
			throw new HTTPError(`Failed deleting user with id ${id}, not found.`, 404);
		}
		await user.$query().delete();
		return true;
	}

	public async deleteMany(users: User[]) {
		for (const user of users) {
			await this.deleteById(user.id);
		}
	}

	public countWhere(column: keyof User, value: string | number) {
		return this.db.count(User.query().findOne(column, value));
	}

	public count() {
		return this.db.count(User.query());
	}
}

gha: TypeScript, lang: javascript
# multidim::for_eachs / multidim::for_eachs_n


```cpp
template <typename Function, typename InputIt, typename... InputIts>
constexpr inline Function for_eachs(Function f, InputIt first, InputIt last, InputIts... firsts);
```
```cpp
template <typename Function, typename InputIt, typename Size, typename... InputIts>
constexpr inline InputIt for_eachs_n(Function f, InputIt first, Size n, InputIts... firsts);
```

These functions are similar to `multidim::for_each` and `multidim::for_each_n`, but allow multiple sequences to be iterated together.  For `for_eachs`, `std::distance(first, last)` determines the number of applications of `f`; for `for_eachs_n`, `n` determines the number of applications of `f`.

`f` - function object, which must be callable as `f(*it, (*its)...)`, where `it` has type `InputIt` and `its...` has type `InputIts...`.

### Possible implementation

```cpp
template <typename Function, typename InputIt, typename... InputIts>
constexpr inline Function for_eachs(Function f, InputIt first, InputIt last, InputIts... firsts) {
    for (; first != last; ++first, ((++firsts), ...)) {
        f(*first, (*firsts)...);
    }
    return f;
}
template <typename Function, typename InputIt, typename Size, typename... InputIts>
constexpr inline InputIt for_eachs_n(Function f, InputIt first, Size n, InputIts... firsts) {
    for (Size i = 0; i < n; ++i, ++first, ((++firsts), ...)) {
        f(*first, (*firsts)...);
    }
    return first;
}
```

gha: C++, lang: markdown
#include<iostream>
using namespace std;
int main() {
	char a[50];
	cin>>a;

	int i=0;
	if(a[i]=='9')
	{
		i++;
	}
	// Iterate over remaining chars
	for( ;a[i]!='\0';i++)
	{
		// Convert my char into a int digit
		int digit=a[i]-'0';
		if(digit>=5)
		{
			digit=9-digit;
			a[i]=digit + '0';
		}
	}
	cout<<a<<endl;
	return 0;
}

gha: C++, lang: cpp
# Setting up Native Instruments Komplete 6 for Audacity

Tags: `#GriffWiki`

This is our family guide to setting up a Native Instruments Komplete Audio 6 soundcard with a voice recording mic. It may be of limited use to outsiders ;)

 * Plug the sound card into the PC via USB
 * The lights should come on steady on the sound card;
	 + If they don't, unplug and replug, or try a different USB port.
 * Plug the mic via XLR into channel 1 or 2 and check the connection is good at both ends
 * Set the button for the Mic to INST (INSTrument level is for things with no built-in preamp, like mics and guitar pickups. LINE level is for powered inputs like Keyboards or Drum machines)
 * Switch on the 48V (phantom power) button on the back of the sound card by pressing it in
	 + The light on the mic should come on; if it doesn't, check the XLR connection and that the sound card is able to draw enough power.
 * Turn up the gain knob for the channel you're using. It's better to use the high quality preamp in the soundcard than amps and software amps on the computer, and this should reduce hiss and buzz.

## Things to check

 * Right click the Volume icon, go to Recording devices, and set `Komplete Audio Channel 1|2` to the default recording device
 * In Audacity, select `Komplete Audio Channel 1|2` as the recording device in the top bar. Monitor the level and test it
 * If there is a problem, try switching between Mono and Stereo
 * You may need to close and re-open Audacity
 * Make a test recording and play it back. Tap on the laptop body during the recording to verify that it is not recording using the laptop body mic.


gha: PHP, lang: markdown
<template>
    <v-row justify="center">
        <v-dialog
                v-model="showAlert"
                max-width="290">
            <v-card>
                <v-card-title class="headline red lighten-2">
                    <span class="white--text">Server Error</span>
                </v-card-title>
                <v-card-text class="pa-2">
                    Some internal server error accrued
                </v-card-text>
                <v-card-text class="pa-2">
                    Please try again in a moment
                </v-card-text>
                <v-card-actions>
                    <v-spacer></v-spacer>
                    <v-btn
                            color="green darken-1"
                            text
                            @click="emitCloseAlert()">
                        Close
                    </v-btn>
                </v-card-actions>
            </v-card>
        </v-dialog>
    </v-row>
</template>

<script>
    export default {
        name: 'ServerErrAlert',
        props: {
            showAlert: Boolean,
            errorDescription: String // For later use
        },
        methods: {
            emitCloseAlert () {
                this.$emit('alertclose')
            }
        }
    }
</script>

<style scoped>

</style>

gha: Vue, lang: html
---
title: "유튜브에서 앨범 전체 받아서 컬렉션 만들기"
tags: [youtube]
layout: post
author: "Keith"
---

세상이 좋아져서 구하기 힘든 음반을 전체로 cd rip을 해서 유튜브에 올려놓는 사람들까지 생겼다. 워낙 오래된 앨범이고 돈이 된다고 생각을 하지 않아서인지 (그래서 찍어내서 팔지도 않겠지만) 저작권을 문제 삼지 않는 음반도 상당히 많은 것을 알게 되었다. 앨범이 나왔을 때 일본의 어느 레코드 점에서 본 적 있었던, 그러나 사지 못했던, 앨범도 유튜브에 있었다. 이렇게 잘 만든 앨범이 전혀 뜨지 못했구나 생각하면 음악의 상업적 성공은 뮤지션의 능력이라든가 작품의 퀄리티와는 전적으로 무관한 것이라는 것도 알게 된다. 

그러면 어떻게 하느냐?

1) 유튜브에서 오디오를 다운로드 받는다 (방법은 워낙 많아서 그냥 검색하면 나온다).
2) 오디오를 받으면 대개 AAC format (m4a)로 나오는데, ffmpeg 같은 것으로 wave로 바꿔주면 처리가 간편해진다.
3) Cue sheet를 만든다. 어디서 cue sheet를 가져올 수 있으면 더 좋다.
4) XLD 같은 소프트웨어를 쓰면 cue sheet만 넘겨도 split/format conversion이 자동으로 이루어진다. 물론 labeling도 다 알아서 해준다.
5) album artwork을 찾아서 붙여주고 파일들을 보관한다.

자동화시키면 이 작업은 모두 해봐야 5분 이내로 다 끝난다. 문제는 cue sheet를 작성하는 것이다. wave file을 자동으로 분석해서 트랙별로 자동 분할을 할 수도 있는데, 그게 분할이 되지 않는 것들도 있어서 이 방법을 적용하긴 좀 어려움이 있다.



gha: HTML, lang: ini
<template>
  <span
    :class="{small, medium, big}"
    :style="getIconStyles"
    class="anthive-icon"
    @click="$emit('click')" />
</template>

<script>
export default {
  name: 'AntHiveIcon',
  props: {
    small: {
      type: Boolean,
      required: false,
      default: false
    },
    medium: {
      type: Boolean,
      required: false,
      default: false
    },
    big: {
      type: Boolean,
      required: false,
      default: false
    },
    color: {
      type: String,
      required: false,
      default: 'black'
    },
    icon: {
      type: String,
      required: true
    }
  },
  computed: {
    getIconStyles() {
      return `
        background-color: ${this.color};
        -webkit-mask: url(/img/${this.icon}.svg) no-repeat center;
        mask: url(/img/${this.icon}.svg) no-repeat center;
        mask-size: cover;
      `
    }
  }
}
</script>

<style lang="scss" scoped>
.anthive-icon {
  display: inline-block;
  width: 22px;
  height: 22px;
}
.small {
  width: 16px;
  height: 16px;
}
.medium {
  width: 24px;
  height: 24px;
}
.big {
  width: 40px;
  height: 40px;
}
</style>

gha: Vue, lang: javascript
name: ci

on:
  [pull_request]

jobs:
  buildx:
    runs-on: ubuntu-latest
    steps:
      -
        name: Checkout
        uses: actions/checkout@v2
      -
        uses: docker/setup-buildx-action@v1
        id: buildx
        with:
          install: true
      -
        name: Build
        run: |
          docker build . # will run buildx

gha: OCaml, lang: yaml
/*
 * arch/arm/mach-spear13xx/platsmp.c
 *
 * based upon linux/arch/arm/mach-realview/platsmp.c
 *
 * Copyright (C) 2012 ST Microelectronics Ltd.
 * Shiraz Hashim <shiraz.hashim@st.com>
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License version 2 as
 * published by the Free Software Foundation.
 */

#include <linux/delay.h>
#include <linux/jiffies.h>
#include <linux/io.h>
#include <linux/smp.h>
#include <asm/cacheflush.h>
#include <asm/smp_scu.h>
#include <mach/spear.h>
#include "generic.h"

static DEFINE_SPINLOCK(boot_lock);

static void __iomem *scu_base = IOMEM(VA_SCU_BASE);

static void __cpuinit spear13xx_secondary_init(unsigned int cpu)
{
	/*
	 * let the primary processor know we're out of the
	 * pen, then head off into the C entry point
	 */
	pen_release = -1;
	smp_wmb();

	/*
	 * Synchronise with the boot thread.
	 */
	spin_lock(&boot_lock);
	spin_unlock(&boot_lock);
}

static int __cpuinit spear13xx_boot_secondary(unsigned int cpu, struct task_struct *idle)
{
	unsigned long timeout;

	/*
	 * set synchronisation state between this boot processor
	 * and the secondary one
	 */
	spin_lock(&boot_lock);

	/*
	 * The secondary processor is waiting to be released from
	 * the holding pen - release it, then wait for it to flag
	 * that it has been released by resetting pen_release.
	 *
	 * Note that "pen_release" is the hardware CPU ID, whereas
	 * "cpu" is Linux's internal ID.
	 */
	pen_release = cpu;
	flush_cache_all();
	outer_flush_all();

	timeout = jiffies + (1 * HZ);
	while (time_before(jiffies, timeout)) {
		smp_rmb();
		if (pen_release == -1)
			break;

		udelay(10);
	}

	/*
	 * now the secondary core is starting up let it run its
	 * calibrations, then wait for it to finish
	 */
	spin_unlock(&boot_lock);

	return pen_release != -1 ? -ENOSYS : 0;
}

/*
 * Initialise the CPU possible map early - this describes the CPUs
 * which may be present or become present in the system.
 */
static void __init spear13xx_smp_init_cpus(void)
{
	unsigned int i, ncores = scu_get_core_count(scu_base);

	if (ncores > nr_cpu_ids) {
		pr_warn("SMP: %u cores greater than maximum (%u), clipping\n",
			ncores, nr_cpu_ids);
		ncores = nr_cpu_ids;
	}

	for (i = 0; i < ncores; i++)
		set_cpu_possible(i, true);
}

static void __init spear13xx_smp_prepare_cpus(unsigned int max_cpus)
{

	scu_enable(scu_base);

	/*
	 * Write the address of secondary startup into the system-wide location
	 * (presently it is in SRAM). The BootMonitor waits until it receives a
	 * soft interrupt, and then the secondary CPU branches to this address.
	 */
	__raw_writel(virt_to_phys(spear13xx_secondary_startup), SYS_LOCATION);
}

struct smp_operations spear13xx_smp_ops __initdata = {
       .smp_init_cpus		= spear13xx_smp_init_cpus,
       .smp_prepare_cpus	= spear13xx_smp_prepare_cpus,
       .smp_secondary_init	= spear13xx_secondary_init,
       .smp_boot_secondary	= spear13xx_boot_secondary,
#ifdef CONFIG_HOTPLUG_CPU
       .cpu_die			= spear13xx_cpu_die,
#endif
};

gha: C, lang: cpp
OneServer
=========

The OneServer server.
gha: Python, lang: ini
﻿using System.Collections.Generic;

namespace ObjectsComparator.Tests.TestModels
{
    internal class Library
    {
        public Dictionary<string, Book> Books { get; set; } = new();
    }

    internal class Library2
    {
        public IDictionary<string, Book> Books { get; set; } = new Dictionary<string, Book>();
    }
}
gha: C#, lang: c_sharp
---
layout: post
title:  "Elasticsearch Parte II - Busquedas"
date:   2016-05-08 00:37:19 -0300
categories: elasticsearch
---
## Search API

```javascript
curl -XGET 'search-es:9200/bank/_search?q=*&sort=account_number:asc&pretty&pretty'
```

Primero buscamos ( ```_search``` final) en el índice de bancos, y el ```q=*``` parámetro indica Elasticsearch para que coincida con todos los documentos en el índice. El ```sort=account_number:asc``` parámetro indica para ordenar los resultados usando el ```account_number``` campo de cada documento en un orden ascendente. El ```pretty``` parámetro, de nuevo, sólo le dice Elasticsearch para devolver resultados JSON bastante impresos.

## Introducctión a Query Language
<hr>
### Query DSL

```query``` definición de la consulta.

```match_all``` consulta es una búsqueda en todos los documentos en el índice especificado.

También podemos pasar a otros parámetros para influir en los resultados de búsqueda. En el ejemplo de la sección anterior pasamos en ```sort```, ```size```:

El parámetro ```from``` especifica el índice de documentos para iniciar desde y al size parámetro especifica el número de documentos para volver a partir de la del parámetro. Esta función es útil cuando se implementa paginación de resultados de búsqueda. Tenga en cuenta que si from no se especifica, el valor predeterminado es 0.

Este ejemplo devolvera "_source": ["account_number", "balance"]


```javascript
curl -XGET 'localhost:9200/bank/_search?pretty' -d'
{
  "query": { "match_all": {} },
  "sort": { "balance": { "order": "desc" } },
  "from": 10,
  "size": 10
  "_source": ["account_number", "balance"]
}'
```

### Match query

Retorna todos los ```account_number``` cuando su valor es 20

```javascript
curl -XGET 'localhost:9200/bank/_search?pretty' -d'
{
  "query": { "match": { "account_number": 20 } }
}'
```

Este ejemplo devuelve todas las cuentas que contienen el término "mill" o "lane" en ```address```:

```javascript
curl -XGET 'localhost:9200/bank/_search?pretty' -d'
{
  "query": { "match": { "address": "mill lane" } }
}'
```

```match_phrase``` devuelve todas las cuentas que contienen la frase "carril del molino" en  ```address```:

```javascript
curl -XGET 'localhost:9200/bank/_search?pretty' -d'
{
  "query": { "match_phrase": { "address": "mill lane" } }
}'
```

### bool

La consulta ```bool``` nos permite componer consultas más grandes en consultas más pequeñas que utilizan lógica booleana.

Ejemplo: Devuelve todas las cuentas que contienen "mill" AND "lane" en ```address```:

```javascript
curl -XGET 'localhost:9200/bank/_search?pretty' -d'
{
  "query": {
    "bool": {
      "must": [
        { "match": { "address": "mill" } },
        { "match": { "address": "lane" } }
      ]
    }
  }
}'
```

```must``` == AND 

Ejemplo: Devuelve todas las cuentas que contienen "molino" OR "carril" en ```adress```:

```javascript
curl -XGET 'localhost:9200/bank/_search?pretty' -d'
{
  "query": {
    "bool": {
      "should": [
        { "match": { "address": "mill" } },
        { "match": { "address": "lane" } }
      ]
    }
  }
}'
```

```should``` == OR 


Ejemplo: se compone de dos consultas match y devuelve todas las cuentas que no contienen ni "molino" ni "Lane" en ```adress```:

```javascript
curl -XGET 'localhost:9200/bank/_search?pretty' -d'
{
  "query": {
    "bool": {
      "must_not": [
        { "match": { "address": "mill" } },
        { "match": { "address": "lane" } }
      ]
    }
  }
}'
```

## Filtros

```_score``` es la relevancia de nuestro documento

```filter``` permite utilizar una consulta para restringir los documentos que serán igualados por otras cláusulas.

En este ejemplo se utiliza una consulta ```bool``` para devolver todas las cuentas con saldos entre 20000 y 30000, ambos inclusive. En otras palabras, queremos encontrar cuentas con un equilibrio que es mayor que o igual a 20.000 e inferior o igual a 30.000.

```javascript
curl -XGET 'localhost:9200/bank/_search?pretty' -d'
{
  "query": {
    "bool": {
      "must": { "match_all": {} },
      "filter": {
        "range": {
          "balance": {
            "gte": 20000,
            "lte": 30000
          }
        }
      }
    }
  }
}'

```

## Executing Aggregations

```javascript
curl -XGET 'localhost:9200/ banco / _search?pretty' -d'
{
  "Tamaño": 0,
  "aggs": {
    "Group_by_state": {
      "términos": {
        "Campo": "state.keyword"
      }
    }
  }
}'
```

```
SELECT state, COUNT(*) FROM bank GROUP BY state ORDER BY COUNT(*) DESC
```

otro ejemplo 

```javascript
curl -XGET 'localhost:9200/bank/_search?pretty' -d'
{
  "size": 0,
  "aggs": {
    "group_by_age": {
      "range": {
        "field": "age",
        "ranges": [
          {
            "from": 20,
            "to": 30
          },
          {
            "from": 30,
            "to": 40
          },
          {
            "from": 40,
            "to": 50
          }
        ]
      },
      "aggs": {
        "group_by_gender": {
          "terms": {
            "field": "gender.keyword"
          },
          "aggs": {
            "average_balance": {
              "avg": {
                "field": "balance"
              }
            }
          }
        }
      }
    }
  }
}'
```



<!-- Querys mas especificas

curl -XGET "http://search-es:9200/articles/article/A1?
						_soruce_include=*id&_source_explude=*pidcture"


Para comprobar si existe el documento, evitar el overhead de transferir el JSON

curl -XHEAD 'http://search-es:9200/articles/article/A1'

Sin metadatos extra

curl -XHEAD 'http://search-es:9200/articles/article/A1/_source'

curl -XPOST 'http://search-es:9200/articles/article/A1/_update' -d {
	"id" : ""
	"title" : ""
}

## SEARCH API

Relevancia(Scoring) : define que tan importante es un documento en un conjunto de resultados.

Spellchecker : Permite interpretar una busqueda aunque tenga errores ortograficos

Multi-lenguaje

autocomplete


### Busquedas de Texto:

busquedas booleanas

curl -XGET 'http://search-es:9200/articles/A1/_search?q=sony+OR+nikon'

busquedas por rango

curl -XGET 'http://search-es:9200/articles/A1/_search?q=proce:[10+TO+*]'


SHARD ROUTING

curl -XPUT 'http://search-es:9200/articles/A1/_routing=MLB' -d {...}


QUERY DSL
{
	"query" : {...}
	"filter" : {...}

}

busqueda de texto

{ 
 	"match" : { "titulo" : "as"}
}

buscando frases

{

}

max_expansion

multi_match buscar en muchos campos

match_all
 -->










gha: CSS, lang: markdown
﻿using UnityEngine;
using System.Collections;
using UnityEngine.Networking;

public class Ground : NetworkBehaviour {


	//void OnCollisionExit(Collision col)
	//{
	//	if(col.gameObject.tag == "Robot")
	//	{
	//		col.gameObject.GetComponent<RobotMovement3D>().Grounded = false;
	//	}
	//}



	//void OnCollisionStay(Collision col)
	//{
	//	if(col.gameObject.tag == "Robot" && col.gameObject.GetComponent<RobotMovement3D>().Grounded == false)
	//	{
	//		col.gameObject.GetComponent<RobotMovement3D>().Grounded = true;
	//	}
	//}
}
gha: C#, lang: c_sharp
﻿using System;
using System.Collections;
using System.Collections.Generic;
using System.IO;
using System.Linq;
using UnityEngine;

/*
 * このクラスはシングルトンで作成されています。
 * 
 * セーブスロットについてですが、3つ必要という要件でしたが4つ分作成しています。
 * slot の 0 にはセーブデータの数など全セーブデータで共通するものを保存するようです
 * 
 * 使い方は 基本的に PlayerPrefs と変わりません
 * ですがセーブとロードはそれぞれ一括で行うため関数を呼び出さないとセーブ/ロードを行いません
 * 
 * Saveファイルのディレクトリは Directory.GetCurrentDirectory()/Save ないに保存されます
 * Save データは 現在 JSON のテキストデータは暗号化したバイナリデータで保存しています
 * 
 * 暗号化についてですが、ソースコードに暗号化用のパスが埋め込まれているため、
 * Github でソースコードを見れば簡単に復号化できるため、別の方法を使うかもしれません
 * 
 * Save はプリミティブ型および自作クラスを扱うことができます
 * 自作クラスを使用する場合は宣言時に [Serializable]を指定する必要があります
 * またセーブされるデータは public または [SerializeField] の設定が必要がです
 *
 * 使うかはわかりませんが現在GVというGlovalVariables用のクラスを作成して、このクラスを使用いるので参考にしてください
 * 
 */

/// <summary>
/// Save 用のクラス
/// </summary>
public class SaveData
{
    const int MaxData = 4;
    public const int SaveSlotCount = MaxData - 1;
    static SaveBase[] saveBase;
    static SaveBase[] SaveObj
    {
        get
        {
            if (saveBase == null)
            {
                saveBase = new SaveBase[MaxData];
                for (int i = 0; i < MaxData; ++i)
                {
                    string path = Directory.GetCurrentDirectory() + "/Save";
                    string fileName = "save" + i.ToString() + ".sav";
                    saveBase[i] = new SaveBase(path, fileName);
                }
            }
            return saveBase;
        }
    }
    static int saveSlot = 1;

    #region Setter
    /// <summary>
    /// int 型を書き込みます
    /// </summary>
    /// <param name="key">key</param>
    /// <param name="value">書き込む値</param>
    static public void setInt(string key, int value)
    {
        SaveObj[saveSlot].setInt(key, value);
    }
    /// <summary>
    /// float 型を書き込みます
    /// </summary>
    /// <param name="key">key</param>
    /// <param name="value">書き込む値</param>
    static public void setFloat(string key, float value)
    {
        SaveObj[saveSlot].setFloat(key, value);
    }
    /// <summary>
    /// bool 型を書き込みます
    /// </summary>
    /// <param name="key">key</param>
    /// <param name="value">書き込む値</param>
    static public void setBool(string key, bool value)
    {
        SaveObj[saveSlot].setBool(key, value);
    }
    /// <summary>
    /// string 型を書き込みます
    /// </summary>
    /// <param name="key">key</param>
    /// <param name="value">書き込む値</param>
    static public void setString(string key, string value)
    {
        SaveObj[saveSlot].setString(key, value);
    }
    /// <summary>
    /// class 型を書き込みます
    /// </summary>
    /// <param name="key">key</param>
    /// <param name="obj">書き込む値</param>
    static public void setClass<T>(string key, T obj) where T : class, new()
    {
        SaveObj[saveSlot].setClass<T>(key, obj);
    }
    /// <summary>
    /// list 型を書き込みます
    /// </summary>
    /// <param name="key">key</param>
    /// <param name="list">書き込む値</param>
    static public void setList<T>(string key, List<T> list)
    {
        SaveObj[saveSlot].setList<T>(key, list);
    }
	/// <summary>
	/// Dictionary 型を書き込みます
	/// </summary>
	/// <param name="key">key</param>
	/// <param name="list">書き込む値</param>
	static public void setDictionary<TKey, TValue>( string key, Dictionary<TKey, TValue> dictionary )
	{
		SaveObj [ saveSlot ].setDictionary<TKey, TValue>( key, dictionary );
	}
    #endregion

    #region Getter
    /// <summary>
    /// int 型を読み込みます
    /// </summary>
    /// <param name="key">key</param>
    /// <param name="defaultValue">keyが見つからなかったときの値</param>
    /// <returns>見つかった値を返します</returns>
    static public int getInt(string key, int defaultValue)
    {
        return SaveObj[saveSlot].getInt(key, defaultValue);
    }
    /// <summary>
    /// float 型を読み込みます
    /// </summary>
    /// <param name="key">key</param>
    /// <param name="defaultValue">keyが見つからなかったときの値</param>
    /// <returns>見つかった値を返します</returns>
    static public float getFloat(string key, float defaultValue)
    {
        return SaveObj[saveSlot].getFloat(key, defaultValue);
    }
    /// <summary>
    /// bool 型を読み込みます
    /// </summary>
    /// <param name="key">key</param>
    /// <param name="defaultValue">keyが見つからなかったときの値</param>
    /// <returns>見つかった値を返します</returns>
    static public bool getBool(string key, bool defaultValue)
    {
        return SaveObj[saveSlot].getBool(key, defaultValue);
    }
    /// <summary>
    /// string 型を読み込みます
    /// </summary>
    /// <param name="key">key</param>
    /// <param name="defaultValue">keyが見つからなかったときの値</param>
    /// <returns>見つかった値を返します</returns>
    static public string getString(string key, string defaultValue = "")
    {
        return SaveObj[saveSlot].getString(key, defaultValue);
    }
    /// <summary>
    /// class 型を読み込みます
    /// </summary>
    /// <param name="key">key</param>
    /// <param name="defaultValue">keyが見つからなかったときの値</param>
    /// <returns>見つかった値を返します</returns>
    static public T getClass<T>(string key, T defaultValue = null) where T : class, new()
    {
        return SaveObj[saveSlot].getClass(key, defaultValue);
    }
    /// <summary>
    /// list 型を読み込みます
    /// </summary>
    /// <param name="key">key</param>
    /// <param name="defaultValue">keyが見つからなかったときの値</param>
    /// <returns>見つかった値を返します</returns>
    static public List<T> getList<T>(string key, List<T> defaultValue = null)
    {
        return SaveObj[saveSlot].getList(key, defaultValue);
    }
	/// <summary>
	/// Dictionary 型を読み込みます
	/// </summary>
	/// <param name="key">key</param>
	/// <param name="defaultValue">keyが見つからなかったときの値</param>
	/// <returns>見つかった値を返します</returns>
	static public Dictionary<TKey, TValue> getDictionary<TKey, TValue>( string key, Dictionary<TKey, TValue> defaultValue = null )
	{
		return SaveObj [ saveSlot ].getDictionary( key, defaultValue );
	}
    #endregion

    /// <summary>
    /// save するスロットを設定します
    /// </summary>
    /// <param name="slot"></param>
    static public void setSlot(int slot)
    {
        saveSlot = slot;
    }

    /// <summary>
    /// セーブデータを削除します
    /// </summary>
    /// <param name="slot"></param>
    static public void remove(int slot)
    {
        SaveObj[saveSlot].remove(slot);
    }

	/// <summary>
	/// 指定した key を削除します
	/// </summary>
	/// <param name="key"></param>
	static public void remove(string key)
    {
        SaveObj[saveSlot].remove(key);
    }

    /// <summary>
    /// key が保存されているか返します
    /// </summary>
    /// <param name="key">検索するkey</param>
    /// <returns>true 持っている場合, false key が保存されていない</returns>
    static public bool containsKey(string key)
    {
        return SaveObj[saveSlot].containsKey(key);
    }

    /// <summary>
    /// 保存されいる key の一覧を返します
    /// </summary>
    /// <returns>key の一覧</returns>
    static public List<string> getKeys()
    {
        return SaveObj[saveSlot].getKeys();
    }

    /// <summary>
    /// ファイル書き込み
    /// </summary>
    public static void save()
    {
        SaveObj[saveSlot].save();
    }

    /// <summary>
    /// ファイル読み込み
    /// </summary>
    /// <returns>セーブデータがなければ False</returns>
    public static bool load()
    {
        return SaveObj[saveSlot].load();
    }

    /// <summary>
    /// save データを実際に扱うクラス
    /// </summary>
    class SaveBase
    {
        string savePath_;
        string fileName_;

        Dictionary<string, string> saveData;
        Rijndael rijndael;

        public SaveBase(string savePath, string fileName)
        {
            savePath_ = savePath + "/";
            fileName_ = fileName;

            saveData = new Dictionary<string, string>();
            rijndael = new Rijndael();
        }

        #region Setter
        public void setInt(string key, int value)
        {
            saveData[key] = value.ToString();
        }
        public void setFloat(string key, float value)
        {
            saveData[key] = value.ToString();
        }
        public void setBool(string key, bool value)
        {
            saveData[key] = value.ToString();
        }
        public void setString(string key, string value)
        {
            saveData[key] = value;
        }
        public void setClass<T>(string key, T obj) where T : class, new()
        {
            var json = JsonUtility.ToJson(obj);
            saveData[key] = json;
        }
        public void setList<T>(string key, List<T> list)
        {
            var json = JsonUtility.ToJson(new Serialization<T>(list));
            saveData[key] = json;
        }
		public void setDictionary<TKey, TValue>( string key, Dictionary<TKey, TValue> dictionary ) {
			var json = JsonUtility.ToJson( new Serialization<TKey, TValue>( dictionary ) );
			saveData [ key ] = json;
		}
        #endregion

        #region Getter
        public int getInt(string key, int defaultValue)
        {
            if (!saveData.ContainsKey(key)) {
                return defaultValue;
            }

            return int.Parse(saveData[key]);
        }
        public float getFloat(string key, float defaultValue)
        {
            if (!saveData.ContainsKey(key)) {
                return defaultValue;
            }

            return float.Parse(saveData[key]);
        }
        public bool getBool(string key, bool defaultValue)
        {
            if (!saveData.ContainsKey(key)) {
                return defaultValue;
            }

            return bool.Parse(saveData[key]);
        }
        public string getString(string key, string defaultValue = "")
        {
            if (!saveData.ContainsKey(key)) {
                return defaultValue;
            }

            return saveData[key];
        }
        public T getClass<T>(string key, T defaultValue) where T : class, new()
        {
            if (!saveData.ContainsKey(key)) {
                return defaultValue;
            }

            var json = saveData[key];
            var obj = JsonUtility.FromJson<T>(json);

            return obj;
        }
        public List<T> getList<T>(string key, List<T> defaultValue)
        {
            if (!saveData.ContainsKey(key)) {
                return defaultValue;
            }

            var json = saveData[key];
            var list = JsonUtility.FromJson<Serialization<T>>(json).Target;
            return list;
        }
		public Dictionary<TKey, TValue>getDictionary<TKey,TValue>( string key, Dictionary<TKey, TValue> defaultValue )
		{
			if ( !saveData.ContainsKey( key ) ) {
				return defaultValue;
			}

			var json = saveData [ key ];
			var dictionary = JsonUtility.FromJson<Serialization<TKey, TValue>>( json ).Target;
			return dictionary;
		}
        #endregion

        public void save()
        {
            if (!File.Exists(savePath_)) {
                Directory.CreateDirectory(@savePath_);
            }
            BinaryWriter bw = new BinaryWriter(File.OpenWrite(savePath_ + fileName_));
            var str = JsonUtility.ToJson(new Serialization<string, string>(saveData));
            var data = rijndael.encryption(str);
            bw.Write(data.Length);
            bw.Write(data);
            bw.Close();
        }

        public bool load()
        {
            if (!File.Exists(savePath_ + fileName_)) {
                return false;
            }

            var file = File.OpenRead(savePath_ + fileName_);
            BinaryReader br = new BinaryReader(file);
            var size = br.ReadInt32();
            var data = br.ReadBytes(size);
            br.Close();
            var str = rijndael.decryption(data);
            var temp = JsonUtility.FromJson<Serialization<string, string>>(str);
            saveData = temp.Target;
            return true;
        }

		public void remove( ) {
			//// ファイルを削除する
			//System.IO.File.Delete( savePath_ + fileName_ );
		}

        // TODO: 今後実装
        public void remove(int slot)
        {
			GV.Instance.SData.usedSave[ slot - 1 ] = false;

			SaveData.setSlot( 0 );
			SaveData.setClass( "SystemData", GV.Instance.SData );
			SaveData.save( );

			// ファイルを削除する
			System.IO.File.Delete( savePath_ + fileName_ );
		}

        public void remove(string key)
        {

        }

        public bool containsKey(string key)
        {
            return saveData.ContainsKey(key);
        }

        public List<string> getKeys()
        {
            return saveData.Keys.ToList<string>();
        }
    }
}

gha: C#, lang: c_sharp
// Windows/FileName.h

#ifndef __WINDOWS_FILE_NAME_H
#define __WINDOWS_FILE_NAME_H

#include "../Common/MyString.h"

namespace NWindows {
namespace NFile {
namespace NName {

void NormalizeDirPathPrefix(FString &dirPath); // ensures that it ended with '\\', if dirPath is not epmty
void NormalizeDirPathPrefix(UString &dirPath);

#ifdef _WIN32

extern const wchar_t *kSuperPathPrefix; /* \\?\ */
const unsigned kDevicePathPrefixSize = 4;
const unsigned kSuperPathPrefixSize = 4;
const unsigned kSuperUncPathPrefixSize = kSuperPathPrefixSize + 4;

bool IsDevicePath(CFSTR s) throw(); /* \\.\ */
bool IsSuperUncPath(CFSTR s) throw();

bool IsDrivePath(const wchar_t *s) throw();
bool IsSuperPath(const wchar_t *s) throw();
bool IsSuperOrDevicePath(const wchar_t *s) throw();

#ifndef USE_UNICODE_FSTRING
bool IsDrivePath(CFSTR s) throw();
bool IsSuperPath(CFSTR s) throw();
bool IsSuperOrDevicePath(CFSTR s) throw();
#endif

#endif // _WIN32

bool IsAbsolutePath(const wchar_t *s) throw();
unsigned GetRootPrefixSize(const wchar_t *s) throw();

#ifdef WIN_LONG_PATH

const int kSuperPathType_UseOnlyMain = 0;
const int kSuperPathType_UseOnlySuper = 1;
const int kSuperPathType_UseMainAndSuper = 2;

int GetUseSuperPathType(CFSTR s) throw();
bool GetSuperPath(CFSTR path, UString &longPath, bool onlyIfNew);
bool GetSuperPaths(CFSTR s1, CFSTR s2, UString &d1, UString &d2, bool onlyIfNew);

#define USE_MAIN_PATH (__useSuperPathType != kSuperPathType_UseOnlySuper)
#define USE_MAIN_PATH_2 (__useSuperPathType1 != kSuperPathType_UseOnlySuper && __useSuperPathType2 != kSuperPathType_UseOnlySuper)

#define USE_SUPER_PATH (__useSuperPathType != kSuperPathType_UseOnlyMain)
#define USE_SUPER_PATH_2 (__useSuperPathType1 != kSuperPathType_UseOnlyMain || __useSuperPathType2 != kSuperPathType_UseOnlyMain)

#define IF_USE_MAIN_PATH int __useSuperPathType = GetUseSuperPathType(path); if (USE_MAIN_PATH)
#define IF_USE_MAIN_PATH_2(x1, x2) \
    int __useSuperPathType1 = GetUseSuperPathType(x1); \
    int __useSuperPathType2 = GetUseSuperPathType(x2); \
    if (USE_MAIN_PATH_2)

#else

#define IF_USE_MAIN_PATH
#define IF_USE_MAIN_PATH_2(x1, x2)

#endif // WIN_LONG_PATH

bool GetFullPath(CFSTR dirPrefix, CFSTR path, FString &fullPath);
bool GetFullPath(CFSTR path, FString &fullPath);

}}}

#endif

gha: C, lang: cpp
// -*- LSST-C++ -*-
/*
 * This file is part of afw.
 *
 * Developed for the LSST Data Management System.
 * This product includes software developed by the LSST Project
 * (https://www.lsst.org).
 * See the COPYRIGHT file at the top-level directory of this distribution
 * for details of code ownership.
 *
 * This program is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program.  If not, see <https://www.gnu.org/licenses/>.
 */

#ifndef LSST_AFW_TYPEHANDLING_POLYMORPHICVALUE_H
#define LSST_AFW_TYPEHANDLING_POLYMORPHICVALUE_H

#include <memory>

#include "lsst/pex/exceptions.h"
#include "lsst/afw/typehandling/Storable.h"

namespace lsst {
namespace afw {
namespace typehandling {

/**
 * Container that passes Storable objects by value while preserving type.
 *
 * This class is implicitly convertible to and from a reference to Storable,
 * but behaves like a value: changing the internal Storable changes the
 * object's state, and copying the object creates a new Storable.
 *
 * @note While a PolymorphicValue is always initialized with a Storable, it
 * may become empty if it is the source of a move-construction or
 * move-assignment. Conversion of an empty value to Storable& throws.
 */
/*
 * Note: I would like to disallow the empty state, as it serves no purpose,
 * but I can't think of any other sensible post-move state.
 */
class PolymorphicValue final {
public:
    /**
     * Create a new object containing a copy of a Storable.
     *
     * @param value the value to copy into a PolymorphicValue
     */
    PolymorphicValue(Storable const& value);
    ~PolymorphicValue() noexcept;

    /**
     * Try to copy a PolymorphicValue.
     *
     * @param other the PolymorphicValue to copy.
     *
     * @throws UnsupportedOperationException Thrown if a copy is required and
     *      the object in `other` does not implement Storable::cloneStorable.
     *
     * @{
     */
    PolymorphicValue(PolymorphicValue const& other);
    PolymorphicValue(PolymorphicValue&& other) noexcept;

    /** @} */

    /**
     * Try to assign a PolymorphicValue.
     *
     * To preserve the run-time type of the object in `other`, this method
     * swaps (and possibly copies) the Storables instead of relying on the
     * `Storable`'s `operator=`.
     *
     * @param other the PolymorphicValue to overwrite this value with.
     *
     * @throws UnsupportedOperationException Thrown if a copy is required and
     *      the object in `other` does not implement Storable::cloneStorable.
     *
     * @{
     */
    PolymorphicValue& operator=(PolymorphicValue const& other);
    PolymorphicValue& operator=(PolymorphicValue&& other) noexcept;

    /// Exchange the contents of this container and another.
    void swap(PolymorphicValue& other) noexcept;

    /** @} */

    /**
     * Check whether this object contains a Storable.
     *
     * @return `true` if this object has no Storable, `false` otherwise
     */
    bool empty() const noexcept;

    /**
     * Return a reference to the internal Storable, if one exists.
     *
     * @returns a reference to the internal object
     * @throws pex::exceptions::LogicError Thrown if this object is empty.
     *
     * @{
     */
    operator Storable&();
    operator Storable const&() const;
    Storable& get();
    Storable const& get() const;

    /** @} */

    /**
     * Test whether the contained Storables are equal.
     *
     * Empty PolymorphicValues compare equal to each other and unequal to any
     * non-empty PolymorphicValue.
     *
     * @{
     */
    bool operator==(PolymorphicValue const& other) const noexcept;
    bool operator!=(PolymorphicValue const& other) const noexcept { return !(*this == other); }

    /** @} */

    /**
     * Return a hash of this object (optional operation).
     *
     * @throws UnsupportedOperationException Thrown if the internal Storable
     *      is not hashable.
     */
    std::size_t hash_value() const;

private:
    // unique_ptr would be more appropriate, but Storable::cloneStorable must return shared_ptr
    std::shared_ptr<Storable> _value;
};

/**
 * Swap specialization for PolymorphicValue.
 *
 * @relatesalso PolymorphicValue
 */
inline void swap(PolymorphicValue& lhs, PolymorphicValue& rhs) noexcept { lhs.swap(rhs); }

}  // namespace typehandling
}  // namespace afw
}  // namespace lsst

namespace std {
/**
 * Hash specialization for PolymorphicValue.
 *
 * @returns the hash of the Storable inside the PolymorphicValue, or an
 *          arbitrary value if it is empty
 * @throws UnsupportedOperationException Thrown if the Storable is not hashable.
 */
template <>
struct hash<lsst::afw::typehandling::PolymorphicValue> {
    using argument_type = lsst::afw::typehandling::PolymorphicValue;
    using result_type = size_t;
    size_t operator()(argument_type const& obj) const { return obj.hash_value(); }
};

/// Swap specialization for PolymorphicValue.
template <>
inline void swap(lsst::afw::typehandling::PolymorphicValue& lhs,
                 lsst::afw::typehandling::PolymorphicValue& rhs) noexcept {
    lhs.swap(rhs);
}

}  // namespace std

#endif

gha: C++, lang: cpp
Tween    = window.mojs.Tween
easing   = window.mojs.easing
h        = window.mojs.h
tweener  = window.mojs.tweener

describe 'Tween ->', ->
  describe 'defaults ->', ->
    it 'should have vars', ->
      t = new Tween
      expect(t.props) .toBeDefined()
      expect(t.h)     .toBeDefined()
      expect(t.progress).toBe 0
    it 'should have defaults', ->
      t = new Tween
      expect(t.defaults.duration).toBe  600
      expect(t.defaults.delay).toBe     0
      expect(t.defaults.yoyo).toBe      false
      expect(t.defaults.isChained).toBe false
    it 'should extend defaults to props', ->
      t = new Tween duration: 1000
      expect(t.props.duration).toBe   1000
      expect(t.props.delay).toBe      0
  describe 'init ->', ->
    it 'should calc time, repeatTime', ->
      t = new Tween duration: 1000, delay: 100
      expect(t.props.time).toBe        1100
      expect(t.props.repeatTime).toBe  1100
    it 'should calc time, repeatTime #2', ->
      t = new Tween duration: 1000, delay: 100, repeat: 2
      expect(t.props.time).toBe        1100
      expect(t.props.repeatTime).toBe  3300
    # it 'should calculate shiftedRepeatTime', ->
    #   t = new Tween duration: 1000, delay: 100, repeat: 2
    #   expect(t.props.time).toBe             1100
    #   expect(t.props.repeatTime).toBe       3300
    #   expect(t.props.shiftedRepeatTime).toBe  3200
    # it 'should calculate shiftedRepeatTime #2', ->
    #   t = new Tween duration: 1000, delay: 100, repeat: 2
    #   t.setProp 'shiftTime', 700
    #   expect(t.props.time).toBe              1100
    #   expect(t.props.repeatTime).toBe        3300
    #   expect(t.props.shiftedRepeatTime).toBe 3900

  describe 'isChained option ->', ->
    it 'should recieve isChained option', ->
      t = new Tween
        duration: 1000, isChained: true
      expect(t.props.isChained).toBe  true
    it 'should fallback to default isChained option', ->
      t = new Tween duration: 1000
      expect(t.props.isChained).toBe false

  describe 'start ->', ->
    it 'should calculate start time', ->
      t = new Tween(duration: 1000, delay: 500).start()
      expectedTime = performance.now() + 500
      expect(t.props.startTime).toBeGreaterThan expectedTime - 50
      expect(t.props.startTime).not.toBeGreaterThan expectedTime
    it 'should recieve the start time', ->
      t = new Tween(duration: 1000).start 1
      expect(t.props.startTime).toBe 1
    it 'should calculate end time', ->
      duration = 1000; delay = 500
      t = new Tween(duration: duration, delay: delay).start()
      endTime = t.props.startTime + t.props.repeatTime - t.props.delay
      expect(t.props.endTime).toBe endTime
    it 'should calculate end time with repeat', ->
      duration = 1000; delay = 500
      t = new Tween(duration: duration, delay: delay, repeat: 2).start()
      endTime = t.props.startTime + t.props.repeatTime - t.props.delay
      expect(t.props.endTime).toBe endTime
    it 'should calculate end time if repeat', ->
      duration = 1000; delay = 500
      t = new Tween(duration: duration, delay: delay, repeat: 2).start()
      time = t.props.startTime + (3*(duration+delay)) - delay
      expect(t.props.endTime).toBe time
    it 'should calculate startTime and endTime if shifted', ->
      duration = 1000; delay = 500
      t = new Tween(duration: duration, delay: delay, repeat: 2)
      t.setProp 'shiftTime', 500
      t.start()

      expectedTime = performance.now() + 500 + delay
      expect(t.props.startTime).toBeGreaterThan expectedTime - 50
      expect(t.props.startTime).not.toBeGreaterThan expectedTime

      endTime = t.props.startTime + (3*(duration+delay)) - delay
      expect(t.props.endTime).toBe endTime

    it 'should restart flags', ->
      t = new Tween(duration: 20, repeat: 2).start()
      t.update t.props.startTime + 10
      t.update t.props.startTime + 60
      expect(t.isCompleted).toBe true
      expect(t.isStarted)  .toBe false
      t.start()
      expect(t.isCompleted).toBe false
      expect(t.isStarted)  .toBe false
  
  describe 'update method ->', ->
    it 'should update progress', ->
      t = new Tween(duration: 1000, delay: 500)
      t.start()
      time = t.props.startTime + 200
      t.update time
      expect(t.progress).toBeCloseTo .2, 5
    it 'should update progress with repeat', ->
      t = new Tween(duration: 1000, delay: 200, repeat: 2)
      t.start()
      t.update t.props.startTime + 1400
      expect(t.progress).toBeCloseTo .2
      t.update t.props.startTime + 2700
      expect(t.progress).toBeCloseTo .3
      t.update t.props.startTime + 3400
      expect(t.progress).toBe 1
    it 'should update progress to 1 if in delay gap and previous time value
        was smaller then the current one', ->
      t = new Tween(duration: 1000, delay: 200, repeat: 2)
      t.start()
      t.update t.props.startTime + 300
      t.update t.props.startTime + 1100
      expect(t.progress).toBe 1
    it 'should update progress to 1 if in delay gap and previous time value
        was bigger then the current one', ->
      t = new Tween(duration: 1000, delay: 200, repeat: 2)
      t.start()
      t.update t.props.startTime + 1300
      t.update t.props.startTime + 1100
      expect(t.progress).toBe 0
    it 'should update progress to 1 on the end', ->
      t = new Tween(duration: 1000, delay: 200, repeat: 2)
      t.start()
      t.update t.props.startTime + 1000
      expect(t.progress).toBeCloseTo 1, 5
    it 'should return true on the end', ->
      t = new Tween(duration: 1000, delay: 200)
      t.start()
      returnValue = t.update t.props.startTime + 1000
      expect(t.progress).toBeCloseTo 1, 5
      expect(t.isCompleted).toBe true
      expect(returnValue).toBe true
    it 'should set progress to 1 on delay gaps', ->
      t = new Tween(duration: 1000, delay: 200)
      t.start()

      spyOn(t, '_complete').and.callThrough()
      t.update t.props.startTime + 20, true
      t.update t.props.startTime - 20, true
      expect(t.progress).toBe 1
      expect(t._complete).toHaveBeenCalled()

    it 'should not call update method if timeline isnt active "-"', ->
      t = new Tween(duration: 1000, onUpdate:->)
      t.start()
      spyOn t, 'onUpdate'
      t.update(t.props.startTime - 500)
      expect(t.onUpdate).not.toHaveBeenCalled()
    it 'should not call update method if timeline isnt active "+"', ->
      cnt = 0
      t = new Tween(duration: 1000, onUpdate:-> cnt++ )
      t.start(); t.update(performance.now() + 1500)
      expect(cnt).toBe 1
    it 'should set Tween to the end if Tween ended', ->
      t = new Tween(duration: 1000, delay: 500)
      t.start()
      t.update t.props.startTime + 1200
      expect(t.progress).toBe 1
  
  describe 'onUpdate callback ->', ->
    it 'should be defined', ->
      t = new Tween onUpdate: ->
      expect(t.props.onUpdate).toBeDefined()
    it 'should call onUpdate callback with the current progress', ->
      t = new Tween duration: 1000, easing: 'bounce.out', onUpdate: ->
      spyOn t, 'onUpdate'
      t.start()
      t.update t.props.startTime + 500
      expect(t.onUpdate).toHaveBeenCalledWith t.easedProgress, t.progress
    it 'should have the right scope', ->
      isRightScope = false
      t = new Tween onUpdate:-> isRightScope = @ instanceof Tween
      t.start()
      t.update t.props.startTime + 200
      expect(isRightScope).toBe true
    it 'should be called just once on delay', ->
      t = new Tween delay: 200, repeat: 2, onUpdate:->
      spyOn(t, 'onUpdate').and.callThrough()
      t.start()
      t.update t.props.startTime + t.props.duration + 50
      t.update t.props.startTime + t.props.duration + 100
      t.update t.props.startTime + t.props.duration + 150
      expect(t.onUpdate.calls.count()).toBe 1
    it 'should pass eased progress and raw progress', ->
      easedProgress = null
      progress      = null
      t = new Tween
        easing: 'cubic.out'
        onUpdate:(ep, p)->
          easedProgress = ep
          progress = p

      t.setProgress .5
      expect(easedProgress).toBe mojs.easing.cubic.out progress

  describe 'onStart callback ->', ->
    it 'should be defined', ->
      t = new Tween(onStart: ->)
      t.start()
      expect(t.props.onStart).toBeDefined()
    it 'should call onStart callback', ->
      t = new Tween duration: 32, onStart:->
      t.start()
      spyOn(t.props, 'onStart')
      t.update t.props.startTime + 1
      expect(t.props.onStart).toHaveBeenCalled()
    it 'should be called just once', ->
      cnt = 0
      t = new Tween(duration: 32, onStart:-> cnt++).start()
      t.update(t.props.startTime + 1); t.update(t.props.startTime + 1)
      expect(cnt).toBe 1
    it 'should have the right scope', ->
      isRightScope = false
      t = new Tween(onStart:-> isRightScope = @ instanceof Tween)
      t.start()
      t.update t.props.startTime + 1
      expect(isRightScope).toBe true

  describe 'onReverseComplete callback ->', ->
    it 'should be defined', ->
      t = new Tween onReverseComplete: ->
      expect(t.props.onReverseComplete).toBeDefined()

    it 'should call onReverseComplete callback', ->
      t = new Tween(
        duration: 100
        onReverseComplete:->
      ).start()
      spyOn(t.props, 'onReverseComplete')
      t.update t.props.startTime + 55
      t.update t.props.startTime
      expect(t.props.onReverseComplete).toHaveBeenCalled()

    it 'should onReverseComplete only once', ->
      cnt = 0
      t = new Tween(
        duration: 100
        onReverseComplete:-> cnt++
      ).start()
      t.update t.props.startTime + 55
      t.update t.props.startTime
      t.update t.props.startTime - 20
      t.update t.props.startTime - 30
      expect(cnt).toBe 1
      expect(t.isOnReverseComplete).toBe true

    it 'should reset isOnReverseComplete flag', ->
      cnt = 0
      t = new Tween(
        duration: 100
        onReverseComplete:-> cnt++
      ).start()
      t.update t.props.startTime + 55
      t.update t.props.startTime
      t.update t.props.startTime - 20
      t.update t.props.startTime - 30
      t.update t.props.startTime + 1
      expect(t.isOnReverseComplete).toBe false

    it 'should reset isOnReverseComplete flag #2', ->
      cnt = 0
      t = new Tween(
        duration: 100
        onReverseComplete:-> cnt++
      ).start()
      t.update t.props.startTime + 55
      t.update t.props.startTime
      t.update t.props.startTime - 20
      t.update t.props.startTime - 30
      t.update t.props.endTime
      expect(t.isOnReverseComplete).toBe false

    it 'should have the right scope', ->
      isRightScope = null
      t = new Tween(
        duration: 100
        onReverseComplete:-> isRightScope = @ instanceof Tween
      ).start()
      t.update t.props.startTime + 55
      t.update t.props.startTime
      expect(isRightScope).toBe true

    it 'should setProgress to 0 if progress went before startTime', ->
      t = new Tween(
        duration: 100
        onReverseComplete:->
        onUpdate:->
      ).start()
      spyOn(t, 'onUpdate')
      t.update t.props.startTime + 55
      t.update t.props.startTime - 20
      expect(t.onUpdate).toHaveBeenCalledWith 0, 0
      expect(t.progress).toBe 0

    it 'should not setProgress to 0 if timeline isChained', ->
      t = new Tween(
        duration: 100, isChained: true
        onReverseComplete:->
        onUpdate:->
      ).start()
      spyOn(t, 'onUpdate')
      t.update t.props.startTime + 55
      t.update t.props.startTime - 20
      expect(t.onUpdate).not.toHaveBeenCalledWith 0
      # expect(t.progress).toBe 0

  describe 'onComplete callback ->', ->
    it 'should be defined', ->
      t = new Tween onComplete: ->
      expect(t.props.onComplete).toBeDefined()
    it 'should call onComplete callback', ->
      t = new Tween(duration: 100, onComplete:->).start()
      spyOn(t.props, 'onComplete')
      t.update t.props.startTime + 101
      expect(t.props.onComplete).toHaveBeenCalled()
    it 'should be called just once', ->
      cnt = 0
      t = new Tween(duration: 32, onComplete:-> cnt++).start()
      t.update(t.props.startTime + 33)
      t.update(t.props.startTime + 33)
      expect(cnt).toBe 1

    it 'should reset isCompleted flag', ->
      t = new Tween(duration: 32, onComplete:->).start()
      t.update(t.props.startTime + 10)
      t.update(t.props.endTime)
      expect(t.isCompleted).toBe true
      t.update(t.props.startTime + 10)
      expect(t.isCompleted).toBe false

    it 'should have the right scope', ->
      isRightScope = false
      t = new Tween
        duration: 1, onComplete:-> isRightScope = @ instanceof Tween
      t.start().update t.props.startTime + 2
      expect(isRightScope).toBe true

    it 'should fire after the last onUpdate', (dfr)->
      proc = 0
      t = new Tween
        duration: 1,
        onUpdate:(p)->  proc = p
        onComplete:-> expect(proc).toBe(1); dfr()
      t.start().update t.props.startTime + 2
      

  describe 'onFirstUpdate callback ->', ->
    it 'should be defined', ->
      t = new Tween onFirstUpdate: ->
      expect(t.props.onFirstUpdate).toBeDefined()
    it 'should call onFirstUpdate callback', ->
      t = new Tween(duration: 100, onFirstUpdate:->).start()
      spyOn(t.props, 'onFirstUpdate')
      t.update t.props.startTime + 3
      expect(t.props.onFirstUpdate).toHaveBeenCalled()
    it 'should be called just once', ->
      cnt = 0
      t = new Tween(duration: 100, onFirstUpdate:-> cnt++ ).start()
      t.update t.props.startTime + 3
      t.update t.props.startTime + 3
      t.update t.props.startTime + 3
      expect(cnt).toBe 1
    it 'should have the right scope', ->
      isRightScope = false
      t = new Tween
        duration: 10, onFirstUpdate:-> isRightScope = @ instanceof Tween
      t.start().update t.props.startTime + 2
      expect(isRightScope).toBe true
    it 'should be called after progress went further the timeline', ->
      isRightScope = false
      t = new Tween
        duration: 10
        onFirstUpdate:->
      .start()
      t.update t.props.startTime + 1
      t.update t.props.startTime + 12
      spyOn(t.props, 'onFirstUpdate')
      t.update t.props.startTime + 9
      expect(t.props.onFirstUpdate).toHaveBeenCalled()

    it 'should be called before onStart callback', ->
      isOnStart = false; isOnStartCalled = true
      t = new Tween
        duration: 10
        onStart:-> isOnStart = true
        onFirstUpdate:-> isOnStartCalled = isOnStart
      .start()
      t.update t.props.startTime + 1
      expect(isOnStartCalled).toBe false

    it 'should be called after progress went before the timeline', ->
      isRightScope = false
      t = new Tween
        duration: 10
        onFirstUpdate:->
      .start()
      t.update t.props.startTime + 1
      t.update t.props.startTime + -1
      spyOn(t.props, 'onFirstUpdate')
      t.update t.props.startTime + 2
      expect(t.props.onFirstUpdate).toHaveBeenCalled()

  describe 'onFirstUpdateBackward callback ->', ->
    it 'should be defined', ->
      t = new Tween onFirstUpdateBackward: ->
      expect(t.props.onFirstUpdateBackward).toBeDefined()
    it 'should be called only on backward progress', ->
      isRightScope = false
      t = new Tween
        duration: 100
        onFirstUpdateBackward:->
      .start()
      t.update t.props.startTime + 500
      spyOn(t.props, 'onFirstUpdateBackward')
      t.update t.props.startTime + 40
      expect(t.props.onFirstUpdateBackward).toHaveBeenCalled()
    it 'should be called just once', ->
      cnt = 0
      t = new Tween(duration: 100, onFirstUpdateBackward:-> cnt++ ).start()
      t.prevTime = t.props.startTime + 103
      t.update t.props.startTime + 90
      t.update t.props.startTime + 80
      t.update t.props.startTime + 70
      expect(cnt).toBe 1
    it 'should have the right scope', ->
      isRightScope = false
      t = new Tween
        duration: 10
        onFirstUpdateBackward:-> isRightScope = @ instanceof Tween
      t.start()
      t.update t.props.startTime + 12
      t.update t.props.startTime + 9
      expect(isRightScope).toBe true
    it 'should be called after progress went further the timeline', ->
      t = new Tween(duration: 10, onFirstUpdateBackward: ->)
        .start()
      t.prevTime = t.props.startTime + 11
      t.update t.props.startTime + 9
      t.update t.props.startTime + 12
      spyOn(t.props, 'onFirstUpdateBackward')
      t.update t.props.startTime + 9
      expect(t.props.onFirstUpdateBackward).toHaveBeenCalled()
    it 'should not be called at the start', ->
      t = new Tween(duration: 10, onFirstUpdateBackward: ->)
        .start()
      spyOn(t.props, 'onFirstUpdateBackward')
      t.update t.props.startTime + 1
      expect(t.props.onFirstUpdateBackward).not.toHaveBeenCalled()
    it 'should be called even if new time is less then start time', ->
      t = new Tween
        duration: 100
        onFirstUpdateBackward:->
      .start()
      t.update t.props.startTime + 500
      spyOn(t.props, 'onFirstUpdateBackward')
      t.update t.props.startTime - 40
      expect(t.props.onFirstUpdateBackward).toHaveBeenCalled()
    it 'should be called ONCE if new time is less then start time', ->
      cnt = 0
      t = new Tween
        duration: 100
        onFirstUpdateBackward:-> cnt++
        
      .start()
      t.update t.props.startTime + 500
      t.update t.props.startTime - 40
      t.update t.props.startTime - 100
      expect(cnt).toBe 1

  describe 'yoyo option ->', ->
    it 'should recieve yoyo option', ->
      t = new Tween yoyo: true
      expect(t.props.yoyo).toBe true
    it 'should toggle the progress direction on repeat', ->
      t = new Tween(repeat: 2, duration: 10, yoyo: true).start()
      time = t.props.startTime
      t.update(time+1);   expect(t.progress).toBe .1
      t.update(time+5);   expect(t.progress).toBe .5
      t.update(time+10);  expect(t.progress).toBe 1

      t.update(time+11);  expect(t.progress).toBe .9
      t.update(time+15);  expect(t.progress).toBe .5
      t.update(time+19);  expect(parseFloat t.progress.toFixed(1)).toBe .1

      t.update(time+20);  expect(t.progress).toBe 0
      t.update(time+21);  expect(t.progress).toBe .1
      t.update(time+25);  expect(t.progress).toBe .5
      t.update(time+29);  expect(t.progress).toBe .9
      t.update(time+30);  expect(t.progress).toBe 1
      expect(t.isCompleted).toBe true

  describe 'easing ->', ->
    it 'should parse easing string', ->
      t = new Tween(easing: 'Linear.None')
      expect(typeof t.props.easing).toBe 'function'
    it 'should parse standart easing', ->
      t = new Tween(easing: 'Sin.Out', duration: 100)
      t.start(); t.update(t.props.startTime + 50)
      expect(t.easedProgress).toBe easing.sin.out t.progress
    it 'should work with easing function', ->
      easings = one: -> a = 1
      t = new Tween(easing: easings.one)
      expect(t.props.easing.toString()).toBe easings.one.toString()
    it 'should work with easing function', (dfr)->
      easings = one:(k)-> k
      spyOn easings, 'one'
      t = new Tween(easing: easings.one)
      t.start(); t.update t.props.startTime + 40
      setTimeout (-> expect(easings.one).toHaveBeenCalled(); dfr()), 50
  describe 'setProgress method ->', ->
    it 'should set the current progress', ->
      t = new Tween(easing: 'Bounce.Out')
      t.setProgress .75
      expect(t.progress).toBe .75
      expect(t.easedProgress.toFixed(2)).toBe '0.97'

  describe 'setProp method ->', ->
    it 'should set new timeline options', ->
      t = new Tween duration: 100, delay: 0
      t.setProp duration: 1000, delay: 200
      expect(t.props.duration).toBe 1000
      expect(t.props.delay).toBe    200
    it 'should work with arguments', ->
      t = new Tween duration: 100
      t.setProp 'duration', 1000
      expect(t.props.duration).toBe 1000
    it 'should call calcDimentions method', ->
      t = new Tween duration: 100
      spyOn t, 'calcDimentions'
      t.setProp 'duration', 1000
      expect(t.calcDimentions).toHaveBeenCalled()
    it 'should update the time', ->
      t = new Tween duration: 100, delay: 100
      t.setProp 'duration', 1000
      expect(t.props.time).toBe 1100
    it 'should parse easing', ->
      t = new Tween duration: 100
      t.setProp 'easing', 'elastic.in'
      expect(t.props.easing).toBe mojs.easing.elastic.in

  describe 'run method ->', ->
    it 'should get the start time',->
      t = new Tween
      t.run()
      expect(t.props.startTime).toBeDefined()
      expect(t.props.endTime).toBe t.props.startTime + t.props.repeatTime
    it 'should call the setStartTime method',->
      t = new Tween
      spyOn t, 'start'
      time = 0
      t.run time
      expect(t.start).toHaveBeenCalledWith time
    it 'should add itself to tweener',->
      t = new Tween
      spyOn tweener, 'add'
      t.run()
      expect(tweener.add).toHaveBeenCalled()
    it 'should not add itself to tweener if time was passed',->
      t = new Tween
      spyOn tweener, 'add'
      t.run 10239123
      expect(tweener.add).not.toHaveBeenCalled()

  describe '_removeFromTweener method ->', ->
    it 'should call tweener.remove method with self',->
      tweener.removeAll()
      timeline = new Tween duration: 2000
      timeline.run()
      timeline._removeFromTweener()
      expect(tweener.tweens.length).toBe 0

  describe 'stop method', ->
    it 'should call r_emoveFromTweener method with self',->
      tweener.removeAll()
      timeline = new Tween duration: 2000
      timeline.run()
      spyOn timeline, '_removeFromTweener'
      timeline.stop()
      expect(timeline._removeFromTweener).toHaveBeenCalled()
    it 'should reset progress to 0',->
      tweener.removeAll()
      timeline = new Tween duration: 2000
      timeline.run()
      spyOn timeline, 'setProgress'
      timeline.stop()
      expect(timeline.setProgress).toHaveBeenCalledWith 0
    # it 'should set state to "stop"',->
    #   tweener.tweens = []
    #   t = new Tween
    #   timeline = new Tween duration: 2000
    #   t.add(timeline); t.start(); t.stop()
    #   expect(t.state).toBe 'stop'

  describe 'pause method ->', ->
    it 'should call t.remove method with self',->
      tweener.removeAll()
      timeline = new Tween duration: 2000
      timeline.run()
      spyOn timeline, '_removeFromTweener'
      timeline.pause()
      expect(timeline._removeFromTweener).toHaveBeenCalled()
    # it 'should set state to "pause"',->
    #   tweener.tweens = []
    #   t = new Tween
    #   timeline = new Tween duration: 2000
    #   t.add(timeline); t.start(); t.pause()
    #   expect(t.state).toBe 'pause'

  describe '_complete method ->', ->
    it 'should set progress to 1', ->
      tw = new Tween
      spyOn tw, 'setProgress'
      tw._complete()
      expect(tw.setProgress).toHaveBeenCalledWith 1
    it 'should call onComplete callback', ->
      isCalled = null
      fun = -> isCalled = true
      tw = new Tween onComplete: fun
      tw._complete()
      expect(isCalled).toBe true
    it 'should set isOnReverseComplete to false', ->
      tw = new Tween
      tw._complete()
      expect(tw.isOnReverseComplete).toBe false
    it 'should set isCompleted to true', ->
      tw = new Tween
      tw._complete()
      expect(tw.isCompleted).toBe true
    it 'should set isStarted flag to false', ->
      tw = new Tween
      tw._complete()
      expect(tw.isStarted).toBe false






gha: JavaScript, lang: coffeescript
// Copyright 2019-2023 Cambridge Quantum Computing
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#include <boost/range/join.hpp>
#include <catch2/catch_test_macros.hpp>
#include <iostream>

#include "CircuitsForTesting.hpp"
#include "testutil.hpp"
#include "tket/Architecture/Architecture.hpp"
#include "tket/Circuit/CircPool.hpp"
#include "tket/Circuit/CircUtils.hpp"
#include "tket/Circuit/Circuit.hpp"
#include "tket/Circuit/Command.hpp"
#include "tket/Circuit/ConjugationBox.hpp"
#include "tket/Circuit/DiagonalBox.hpp"
#include "tket/Circuit/Multiplexor.hpp"
#include "tket/Circuit/PauliExpBoxes.hpp"
#include "tket/Circuit/Simulation/CircuitSimulator.hpp"
#include "tket/Circuit/StatePreparation.hpp"
#include "tket/Circuit/ToffoliBox.hpp"
#include "tket/Converters/PhasePoly.hpp"
#include "tket/Gate/SymTable.hpp"
#include "tket/Mapping/LexiLabelling.hpp"
#include "tket/Mapping/LexiRoute.hpp"
#include "tket/Mapping/RoutingMethod.hpp"
#include "tket/MeasurementSetup/MeasurementSetup.hpp"
#include "tket/OpType/OpType.hpp"
#include "tket/Ops/ClassicalOps.hpp"
#include "tket/Ops/OpPtr.hpp"
#include "tket/Predicates/PassGenerators.hpp"
#include "tket/Predicates/PassLibrary.hpp"
#include "tket/Transformations/OptimisationPass.hpp"
#include "tket/Transformations/PauliOptimisation.hpp"
#include "tket/Transformations/Transform.hpp"
#include "tket/Utils/Json.hpp"

namespace tket {
namespace test_json {

template <class T>
bool serialize_deserialize(const T& obj) {
  nlohmann::json j = obj;
  auto new_obj = j.get<T>();
  return obj == new_obj;
}

template <class T>
void check_cases(const std::vector<T>& cases) {
  for (const auto& test : cases) {
    CHECK(serialize_deserialize(test));
  }
}

bool check_circuit(const Circuit& c) {
  nlohmann::json j = c;
  auto new_c = j.get<Circuit>();
  return c.circuit_equality(new_c);
}

SCENARIO("Test Op serialization") {
  GIVEN("OpType") {
    const OpTypeSet metaops = {OpType::Input,     OpType::Output,
                               OpType::ClInput,   OpType::ClOutput,
                               OpType::WASMInput, OpType::WASMOutput,
                               OpType::Barrier};
    const OpTypeSet boxes = {
        OpType::CircBox,         OpType::Unitary1qBox,
        OpType::Unitary2qBox,    OpType::Unitary3qBox,
        OpType::ExpBox,          OpType::PauliExpBox,
        OpType::PauliExpPairBox, OpType::PauliExpCommutingSetBox,
        OpType::ToffoliBox,      OpType::CustomGate,
        OpType::CliffBox,        OpType::PhasePolyBox,
        OpType::QControlBox};

    std::set<std::string> type_names;
    for (auto type :
         boost::join(all_gate_types(), boost::join(metaops, boxes))) {
      bool success_insert =
          type_names.insert(optypeinfo().at(type).name).second;
      // check all optype names are unique
      CHECK(success_insert);
      CHECK(serialize_deserialize(type));
    }

    nlohmann::json false_str = "NOTANOPTYPE";
    nlohmann::json correct_str = "Z";
    CHECK(correct_str.get<OpType>() == OpType::Z);
    REQUIRE_THROWS_AS(false_str.get<OpType>(), JsonError);
  }

  GIVEN("Expressions") {
    std::vector<Expr> e_tests = {
        Expr(0.3), Expr("a"), Expr((2 * 3. / 4 - 1)),
        Expr(-0.3 + (3.4 * Expr(SymEngine::sin(Expr("d") - 2.3))))};
    check_cases(e_tests);
  }
}

SCENARIO("Test UnitID serialization") {
  GIVEN("A list of Qubit instances") {
    std::vector<Qubit> test_q = {
        Qubit("test", 1), Qubit(4), Node(3), Qubit("a", {1, 2, 3, 4}),
        Qubit("sdaf", 1, 2)};
    check_cases(test_q);

    std::vector<Bit> test_b = {
        Bit("test", 1), Bit(4), Bit("a", {1, 2, 3, 4}), Bit("sdaf", 1, 2)};
    check_cases(test_b);
  }
}

SCENARIO("Test Command serialization") {
  GIVEN("A test circuit") {
    Circuit c(2, 2);
    c.add_op<unsigned>(OpType::Rz, 0.2, {0});
    c.add_op<unsigned>(OpType::H, {0});
    c.add_op<unsigned>(OpType::Measure, {0, 1});
    const qubit_vector_t& q = c.all_qubits();
    const Qubit a = Qubit("a", 1, 2);
    c.add_qubit(a);
    c.add_op<UnitID>(OpType::CnRy, 0.1, {q[0], a, q[1]});
    c.add_barrier({q[0], a});

    check_cases(c.get_commands());
  }
  GIVEN("check classical operations") {
    Circuit c(3, 3);
    c.add_op<unsigned>(OpType::X, {0});
    c.add_op<unsigned>(OpType::H, {1});
    c.add_op<unsigned>(OpType::H, {2});
    c.add_op<unsigned>(OpType::CY, {1, 2});
    c.add_op<unsigned>(OpType::Measure, {0, 0});
    c.add_op<unsigned>(OpType::Measure, {1, 1});
    c.add_op<unsigned>(OpType::Measure, {2, 2});
    // Without any Create or Discard ...
    CompilationUnit cu0(c);
    PassPtr pp = gen_contextual_pass();
    REQUIRE(!pp->apply(cu0));
    // With Create and Discard ...
    c.qubit_create_all();
    c.qubit_discard_all();
    CompilationUnit cu1(c);
    REQUIRE(pp->apply(cu1));
    const Circuit& c1 = cu1.get_circ_ref();
    REQUIRE(c1.count_gates(OpType::X) == 0);
    REQUIRE(c1.count_gates(OpType::H) == 2);
    REQUIRE(c1.count_gates(OpType::CY) == 0);
    REQUIRE(c1.count_gates(OpType::Measure) == 2);
    REQUIRE(c1.count_gates(OpType::SetBits) == 1);
    REQUIRE(c1.count_gates(OpType::ClassicalTransform) == 2);

    check_cases(c1.get_commands());
  }
  GIVEN("check wasm operations") {
    // current issue
    std::string wasm_file = "string/with/path/to/wasm/file";
    std::string wasm_func = "stringNameOfWASMFunc";

    std::vector<unsigned> uv = {2, 1};

    const std::shared_ptr<WASMOp> wop_ptr =
        std::make_shared<WASMOp>(6, 1, uv, uv, wasm_func, wasm_file);

    Circuit c(7, 7);
    c.add_op<unsigned>(OpType::X, {0});
    c.add_op<unsigned>(OpType::H, {1});
    c.add_op<unsigned>(OpType::H, {2});
    c.add_op<unsigned>(OpType::CY, {1, 2});
    c.add_op<UnitID>(
        wop_ptr,
        {Bit(0), Bit(1), Bit(2), Bit(3), Bit(4), Bit(5), WasmState(0)});
    c.add_op<unsigned>(OpType::Measure, {0, 0});
    c.add_op<unsigned>(OpType::Measure, {1, 1});
    c.add_op<unsigned>(OpType::Measure, {2, 2});
    check_cases(c.get_commands());
    CHECK(serialize_deserialize(c));
  }
}

SCENARIO("Test Circuit serialization") {
  GIVEN("A simple test circuit") {
    Circuit c(2, 2, "test_circ_1");
    // add standard ops
    c.add_op<unsigned>(OpType::Rz, 0.2, {0});
    c.add_op<unsigned>(OpType::H, {0});
    c.add_op<unsigned>(OpType::Measure, {0, 1});
    // add custom qubit
    const qubit_vector_t& q = c.all_qubits();
    const Qubit a = Qubit("a", 1, 2);
    c.add_qubit(a);
    // variable arity gate
    c.add_op<UnitID>(OpType::CnRy, 0.1, {q[0], a, q[1]});
    // barrier metaop
    c.add_barrier({q[0], a});
    // phase
    c.add_phase(0.3);
    c.qubit_create(q[0]);
    c.qubit_create(q[1]);
    c.qubit_discard(a);
    REQUIRE(check_circuit(c));
  }

  GIVEN("An implicit permutation") {
    Circuit circ(3);
    add_2qb_gates(circ, OpType::CX, {{0, 1}, {1, 0}, {1, 2}, {2, 1}});

    Transforms::clifford_simp().apply(circ);

    REQUIRE(check_circuit(circ));
  }

  GIVEN("Conditional") {
    Circuit c(2, 3);
    c.add_conditional_gate<unsigned>(OpType::Ry, {-0.75}, {0}, {0, 1}, 1);
    c.add_conditional_gate<unsigned>(OpType::CX, {}, {0, 1}, {0, 1}, 1);
    c.add_conditional_gate<unsigned>(OpType::Measure, {}, {0, 2}, {0, 1}, 1);

    nlohmann::json j_box = c;
    const Circuit new_c = j_box.get<Circuit>();
    c.circuit_equality(new_c);
    const auto& cond =
        static_cast<const Conditional&>(*new_c.get_commands()[1].get_op_ptr());

    REQUIRE(*cond.get_op() == *get_op_ptr(OpType::CX));
    REQUIRE(cond.get_width() == 2);
    REQUIRE(cond.get_value() == 1);
  }

  GIVEN("A circbox") {
    Circuit c(3, 2, "circbox_base");
    c.add_op<unsigned>(OpType::Rz, 0.2, {0});

    Circuit temp_circ(2, "circbox");
    temp_circ.add_op<unsigned>(OpType::Ry, 0.75, {0});
    temp_circ.add_op<unsigned>(OpType::CX, {0, 1});
    CircBox temp_box(temp_circ);
    c.add_box(temp_box, {0, 1});

    nlohmann::json j_cbox = c;
    const Circuit new_c = j_cbox.get<Circuit>();

    const Command cbox_com = new_c.get_commands()[1];
    const CircBox& c_b = static_cast<const CircBox&>(*cbox_com.get_op_ptr());
    REQUIRE(temp_box == c_b);
    const Circuit& new_temp = *c_b.to_circuit();
    CHECK(new_temp.get_name() == temp_circ.get_name());
    REQUIRE(new_temp == temp_circ);
  }

  GIVEN("Unitary Boxes") {
    Circuit c(3, 2, "unitarybox");
    c.add_op<unsigned>(OpType::Rz, 0.2, {0});

    Circuit setup(1);
    setup.add_op<unsigned>(OpType::TK1, {0.2374, 1.0353, 0.5372}, {0});
    Eigen::Matrix2cd m = get_matrix_from_circ(setup);
    Unitary1qBox mbox(m);
    c.add_box(mbox, {1});

    Eigen::Matrix4cd m2;
    m2 << 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0;
    Unitary2qBox mbox2(m2);
    c.add_box(mbox2, {0, 2});

    Matrix8cd U = Matrix8cd::Zero();
    U(0, 3) = 1;
    U(1, 1) = 1;
    U(2, 7) = 1;
    U(3, 5) = 1;
    U(4, 0) = 1;
    U(5, 4) = 1;
    U(6, 2) = 1;
    U(7, 6) = 1;
    Unitary3qBox mbox3(U);

    c.add_box(mbox3, {0, 1, 2});

    Eigen::Matrix4cd A;
    A << 0., 1., 2., 3., 1., 2., 3. * i_, 4., 2., -3. * i_, 3, 2. - 3. * i_, 3.,
        4., 2. + 3. * i_, 5.;
    ExpBox ebox(A, -0.5);
    c.add_box(ebox, {1, 2});

    nlohmann::json j_mbox = c;
    const Circuit new_c = j_mbox.get<Circuit>();

    const std::vector<Command> coms = new_c.get_commands();
    const auto& m_b = static_cast<const Unitary1qBox&>(*coms[1].get_op_ptr());
    REQUIRE(matrices_are_equal(mbox.get_matrix(), m_b.get_matrix()));
    REQUIRE(mbox == m_b);
    const auto& m2_b = static_cast<const Unitary2qBox&>(*coms[2].get_op_ptr());
    REQUIRE(matrices_are_equal(mbox2.get_matrix(), m2_b.get_matrix()));
    REQUIRE(mbox2 == m2_b);

    const auto& m3_b = static_cast<const Unitary3qBox&>(*coms[3].get_op_ptr());
    REQUIRE(matrices_are_equal(mbox3.get_matrix(), m3_b.get_matrix()));
    REQUIRE(mbox3 == m3_b);

    const auto& exp_b = static_cast<const ExpBox&>(*coms[4].get_op_ptr());

    const auto ebox_m_p = ebox.get_matrix_and_phase();
    const auto exp_b_m_p = exp_b.get_matrix_and_phase();
    REQUIRE(matrices_are_equal(ebox_m_p.first, exp_b_m_p.first));
    REQUIRE(ebox_m_p.second == exp_b_m_p.second);

    REQUIRE(ebox == exp_b);
  }
  GIVEN("PauliExpBoxes") {
    Circuit c(4, 2, "paulibox");
    PauliExpBox pbox(
        {Pauli::X, Pauli::Y, Pauli::I, Pauli::Z}, -0.72521,
        CXConfigType::MultiQGate);
    c.add_box(pbox, {0, 1, 2, 3});
    nlohmann::json j_pbox = c;
    const Circuit new_c = j_pbox.get<Circuit>();

    const auto& p_b =
        static_cast<const PauliExpBox&>(*new_c.get_commands()[0].get_op_ptr());

    REQUIRE(p_b.get_paulis() == pbox.get_paulis());
    REQUIRE(p_b.get_phase() == pbox.get_phase());
    REQUIRE(p_b.get_cx_config() == pbox.get_cx_config());
    REQUIRE(p_b == pbox);
  }

  GIVEN("PauliExpPairBoxes") {
    Circuit c(4, 2, "paulipairbox");
    PauliExpPairBox pbox(
        {Pauli::X, Pauli::Y, Pauli::I, Pauli::Z}, -0.72521,
        {Pauli::X, Pauli::I, Pauli::I, Pauli::X}, -0.32421,
        CXConfigType::MultiQGate);
    c.add_box(pbox, {0, 1, 2, 3});
    nlohmann::json j_pbox = c;
    const Circuit new_c = j_pbox.get<Circuit>();

    const auto& p_b = static_cast<const PauliExpPairBox&>(
        *new_c.get_commands()[0].get_op_ptr());

    const auto [actual_paulis0, actual_paulis1] = p_b.get_paulis_pair();
    const auto [actual_phase0, actual_phase1] = p_b.get_phase_pair();
    const auto [expected_paulis0, expected_paulis1] = pbox.get_paulis_pair();
    const auto [expected_phase0, expected_phase1] = pbox.get_phase_pair();

    REQUIRE(actual_paulis0 == expected_paulis0);
    REQUIRE(actual_phase0 == expected_phase0);
    REQUIRE(actual_paulis1 == expected_paulis1);
    REQUIRE(actual_phase1 == expected_phase1);
    REQUIRE(p_b.get_cx_config() == pbox.get_cx_config());
    REQUIRE(p_b == pbox);
  }

  GIVEN("PauliExpCommutingSetBoxes") {
    Circuit c(5, 2, "paulisetbox");
    PauliExpCommutingSetBox pbox(
        {{{Pauli::I, Pauli::X, Pauli::Z, Pauli::I, Pauli::Z}, 0.3112},
         {{Pauli::I, Pauli::Y, Pauli::I, Pauli::Z, Pauli::Y}, 1.178},
         {{Pauli::X, Pauli::X, Pauli::I, Pauli::Y, Pauli::I}, -0.911}},
        CXConfigType::MultiQGate);
    c.add_box(pbox, {0, 1, 2, 3, 4});
    nlohmann::json j_pbox = c;
    const Circuit new_c = j_pbox.get<Circuit>();

    const auto& p_b = static_cast<const PauliExpCommutingSetBox&>(
        *new_c.get_commands()[0].get_op_ptr());

    REQUIRE(p_b.get_pauli_gadgets() == pbox.get_pauli_gadgets());
    REQUIRE(p_b.get_cx_config() == pbox.get_cx_config());
    REQUIRE(p_b == pbox);
  }

  GIVEN("ToffoliBoxes") {
    Circuit c(2, 2, "toffolibox");
    std::map<std::vector<bool>, std::vector<bool>> permutation;
    permutation[{0, 0}] = {1, 1};
    permutation[{1, 1}] = {0, 0};
    ToffoliBox tbox(permutation);
    c.add_box(tbox, {0, 1});
    nlohmann::json j_tbox = c;
    const Circuit new_c = j_tbox.get<Circuit>();

    const auto& t_b =
        static_cast<const ToffoliBox&>(*new_c.get_commands()[0].get_op_ptr());

    REQUIRE(t_b.get_permutation() == tbox.get_permutation());
    REQUIRE(t_b.get_rotation_axis() == tbox.get_rotation_axis());
    REQUIRE(t_b == tbox);
  }

  GIVEN("CustomGate") {
    Circuit setup(2);
    Sym a = SymTable::fresh_symbol("a");
    Sym c = SymTable::fresh_symbol("c");
    Expr b(SymTable::fresh_symbol("b"));
    setup.add_op<unsigned>(OpType::Rx, {c}, {0});
    setup.add_op<unsigned>(OpType::CX, {0, 1});
    setup.add_op<unsigned>(OpType::Ry, {a}, {0});
    composite_def_ptr_t def = CompositeGateDef::define_gate("g", setup, {a});
    CustomGate g0(def, {0.2374});
    CustomGate g1(def, {b});

    Circuit circ(3);
    circ.add_box(g0, {0, 1});
    circ.add_box(g1, {1, 2});

    nlohmann::json j_pbox = circ;
    const Circuit new_c = j_pbox.get<Circuit>();

    const std::vector<Command> coms = new_c.get_commands();

    const auto& g_0_new = static_cast<const CustomGate&>(*coms[0].get_op_ptr());

    REQUIRE(g0.get_params() == g_0_new.get_params());
    REQUIRE(*g0.get_gate() == *g_0_new.get_gate());
    REQUIRE(g0 == g_0_new);
    const auto& g_1_new = static_cast<const CustomGate&>(*coms[1].get_op_ptr());

    REQUIRE(g1.get_params() == g_1_new.get_params());
    REQUIRE(*g1.get_gate() == *g_1_new.get_gate());
    REQUIRE(g1 == g_1_new);
  }

  GIVEN("QControlBox") {
    Op_ptr op = get_op_ptr(OpType::Sycamore);
    QControlBox qcbox(op, 2, {1, 1});
    Circuit c(4);
    c.add_box(qcbox, {0, 1, 2, 3});

    nlohmann::json j_circ = c;
    const Circuit new_c = j_circ.get<Circuit>();

    const auto& qc_b =
        static_cast<const QControlBox&>(*new_c.get_commands()[0].get_op_ptr());

    REQUIRE(qc_b == qcbox);

    // test backward compatibility
    nlohmann::json j_box = std::make_shared<QControlBox>(qcbox);
    j_box.erase("control_state");
    Op_ptr qcbox_ptr = j_box.get<Op_ptr>();
    const auto& qcbox2 = static_cast<const QControlBox&>(*qcbox_ptr);
    REQUIRE(qcbox == qcbox2);
  }

  GIVEN("MultiplexorBox") {
    Circuit c0(2);
    c0.add_op<unsigned>(OpType::H, {0});
    CircBox cbox(c0);
    Op_ptr op0 = std::make_shared<CircBox>(cbox);
    ctrl_op_map_t op_map = {
        {{1, 1}, op0},
        {{0, 1}, get_op_ptr(OpType::CX)},
        {{1, 0}, get_op_ptr(OpType::TK2, std::vector<Expr>{0.2, 0.4, 0.4})}};
    MultiplexorBox multiplexor(op_map);
    Circuit c(4);
    c.add_box(multiplexor, {0, 1, 2, 3});
    nlohmann::json j_box = c;
    const Circuit new_c = j_box.get<Circuit>();
    const auto& m_b = static_cast<const MultiplexorBox&>(
        *new_c.get_commands()[0].get_op_ptr());
    ctrl_op_map_t new_op_map = m_b.get_op_map();
    REQUIRE(new_op_map.size() == op_map.size());
    for (auto it = op_map.begin(); it != op_map.end(); it++) {
      auto new_it = new_op_map.find(it->first);
      REQUIRE(new_it != new_op_map.end());
      REQUIRE(*it->second == *new_it->second);
    }
  }

  GIVEN("MultiplexedRotationBox") {
    ctrl_op_map_t op_map = {
        {{1, 1, 0, 1, 0, 0}, get_op_ptr(OpType::Ry, 0.3)},
        {{0, 1, 1, 1, 1, 0}, get_op_ptr(OpType::Ry, 1.4)},
        {{1, 0, 1, 1, 1, 0}, get_op_ptr(OpType::Ry, 0.7)}};
    MultiplexedRotationBox multiplexor(op_map);
    Circuit c(7);
    c.add_box(multiplexor, {0, 1, 2, 3, 4, 5, 6});
    nlohmann::json j_box = c;
    const Circuit new_c = j_box.get<Circuit>();
    const auto& m_b = static_cast<const MultiplexedRotationBox&>(
        *new_c.get_commands()[0].get_op_ptr());
    ctrl_op_map_t new_op_map = m_b.get_op_map();
    REQUIRE(new_op_map.size() == op_map.size());
    for (auto it = op_map.begin(); it != op_map.end(); it++) {
      auto new_it = new_op_map.find(it->first);
      REQUIRE(new_it != new_op_map.end());
      REQUIRE(*it->second == *new_it->second);
    }
  }

  GIVEN("MultiplexedU2Box") {
    Circuit c0(1);
    c0.add_op<unsigned>(OpType::TK1, {0.2374, 1.0353, 0.5372}, {0});
    Eigen::Matrix2cd m = tket_sim::get_unitary(c0);
    Unitary1qBox mbox(m);
    Op_ptr mbox_op = std::make_shared<Unitary1qBox>(mbox);
    ctrl_op_map_t op_map = {
        {{1, 1}, mbox_op},
        {{0, 1}, get_op_ptr(OpType::X)},
        {{1, 0}, get_op_ptr(OpType::TK1, std::vector<Expr>{0.3, 1.8, 3.4})}};
    MultiplexedU2Box multiplexor(op_map, false);
    Circuit c(3);
    c.add_box(multiplexor, {0, 1, 2});
    nlohmann::json j_box = c;
    const Circuit new_c = j_box.get<Circuit>();
    const auto& qc_b = static_cast<const MultiplexedU2Box&>(
        *new_c.get_commands()[0].get_op_ptr());
    ctrl_op_map_t new_op_map = qc_b.get_op_map();
    REQUIRE(new_op_map.size() == op_map.size());
    for (auto it = op_map.begin(); it != op_map.end(); it++) {
      auto new_it = new_op_map.find(it->first);
      REQUIRE(new_it != new_op_map.end());
      REQUIRE(*it->second == *new_it->second);
    }
    REQUIRE(multiplexor.get_impl_diag() == qc_b.get_impl_diag());
  }

  GIVEN("MultiplexedTensoredU2Box") {
    Circuit c0(1);
    c0.add_op<unsigned>(OpType::TK1, {0.2374, 1.0353, 0.5372}, {0});
    Eigen::Matrix2cd m = tket_sim::get_unitary(c0);
    Unitary1qBox mbox(m);
    Op_ptr mbox_op = std::make_shared<Unitary1qBox>(mbox);
    ctrl_tensored_op_map_t op_map = {
        {{1, 1}, {mbox_op, get_op_ptr(OpType::X)}},
        {{0, 1}, {get_op_ptr(OpType::X), get_op_ptr(OpType::H)}},
        {{1, 0},
         {get_op_ptr(OpType::TK1, std::vector<Expr>{0.3, 1.8, 3.4}),
          get_op_ptr(OpType::X)}}};
    MultiplexedTensoredU2Box multiplexor(op_map);
    Circuit c(4);
    c.add_box(multiplexor, {0, 1, 2, 3});
    nlohmann::json j_box = c;
    const Circuit new_c = j_box.get<Circuit>();
    const auto& qc_b = static_cast<const MultiplexedTensoredU2Box&>(
        *new_c.get_commands()[0].get_op_ptr());
    ctrl_tensored_op_map_t new_op_map = qc_b.get_op_map();
    REQUIRE(new_op_map.size() == op_map.size());
    for (auto it = op_map.begin(); it != op_map.end(); it++) {
      auto new_it = new_op_map.find(it->first);
      REQUIRE(new_it != new_op_map.end());
      REQUIRE(it->second.size() == new_it->second.size());
      for (unsigned i = 0; i < it->second.size(); i++) {
        REQUIRE(*it->second[i] == *new_it->second[i]);
      }
    }
  }

  GIVEN("StatePreparationBox") {
    Eigen::VectorXcd state(8);
    state << std::sqrt(0.125), -std::sqrt(0.125), std::sqrt(0.125),
        -std::sqrt(0.125), std::sqrt(0.125), -std::sqrt(0.125),
        std::sqrt(0.125), -std::sqrt(0.125);
    StatePreparationBox prep(state, true);
    Circuit c(3);
    c.add_box(prep, {0, 1, 2});
    nlohmann::json j_box = c;
    const Circuit new_c = j_box.get<Circuit>();
    const auto& box = static_cast<const StatePreparationBox&>(
        *new_c.get_commands()[0].get_op_ptr());
    REQUIRE((state - box.get_statevector()).cwiseAbs().sum() < ERR_EPS);
    REQUIRE(box.is_inverse() == true);
  }

  GIVEN("DiagonalBox") {
    Eigen::VectorXcd diag(8);
    diag << i_, i_, i_, -i_, 1, -i_, 1, -i_;
    DiagonalBox diagbox(diag, false);
    Circuit c(3);
    c.add_box(diagbox, {0, 1, 2});
    nlohmann::json j_box = c;
    const Circuit new_c = j_box.get<Circuit>();
    const auto& box =
        static_cast<const DiagonalBox&>(*new_c.get_commands()[0].get_op_ptr());
    REQUIRE((diag - box.get_diagonal()).cwiseAbs().sum() < ERR_EPS);
    REQUIRE(!box.is_upper_triangle());
  }

  GIVEN("PhasePolyBox") {
    Circuit circ(2);
    circ.add_op<unsigned>(OpType::CX, {0, 1});
    circ.add_op<unsigned>(OpType::Rz, 0.3, {1});
    circ.add_op<unsigned>(OpType::CX, {0, 1});
    PhasePolyBox ppbox(circ);
    Circuit c(3);
    c.add_box(ppbox, {1, 2});
    nlohmann::json j_box = c;

    const Circuit new_c = j_box.get<Circuit>();

    const auto& pp_b =
        static_cast<const PhasePolyBox&>(*new_c.get_commands()[0].get_op_ptr());

    // can use box equality check here as in this case all members are checked
    REQUIRE(pp_b == ppbox);
  }

  GIVEN("ConjugationBox") {
    Circuit compute(2);
    compute.add_op<unsigned>(OpType::CRx, 0.5, {1, 0});
    Op_ptr compute_op = std::make_shared<CircBox>(CircBox(compute));
    Circuit action(2);
    action.add_op<unsigned>(OpType::H, {0});
    Op_ptr action_op = std::make_shared<CircBox>(CircBox(action));
    ConjugationBox box(compute_op, action_op);
    nlohmann::json j_box = std::make_shared<ConjugationBox>(box);
    // check the uncompute field is null
    REQUIRE(
        (j_box.at("box").contains("uncompute") &&
         j_box.at("box").at("uncompute").is_null()));
    Op_ptr box_ptr = j_box.get<Op_ptr>();
    const auto& new_box = static_cast<const ConjugationBox&>(*box_ptr);
    REQUIRE(new_box == box);
    // uncompute is not null
    ConjugationBox box2(compute_op, action_op, compute_op->dagger());
    nlohmann::json j_box2 = std::make_shared<ConjugationBox>(box2);
    REQUIRE(
        (j_box2.at("box").contains("uncompute") &&
         !j_box2.at("box").at("uncompute").is_null()));
    Op_ptr box_ptr2 = j_box2.get<Op_ptr>();
    const auto& new_box2 = static_cast<const ConjugationBox&>(*box_ptr2);
    REQUIRE(new_box2 == box2);
  }

  GIVEN("Circuits with named operations") {
    Circuit circ(2);
    circ.add_op<unsigned>(OpType::CX, {0, 1});
    circ.add_op<unsigned>(OpType::Rz, 0.125, {1}, "foo");
    circ.add_op<unsigned>(OpType::CX, {0, 1});
    Circuit circ1(2);
    circ1.add_op<unsigned>(OpType::CX, {0, 1}, "bar");
    circ1.add_op<unsigned>(OpType::Rz, 0.125, {1});
    circ1.add_op<unsigned>(OpType::CX, {0, 1}, "bar");
    REQUIRE(check_circuit(circ));
    REQUIRE(check_circuit(circ1));
    REQUIRE(!(circ == circ1));
  }
}

SCENARIO("Test device serializations") {
  GIVEN("Architecture") {
    Architecture arc({{0, 1}, {1, 2}});
    nlohmann::json j_arc = arc;
    Architecture loaded_arc = j_arc.get<Architecture>();
    CHECK(arc == loaded_arc);
    nlohmann::json j_loaded_arc = loaded_arc;
    CHECK(j_arc == j_loaded_arc);
    Architecture ring = RingArch(6);
    node_vector_t nodes = ring.get_all_nodes_vec();
    ring.add_connection(nodes.at(0), nodes.at(3), 20);
    nlohmann::json j_ring = ring;
    Architecture loaded_ring = j_ring.get<Architecture>();
    CHECK(ring == loaded_ring);
    nlohmann::json j_loaded_ring = loaded_ring;
    CHECK(j_ring == j_loaded_ring);
  }
  GIVEN("FullyConnected") {
    FullyConnected full(4);
    nlohmann::json j_full = full;
    FullyConnected loaded_full = j_full.get<FullyConnected>();
    CHECK(full == loaded_full);
    nlohmann::json j_loaded_full = loaded_full;
    CHECK(j_full == j_loaded_full);
  }
  GIVEN("DeviceCharacterisation") {
    Architecture ring = RingArch(3);
    node_vector_t nodes = ring.get_all_nodes_vec();
    op_errors_t node_err0{{{OpType::X, 0.3}, {OpType::Y, 0.4}}};
    op_errors_t node_err1{{{OpType::X, 0.2}, {OpType::Y, 0.5}}};
    op_node_errors_t ne{
        {nodes.at(0), node_err0},
        {nodes.at(1), node_err1},
        {nodes.at(2), node_err1}};
    op_errors_t link_err0{{{OpType::CX, 0.1}}};
    op_errors_t link_err1{{{OpType::CX, 0.1}, {OpType::CZ, 0.2}}};
    op_link_errors_t le{
        {{nodes.at(0), nodes.at(1)}, link_err0},
        {{nodes.at(1), nodes.at(2)}, link_err1},
        {{nodes.at(0), nodes.at(2)}, link_err0}};
    avg_readout_errors_t roe{
        {nodes.at(0), 0.02}, {nodes.at(1), 0.01}, {nodes.at(2), 0.98}};
    DeviceCharacterisation op_dc{ne, le, roe};
    nlohmann::json j_op_dc = op_dc;
    DeviceCharacterisation loaded_op_dc = j_op_dc.get<DeviceCharacterisation>();
    CHECK(op_dc == loaded_op_dc);
    nlohmann::json j_loaded_op_dc = loaded_op_dc;
    CHECK(j_op_dc == j_loaded_op_dc);
    avg_node_errors_t avg_ne{
        {nodes.at(0), 0.}, {nodes.at(1), 0.1}, {nodes.at(2), 0.2}};
    avg_link_errors_t avg_le{
        {{nodes.at(0), nodes.at(1)}, 0.},
        {{nodes.at(1), nodes.at(2)}, 0.1},
        {{nodes.at(1), nodes.at(2)}, 0.9}};
    DeviceCharacterisation avg_dc{avg_ne, avg_le, roe};
    nlohmann::json j_avg_dc = avg_dc;
    DeviceCharacterisation loaded_avg_dc =
        j_avg_dc.get<DeviceCharacterisation>();
    CHECK(avg_dc == loaded_avg_dc);
    nlohmann::json j_loaded_avg_dc = loaded_avg_dc;
    CHECK(j_avg_dc == j_loaded_avg_dc);
  }
}

SCENARIO("Test RoutingMethod serializations") {
  RoutingMethod rm;
  nlohmann::json rm_j = rm;
  RoutingMethod loaded_rm_j = rm_j.get<RoutingMethod>();

  Circuit c(2, 2);
  c.add_op<unsigned>(OpType::CX, {0, 1});

  MappingFrontier mf(c);
  MappingFrontier_ptr mf_sp = std::make_shared<MappingFrontier>(mf);
  CHECK(!loaded_rm_j.routing_method(mf_sp, std::make_shared<SquareGrid>(2, 2))
             .first);

  std::vector<RoutingMethodPtr> rmp = {
      std::make_shared<RoutingMethod>(rm),
      std::make_shared<LexiLabellingMethod>(),
      std::make_shared<LexiRouteRoutingMethod>(5)};

  nlohmann::json rmp_j = rmp;
  std::vector<RoutingMethodPtr> loaded_rmp_j =
      rmp_j.get<std::vector<RoutingMethodPtr>>();
  CHECK(!loaded_rmp_j[0]
             ->routing_method(mf_sp, std::make_shared<SquareGrid>(2, 2))
             .first);
  CHECK(loaded_rmp_j[1]
            ->routing_method(mf_sp, std::make_shared<SquareGrid>(2, 2))
            .first);
}

SCENARIO("Test predicate serializations") {
#define BASICPREDJSONTEST(classname)                             \
  GIVEN(#classname) {                                            \
    PredicatePtr pp = std::make_shared<classname>();             \
    nlohmann::json j_pp = pp;                                    \
    PredicatePtr loaded_pp = j_pp.get<PredicatePtr>();           \
    REQUIRE_NOTHROW(dynamic_cast<const classname&>(*loaded_pp)); \
    nlohmann::json j_loaded_pp = loaded_pp;                      \
    REQUIRE(j_pp == j_loaded_pp);                                \
  }
  BASICPREDJSONTEST(NoClassicalControlPredicate)
  BASICPREDJSONTEST(NoFastFeedforwardPredicate)
  BASICPREDJSONTEST(NoClassicalBitsPredicate)
  BASICPREDJSONTEST(NoWireSwapsPredicate)
  BASICPREDJSONTEST(MaxTwoQubitGatesPredicate)
  BASICPREDJSONTEST(CliffordCircuitPredicate)
  BASICPREDJSONTEST(DefaultRegisterPredicate)
  BASICPREDJSONTEST(NoBarriersPredicate)
  BASICPREDJSONTEST(NoMidMeasurePredicate)
  BASICPREDJSONTEST(NoSymbolsPredicate)
  BASICPREDJSONTEST(GlobalPhasedXPredicate)
  BASICPREDJSONTEST(NormalisedTK2Predicate)
#undef BASICPREDJSONTEST
  GIVEN("GateSetPredicate") {
    OpTypeSet ops = {OpType::X, OpType::V, OpType::Rz, OpType::ZZMax};
    PredicatePtr gs = std::make_shared<GateSetPredicate>(ops);
    nlohmann::json j_gs = gs;
    PredicatePtr loaded_gs = j_gs.get<PredicatePtr>();
    REQUIRE(
        dynamic_cast<const GateSetPredicate&>(*loaded_gs).get_allowed_types() ==
        ops);
    // Don't check the json equality here since ordering of elements in an
    // OpTypeSet (std::unordered_set<OpType>) is not guaranteed
  }
  GIVEN("PlacementPredicate") {
    node_set_t nodes = {Node(0), Node(14), Node(16)};
    PredicatePtr pl = std::make_shared<PlacementPredicate>(nodes);
    nlohmann::json j_pl = pl;
    PredicatePtr loaded_pl = j_pl.get<PredicatePtr>();
    REQUIRE(
        dynamic_cast<const PlacementPredicate&>(*loaded_pl).get_nodes() ==
        nodes);
    nlohmann::json j_loaded_pl = loaded_pl;
    REQUIRE(j_pl == j_loaded_pl);
  }
  GIVEN("ConnectivityPredicate") {
    Architecture ring = RingArch(3);
    PredicatePtr conn = std::make_shared<ConnectivityPredicate>(ring);
    nlohmann::json j_conn = conn;
    PredicatePtr loaded_conn = j_conn.get<PredicatePtr>();
    REQUIRE(
        dynamic_cast<const ConnectivityPredicate&>(*loaded_conn).get_arch() ==
        ring);
    nlohmann::json j_loaded_conn = loaded_conn;
    REQUIRE(j_conn == j_loaded_conn);
  }
  GIVEN("DirectednessPredicate") {
    Architecture ring = RingArch(3);
    PredicatePtr conn = std::make_shared<DirectednessPredicate>(ring);
    nlohmann::json j_conn = conn;
    PredicatePtr loaded_conn = j_conn.get<PredicatePtr>();
    REQUIRE(
        dynamic_cast<const DirectednessPredicate&>(*loaded_conn).get_arch() ==
        ring);
    nlohmann::json j_loaded_conn = loaded_conn;
    REQUIRE(j_conn == j_loaded_conn);
  }
  GIVEN("MaxNQubitsPredicate") {
    PredicatePtr max = std::make_shared<MaxNQubitsPredicate>(12);
    nlohmann::json j_max = max;
    PredicatePtr loaded_max = j_max.get<PredicatePtr>();
    REQUIRE(
        dynamic_cast<const MaxNQubitsPredicate&>(*loaded_max).get_n_qubits() ==
        12);
    nlohmann::json j_loaded_max = loaded_max;
    REQUIRE(j_max == j_loaded_max);
  }
  GIVEN("MaxNClRegPredicate") {
    PredicatePtr max = std::make_shared<MaxNClRegPredicate>(12);
    nlohmann::json j_max = max;
    PredicatePtr loaded_max = j_max.get<PredicatePtr>();
    REQUIRE(
        dynamic_cast<const MaxNClRegPredicate&>(*loaded_max).get_n_cl_reg() ==
        12);
    nlohmann::json j_loaded_max = loaded_max;
    REQUIRE(j_max == j_loaded_max);
  }
  GIVEN("UserDefinedPredicate") {
    std::function<bool(const Circuit&)> func = [](const Circuit&) {
      return false;
    };
    PredicatePtr custom = std::make_shared<UserDefinedPredicate>(func);
    nlohmann::json j_custom = custom;
    REQUIRE_THROWS_AS(j_custom.get<PredicatePtr>(), PredicateNotSerializable);
  }
}

SCENARIO("Test compiler pass serializations") {
  Architecture arc = SquareGrid(2, 4, 2);
  RoutingMethodPtr rmp = std::make_shared<LexiRouteRoutingMethod>(80);
  std::vector<RoutingMethodPtr> rcon = {rmp};
  Placement::Ptr ga_place = std::make_shared<GraphPlacement>(arc);
  Placement::Ptr place = std::make_shared<Placement>(arc);
  std::map<Qubit, Qubit> qmap = {{Qubit(0), Node(1)}, {Qubit(3), Node(2)}};
  Placement::Ptr na_place = std::make_shared<NoiseAwarePlacement>(arc);
  Placement::Ptr la_place = std::make_shared<LinePlacement>(arc);
#define COMPPASSJSONTEST(passname, pass)               \
  GIVEN(#passname) {                                   \
    Circuit circ = CircuitsForTesting::get().uccsd;    \
    CompilationUnit cu{circ};                          \
    CompilationUnit copy = cu;                         \
    PassPtr pp = pass;                                 \
    nlohmann::json j_pp = pp;                          \
    PassPtr loaded = j_pp.get<PassPtr>();              \
    pp->apply(cu);                                     \
    loaded->apply(copy);                               \
    REQUIRE(cu.get_circ_ref() == copy.get_circ_ref()); \
    nlohmann::json j_loaded = loaded;                  \
    REQUIRE(j_pp == j_loaded);                         \
  }
  COMPPASSJSONTEST(CommuteThroughMultis, CommuteThroughMultis())
  COMPPASSJSONTEST(
      DecomposeArbitrarilyControlledGates,
      DecomposeArbitrarilyControlledGates())
  COMPPASSJSONTEST(DecomposeBoxes, DecomposeBoxes())
  COMPPASSJSONTEST(DecomposeMultiQubitsCX, DecomposeMultiQubitsCX())
  COMPPASSJSONTEST(DecomposeSingleQubitsTK1, DecomposeSingleQubitsTK1())
  COMPPASSJSONTEST(PeepholeOptimise2Q, PeepholeOptimise2Q())
  COMPPASSJSONTEST(FullPeepholeOptimise, FullPeepholeOptimise())
  COMPPASSJSONTEST(RebaseTket, RebaseTket())
  COMPPASSJSONTEST(RebaseUFR, RebaseUFR())
  COMPPASSJSONTEST(RemoveRedundancies, RemoveRedundancies())
  COMPPASSJSONTEST(SynthesiseHQS, SynthesiseHQS())
  COMPPASSJSONTEST(SynthesiseTK, SynthesiseTK())
  COMPPASSJSONTEST(SynthesiseTket, SynthesiseTket())
  COMPPASSJSONTEST(SynthesiseOQC, SynthesiseOQC())
  COMPPASSJSONTEST(SynthesiseUMD, SynthesiseUMD())
  COMPPASSJSONTEST(SquashTK1, SquashTK1())
  COMPPASSJSONTEST(SquashRzPhasedX, SquashRzPhasedX())
  COMPPASSJSONTEST(FlattenRegisters, FlattenRegisters())
  COMPPASSJSONTEST(DelayMeasures, DelayMeasures())
  COMPPASSJSONTEST(TryDelayMeasures, DelayMeasures(true))
  COMPPASSJSONTEST(RemoveDiscarded, RemoveDiscarded())
  COMPPASSJSONTEST(SimplifyMeasured, SimplifyMeasured())
  COMPPASSJSONTEST(ZZPhaseToRz, ZZPhaseToRz())
  COMPPASSJSONTEST(RemoveBarriers, RemoveBarriers())
  COMPPASSJSONTEST(ComposePhasePolyBoxes, ComposePhasePolyBoxes())
  COMPPASSJSONTEST(DecomposeBridges, DecomposeBridges())
  COMPPASSJSONTEST(
      RemoveImplicitQubitPermutation, RemoveImplicitQubitPermutation())
  COMPPASSJSONTEST(KAKDecomposition, KAKDecomposition(OpType::CX, 0.98))
  COMPPASSJSONTEST(
      DecomposeTK2, DecomposeTK2({0.98, std::nullopt, std::nullopt}, false))
  COMPPASSJSONTEST(ThreeQubitSquash, ThreeQubitSquash(false))
  COMPPASSJSONTEST(
      EulerAngleReduction, gen_euler_pass(OpType::Rx, OpType::Ry, false))
  COMPPASSJSONTEST(RenameQubitsPass, gen_rename_qubits_pass(qmap))
  COMPPASSJSONTEST(
      FlattenRelabelRegistersPass, gen_flatten_relabel_registers_pass("test"))
  COMPPASSJSONTEST(CliffordSimp, gen_clifford_simp_pass(true))
  COMPPASSJSONTEST(
      DecomposeSwapsToCXs, gen_decompose_routing_gates_to_cxs_pass(arc, false))
  COMPPASSJSONTEST(
      DecomposeSwapsToCircuit,
      gen_user_defined_swap_decomp_pass(CircPool::SWAP_using_CX_1()))
  COMPPASSJSONTEST(
      OptimisePhaseGadgets, gen_optimise_phase_gadgets(CXConfigType::Star))
  COMPPASSJSONTEST(
      OptimisePairwiseGadgets, gen_pairwise_pauli_gadgets(CXConfigType::Tree))
  COMPPASSJSONTEST(
      GuidedPauliSimp,
      gen_special_UCC_synthesis(
          Transforms::PauliSynthStrat::Pairwise, CXConfigType::Snake))
  COMPPASSJSONTEST(
      SimplifyInitial,
      gen_simplify_initial(
          Transforms::AllowClassical::No, Transforms::CreateAllQubits::Yes,
          std::make_shared<Circuit>(CircPool::X())))
  COMPPASSJSONTEST(PlacementPass, gen_placement_pass(place))
  // TKET-1419
  COMPPASSJSONTEST(NoiseAwarePlacement, gen_placement_pass(na_place))
  COMPPASSJSONTEST(NaivePlacementPass, gen_naive_placement_pass(arc))
  COMPPASSJSONTEST(LinePlacement, gen_placement_pass(la_place))
  COMPPASSJSONTEST(GraphPlacement, gen_placement_pass(ga_place))
  COMPPASSJSONTEST(RoundAngles, RoundAngles(8, true))
#undef COMPPASSJSONTEST
  GIVEN("PauliExponentials") {
    Circuit circ = CircuitsForTesting::get().uccsd;
    CompilationUnit cu{circ};
    CompilationUnit copy = cu;
    PassPtr pp = gen_pauli_exponentials(
        Transforms::PauliSynthStrat::Sets, CXConfigType::Tree);
    nlohmann::json j_pp = pp;
    PassPtr loaded = j_pp.get<PassPtr>();
    pp->apply(cu);
    loaded->apply(copy);
    DecomposeBoxes()->apply(cu);
    DecomposeBoxes()->apply(copy);
    REQUIRE(cu.get_circ_ref() == copy.get_circ_ref());
    nlohmann::json j_loaded = loaded;
    REQUIRE(j_pp == j_loaded);
  }
  GIVEN("RoutingPass") {
    // Can only be applied to placed circuits
    Circuit circ = CircuitsForTesting::get().uccsd;
    CompilationUnit cu{circ};
    PassPtr placement = gen_placement_pass(place);
    placement->apply(cu);
    CompilationUnit copy = cu;
    PassPtr pp = gen_routing_pass(arc, rcon);
    nlohmann::json j_pp = pp;
    PassPtr loaded = j_pp.get<PassPtr>();
    pp->apply(cu);
    loaded->apply(copy);
    REQUIRE(cu.get_circ_ref() == copy.get_circ_ref());
    nlohmann::json j_loaded = loaded;
    REQUIRE(j_pp == j_loaded);
  }
  GIVEN("Routing with multiple routing methods") {
    RoutingMethodPtr mrmp =
        std::make_shared<MultiGateReorderRoutingMethod>(60, 80);
    RoutingMethodPtr brmp = std::make_shared<BoxDecompositionRoutingMethod>();
    std::vector<RoutingMethodPtr> mrcon = {mrmp, rmp, brmp};
    Circuit circ = CircuitsForTesting::get().uccsd;
    CompilationUnit cu{circ};
    PassPtr placement = gen_placement_pass(place);
    placement->apply(cu);
    CompilationUnit copy = cu;
    PassPtr pp = gen_routing_pass(arc, mrcon);
    nlohmann::json j_pp = pp;
    PassPtr loaded = j_pp.get<PassPtr>();
    pp->apply(cu);
    loaded->apply(copy);
    REQUIRE(cu.get_circ_ref() == copy.get_circ_ref());
    nlohmann::json j_loaded = loaded;
    REQUIRE(j_pp == j_loaded);
  }
  GIVEN("FullMappingPass") {
    // Sequence pass - deserializable only
    Circuit circ = CircuitsForTesting::get().uccsd;
    CompilationUnit cu{circ};
    CompilationUnit copy = cu;
    PassPtr pp = gen_full_mapping_pass(arc, place, rcon);
    nlohmann::json j_pp;
    j_pp["pass_class"] = "StandardPass";
    j_pp["StandardPass"]["name"] = "FullMappingPass";
    j_pp["StandardPass"]["architecture"] = arc;
    j_pp["StandardPass"]["placement"] = place;

    nlohmann::json config_array;
    for (const auto& con : rcon) {
      config_array.push_back(*con);
    }

    j_pp["StandardPass"]["routing_config"] = config_array;
    PassPtr loaded = j_pp.get<PassPtr>();
    pp->apply(cu);
    loaded->apply(copy);
    REQUIRE(cu.get_circ_ref() == copy.get_circ_ref());
  }
  GIVEN("DefaultMappingPass") {
    // Sequence pass - deserializable only
    Circuit circ = CircuitsForTesting::get().uccsd;
    CompilationUnit cu{circ};
    CompilationUnit copy = cu;
    PassPtr pp = gen_default_mapping_pass(arc, true);
    nlohmann::json j_pp;
    j_pp["pass_class"] = "StandardPass";
    j_pp["StandardPass"]["name"] = "DefaultMappingPass";
    j_pp["StandardPass"]["architecture"] = arc;
    j_pp["StandardPass"]["delay_measures"] = true;
    PassPtr loaded = j_pp.get<PassPtr>();
    pp->apply(cu);
    loaded->apply(copy);
    REQUIRE(cu.get_circ_ref() == copy.get_circ_ref());
  }
  GIVEN("CXMappingPass") {
    // Sequence pass - deserializable only
    Circuit circ = CircuitsForTesting::get().uccsd;
    CompilationUnit cu{circ};
    CompilationUnit copy = cu;
    PassPtr pp = gen_cx_mapping_pass(arc, place, rcon, true, false);
    nlohmann::json j_pp;
    j_pp["pass_class"] = "StandardPass";
    j_pp["StandardPass"]["name"] = "CXMappingPass";
    j_pp["StandardPass"]["architecture"] = arc;
    j_pp["StandardPass"]["placement"] = place;
    nlohmann::json config_array;
    for (const auto& con : rcon) {
      config_array.push_back(*con);
    }
    j_pp["StandardPass"]["routing_config"] = config_array;
    j_pp["StandardPass"]["directed"] = true;
    j_pp["StandardPass"]["delay_measures"] = false;
    PassPtr loaded = j_pp.get<PassPtr>();
    pp->apply(cu);
    loaded->apply(copy);
    REQUIRE(cu.get_circ_ref() == copy.get_circ_ref());
  }
  GIVEN("PauliSquash") {
    // Sequence pass - deserializable only
    Circuit circ = CircuitsForTesting::get().uccsd;
    CompilationUnit cu{circ};
    CompilationUnit copy = cu;
    PassPtr pp =
        PauliSquash(Transforms::PauliSynthStrat::Sets, CXConfigType::Star);
    nlohmann::json j_pp;
    j_pp["pass_class"] = "StandardPass";
    j_pp["StandardPass"]["name"] = "PauliSquash";
    j_pp["StandardPass"]["pauli_synth_strat"] =
        Transforms::PauliSynthStrat::Sets;
    j_pp["StandardPass"]["cx_config"] = CXConfigType::Star;
    PassPtr loaded = j_pp.get<PassPtr>();
    pp->apply(cu);
    loaded->apply(copy);
    REQUIRE(cu.get_circ_ref() == copy.get_circ_ref());
  }
  GIVEN("PauliSimp") {
    // Sequence pass - deserializable only
    Circuit circ = CircuitsForTesting::get().uccsd;
    CompilationUnit cu{circ};
    CompilationUnit copy = cu;
    PassPtr pp = gen_synthesise_pauli_graph(
        Transforms::PauliSynthStrat::Sets, CXConfigType::Star);
    nlohmann::json j_pp;
    j_pp["pass_class"] = "StandardPass";
    j_pp["StandardPass"]["name"] = "PauliSimp";
    j_pp["StandardPass"]["pauli_synth_strat"] =
        Transforms::PauliSynthStrat::Sets;
    j_pp["StandardPass"]["cx_config"] = CXConfigType::Star;
    PassPtr loaded = j_pp.get<PassPtr>();
    pp->apply(cu);
    loaded->apply(copy);
    REQUIRE(cu.get_circ_ref() == copy.get_circ_ref());
  }
  GIVEN("ContextSimp") {
    // Sequence pass - deserializable only
    Circuit circ = CircuitsForTesting::get().uccsd;
    circ.qubit_create_all();
    CompilationUnit cu{circ};
    CompilationUnit copy = cu;
    PassPtr pp = gen_contextual_pass(
        Transforms::AllowClassical::Yes,
        std::make_shared<Circuit>(CircPool::X()));
    nlohmann::json j_pp;
    j_pp["pass_class"] = "StandardPass";
    j_pp["StandardPass"]["name"] = "ContextSimp";
    j_pp["StandardPass"]["allow_classical"] = true;
    j_pp["StandardPass"]["x_circuit"] = CircPool::X();
    PassPtr loaded = j_pp.get<PassPtr>();
    pp->apply(cu);
    loaded->apply(copy);
    REQUIRE(cu.get_circ_ref() == copy.get_circ_ref());
  }
}

SCENARIO("Test compiler pass combinator serializations") {
  GIVEN("Sequences of passes") {
    Circuit circ = CircuitsForTesting::get().uccsd;
    CompilationUnit cu{circ};
    CompilationUnit copy = cu;
    std::vector<PassPtr> seq_vec = {
        gen_pauli_exponentials(), DecomposeBoxes(), gen_clifford_simp_pass()};
    PassPtr seq = std::make_shared<SequencePass>(seq_vec);
    nlohmann::json j_seq = seq;
    PassPtr loaded_seq = j_seq.get<PassPtr>();
    seq->apply(cu);
    loaded_seq->apply(copy);
    REQUIRE(cu.get_circ_ref() == copy.get_circ_ref());
    nlohmann::json j_loaded_seq = loaded_seq;
    REQUIRE(j_seq == j_loaded_seq);
  }
  GIVEN("A complex pass with multiple combinators") {
    Circuit circ(2);
    circ.add_op<unsigned>(OpType::CX, {0, 1});
    circ.add_op<unsigned>(OpType::X, {0});
    circ.add_op<unsigned>(OpType::CX, {1, 0});
    circ.add_op<unsigned>(OpType::X, {0});
    circ.add_op<unsigned>(OpType::Z, {1});
    circ.add_op<unsigned>(OpType::CX, {1, 0});
    circ.add_op<unsigned>(OpType::Z, {0});
    circ.add_op<unsigned>(OpType::Z, {1});
    circ.add_op<unsigned>(OpType::CX, {0, 1});
    CompilationUnit cu{circ};
    CompilationUnit copy = cu;
    PredicatePtr gate_set =
        std::make_shared<GateSetPredicate>(OpTypeSet{OpType::Z});
    PassPtr seq = std::make_shared<SequencePass>(
        std::vector<PassPtr>{RemoveRedundancies(), CommuteThroughMultis()});
    PassPtr rep = std::make_shared<RepeatUntilSatisfiedPass>(seq, gate_set);
    PassPtr comb =
        std::make_shared<SequencePass>(std::vector<PassPtr>{rep, RebaseTket()});
    nlohmann::json j_comb = comb;
    PassPtr loaded_comb = j_comb.get<PassPtr>();
    comb->apply(cu);
    loaded_comb->apply(copy);
    REQUIRE(cu.get_circ_ref() == copy.get_circ_ref());
    nlohmann::json j_loaded_comb = loaded_comb;
    REQUIRE(j_comb == j_loaded_comb);
  }
}

SCENARIO("Test QubitPauliString serialization") {
  QubitPauliString qps(
      {{Qubit(2), Pauli::X}, {Qubit(7), Pauli::Y}, {Qubit(0), Pauli::I}});

  nlohmann::json j_qps = qps;
  QubitPauliString new_qps = j_qps.get<QubitPauliString>();

  REQUIRE(qps == new_qps);
}

SCENARIO("Test MeasurementSetup serializations") {
  GIVEN("MeasurementBitMap") {
    MeasurementSetup::MeasurementBitMap map(0, {0, 1}, 1);
    nlohmann::json j_map = map;
    nlohmann::json j_correct_map = {
        {"circ_index", 0}, {"bits", {0, 1}}, {"invert", true}};
    REQUIRE(j_map == j_correct_map);
    MeasurementSetup::MeasurementBitMap map_loaded =
        j_map.get<MeasurementSetup::MeasurementBitMap>();
    nlohmann::json j_loaded_map = map_loaded;
    REQUIRE(j_loaded_map == j_map);
  }
  GIVEN("MeasurementBitMap with default constructor") {
    MeasurementSetup::MeasurementBitMap map;
    nlohmann::json j_map = map;
    nlohmann::json j_correct_map = {
        {"circ_index", 0},
        {"bits", nlohmann::json::array()},
        {"invert", false}};
    REQUIRE(j_map == j_correct_map);
    MeasurementSetup::MeasurementBitMap map_loaded =
        j_map.get<MeasurementSetup::MeasurementBitMap>();
    nlohmann::json j_loaded_map = map_loaded;
    REQUIRE(j_loaded_map == j_map);
  }
  GIVEN("MeasurementSetup") {
    MeasurementSetup ms;
    Circuit mc(2, 2);
    mc.add_measure(0, 0);
    mc.add_measure(1, 1);
    Circuit mc2(2, 2);
    mc2.add_measure(0, 1);
    mc2.add_measure(1, 0);
    ms.add_measurement_circuit(mc);
    ms.add_measurement_circuit(mc2);
    Qubit q0(q_default_reg(), 0);
    Qubit q1(q_default_reg(), 1);
    QubitPauliString ii;
    QubitPauliString zi({{q0, Pauli::Z}});
    QubitPauliString iz({{q1, Pauli::Z}});
    QubitPauliString zz({{q0, Pauli::Z}, {q1, Pauli::Z}});
    QubitPauliString xx({{q0, Pauli::X}, {q1, Pauli::X}});
    QubitPauliString yy({{q0, Pauli::Y}, {q1, Pauli::Y}});
    ms.add_result_for_term(ii, {0, {}, false});
    ms.add_result_for_term(zi, {0, {0}, false});
    ms.add_result_for_term(iz, {0, {1}, false});
    ms.add_result_for_term(zz, {0, {0, 1}, false});
    ms.add_result_for_term(zi, {1, {0}, true});
    ms.add_result_for_term(xx, {1, {0, 1}, true});
    ms.add_result_for_term(yy, {1, {0, 1}, true});
    nlohmann::json j_ms = ms;
    nlohmann::json j_circs = {mc, mc2};
    nlohmann::json j_result_map = {
        {ii,
         {{{"circ_index", 0},
           {"bits", nlohmann::json::array()},
           {"invert", false}}}},
        {iz, {{{"circ_index", 0}, {"bits", {1}}, {"invert", false}}}},
        {xx, {{{"circ_index", 1}, {"bits", {0, 1}}, {"invert", true}}}},
        {yy, {{{"circ_index", 1}, {"bits", {0, 1}}, {"invert", true}}}},
        {zi,
         {{{"circ_index", 0}, {"bits", {0}}, {"invert", false}},
          {{"circ_index", 1}, {"bits", {0}}, {"invert", true}}}},
        {zz, {{{"circ_index", 0}, {"bits", {0, 1}}, {"invert", false}}}},
    };
    REQUIRE(j_ms["circs"] == j_circs);
    REQUIRE(j_ms["result_map"] == j_result_map);
    MeasurementSetup ms_loaded = j_ms.get<MeasurementSetup>();
    nlohmann::json j_loaded_ms = ms_loaded;
    REQUIRE(j_loaded_ms == j_ms);
  }
  GIVEN("Empty MeasurementSetup") {
    MeasurementSetup ms;
    nlohmann::json j_ms = ms;
    nlohmann::json j_correct_ms = {
        {"circs", nlohmann::json::array()},
        {"result_map", nlohmann::json::array()}};
    REQUIRE(j_ms == j_correct_ms);
    MeasurementSetup ms_loaded = j_ms.get<MeasurementSetup>();
    nlohmann::json j_loaded_ms = ms_loaded;
    REQUIRE(j_loaded_ms == j_ms);
  }
}

}  // namespace test_json
}  // namespace tket

gha: C++, lang: cpp
{ ... }:

{
  services.prometheus = {
    enable = true;
    listenAddress = "localhost";
    exporters = {
      node = {
        enable = true;
        disabledCollectors = [ "rapl" ];
        listenAddress = "localhost";
      };
    };
    scrapeConfigs = [
      {
        job_name = "node";
        scrape_interval = "10s";
        static_configs = [
          {
            targets = [ "localhost:9100" ];
          }
        ];
      }
    ];
  };
}

gha: Emacs Lisp, lang: javascript
*************
OHSU Data Set
*************

About the Oregon Health & Science University
--------------------------------------------

The `Oregon Health & Science University <https://www.ohsu.edu/>`_ contains data generated from chronic neutrophilic leukemia (CNL), atypical chronic myeloid leukemia (aCML), and unclassified myelodysplastic syndrome/myeloproliferative neoplasms (MDS/MPN-U), which are a group of rare, heterogeneous myeloid disorders. 

About the Oregon Health & Science University Data
-------------------------------------------------

The data set consists of whole-exome and RNA sequencing on a cohort of over 100 cases of these rare hematologic malignancies. It presents the complete survey of the genomic landscape of these diseases to date. The Project ID in the GDC Data Portal is `OHSU-CNL <https://portal.gdc.cancer.gov/projects/OHSU-CNL>`_. 

For more information on the OHSU data, please refer to these sites:

- `dbGaP site <https://www.ncbi.nlm.nih.gov/projects/gap/cgi-bin/study.cgi?study_id=phs001799.v1.p1>`_
- `GDC Data Portal <https://portal.gdc.cancer.gov/repository?facetTab=cases&filters=%7B%22op%22%3A%22and%22%2C%22content%22%3A%5B%7B%22op%22%3A%22in%22%2C%22content%22%3A%7B%22field%22%3A%22cases.project.program.name%22%2C%22value%22%3A%5B%22OHSU%22%5D%7D%7D%5D%7D&searchTableTab=files>`_

Accessing the Oregon Health & Science University Data on the Cloud
------------------------------------------------------------------

Besides accessing the files on the GDC Data Portal, you can also access them from the GDC Google Cloud Storage Bucket, which means that you don’t need to download them to perform analysis. ISB-CGC stores the cloud file locations in tables in the ``isb-cgc-bq.GDC_case_file_metadata`` data set in BigQuery.

- To access these metadata files, go to the Google BigQuery console.
- Perform SQL queries to find the OHSU files. Here is an example:

.. code-block:: sql

  SELECT active.*, file_gdc_url
  FROM `isb-cgc-bq.GDC_case_file_metadata.fileData_active_current` as active, `isb-cgc-bq.GDC_case_file_metadata.GDCfileID_to_GCSurl_current` as GCSurl
  WHERE program_name = 'OHSU'
  AND active.file_gdc_id = GCSurl.file_gdc_id

Accessing the OHSU Data in Google BigQuery
------------------------------------------------

ISB-CGC has OHSU data, such as clinical, metadata and RNA-seq stored in Google BigQuery tables. Information about these tables can be found using the `ISB-CGC BigQuery Table Search <https://isb-cgc.appspot.com/bq_meta_search/>`_ with OHSU selected for filter PROGRAM. To learn more about this tool, see the `ISB-CGC BigQuery Table Search documentation <../BigQueryTableSearchUI.html>`_.

The OHSU tables are in project isb-cgc-bq. To learn more about how to view and query tables in the Google BigQuery console, see the `ISB-CGC BigQuery Tables documentation <../BigQuery.html>`_.

- Data set ``isb-cgc-bq.OHSU`` contains the latest tables for each data type.
- Data set ``isb-cgc-bq.OHSU_versioned`` contains previously released tables, as well as the most current table.

gha: Python, lang: markdown
<button {{action 'sendAction' 'delete' record}}>Delete</button>

gha: JavaScript, lang: sql

Chapter 8: Detecting Interest Points
==================================================

| [<Previous: Chapter 7][chapter07] |  [Next: Chapter 9>][chapter09] |



| [<Previous: Chapter 7][chapter07] | **Chapter 8: Detecting Interest Points** | [Next: Chapter 9>][chapter09] |

[chapter07]: /OpenCV_Cookbook/src/main/scala/opencv_cookbook/chapter07
[chapter09]: /OpenCV_Cookbook/src/main/scala/opencv_cookbook/chapter09
gha: Scala, lang: markdown
import React, { FunctionComponent, ReactNode, useCallback } from 'react';
import { PositionProps } from 'helpers';
import { useUniqueIds } from 'hooks/UI';
import { Text } from 'components/base-components/Typography';
import FlexBox from 'components/base-components/FlexBox';
import RenderIf from 'components/base-components/RenderIf';
import Faux from './Faux';

interface Props extends PositionProps {
  id?: string;
  name?: string;
  label?: string | ReactNode;
  value: boolean;
  onChange?: (event) => void;
  disabled?: boolean;
}

const inputStyles = { display: 'none' };

const Checkbox: FunctionComponent<Props> = (props) => {
  const { id, name, label, value, onChange, disabled, ...rest } = props;
  const [inputName] = useUniqueIds([name || id || 'input']);

  const handleFauxClick = useCallback(() => {
    if (onChange && !disabled) {
      onChange(!value);
    }
  }, [value, onChange]);

  return (
    <FlexBox align="center" {...rest}>
      <Faux isChecked={value} onClick={handleFauxClick} />
      <RenderIf condition={!!label}>
        <Text padding="0 0 0 6px">{label}</Text>
      </RenderIf>
      <input
        type="checkbox"
        id={id}
        name={inputName}
        value={inputName}
        checked={value}
        style={inputStyles}
        readOnly
      />
    </FlexBox>
  );
};

export default Checkbox;

gha: TypeScript, lang: javascript
/*
 * Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License").
 * You may not use this file except in compliance with the License.
 * A copy of the License is located at
 *
 *     http://aws.amazon.com/apache2.0/
 *
 * or in the "license" file accompanying this file. This file is distributed
 * on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either
 * express or implied. See the License for the specific language governing
 * permissions and limitations under the License.
 */

#ifndef ALEXA_CLIENT_SDK_REGISTRATIONMANAGER_INCLUDE_REGISTRATIONMANAGER_CUSTOMERDATAHANDLER_H_
#define ALEXA_CLIENT_SDK_REGISTRATIONMANAGER_INCLUDE_REGISTRATIONMANAGER_CUSTOMERDATAHANDLER_H_

#include <memory>

namespace alexaClientSDK {
namespace registrationManager {

class CustomerDataManager;

/**
 * Abstract base class which requires the derived class to implement a @c clearData() function.
 *
 * For changes in the device registration, it is extremely important to remove any customer data saved in the device.
 * Classes that have any data related to the currently logged user must extend this class to guarantee that their data
 * will be wiped out during logout.
 */
class CustomerDataHandler {
public:
    /**
     * Build and register the new object with the CustomerDataManager.
     *
     * @param customerDataManager The CustomerDataManager that will keep track of the new data handler.
     * @note The customerDataManager must have a valid pointer to a manager instance.
     */
    CustomerDataHandler(std::shared_ptr<CustomerDataManager> customerDataManager);

    /**
     * CustomerDataHandler destructor.
     *
     * Deregister the handler with the CustomerDataManager.
     */
    virtual ~CustomerDataHandler();

    /**
     * Reset any internal state that may be associated with a particular user.
     *
     * @warning Object must succeed in deleting any customer data.
     * @warning This method is called while CustomerDataManager is in a locked state. Do not call or wait for any
     * CustomerDataManager operation.
     */
    virtual void clearData() = 0;

private:
    /**
     * Keep a constant pointer to CustomerDataManager so that the CustomerDataHandler object can auto remove itself.
     *
     * @note The goal is to guarantee that all customerDataHandlers are properly managed. The trade-off is that we have
     * to keep a shared_pointer to its manager and the manager has to keep a raw pointer to each handler.
     */
    const std::shared_ptr<CustomerDataManager> m_dataManager;
};

}  // namespace registrationManager
}  // namespace alexaClientSDK

#endif  // ALEXA_CLIENT_SDK_REGISTRATIONMANAGER_INCLUDE_REGISTRATIONMANAGER_CUSTOMERDATAHANDLER_H_

gha: C++, lang: cpp
// Components
import VFileInput from '../VFileInput'

// Services
import { Lang } from '../../../services/lang'

// Preset
import { preset } from '../../../presets/default'

// Libraries
import {
  Wrapper,
  mount,
  MountOptions,
} from '@vue/test-utils'

const oneMBFile = new File([new ArrayBuffer(1048576)], 'test')
const twoMBFile = new File([new ArrayBuffer(2097152)], 'test')

describe('VFileInput.ts', () => {
  type Instance = InstanceType<typeof VFileInput>
  let mountFunction: (options?: MountOptions<Instance>) => Wrapper<Instance>

  beforeEach(() => {
    mountFunction = (options?: MountOptions<Instance>) => {
      return mount(VFileInput, {
        // https://github.com/vuejs/vue-test-utils/issues/1130
        sync: false,
        mocks: {
          $vuetify: {
            lang: new Lang(preset),
          },
        },
        ...options,
      })
    }
  })

  it('should render', () => {
    const wrapper = mountFunction()

    expect(wrapper.html()).toMatchSnapshot()
  })

  it('should render counter', () => {
    const wrapper = mountFunction({
      propsData: {
        counter: true,
        value: [oneMBFile],
      },
    })

    expect(wrapper.html()).toMatchSnapshot()
  })

  it('should display file size', () => {
    const wrapper = mountFunction({
      propsData: {
        showSize: true,
        value: [twoMBFile],
      },
    })

    expect(wrapper.html()).toMatchSnapshot()

    wrapper.setProps({
      showSize: 1000,
    })

    expect(wrapper.html()).toMatchSnapshot()
  })

  it('should display total size in counter', () => {
    const wrapper = mountFunction({
      propsData: {
        showSize: true,
        counter: true,
        value: [oneMBFile, twoMBFile],
      },
    })

    expect(wrapper.html()).toMatchSnapshot()

    wrapper.setProps({
      showSize: 1000,
    })

    expect(wrapper.html()).toMatchSnapshot()
  })

  it('should be unclearable', () => {
    const wrapper = mountFunction({
      propsData: {
        clearable: false,
      },
    })

    expect(wrapper.html()).toMatchSnapshot()
  })

  it('should work with accept', () => {
    const wrapper = mountFunction({
      propsData: {
        accept: 'image/*',
      },
    })

    expect(wrapper.find('input').element.getAttribute('accept')).toBe('image/*')
  })

  it('should disable file input', () => {
    const wrapper = mountFunction({
      propsData: {
        disabled: true,
      },
    })

    expect(wrapper.find('input').element.getAttribute('disabled')).toBe('disabled')
  })

  it('should proxy icon and text click to input', () => {
    const fn = jest.fn()
    const wrapper = mountFunction()

    const input = wrapper.find('input').element
    input.click = fn

    const icon = wrapper.find('.v-icon')
    icon.trigger('click')
    expect(fn).toHaveBeenCalledTimes(1)

    const text = wrapper.find('.v-file-input__text')
    text.trigger('click')
    expect(fn).toHaveBeenCalledTimes(2)
  })

  it('should clear', () => {
    const wrapper = mountFunction({
      propsData: { value: oneMBFile },
    })

    wrapper.vm.clearableCallback()
    expect(wrapper.vm.internalValue).toBeUndefined()

    const wrapper2 = mountFunction({
      attrs: { multiple: '' },
      propsData: { value: oneMBFile },
    })

    wrapper2.vm.clearableCallback()
    expect(wrapper2.vm.internalValue).toEqual([])
  })

  it('should react to setting fileValue', async () => {
    const wrapper = mountFunction()

    wrapper.setProps({
      value: [oneMBFile],
    })

    await wrapper.vm.$nextTick()

    expect(wrapper.vm.internalValue).toEqual([oneMBFile])
  })

  it('should render chips', () => {
    const wrapper = mountFunction({
      propsData: {
        chips: true,
        value: [oneMBFile],
      },
    })

    expect(wrapper.html()).toMatchSnapshot()
  })

  it('should render small chips', () => {
    const wrapper = mountFunction({
      propsData: {
        smallChips: true,
      },
      data: () => ({
        lazyValue: [oneMBFile],
      }),
    })

    expect(wrapper.html()).toMatchSnapshot()
  })

  // https://github.com/vuetifyjs/vuetify/issues/8049
  it('should render without icon', () => {
    const wrapper = mountFunction({
      propsData: {
        prependIcon: '',
      },
    })

    expect(wrapper.html()).toMatchSnapshot()
  })

  // https://github.com/vuetifyjs/vuetify/issues/8167
  it('should not emit change event when blurred', async () => {
    const change = jest.fn()
    const wrapper = mountFunction({
      listeners: {
        change,
      },
    })

    const input = wrapper.find('input')

    input.trigger('focus')
    await wrapper.vm.$nextTick()

    // TODO: Is there a better way to fake the file change event?
    wrapper.vm.onInput({ target: {} })

    input.trigger('blur')
    await wrapper.vm.$nextTick()

    expect(change).toHaveBeenCalledTimes(1)
  })

  it('should not emit change event when pressing enter', async () => {
    const change = jest.fn()
    const wrapper = mountFunction({
      listeners: {
        change,
      },
    })

    const input = wrapper.find('input')

    input.trigger('keydown.enter')
    await wrapper.vm.$nextTick()

    expect(change).not.toHaveBeenCalled()
  })

  it('should truncate correctly', async () => {
    const fifteenCharFile = new File(['V'.repeat(15)], 'testFile15Chars')
    const wrapper = mountFunction({
      propsData: {
        truncateLength: 1,
        value: fifteenCharFile,
      },
    })

    expect(wrapper.find('.v-file-input__text').text()).toBe('…')

    wrapper.setProps({
      truncateLength: 2,
    })

    await wrapper.vm.$nextTick()

    expect(wrapper.find('.v-file-input__text').text()).toBe('…')

    wrapper.setProps({
      truncateLength: 3,
    })

    await wrapper.vm.$nextTick()

    expect(wrapper.find('.v-file-input__text').text()).toBe('t…s')

    wrapper.setProps({
      truncateLength: 10,
    })

    await wrapper.vm.$nextTick()

    expect(wrapper.find('.v-file-input__text').text()).toBe('test…hars')
  })

  it('should filter internal array values for instanceof File', () => {
    const wrapper = mountFunction()

    const values = [null, undefined, {}, [null], [undefined], [{}]]

    for (const value of values) {
      wrapper.setProps({ value })

      expect(wrapper.vm.internalArrayValue).toEqual([])
    }
  })

  it('should set display none if hide-input prop is set', () => {
    const wrapper = mountFunction({
      propsData: { hideInput: true },
    })

    expect(wrapper.html()).toMatchSnapshot()
  })
})

gha: TypeScript, lang: javascript
import { Injectable } from '@angular/core';
import { HttpClient } from '@angular/common/http';

@Injectable({
  providedIn: 'root'
})
export class MoviedetailsService {

  constructor(private http:HttpClient) { }
public imdb_id:any;
  getDetails(val:any){

    return this.http.get(`https://www.omdbapi.com/?s=${val}&apikey=9e930b0`);
  }
  getfulldetails(){
    this.imdb_id = sessionStorage.getItem('movieId');
    return this.http.get(`https://www.omdbapi.com/?i=${this.imdb_id}&apikey=9e930b0`);
  }
}

gha: TypeScript, lang: javascript
#include <math.h>
int factorial(int input) {
    int output = 1;
    for (int i = 2; i <= input; i++) {
        output *= i;
    }
    return output;
}
float pi(int precision) {
    float sum = 0;
    for (int i = 0; i < precision; i++) {
        sum += factorial(12 * i) * (1090280268 * i + 13591409) / (pow(factorial(2 * i), 3) * factorial(6 * i) * pow(640320, 6 * i + 1) * sqrt(640320)) - factorial(12 * i + 6) * (1090280268 * i + 558731543) / (pow(factorial(2 * i + 1), 3) * factorial(6 * i + 3) * pow(640320, 6 * i + 4) * sqrt(640320));
        /* TOneverDO
         * you might want to use this:
         * sum += pow(-1, i) * factorial(6 * i) * (545140134 * i + 13591409) / (pow(factorial(i), 3) * factorial(3 * i) * pow(640320, 3 * i + 1.5f));
         * instead, trust me, it's worst in every possible way
         */
    }
    return 1 / (12 * sum);
}
float Wallis(int precision) {
    float product = 1, expectation = pi(precision) / 2;
    for (int i = 0; product <= expectation; i++) {
        /*
         * I know, in order to make sure both functions have the same precision
         * I slowed this function by using mine, but considering how slow this
         * is compared to mine I don't think it is really an issue, and by the
         * way, this is an ideal method to do so because `product` is being
         * incremented each iteration...
         */
        product *= pow((2 * (i + 1)), 2);
        product /= (2 * i + 1) * (2 * i + 3);
    }
    return 2 * product;
}
gha: C, lang: cpp
var namespace_t_s_i___multi_client =
[
    [ "TSI_MultiClient", "d3/df8/class_t_s_i___multi_client_1_1_t_s_i___multi_client.html", "d3/df8/class_t_s_i___multi_client_1_1_t_s_i___multi_client" ],
    [ "TSI_MultiClient_Interface", "d5/d03/interface_t_s_i___multi_client_1_1_t_s_i___multi_client___interface.html", "d5/d03/interface_t_s_i___multi_client_1_1_t_s_i___multi_client___interface" ]
];
gha: PHP, lang: makefile
import Vue from 'vue'
import Router from 'vue-router'
import Login from '@/pages/Login.vue'
import Main from '@/pages/Main.vue'
import global_msg from '../global.js'   //注意文件路径，实际路径以项目目录结构为准
Vue.prototype.$global_msg = global_msg;
Vue.use(Router)

export default new Router({
  routes: [
    {
      path: '/home',
      name: 'Main',
      component: Main,
    },
    {
      path: '/',
      name: 'Login',
      component: Login,
    }
  ]
})
gha: Vue, lang: javascript
import { assert } from "chai";
import {BufferToArrayBufferService} from "../services/bufferToArrayBufferService";

describe("bufferToArrayBuffer function", async () => {

  const bufferToArrayBuffer: BufferToArrayBufferService = new BufferToArrayBufferService();
  const buffer: Buffer = new Buffer("");

  it("Should return an array buffer when bufferToArrayBuffer is passed a buffer", () => {
    assert.instanceOf(bufferToArrayBuffer.bufferToArrayBuffer(buffer), ArrayBuffer);
  });
});

gha: TypeScript, lang: javascript
@extends('site.layouts.app')

@section('content')

    <div class="box_color_pages baclite">
        <div class="product_page_list">

            <div class="zm_order_lists">
                <div class="container">
                    <div class="row">

                        @if($request->image && !file_exists($request->image))
                            <div class="image_cover"><img src="{{ url($request->image) }}"></div>
                        @endif

                        <div class="zm_step_box" style="padding: 15px">
                            <h1 class="c-info-page__title">{{ $request->title }}</h1>

                            <div class="c-info-page">{!! $request->content !!}</div>
                        </div>

                    </div>
                </div>
            </div>

        </div>
    </div>

@endsection

gha: JavaScript, lang: php

I&#39;ll tell you a little bit
about irrational behavior.
Not yours, of course -- other people&#39;s.

(Laughter)

So after being at MIT for a few years,
I realized that writing academic papers
is not that exciting.
You know, I don&#39;t know
how many of those you read,
but it&#39;s not fun to read
and often not fun to write --
even worse to write.
So I decided to try and write
something more fun.
And I came up with an idea
that I would write a cookbook.
And the title for my cookbook
was going to be,

&quot;Dining Without Crumbs:
The Art of Eating Over the Sink.&quot;

(Laughter)

And it was going to be a look
at life through the kitchen.
I was quite excited about this.
I was going to talk
a little bit about research,
a little bit about the kitchen.
We do so much in the kitchen,
I thought this would be interesting.
I wrote a couple of chapters,
and took it to MIT Press and they said,
&quot;Cute, but not for us.
Go and find somebody else.&quot;
I tried other people,
and everybody said the same thing,
&quot;Cute. Not for us.&quot;
Until somebody said,
&quot;Look, if you&#39;re serious about this,
you have to write about your research
first; you have to publish something,
then you&#39;ll get the opportunity
to write something else.
If you really want to do it,
you have to do it.&quot;
I said, &quot;I don&#39;t want to write
about my research.
I do it all day long,
I want to write something
a bit more free, less constrained.&quot;
And this person
was very forceful and said,
&quot;Look, that&#39;s the only way
you&#39;ll ever do it.&quot;
So I said, &quot;Okay, if I have to do it --&quot;
I had a sabbatical.
I said, &quot;I&#39;ll write about my research,
if there&#39;s no other way.
And then I&#39;ll get to do my cookbook.&quot;
So, I wrote a book on my research.
And it turned out to be
quite fun in two ways.
First of all, I enjoyed writing.
But the more interesting thing
was that I started learning from people.
It&#39;s a fantastic time to write,
because there&#39;s so much feedback
you can get from people.
People write to me
about their personal experience,
and about their examples,
and where they disagree,
and their nuances.
And even being here --
I mean, the last few days,
I&#39;ve known heights of obsessive behavior
I never thought about.

(Laughter)

Which I think is just fascinating.
I will tell you a little bit
about irrational behavior,
and I want to start by giving you
some examples of visual illusion
as a metaphor for rationality.
So think about these two tables.
And you must have seen this illusion.
If I asked you what&#39;s longer, the vertical
line on the table on the left,
or the horizontal line
on the table on the right,
which one seems longer?
Can anybody see anything
but the left one being longer?
No, right? It&#39;s impossible.
But the nice thing about visual illusion
is we can easily demonstrate mistakes.
So I can put some lines
on; it doesn&#39;t help.
I can animate the lines.
And to the extent you believe
I didn&#39;t shrink the lines,
which I didn&#39;t, I&#39;ve proven to you
that your eyes were deceiving you.
Now, the interesting thing about this
is when I take the lines away,
it&#39;s as if you haven&#39;t learned
anything in the last minute.

(Laughter)

You can&#39;t look at this and say,
&quot;Now I see reality as it is.&quot;
Right? It&#39;s impossible to overcome
this sense that this is indeed longer.
Our intuition is really fooling us
in a repeatable,
predictable, consistent way.
and there is almost nothing
we can do about it,
aside from taking a ruler
and starting to measure it.
Here&#39;s another one.
It&#39;s one of my favorite illusions.
What color is the top arrow pointing to?

Audience: Brown.

Dan Ariely: Brown. Thank you.
The bottom one? Yellow.
Turns out they&#39;re identical.
Can anybody see them as identical?
Very, very hard.
I can cover the rest of the cube up.
If I cover the rest of the cube,
you can see that they are identical.
If you don&#39;t believe me,
you can get the slide later
and do some arts and crafts
and see that they&#39;re identical.
But again, it&#39;s the same story,
that if we take the background away,
the illusion comes back.
There is no way for us not
to see this illusion.
I guess maybe if you&#39;re colorblind,
I don&#39;t think you can see that.
I want you to think
about illusion as a metaphor.
Vision is one of the best things we do.
We have a huge part of our brain
dedicated to vision --
bigger than dedicated to anything else.
We use our vision more hours
of the day than anything else.
We&#39;re evolutionarily
designed to use vision.
And if we have these predictable
repeatable mistakes in vision,
which we&#39;re so good at,
what are the chances we won&#39;t make
even more mistakes
in something we&#39;re not as good at,
for example, financial decision-making.

(Laughter)

Something we don&#39;t have
an evolutionary reason to do,
we don&#39;t have a specialized
part of the brain for,
and we don&#39;t do that many
hours of the day.
The argument is in those cases,
it might be that we actually
make many more mistakes.
And worse -- not having
an easy way to see them,
because in visual illusions, we can
easily demonstrate the mistakes;
in cognitive illusion
it&#39;s much, much harder
to demonstrate the mistakes to people.
So I want to show you
some cognitive illusions,
or decision-making illusions,
in the same way.
And this is one of my favorite
plots in social sciences.
It&#39;s from a paper
by Johnson and Goldstein.
It basically shows the percentage
of people who indicated
they would be interested
in donating their organs.
These are different countries in Europe.

You basically see two types of countries:
countries on the right,
that seem to be giving a lot;
and countries on the left
that seem to giving very little,
or much less.
The question is, why?
Why do some countries give a lot
and some countries give a little?
When you ask people this question,
they usually think that it has
to be about culture.
How much do you care about people?
Giving organs to somebody else
is probably about how much you care
about society, how linked you are.
Or maybe it&#39;s about religion.
But if you look at this plot,
you can see that countries
that we think about as very similar,
actually exhibit very different behavior.
For example, Sweden
is all the way on the right,
and Denmark, which we think
is culturally very similar,
is all the way on the left.
Germany is on the left,
and Austria is on the right.
The Netherlands is on the left,
and Belgium is on the right.
And finally, depending
on your particular version
of European similarity,
you can think about the U.K. and France
as either similar culturally or not,
but it turns out that with organ
donation, they are very different.
By the way, the Netherlands
is an interesting story.
You see, the Netherlands is kind
of the biggest of the small group.
It turns out that they got to 28 percent
after mailing every household
in the country a letter,
begging people to join
this organ donation program.
You know the expression,
&quot;Begging only gets you so far.&quot;
It&#39;s 28 percent in organ donation.

(Laughter)

But whatever the countries
on the right are doing,
they&#39;re doing a much
better job than begging.
So what are they doing?
Turns out the secret has to do
with a form at the DMV.
And here is the story.
The countries on the left
have a form at the DMV
that looks something like this.
&quot;Check the box below if you want to
participate in the organ donor program.&quot;
And what happens?
People don&#39;t check, and they don&#39;t join.
The countries on the right,
the ones that give a lot,
have a slightly different form.
It says, &quot;Check the box below
if you don&#39;t want to participate ...&quot;
Interestingly enough,
when people get this,
they again don&#39;t check, but now they join.

(Laughter)

Now, think about what this means.
You know, we wake up in the morning
and we feel we make decisions.
We wake up in the morning
and we open the closet;
we feel that we decide what to wear.
we open the refrigerator and we feel
that we decide what to eat.
What this is actually saying,
is that many of these decisions
are not residing within us.
They are residing in the person
who is designing that form.
When you walk into the DMV,
the person who designed the form
will have a huge influence
on what you&#39;ll end up doing.
Now, it&#39;s also very hard
to intuit these results.
Think about it for yourself.
How many of you believe
that if you went to renew
your license tomorrow,
and you went to the DMV,
and you encountered one of these forms,
that it would actually
change your own behavior?
Very hard to think
that it would influence us.
We can say, &quot;Oh, these funny Europeans,
of course it would influence them.&quot;
But when it comes to us,
we have such a feeling
that we&#39;re in the driver&#39;s seat,
such a feeling that we&#39;re in control
and we are making the decision,
that it&#39;s very hard
to even accept the idea
that we actually have an illusion
of making a decision,
rather than an actual decision.
Now, you might say,
&quot;These are decisions we don&#39;t care about.&quot;
In fact, by definition,
these are decisions
about something that will happen
to us after we die.
How could we care about something less
than about something
that happens after we die?
So a standard economist,
somebody who believes in rationality,
would say, &quot;You know what?
The cost of lifting the pencil
and marking a &quot;V&quot; is higher
than the possible benefit of the decision,
so that&#39;s why we get this effect.&quot;

(Laughter)

But, in fact, it&#39;s not because it&#39;s easy.
It&#39;s not because it&#39;s trivial.
It&#39;s not because we don&#39;t care.
It&#39;s the opposite. It&#39;s because we care.
It&#39;s difficult and it&#39;s complex.
And it&#39;s so complex
that we don&#39;t know what to do.
And because we have no idea what to do,
we just pick whatever it was
that was chosen for us.
I&#39;ll give you one more example.
This is from a paper
by Redelmeier and Shafir.
And they said, &quot;Would this
effect also happens to experts?
People who are well-paid,
experts in their decisions,
and who make a lot of them?&quot;
And they took a group of physicians.
They presented to them
a case study of a patient.
They said, &quot;Here is a patient.
He is a 67-year-old farmer.
He&#39;s been suffering from
right hip pain for a while.&quot;
And then, they said to the physicians,
&quot;You decided a few weeks ago
that nothing is working for this patient.
All these medications,
nothing seems to be working.
So you refer the patient
for hip replacement therapy.
Hip replacement. Okay?&quot;
So the patient is on a path
to have his hip replaced.
Then they said to half of the physicians,
&quot;Yesterday, you reviewed
the patient&#39;s case,
and you realized that you forgot
to try one medication.
You did not try ibuprofen.
What do you do? Do you pull
the patient back and try ibuprofen?
Or do you let him go
and have hip replacement?&quot;
Well, the good news is
that most physicians in this case
decided to pull the patient
and try ibuprofen.
Very good for the physicians.
To the other group
of physicians, they said,
&quot;Yesterday when you reviewed the case,
you discovered there were two medications
you didn&#39;t try out yet --
ibuprofen and piroxicam.&quot;
You have two medications
you didn&#39;t try out yet.
What do you do? You let him go,
or you pull him back?
And if you pull him back, do you try
ibuprofen or piroxicam? Which one?&quot;

Now, think of it:
This decision makes it as easy to let
the patient continue with hip replacement,
but pulling him back, all of the sudden
it becomes more complex.
There is one more decision.
What happens now?
The majority of the physicians
now choose to let the patient go
for a hip replacement.
I hope this worries you, by the way --

(Laughter)

when you go to see your physician.
The thing is that
no physician would ever say,
&quot;Piroxicam, ibuprofen, hip replacement.
Let&#39;s go for hip replacement.&quot;
But the moment you set this
as the default,
it has a huge power over whatever
people end up doing.
I&#39;ll give you a couple of more examples
on irrational decision-making.

Imagine I give you a choice:
Do you want to go for a weekend to Rome,
all expenses paid --
hotel, transportation, food,
a continental breakfast, everything --
or a weekend in Paris?
Now, weekend in Paris, weekend
in Rome -- these are different things.
They have different food,
different culture, different art.
Imagine I added a choice to the set
that nobody wanted.
Imagine I said, &quot;A weekend in Rome,
a weekend in Paris,
or having your car stolen?&quot;

(Laughter)

It&#39;s a funny idea, because why
would having your car stolen,
in this set, influence anything?

(Laughter)

But what if the option to have your car
stolen was not exactly like this?
What if it was a trip to Rome,
all expenses paid,
transportation, breakfast,
but it doesn&#39;t include
coffee in the morning?
If you want coffee, you have to pay
for it yourself, it&#39;s two euros 50.

(Laughter)

Now in some ways,
given that you can have Rome with coffee,
why would you possibly
want Rome without coffee?
It&#39;s like having your car stolen.
It&#39;s an inferior option.
But guess what happened?
The moment you add Rome without coffee,
Rome with coffee becomes more popular,
and people choose it.
The fact that you have Rome without coffee
makes Rome with coffee look superior,
and not just to Rome without coffee --
even superior to Paris.

(Laughter)

Here are two examples of this principle.
This was an ad in The Economist
a few years ago

that gave us three choices:
an online subscription for 59 dollars,
a print subscription for 125 dollars,
or you could get both for 125.

(Laughter)

Now I looked at this,
and I called up The Economist,
and I tried to figure out
what they were thinking.
And they passed me from one person
to another to another,
until eventually I got to the person
who was in charge of the website,
and I called them up, and they went
to check what was going on.
The next thing I know,
the ad is gone, no explanation.
So I decided to do the experiment
that I would have loved
The Economist to do with me.
I took this and I gave it
to 100 MIT students.
I said, &quot;What would you choose?&quot;
These are the market shares --
most people wanted the combo deal.
Thankfully, nobody wanted
the dominant option.
That means our students can read.

(Laughter)

But now, if you have an option
that nobody wants,
you can take it off, right?
So I printed another version of this,
where I eliminated the middle option.
I gave it to another 100 students.

Here is what happened:
Now the most popular option
became the least popular,
and the least popular
became the most popular.
What was happening
was the option that was useless,
in the middle, was useless
in the sense that nobody wanted it.
But it wasn&#39;t useless in the sense
that it helped people figure out
what they wanted.
In fact, relative
to the option in the middle,
which was get only the print for 125,
the print and web for 125
looked like a fantastic deal.
And as a consequence, people chose it.
The general idea here, by the way,
is that we actually don&#39;t know
our preferences that well.
And because we don&#39;t know
our preferences that well,
we&#39;re susceptible to all of these

influences from the external forces:
the defaults, the particular options
that are presented to us, and so on.
One more example of this.
People believe that when we deal
with physical attraction,
we see somebody, and we know immediately
whether we like them or not,
if we&#39;re attracted or not.
This is why we have
these four-minute dates.
So I decided to do
this experiment with people.
I&#39;ll show you images here, no real people,
but the experiment was with people.
I showed some people a picture
of Tom, and a picture of Jerry.
and I said, &quot;Who do you want to date?
Tom or Jerry?&quot;
But for half the people,
I added an ugly version of Jerry.
I took Photoshop and I made
Jerry slightly less attractive.

(Laughter)

For the other people, I added
an ugly version of Tom.
And the question was,
will ugly Jerry and ugly Tom
help their respective,
more attractive brothers?
The answer was absolutely yes.
When ugly Jerry was around,
Jerry was popular.
When ugly Tom was around, Tom was popular.

(Laughter)

This of course has two
very clear implications
for life in general.
If you ever go bar-hopping,
who do you want to take with you?

(Laughter)

You want a slightly uglier
version of yourself.

(Laughter)

Similar, but slightly uglier.

(Laughter)

The second point, or course, is that
if somebody invites you to bar hop,
you know what they think about you.

(Laughter)

Now you get it.
What is the general point?
The general point is that,
when we think about economics, we have
this beautiful view of human nature.
&quot;What a piece of work is a man!
How noble in reason!&quot;
We have this view of ourselves, of others.
The behavioral economics perspective
is slightly less &quot;generous&quot; to people;
in fact, in medical terms,
that&#39;s our view.

(Laughter)

But there is a silver lining.
The silver lining is, I think,
kind of the reason that behavioral
economics is interesting and exciting.
Are we Superman, or are we Homer Simpson?
When it comes to building
the physical world,
we kind of understand our limitations.
We build steps.
And we build these things
that not everybody can use, obviously.

(Laughter)

We understand our limitations,
and we build around them.
But for some reason, when it comes
to the mental world,
when we design things like healthcare
and retirement and stock markets,
we somehow forget the idea
that we are limited.
I think that if we understood
our cognitive limitations
in the same way we understand
our physical limitations,
even though they don&#39;t stare us
in the face the same way,
we could design a better world,
and that, I think,
is the hope of this thing.
Thank you very much.

(Applause)


gha: Python, lang: markdown
<div class="banner position-relative d-flex align-items-center py-5 p-sm-3" data-target="navbar.banner" style="background-image: linear-gradient(rgba(0,0,0,0.4),rgba(0,0,0,0.4)), url(<%= image_path banner_url %>);">

  <div class="container d-flex justify-content-center flex-column h-100">
    <div class="text-right">
      <h1 class="my-3 col-12 col-sm-12 p-0">Are you driving?</h1>
      <h2 class="my-3 col-12 col-sm-12 p-0">Find passengers to share your travel costs.</h2>
      <%= link_to new_trip_path, class: "btn btn-primary" do %>
        <i class="fas fa-plus-circle"></i> List a new trip
      <% end %>
    </form>
    </div>
  </div>


</div>

gha: Ruby, lang: html
import { ReqorePanel, ReqoreTree, ReqoreVerticalSpacer } from '@qoretechnologies/reqore';
import { size } from 'lodash';
import { ITypeComparatorData } from '../../helpers/functions';
import { useGetInputOutputType } from '../../hooks/useGetInputOutputType';
import Loader from '../Loader';

export interface IInputOutputTypeProps {
  inputProvider?: ITypeComparatorData;
  outputProvider?: ITypeComparatorData;
  compact?: boolean;
}

export const InputOutputType = ({
  inputProvider,
  outputProvider,
  compact,
}: IInputOutputTypeProps) => {
  const { inputType, outputType } = useGetInputOutputType(inputProvider, outputProvider);

  if (compact) {
    return (
      <>
        <ReqoreVerticalSpacer height={10} />
        <ReqorePanel
          label="Input type"
          badge={
            size(inputType)
              ? [inputType.name, { labelKey: 'Fields', label: size(inputType.fields) }]
              : undefined
          }
          size="small"
        >
          {inputType ? !size(inputType) ? 'No input type' : inputType.desc : <Loader size={10} />}
        </ReqorePanel>
        <ReqoreVerticalSpacer height={5} />
        <ReqorePanel
          label="Output type"
          badge={
            size(outputType)
              ? [outputType.name, { labelKey: 'Fields', label: size(outputType.fields) }]
              : undefined
          }
          size="small"
        >
          {outputType ? (
            !size(outputType) ? (
              'No output type'
            ) : (
              outputType.desc
            )
          ) : (
            <Loader size={10} />
          )}
        </ReqorePanel>
      </>
    );
  }

  return (
    <>
      <ReqorePanel
        label="Input type"
        style={{ flex: '1 0' }}
        badge={
          size(inputType)
            ? [inputType.name, { labelKey: 'Fields', label: size(inputType.fields) }]
            : undefined
        }
      >
        {inputType && outputType ? <ReqoreTree data={inputType} size="small" /> : <Loader />}
      </ReqorePanel>
      <ReqoreVerticalSpacer height={10} />
      <ReqorePanel
        label="Output type"
        style={{ flex: '1 0' }}
        badge={
          size(outputType)
            ? [outputType.name, { labelKey: 'Fields', label: size(outputType.fields) }]
            : undefined
        }
      >
        {outputType && inputType ? <ReqoreTree data={outputType} size="small" /> : <Loader />}
      </ReqorePanel>
    </>
  );
};

gha: TypeScript, lang: javascript
# Dziennik

### Wszystko to, czego brakowało w gdyńskim e-dzienniku 😎

### [Dziennik zmian](https://github.com/KarolBarzowski/Dziennik/blob/master/CHANGELOG.md)

gha: JavaScript, lang: markdown
BUD2UTXL ; IHS/CMI/LAB - DISPLAY IND LISTS ;
 ;;9.0;IHS/RPMS UNIFORM DATA SYSTEM;;FEB 02, 2015;Build 42
 ;; ;
EP(BUDTAXI,BUDTAXT) ;EP - CALLED FROM OPTION
 D EN
 Q
EOJ ;EP
 D EN^XBVK("BUD")
 Q
 ;; ;
EN ;EP -- main entry point for 
 D EN^VALM("BUD 12 TAXONOMY EDIT")
 D CLEAR^VALM1
 D FULL^VALM1
 W:$D(IOF) @IOF
 D EOJ
 Q
 ;
HDR ; -- header code
 I BUDTAXT="LAB" S VALMHDR(1)="Updating the "_$P(^ATXLAB(BUDTAXI,0),U)_" taxonomy"
 I BUDTAXT="DRUG" S VALMHDR(1)="Updating the "_$P(^ATXAX(BUDTAXI,0),U)_" taxonomy"
 Q
 ;
INIT ; -- init variables and list array
 K BUDLAB S BUDHIGH="",C=0
 I BUDTAXT="LAB" S BUDX=0 F  S BUDX=$O(^ATXLAB(BUDTAXI,21,BUDX)) Q:BUDX'=+BUDX  D
 .S C=C+1
 .S BUDLABI=$P(^ATXLAB(BUDTAXI,21,BUDX,0),U)
 .S BUDLAB(C,0)=C_")  "_$P($G(^LAB(60,BUDLABI,0)),U)
 .S BUDLAB("IDX",C,C)=BUDLABI
 .Q
 I BUDTAXT="DRUG" S BUDX=0 F  S BUDX=$O(^ATXAX(BUDTAXI,21,BUDX)) Q:BUDX'=+BUDX  D
 .S C=C+1
 .S BUDLABI=$P(^ATXAX(BUDTAXI,21,BUDX,0),U)
 .S BUDLAB(C,0)=C_")  "_$P($G(^PSDRUG(BUDLABI,0)),U)
 .S BUDLAB("IDX",C,C)=BUDLABI
 .Q
 S (VALMCNT,BUDHIGH)=C
 Q
 ;
HELP ; -- help code
 S X="?" D DISP^XQORM1 W !!
 Q
 ;
EXIT ; -- exit code
 Q
 ;
EXPND ; -- expand code
 Q
 ;
BACK ;go back to listman
 D TERM^VALM0
 S VALMBCK="R"
 D INIT
 D HDR
 K DIR
 K X,Y,Z,I
 Q
 ;
REM ;
 W ! K DIR
 I BUDTAXT="LAB" S DIR(0)="NO^1:"_BUDHIGH,DIR("A")="Remove Which Lab test"
 I BUDTAXT="DRUG" S DIR(0)="NO^1:"_BUDHIGH,DIR("A")="Remove Which Drug"
 D ^DIR K DIR S:$D(DUOUT) DIRUT=1
 I Y="" W !,"No lab test selected." G REMX
 I $D(DIRUT) W !,"No lab test selected." G REMX
 S BUDLABI=BUDLAB("IDX",Y,Y)
 ;sure
 I BUDTAXT="LAB" K DIR S DIR(0)="Y",DIR("A")="Are you sure you want to remove the "_$P(^LAB(60,BUDLABI,0),U)_" lab test",DIR("B")="N" KILL DA D ^DIR KILL DIR
 I BUDTAXT="DRUG" K DIR S DIR(0)="Y",DIR("A")="Are you sure you want to remove the "_$P(^PSDRUG(BUDLABI,0),U)_" DRUG",DIR("B")="N" KILL DA D ^DIR KILL DIR
 I 'Y G REM
 I $D(DIRUT) G REMX
 D ^XBFMK
 I BUDTAXT="LAB" S DA(1)=BUDTAXI,DA=$O(^ATXLAB(BUDTAXI,21,"B",BUDLABI,0)),DIE="^ATXLAB("_BUDTAXI_",21,",DR=".01///@" D ^DIE
 I BUDTAXT="DRUG" S DA(1)=BUDTAXI,DA=$O(^ATXAX(BUDTAXI,21,"B",BUDLABI,0)),DIE="^ATXAX("_BUDTAXI_",21,",DR=".01///@" D ^DIE
REMX ;
 D ^XBFMK
 D BACK
 Q
ADD ;EP - add an item to the selected list - called from a protocol
 D FULL^VALM1
 W !
 K DIC
 I BUDTAXT="LAB" S DIC(0)="AEMQ",DIC="^LAB(60,",DIC("A")="Which LAB Test: " D ^DIC
 I BUDTAXT="DRUG" S DIC(0)="AEMQ",DIC="^PSDRUG(",DIC("A")="Which Drug: " D ^DIC
 I Y=-1 G ADDX
 I BUDTAXT="LAB" I $D(^ATXLAB(BUDTAXI,21,"B",+Y)) W !!,"Lab test ",$P(^LAB(60,+Y,0),U)," is already in the taxonomy." H 2 G ADD
 I BUDTAXT="DRUG" I $D(^ATXAX(BUDTAXI,21,"B",+Y)) W !!,"Drug test ",$P(^PSDRUG(+Y,0),U)," is already in the taxonomy." H 2 G ADD
 S DA=BUDTAXI
 S (X,BUDTAXLI)=+Y
 S DA(1)=BUDTAXI
 I BUDTAXT="LAB" S DIC="^ATXLAB("_DA_",21,"
 I BUDTAXT="DRUG" S DIC="^ATXAX("_DA_",21,"
 S DIC(0)="L" K DD,DO
 I BUDTAXT="LAB" S:'$D(^ATXLAB(DA,21,0)) ^ATXLAB(DA,21,0)="^9002228.02101PA"
 I BUDTAXT="DRUG" S:'$D(^ATXAX(DA,21,0)) ^ATXAX(DA,21,0)="^9002226.02101A"
 D FILE^DICN
 I BUDTAXT="LAB" I '$D(^ATXLAB(BUDTAXI,21,"B",BUDTAXLI)) W !!,"adding lab test failed." H 2 G ADD
 I BUDTAXT="DRUG" I '$D(^ATXAX(BUDTAXI,21,"B",BUDTAXLI)) W !!,"adding DRUG failed." H 2 G ADD
ADDX ;
 K DIC,DA,DR,BUDTAXLI,DD,DO
 D BACK
 Q

gha: M, lang: assembly
<% @title = "#{ t "page.user-new-title" }" %>

<h1 class="text-center"><%= @title %></h1>

<div class="container">
  <%= link_to "#{ t "attributes.back" }", users_path, class: 'btn' %>
  <%= form_for(@user) do |f| %>
    <% if @user.errors.any? %>
      <ul>
        <% @user.errors.full_messages.each do |msg| %>
          <li><%= msg %></li>
        <% end %>
      </ul>
    <% end %>
    <div class="row">
      <div class="col-md-6 col-md-offset-3 col-sm-6 col-sm-offset-3">
        <div class="form-group">
          <%= f.label :name %>
          <%= f.text_field :name, class: 'form-control' %>
        </div>
      </div>
    </div>
    <div class="row">
      <div class="col-md-6 col-md-offset-3 col-sm-6 col-sm-offset-3">
        <div class="form-group">
          <%= f.label :password %>
          <%= f.text_field :password, class: 'form-control' %>
        </div>
      </div>
    </div>
    <div class="row">
      <div class="col-md-6 col-md-offset-3 col-sm-6 col-sm-offset-3">
        <div class="form-group">
          <%= f.label :admin %>
          <%= f.select :admin, [['是', true], ['否', false]], {default: false}, class: 'form-control' %>
        </div>
      </div>
    </div>
     <%= f.submit "#{ t "attributes.new" }", class: 'btn btn-primary center-block' %>
  <% end %>
</div>

gha: Ruby, lang: coffeescript
package group.zerry.api_server.dao;

import group.zerry.api_server.entity.Count;
import group.zerry.api_server.entity.PrivateMsg;

public interface PrivateMsgDao {
	/**
	 * @content 用户1和用户2之间的消息总数
	 */
	public Count getMessagesCount(int id1, int id2);
	
	/**
	 * @content 获取所有和用户有过私信交流的id（建立私信列表）
	 */
	public Integer[] selectAllIdTalkedToUser(int id);
	
	/**
	 * @content 用户1与用户2对话的最新消息
	 */
	public PrivateMsg getHotMsg(int id1, int id2);
	
	public PrivateMsg[] getMsg(int id1, int id2);
	
	public void readPrivateMsg(int id1, int id2);
	
	public void insertPrivateMessage(int id1, int id2, String content);
	
}

gha: HTML, lang: java
"""
Utility functions for data-store flask app
"""

import json
import pyarrow as pa
import pandas as pd
from .exceptions import DataStoreException


def filter_json(data, nrow):
    """
    return the first nrow rows of a json object,
    that can be structured as a list of rows [{"colname": val1, ..},...]
    or a dict with keys as column headings and vals as lists of column values
    {"col":[val1,val2,...], ...}
    """
    if isinstance(data, list):
        return json.dumps(data[:nrow])
    elif isinstance(data, dict):
        new_dict = {}
        for k, v in data.items():
            new_dict[k] = v[:nrow]
        return json.dumps(new_dict)
    else:  ## unknown format - just return data as-is
        return data


def filter_arrow(data, nrow):
    """
    Use the 'slice' method of an arrow RecordBatch to return
    the first nrow rows.
    Necessitates conversion between FileBuffer and RecordBatch
    and vice versa.
    """
    reader = pa.ipc.open_file(data)
    record_batch = reader.get_record_batch(0)
    sliced_batch = record_batch.slice(length=nrow)
    sink = pa.BufferOutputStream()
    writer = pa.RecordBatchFileWriter(sink, sliced_batch.schema)
    writer.write_batch(sliced_batch)
    writer.close()
    arrow_buffer = sink.getvalue()
    return arrow_buffer.to_pybytes()


def filter_data(data, nrow):
    """
    return the first nrow rows of data.
    """
    if isinstance(data, bytes):
        try:
            filtered_arrow = filter_arrow(data, nrow)
            return filtered_arrow
        except:
            try:
                data = data.decode("utf-8")
            except(UnicodeDecodeError):
                raise DataStoreError("Bytes data doesn't seem to be arrow or unicode")
    ## see if we can decode as JSON
    if isinstance(data, str):
        try:
            data = json.loads(data)
        except(JSONDecodeError):
            raise DataStoreException("String does not seem to be JSON")
    if isinstance(data, list) or isinstance(data, dict):
        return filter_json(data, nrow)
    elif isinstance(data, pa.lib.Buffer):
        return filter_arrow(data, nrow)
    else: ### unknown format - just return data as-is
        return data


def arrow_to_json(data):
    """
    Convert an arrow FileBuffer into a row-wise json format.
    Go via pandas (To be revisited!!)
    """
    reader = pa.ipc.open_file(data)
    try:
        frame = reader.read_pandas()
        return frame.to_json(orient='records')
    except:
        raise DataStoreException("Unable to convert to JSON")


def json_to_arrow(data):
    """
    Convert a row-wise json object to an arrow FileBuffer.
    Going via pandas (to be revisited!)
    """
    frame = None
    try:
        frame = pd.DataFrame.from_records(data)
    except:
        return data

    batch = pa.RecordBatch.from_pandas(frame, preserve_index=False)
    sink = pa.BufferOutputStream()
    writer = pa.RecordBatchFileWriter(sink, batch.schema)
    writer.write_batch(batch)
    writer.close()
    arrow_buffer = sink.getvalue()
    return arrow_buffer.to_pybytes()


def convert_to_json(data):
    """
    Try to convert a few different formats (bytes, str, arrow)
    into a JSON string
    """
    if (isinstance(data, list) or isinstance(data,dict)):
        return json.dumps(data)
    elif (isinstance(data,str)):
        try:
            json_obj = json.loads(data)
            ## if that worked, it was already a json string
            return data
        except:
            raise DataStoreException("Received string, but not json format")
    elif (isinstance(data, bytes)):
        ## see if it is a json string in bytes format
        try:
            data = json.loads(data.decode('utf-8'))
        except(UnicodeDecodeError):
            try:
                data = arrow_to_json(data)
            except(DataStoreException):
                raise DataStoreException("Receieved 'bytes' data but not Apache Arrow format")
    elif (isinstance(data, pa.lib.Buffer)):
        data = arrow_to_json(data)
    else:
        raise DataStoreException("Unknown data format - cannot convert to JSON")
    return data


def convert_to_arrow(data):
    """
    Try to convert into arrow format if it wasn't already
    """
    if isinstance(data, pa.lib.Buffer):
        return data.to_pybytes()
    elif isinstance(data, bytes):
        try:
            reader = pa.ipc.open_file(data)
            ## if that line worked, must be arrow buffer
            return data
        except(pa.lib.ArrowInvalid):
            try:
                strdata = data.decode("utf-8")
                jsondata = json.loads(strdata)
                return json_to_arrow(jsondata)
            except:
                raise DataStoreException("Unknown bytes data format - cannot convert to Arrow")
    elif (isinstance(data, list) or isinstance(data,dict)):
        return json_to_arrow(data)
    elif (isinstance(data, str)):
        try:
            data = json.loads(data)
            return json_to_arrow(data)
        except:
            raise DataStoreException("Cannot convert string to Arrow")
    else:
        raise DataStoreException("Unknown data format - cannot convert to Arrow")

gha: HTML, lang: python
#include "kernel.h"
#include "errno.h"
#include "globals.h"
#include "limits.h"

#include "vm/vmmap.h"
#include "vm/shadow.h"
#include "vm/anon.h"

#include "proc/proc.h"

#include "util/debug.h"
#include "util/list.h"
#include "util/string.h"
#include "util/printf.h"

#include "fs/vnode.h"
#include "fs/file.h"
#include "fs/fcntl.h"
#include "fs/vfs_syscall.h"

#include "mm/slab.h"
#include "mm/page.h"
#include "mm/mm.h"
#include "mm/mman.h"
#include "mm/mmobj.h"

static slab_allocator_t *vmmap_allocator;
static slab_allocator_t *vmarea_allocator;

void
vmmap_init(void)
{
  vmmap_allocator = slab_allocator_create("vmmap", sizeof(vmmap_t));
  KASSERT(NULL != vmmap_allocator && "failed to create vmmap allocator!");
  vmarea_allocator = slab_allocator_create("vmarea", sizeof(vmarea_t));
  KASSERT(NULL != vmarea_allocator && "failed to create vmarea allocator!");
}

vmarea_t *
vmarea_alloc(void)
{       /* didn't initialize links of list*/
  vmarea_t *newvma = (vmarea_t *) slab_obj_alloc(vmarea_allocator);
  if (newvma) {
    newvma->vma_vmmap = NULL;
  }
  return newvma;
}

void
vmarea_free(vmarea_t *vma)
{
  KASSERT(NULL != vma);
  slab_obj_free(vmarea_allocator, vma);
}

/* Create a new vmmap, which has no vmareas and does
 * not refer to a process. */
vmmap_t *
vmmap_create(void)
{

  vmmap_t* newObj = (vmmap_t *)slab_obj_alloc(vmmap_allocator); /*pankaj*/
  KASSERT(newObj && "could not allocate memory");
  newObj->vmm_proc = NULL;
  list_init(&(newObj->vmm_list));
  return newObj;
}

/* Removes all vmareas from the address space and frees the
 * vmmap struct. */
void
vmmap_destroy(vmmap_t *map)
{


  KASSERT(NULL != map);
  dbg(DBG_ALL, "GRADING3 1.a: vmmap_t map is not NULL \n");

  vmarea_t* iterator =NULL;
  list_iterate_begin( &map->vmm_list, iterator, vmarea_t, vma_plink)
    {
      vmmap_remove(map,iterator->vma_start,iterator->vma_end - iterator->vma_start);
			  
    }list_iterate_end();
		
  slab_obj_free(vmmap_allocator, map);
}

/* Add a vmarea to an address space. Assumes (i.e. asserts to some extent)
 * the vmarea is valid.  This involves finding where to put it in the list
 * of VM areas, and adding it. Don't forget to set the vma_vmmap for the
 * area. */
void
vmmap_insert(vmmap_t *map, vmarea_t *newvma)
{

 vmarea_t* iterator = NULL;

  
  KASSERT(NULL != map && NULL != newvma);
  dbg(DBG_ALL, "GRADING3 1.b: vmmap_t map and  vmarea_t newvma is not NULL \n");


  KASSERT(NULL == newvma->vma_vmmap);
  dbg(DBG_ALL, "GRADING3 1.b: vmarea_t newvma->vma_vmmap is NULL \n");


  KASSERT(newvma->vma_start < newvma->vma_end);/*which means end shouldn't be inclusive*/
  dbg(DBG_ALL, "GRADING3 1.b: vmarea_t newvma->vma_vmastart is less than newvma->vma_end \n");


  KASSERT(ADDR_TO_PN(USER_MEM_LOW) <= newvma->vma_start && ADDR_TO_PN(USER_MEM_HIGH) >= newvma->vma_end);
  dbg(DBG_ALL, "GRADING3 1.b: ADDR_TO_PN(USER_MEM_LOW) is less than or equal to newvma->vma_vmastart and ADDR_TO_PN(USER_MEM_HIGH) is greater than or equal to newvma->vma_end \n");
  


  if(!vmmap_is_range_empty(map, newvma->vma_start, newvma->vma_end - newvma->vma_start))
    return ;
  
   list_iterate_begin(&map->vmm_list, iterator, vmarea_t,vma_plink )
    {
	  if(!( iterator->vma_start < newvma->vma_end))
      	{
	  list_insert_before(&iterator->vma_plink, &newvma->vma_plink);
	  newvma->vma_vmmap = map;
	  return;
      	}
    }list_iterate_end();

  list_insert_tail(&map->vmm_list,&newvma->vma_plink);
  newvma->vma_vmmap = map;        
}

/* Find a contiguous range of free virtual pages of length npages in
 * the given address space. Returns starting vfn for the range,
 * without altering the map. Returns -1 if no such range exists.
 *
 * Your algorithm should be first fit. If dir is VMMAP_DIR_HILO, you
 * should find a gap as high in the address space as possible; if dir
 * is VMMAP_DIR_LOHI, the gap should be as low as possible. */
int
vmmap_find_range(vmmap_t *map, uint32_t npages, int dir)
{


	KASSERT(NULL != map);
	dbg(DBG_ALL, "GRADING3 1.c: vmmap_t map is not NULL \n");


	KASSERT(0 < npages);
	dbg(DBG_ALL, "GRADING3 1.c: uint32_t npages are greater than zero\n");
	vmarea_t* iterator=NULL;
	uint32_t memLowAddr;
	uint32_t memHighAddr ;
	vmarea_t* vmaareaTemp=NULL;
	if(VMMAP_DIR_LOHI != dir)
	{
		vmaareaTemp = NULL;
		memHighAddr = ADDR_TO_PN(USER_MEM_HIGH);
		list_iterate_reverse(&map->vmm_list, vmaareaTemp, vmarea_t, vma_plink)
		{
			if(npages > (memHighAddr - vmaareaTemp->vma_end)  )
			{
				memHighAddr = vmaareaTemp->vma_start;
			}
			else
			{

				return memHighAddr - npages;
			}

		}list_iterate_end();
		if(   ADDR_TO_PN(USER_MEM_LOW) > (memHighAddr- npages ) )
			return -1;
		else

			return memHighAddr - npages;

	}
	else
	{




		memLowAddr = ADDR_TO_PN(USER_MEM_LOW);

		list_iterate_begin(&map->vmm_list, iterator, vmarea_t, vma_plink)
		{
			if( npages > (iterator->vma_start - memLowAddr))
			{
				memLowAddr = iterator->vma_end;
			}
			else
			{

				return memLowAddr;

			}

		}list_iterate_end();

		if(ADDR_TO_PN(USER_MEM_HIGH) < (npages + memLowAddr ))
		{
			return -1;
		}
		else

		{
			return memLowAddr;
		}
	}

}

/* Find the vm_area that vfn lies in. Simply scan the address space
 * looking for a vma whose range covers vfn. If the page is unmapped,
 * return NULL. */
vmarea_t *
vmmap_lookup(vmmap_t *map, uint32_t vfn)
{
  
  
  KASSERT(NULL != map);
  dbg(DBG_ALL, "GRADING3 1.d: vmmap_t map is not NULL \n");

  vmarea_t* iterator = NULL;
  list_iterate_begin(&map->vmm_list, iterator, vmarea_t,vma_plink )
    {
      if(( iterator->vma_start <= vfn)  &&  ( iterator->vma_end  > vfn ) )
	return iterator;
    }list_iterate_end();
  
  return NULL;
}

/* Allocates a new vmmap containing a new vmarea for each area in the
 * given map. The areas should have no mmobjs set yet. Returns pointer
 * to the new vmmap on success, NULL on failure. This function is
 * called when implementing fork(2). */
vmmap_t *
vmmap_clone(vmmap_t *map)
{

  vmmap_t* newMapObj = vmmap_create();

  if(NULL == newMapObj)
    return NULL;
  vmarea_t* iterator=NULL;
  KASSERT(map);		

  list_iterate_begin( &map->vmm_list, iterator, vmarea_t, vma_plink)
    {
      vmarea_t* vma = vmarea_alloc();
      vma->vma_end = iterator->vma_end;
      vma->vma_prot = iterator->vma_prot;
      vma->vma_start = iterator->vma_start;
      vma->vma_obj = NULL;


      vma->vma_off = iterator->vma_off;

      vma->vma_flags = iterator->vma_flags;
      list_link_init(&vma->vma_olink);
      list_link_init(&vma->vma_plink);

      list_insert_tail(&newMapObj->vmm_list, &vma->vma_plink);
      vma->vma_vmmap = newMapObj;
    }list_iterate_end();
				
  return newMapObj;
}

/* Insert a mapping into the map starting at lopage for npages pages.
 * If lopage is zero, we will find a range of virtual addresses in the
 * process that is big enough, by using vmmap_find_range with the same
 * dir argument.  If lopage is non-zero and the specified region
 * contains another mapping that mapping should be unmapped.
 *
 * If file is NULL an anon mmobj will be used to create a mapping
 * of 0's.  If file is non-null that vnode's file will be mapped in
 * for the given range.  Use the vnode's mmap operation to get the
 * mmobj for the file; do not assume it is file->vn_obj. Make sure all
 * of the area's fields except for vma_obj have been set before
 * calling mmap.
 *
 * If MAP_PRIVATE is specified set up a shadow object for the mmobj.
 *
 * All of the input to this function should be valid (KASSERT!).
 * See mmap(2) for for description of legal input.
 * Note that off should be page aligned.
 *
 * Be very careful about the order operations are performed in here. Some
 * operation are impossible to undo and should be saved until there
 * is no chance of failure.
 *
 * If 'new' is non-NULL a pointer to the new vmarea_t should be stored in it.
 */
int
vmmap_map(vmmap_t *map, vnode_t *file, uint32_t lopage, uint32_t npages,
          int prot, int flags, off_t off, int dir, vmarea_t **new)
{
	vmarea_t* vmareaObj = NULL;
	KASSERT(NULL != map);
  dbg(DBG_ALL, "GRADING3 1.f: vmmap_t map is not NULL \n");

 
  KASSERT(0 < npages);
  dbg(DBG_ALL, "GRADING3 1.f: npages is greater than zero \n");

 
  KASSERT(!(~(PROT_NONE | PROT_READ | PROT_WRITE | PROT_EXEC) & prot));
  dbg(DBG_ALL, "GRADING3 1.f: Valid protection flag provided \n");

 
  KASSERT((MAP_SHARED & flags) || (MAP_PRIVATE & flags));
  dbg(DBG_ALL, "GRADING3 1.f: if flags are map shared or private \n");

 
  KASSERT((0 == lopage) || (ADDR_TO_PN(USER_MEM_LOW) <= lopage));
  dbg(DBG_ALL, "GRADING3 1.f: lopage is zero or greater than or equal to USER_MEM_LOW \n");

 
  KASSERT((0 == lopage) || (ADDR_TO_PN(USER_MEM_HIGH) >= (lopage + npages)));
  dbg(DBG_ALL, "GRADING3 1.f: lopage is equal to zero or total no of lopages and npages are less than or equal to USER_MEM_HIGH \n");

 
  KASSERT(PAGE_ALIGNED(off));
  dbg(DBG_ALL, "GRADING3 1.f: PAGE ALIGNED is off \n");
	

  int retVal = 0;
  vmareaObj = vmarea_alloc();
  if(0 != lopage )
    {
	  if(!vmmap_is_range_empty(map, lopage, npages))
	 	{

	 	  vmmap_remove( map, lopage, npages);
	 	  KASSERT(vmmap_is_range_empty(map,lopage,npages));
	 	}
	       vmareaObj->vma_start = lopage;

    }

  else
    {

	  retVal = vmmap_find_range(map, npages, dir);
      if(0 < retVal)
    	  vmareaObj->vma_start = retVal;
      else

      return -ENOMEM;


    }
		
  vmareaObj->vma_end = npages + vmareaObj->vma_start ;
  vmareaObj->vma_flags = flags;
  vmareaObj->vma_prot = prot;
  vmareaObj->vma_off = off;
  list_link_init(&vmareaObj->vma_olink);
  list_link_init(&vmareaObj->vma_plink);


  if(!(MAP_PRIVATE & flags ))
  {

	  if(NULL != file)
	  {
		  file->vn_ops->mmap(file, vmareaObj, &(vmareaObj->vma_obj));
		  list_insert_tail(&(vmareaObj->vma_obj->mmo_un.mmo_vmas),
				  &(vmareaObj->vma_olink));
	  }


  }

  else
  {



	  vmareaObj->vma_obj = shadow_create();


	  	  if(!file)
	  	  {
	  		  vmareaObj->vma_obj->mmo_un.mmo_bottom_obj = anon_create();
	  		  vmareaObj->vma_obj->mmo_shadowed = vmareaObj->vma_obj->mmo_un.mmo_bottom_obj;
	  	  }

	  	  else
	  	  {


	  		  file->vn_ops->mmap(file, vmareaObj, &(vmareaObj->vma_obj->mmo_shadowed));
	  		  vmareaObj->vma_obj->mmo_un.mmo_bottom_obj = vmareaObj->vma_obj->mmo_shadowed;


	  	  }
	  	  list_insert_tail(&(vmareaObj->vma_obj->mmo_shadowed->mmo_un.mmo_vmas),
	  			  &(vmareaObj->vma_olink));


  }
		

  if(NULL != new)
    *new = vmareaObj;

  vmmap_insert(map, vmareaObj);
  return 0;
}

/*
 * We have no guarantee that the region of the address space being
 * unmapped will play nicely with our list of vmareas.
 *
 * You must iterate over each vmarea that is partially or wholly covered
 * by the address range [addr ... addr+len). The vm-area will fall into one
 * of four cases, as illustrated below:
 *
 * key:
 *          [             ]   Existing VM Area
 *        *******             Region to be unmapped
 *
 * Case 1:  [   ******    ]
 * The region to be unmapped lies completely inside the vmarea. We need to
 * split the old vmarea into two vmareas. be sure to increment the
 * reference count to the file associated with the vmarea.
 *
 * Case 2:  [      *******]**
 * The region overlaps the end of the vmarea. Just shorten the length of
 * the mapping.
 *
 * Case 3: *[*****        ]
 * The region overlaps the beginning of the vmarea. Move the beginning of
 * the mapping (remember to update vma_off), and shorten its length.
 *
 * Case 4: *[*************]**
 * The region completely contains the vmarea. Remove the vmarea from the
 * list.
 */
int
vmmap_remove(vmmap_t *map, uint32_t lopage, uint32_t npages)
{



	uint32_t bCount = 0;
	vmarea_t* vmareaObj = NULL;
	uint32_t finishAddr = 0;
	finishAddr = lopage + npages;

	list_iterate_begin(&map->vmm_list, vmareaObj, vmarea_t, vma_plink)
	{
		if((finishAddr < vmareaObj->vma_end) && (lopage > vmareaObj->vma_start))
		{

			vmarea_t* vmareaNew = vmarea_alloc();

			list_link_init(&vmareaNew->vma_plink);
			list_link_init(&vmareaNew->vma_olink);

			vmareaNew->vma_obj = vmareaObj->vma_obj;
			vmareaNew->vma_flags = vmareaObj->vma_flags;
			vmareaNew->vma_prot = vmareaObj->vma_prot;







			vmareaNew->vma_end = vmareaObj->vma_end;
			vmareaNew->vma_start = finishAddr;
			vmareaObj->vma_end = lopage;
			vmareaNew->vma_off = vmareaObj->vma_off + finishAddr - vmareaObj->vma_start;

			vmmap_insert(map,vmareaNew);

			list_insert_tail(mmobj_bottom_vmas(vmareaNew->vma_obj), &vmareaNew->vma_olink);


			if(vmareaObj->vma_obj->mmo_ops->ref != NULL){
				vmareaObj->vma_obj->mmo_ops->ref(vmareaObj->vma_obj);
			}

			bCount =finishAddr + bCount   -lopage;
			pt_unmap_range(curproc->p_pagedir, (uintptr_t)PN_TO_ADDR(lopage), (uintptr_t)PN_TO_ADDR(finishAddr));
			return bCount;
		}
		else if((lopage < vmareaObj->vma_end  ) && lopage > (vmareaObj->vma_start) )
		{

			pt_unmap_range(curproc->p_pagedir, (uintptr_t)PN_TO_ADDR(lopage), (uintptr_t)PN_TO_ADDR(vmareaObj->vma_end));
			vmareaObj->vma_end = lopage;
			bCount =  bCount - lopage + vmareaObj->vma_end;

		}
		else if((finishAddr < vmareaObj->vma_end  ) && (finishAddr > (vmareaObj->vma_start)))
		{

			pt_unmap_range(curproc->p_pagedir, (uintptr_t)PN_TO_ADDR(vmareaObj->vma_start), (uintptr_t)PN_TO_ADDR(finishAddr));
			vmareaObj->vma_off = vmareaObj->vma_off + finishAddr-vmareaObj->vma_start;
			vmareaObj->vma_start = finishAddr;
			bCount = 0 - vmareaObj->vma_start + finishAddr + bCount  ;

			return bCount;
		}
		else if((finishAddr >= vmareaObj->vma_end) && (lopage <= vmareaObj->vma_start)  )
		{

			list_remove(&vmareaObj->vma_olink);
			if(vmareaObj->vma_obj->mmo_ops->put != NULL)
			{
				vmareaObj->vma_obj->mmo_ops->put(vmareaObj->vma_obj);
			}
			list_remove(&vmareaObj->vma_plink);
			pt_unmap_range(curproc->p_pagedir, (uintptr_t)PN_TO_ADDR(vmareaObj->vma_start), (uintptr_t)PN_TO_ADDR(vmareaObj->vma_end));
			vmarea_free(vmareaObj);
			bCount = bCount - vmareaObj->vma_start + vmareaObj->vma_end ;
		}
		else
			continue;

	}list_iterate_end();


	return bCount;
}

/*
 * Returns 1 if the given address space has no mappings for the
 * given range, 0 otherwise.
 */
int
vmmap_is_range_empty(vmmap_t *map, uint32_t startvfn, uint32_t npages)
{
 
	uint32_t vfnMemLow = ADDR_TO_PN(USER_MEM_LOW);

  uint32_t endvfn = startvfn + npages;


  KASSERT((startvfn < endvfn) && (ADDR_TO_PN(USER_MEM_LOW) <= startvfn) && (ADDR_TO_PN(USER_MEM_HIGH) >= endvfn));
  dbg(DBG_ALL, "GRADING3 1.e: startvfn is less than endvfn and USER_MEM_LOW is greater than startvfn and end vfn is less than USER_MEM_HIGH \n");

  vmarea_t* iterator = NULL;
  list_iterate_begin(&map->vmm_list, iterator, vmarea_t, vma_plink)
    {
      if((iterator->vma_start >= endvfn)  && (  vfnMemLow <= startvfn) )
	{
	  return 1;
	}
      else if( (iterator->vma_start > startvfn) && ( iterator->vma_start < endvfn) )
      	{
    	  return 0;
      	}
      else if(vfnMemLow > startvfn)
	{
    	  return 0;
	}

			  
      vfnMemLow = iterator->vma_end;
			  
    }list_iterate_end();

  if( (ADDR_TO_PN(USER_MEM_HIGH) >= endvfn) && (vfnMemLow <= startvfn)  )
    {
	  return 1;
    }
			

  return 0;
}

/* Read into 'buf' from the virtual address space of 'map' starting at
 * 'vaddr' for size 'count'. To do so, you will want to find the vmareas
 * to read from, then find the pframes within those vmareas corresponding
 * to the virtual addresses you want to read, and then read from the
 * physical memory that pframe points to. You should not check permissions
 * of the areas. Assume (KASSERT) that all the areas you are accessing exist.
 * Returns 0 on success, -errno on error.
 */
int
vmmap_read(vmmap_t *map, const void *vaddr, void *buf, size_t count)
{


  uint32_t vfnInitial = ADDR_TO_PN(vaddr);


		
  void* convertedVaddr = (void*)vaddr;
  uint32_t vfnFinal = 1 + ADDR_TO_PN((uint32_t)vaddr + count);
  pframe_t* tempPgFrame = NULL;
  vmarea_t* iterator = NULL;
  uint32_t counter=0;
  uint32_t initialAddr = 0 ;
 	  uint32_t finalAddr = 0;
  	  uint32_t pgofset =0 ;
  list_iterate_begin(&map->vmm_list, iterator, vmarea_t, vma_plink)
    {
      if(iterator->vma_end <= vfnInitial)
	continue;
      else if(iterator->vma_start >= vfnFinal )
	{
	  break;
	}
      else
	{
			  	
	   initialAddr = 0 ;
	   finalAddr = 0;
	  if(iterator->vma_start <= vfnInitial)
		  {
		  initialAddr = vfnInitial;
		  }
	  else
		  {
		  initialAddr = iterator->vma_start;
		  }


	  if(iterator->vma_end > vfnFinal )
		  {
		  finalAddr = vfnFinal;
		  }
	  else
		  {
		  finalAddr = iterator->vma_end;
		  }



	  tempPgFrame = NULL;
	  counter=0;
	  pgofset =0 ;
	  int temp = 0;
	  for(counter= initialAddr; counter < finalAddr;counter++)
	    {

	      pframe_get(iterator->vma_obj, iterator->vma_off + counter - iterator->vma_start , &tempPgFrame);

	      pgofset = ((uint32_t)convertedVaddr)%PAGE_SIZE;
	      convertedVaddr = PN_TO_ADDR(1 + counter);
						  
	      buf = (void *)(temp + (uint32_t)buf );
	      memcpy( buf, (void*)(pgofset + (uint32_t)(tempPgFrame->pf_addr)), MIN((0 -temp + count), (0 - pgofset + PAGE_SIZE)));
	      temp = temp + MIN(0 -temp + count,0 -pgofset + PAGE_SIZE);
	    }
			  	  
	}
    }list_iterate_end();
  return 0;

}

/* Write from 'buf' into the virtual address space of 'map' starting at
 * 'vaddr' for size 'count'. To do this, you will need to find the correct
 * vmareas to write into, then find the correct pframes within those vmareas,
 * and finally write into the physical addresses that those pframes correspond
 * to. You should not check permissions of the areas you use. Assume (KASSERT)
 * that all the areas you are accessing exist. Remember to dirty pages!
 * Returns 0 on success, -errno on error.
 */
int
vmmap_write(vmmap_t *map, void *vaddr, const void *buf, size_t count)
{

	uint32_t vfnInitial = ADDR_TO_PN(vaddr);
	void* tempVaddr = vaddr;
	int temp = 0;
	uint32_t vfnFinal = 1 +  ADDR_TO_PN((uint32_t)vaddr + count);
	pframe_t* tempPgFrame = NULL;
	uint32_t initialAddr = 0 ;
				uint32_t finalAddr = 0 ;
				uint32_t counter=0;
	vmarea_t* iterator = NULL;
	list_iterate_begin(&map->vmm_list, iterator, vmarea_t, vma_plink)
	{
		if(iterator->vma_end <= vfnInitial)
		{
			continue;
		}
		else if(iterator->vma_start >= vfnFinal)
		{
			break;
		}
		else
		{
			initialAddr = 0 ;
			finalAddr = 0 ;

			if(iterator->vma_start <= vfnInitial)
			{
				initialAddr = vfnInitial;
			}
			else
			{

				initialAddr = iterator->vma_start;
			}

			if(iterator->vma_end > vfnFinal )
				{
				finalAddr = vfnFinal;
				}
			else
				{

				finalAddr = iterator->vma_end;
				}



			 counter=0;
			 uint32_t pgOfset = 0;
			 tempPgFrame = NULL;
			for(counter= initialAddr; counter < finalAddr;counter++)
			{

				pframe_get(iterator->vma_obj, (iterator->vma_off - iterator->vma_start + counter ) , &tempPgFrame);

				pgOfset= ((uint32_t)tempVaddr)%PAGE_SIZE;
				tempVaddr = PN_TO_ADDR(1 + counter);

				buf = (void*) (temp + (uint32_t)buf);
				pframe_dirty(tempPgFrame);
				pframe_set_busy(tempPgFrame);

				memcpy( (void*)((uint32_t)(tempPgFrame->pf_addr)+pgOfset),buf, MIN(0-temp + count, (0 -pgOfset + PAGE_SIZE)));
				pframe_clear_busy(tempPgFrame);
				sched_broadcast_on(&tempPgFrame->pf_waitq);
				temp = temp +  MIN(0 -temp + count, 0 -pgOfset + PAGE_SIZE);
			}

		}
	}list_iterate_end();
	return 0;
}

/* a debugging routine: dumps the mappings of the given address space. */
size_t
vmmap_mapping_info(const void *vmmap, char *buf, size_t osize)
{
  KASSERT(0 < osize);
  KASSERT(NULL != buf);
  KASSERT(NULL != vmmap);

  vmmap_t *map = (vmmap_t *)vmmap;
  vmarea_t *vma;
  ssize_t size = (ssize_t)osize;

  int len = snprintf(buf, size, "%21s %5s %7s %8s %10s %12s\n",
		     "VADDR RANGE", "PROT", "FLAGS", "MMOBJ", "OFFSET",
		     "VFN RANGE");
  /*dbg(DBG_CORE,"%21s %5s %7s %8s %10s %12s\n",
    "VADDR RANGE", "PROT", "FLAGS", "MMOBJ", "OFFSET",
    "VFN RANGE");*/

  list_iterate_begin(&map->vmm_list, vma, vmarea_t, vma_plink) {
    size -= len;
    buf += len;
    if (0 >= size) {
      goto end;
    }

    len = snprintf(buf, size,
		   "%#.8x-%#.8x  %c%c%c  %7s 0x%p %#.5x %#.5x-%#.5x\n",
		   vma->vma_start << PAGE_SHIFT,
		   vma->vma_end << PAGE_SHIFT,
		   (vma->vma_prot & PROT_READ ? 'r' : '-'),
		   (vma->vma_prot & PROT_WRITE ? 'w' : '-'),
		   (vma->vma_prot & PROT_EXEC ? 'x' : '-'),
		   (vma->vma_flags & MAP_SHARED ? " SHARED" : "PRIVATE"),
		   vma->vma_obj/*,vma->vma_obj->mmo_un.mmo_bottom_obj*/, vma->vma_off, vma->vma_start, vma->vma_end);
				
    /*dbg(DBG_CORE,"%#.8x-%#.8x  %c%c%c  %7s 0x%p %#.5x %#.5x-%#.5x\n",
      vma->vma_start << PAGE_SHIFT,
      vma->vma_end << PAGE_SHIFT,
      (vma->vma_prot & PROT_READ ? 'r' : '-'),
      (vma->vma_prot & PROT_WRITE ? 'w' : '-'),
      (vma->vma_prot & PROT_EXEC ? 'x' : '-'),
      (vma->vma_flags & MAP_SHARED ? " SHARED" : "PRIVATE"),
      vma->vma_obj, vma->vma_off, vma->vma_start, vma->vma_end);*/
  } list_iterate_end();

 end:
  if (size <= 0) {
    size = osize;
    buf[osize - 1] = '\0';
  }
  /*
    KASSERT(0 <= size);
    if (0 == size) {
    size++;
    buf--;
    buf[0] = '\0';
    }
  */
  return osize - size;
}

gha: C, lang: cpp
import BaseService, { ResourceURI } from "./BaseService";
import { OperatorInfo } from "@/Interface/OperatorInterface";
import Environment from "@/WebApplication/Environment";
import GlobalStoreScheme from "@/Stores/GlobalStoreScheme";

/**
 * 操作员服务
 */
export default class OperatorService extends BaseService {
    /**
     * 获取当前登录操作员
     */
    @ResourceURI(`${Environment.application}-server/operatorInfo/findOperator`)
    public findOperator(url?: string) {
        return this.request
            .post<OperatorInfo>(url)
            .then((response) => response.data)
            .then((operator) => {
                GlobalStoreScheme.operator.change(operator);
                return operator;
            });
    }
}

gha: TypeScript, lang: javascript
var Web3 = require("web3");
var fs = require("fs");
var request = require('request');
var stringify = require('json-stringify-safe');
const url = "http://127.0.0.1:8545"

// Connect to our local node
var web3 = new Web3(new Web3.providers.HttpProvider("http://localhost:8545"));
// NOTE: if you run Kovan node there should be an address you've got in the "Option 2: Run Kovan node" step
web3.eth.defaultAccount = "0x004ec07d2329997267ec62b4166639513386f32e";
// read JSON ABI
var abi = JSON.parse(fs.readFileSync("./calculator/target/json/CalculatorInterface.json"));
// convert Wasm binary to hex format
var codeHex = '0x' + fs.readFileSync("./calculator/target/calculator.wasm").toString('hex');
console.log("code_hex", codeHex);
var TokenContract = new web3.eth.Contract(abi, { data: codeHex, from: web3.eth.defaultAccount });
var TokenDeployTransaction = TokenContract.deploy({ data: codeHex });
var wasm_contract = stringify(TokenDeployTransaction, null, 2)
console.log("wasm_contract", wasm_contract);
// Will create TokenContract with `totalSupply` = 10000000 and print a result
// web3.eth.personal.unlockAccount(web3.eth.defaultAccount, "user").then(() => TokenDeployTransaction.estimateGas()).then(gas => TokenDeployTransaction.send(
//     { gasLimit: 6000000, from: web3.eth.defaultAccount })).then(contract => {
//       console.log("Address of new contract: " + contract.options.address);
//       TokenContract = contract; }).catch(err => console.log(err));


let options = {
  url: "http://127.0.0.1:3030",
  method: "POST",
  headers: { "content-type": "application/json" },
  body: JSON.stringify({ 'jsonrpc': '2.0', 'method': 'eth_sendTransaction', "params": [wasm_contract], 'id': '1' }),
};
request(options, (error, response, body) => {
  if (error) {
    console.error('An error has occurred: ', error);
  } else {
    console.log('Post successful: response: ', body);
  }
});



gha: Rust, lang: javascript
-- This script creates a TCP connection to the target and grabs the TCP banner
-- (basically whatever the target pushes to us after the handshake). This can be
-- used to determine what protocol is run on a particular port and works for
-- protocols like FTP, SMTP, POP3, IMAP, SSH, ...
--
-- Note that on Linux, the kernel will automatically send out a TCP RST packet
-- when the target SYN+ACK is received, ruining everything. It's recommended
-- to use pktzir's --local-addr option to change the source IP address, or in
-- alternative outgoing RST packets can be filtered with iptables like so:
--
--   iptables -A OUTPUT -p tcp --tcp-flags RST RST -j DROP
--
-- Also note that if the remote target doesn't actually send a banner, the
-- connection is left open. The target will, at some point, realize that it's a
-- dead connection anyway, but that may take some time.

local pkt = require("pktizr.pkt")
local std = require("pktizr.std")

-- template packets
local local_addr = std.get_addr()
local local_port = 64434

local pkt_ip4 = pkt.IP()
pkt_ip4.src = local_addr

local pkt_tcp = pkt.TCP()
pkt_tcp.sport = local_port
pkt_tcp.syn   = true

function loop(addr, port)
    pkt_ip4.dst = addr

    pkt_tcp.dport = port
    pkt_tcp.seq   = pkt.cookie32(local_addr, addr, local_port, port)

    return pkt_ip4, pkt_tcp
end

function recv(pkts)
    local pkt_ip4 = pkts[1]
    local pkt_tcp = pkts[2]
    local pkt_raw = pkts[3]

    if #pkts < 3 or pkt_tcp._type ~= 'tcp' or pkt_raw._type ~= 'raw' then
        return
    end

    local src = pkt_ip4.src
    local dst = pkt_ip4.dst

    local sport = pkt_tcp.sport
    local dport = pkt_tcp.dport

    local seq = pkt.cookie32(dst, src, dport, sport)

    if pkt_tcp.ack_seq - 1 ~= seq then
        return
    end

    pkt_ip4.src = dst
    pkt_ip4.dst = src

    pkt_tcp.sport = dport
    pkt_tcp.dport = sport
    pkt_tcp.doff  = 5

    if pkt_tcp.syn and pkt_tcp.ack then
        pkt_tcp.syn     = false
        pkt_tcp.psh     = false
        pkt_tcp.ack     = true
        pkt_tcp.ack_seq = pkt_tcp.seq + 1
        pkt_tcp.seq     = seq + 1

        pkt.send(pkt_ip4, pkt_tcp)
        return
    end

    if pkt_tcp.psh then
        local fmt = "Banner from %s.%u: %s"
        std.print(fmt, src, sport, string.sub(pkt_raw.payload, 1, -2))

        pkt_tcp.syn     = false
        pkt_tcp.psh     = false
        pkt_tcp.ack     = false
        pkt_tcp.rst     = true
        pkt_tcp.seq     = pkt_tcp.ack_seq
        pkt_tcp.ack_seq = 0

        pkt.send(pkt_ip4, pkt_tcp)
        return true
    end

    return false
end

gha: C, lang: lua
//---------------------------------------------------------------------------//
//!
//! \file   MonteCarlo_PositronatomNativeFactory_def.hpp
//! \author Luke Kersting
//! \brief  The positron-atom native factory class template definition.
//!
//---------------------------------------------------------------------------//

#ifndef MONTE_CARLO_POSITRONATOM_NATIVE_FACTORY_DEF_HPP
#define MONTE_CARLO_POSITRONATOM_NATIVE_FACTORY_DEF_HPP

// FRENSIE Includes
#include "MonteCarlo_PositronatomNativeFactory.hpp"
#include "MonteCarlo_PositronatomicReactionNativeFactory.hpp"
#include "Utility_StandardHashBasedGridSearcher.hpp"
#include "Utility_TwoDInterpolationPolicy.hpp"
#include "Utility_Vector.hpp"
#include "Utility_DesignByContract.hpp"

namespace MonteCarlo{

// Create a positron-atom core (using the provided atomic relaxation model)
/*! \details The provided atomic relaxation model will be used with this
 * core. Special care must be taken to assure that the model corresponds to
 * the atom of interest. If the use of atomic relaxation data has been
 * requested, a electroionization reaction for each subshell will be created.
 * Otherwise a single total electroionization reaction will be created.
 */
template <typename TwoDInterpPolicy,template<typename> class TwoDGridPolicy>
void PositronatomNativeFactory::createPositronatomCore(
   const Data::ElectronPhotonRelaxationDataContainer& raw_positronatom_data,
   const std::shared_ptr<const AtomicRelaxationModel>& atomic_relaxation_model,
   const SimulationElectronProperties& properties,
   std::shared_ptr<const PositronatomCore>& positronatom_core )
{
  // Make sure the atomic relaxation model is valid
  testPrecondition( atomic_relaxation_model.get() );

  positronatom_core.reset( new PositronatomCore() );

  Positronatom::ConstReactionMap scattering_reactions, absorption_reactions;

  // Extract the common energy grid used for this atom
  std::shared_ptr<const std::vector<double> > energy_grid(
    new std::vector<double>( raw_positronatom_data.getElectronEnergyGrid().begin(),
                             raw_positronatom_data.getElectronEnergyGrid().end() ) );

  // Construct the hash-based grid searcher for this atom
  std::shared_ptr<const Utility::HashBasedGridSearcher<double>> grid_searcher(
       new Utility::StandardHashBasedGridSearcher<std::vector<double>, false>(
                              energy_grid,
                              properties.getNumberOfElectronHashGridBins() ) );

// Create the elastic scattering reaction
  if ( properties.isElasticModeOn() )
  {
    if( TwoDGridPolicy<TwoDInterpPolicy>::name() == "Unit-base" || TwoDGridPolicy<TwoDInterpPolicy>::name() == "Direct" )
    {
      if( TwoDInterpPolicy::name() == "LogLogLog" )
      {
        if( properties.getElasticElectronDistributionMode() == COUPLED_DISTRIBUTION &&
            properties.getCoupledElasticSamplingMode() == MODIFIED_TWO_D_UNION )
        {
          THROW_EXCEPTION( std::runtime_error, "the bivariate grid policy "
                       << TwoDGridPolicy<TwoDInterpPolicy>::name() << " is not currently supported "
                       << "with a " << properties.getCoupledElasticSamplingMode()
                       << " coupled elastic sampling mode!" );
        }
        else
        {
          if( properties.getElasticElectronDistributionMode() == COUPLED_DISTRIBUTION ||
              ( properties.getElasticElectronDistributionMode() == HYBRID_DISTRIBUTION &&
                properties.getElasticCutoffAngleCosine() < 1.0 ) )
          {
            ThisType::createElasticPositronatomCore<Utility::LogNudgedLogCosLog,Utility::Direct>(
                                                  raw_positronatom_data,
                                                  energy_grid,
                                                  grid_searcher,
                                                  properties,
                                                  scattering_reactions );
          }
          else
          {
            ThisType::createElasticPositronatomCore<Utility::LogLogCosLog,Utility::Direct>(
                                                  raw_positronatom_data,
                                                  energy_grid,
                                                  grid_searcher,
                                                  properties,
                                                  scattering_reactions );
          }
        }
      }
      else
      {
        ThisType::createElasticPositronatomCore<TwoDInterpPolicy,Utility::Direct>(
                                                raw_positronatom_data,
                                                energy_grid,
                                                grid_searcher,
                                                properties,
                                                scattering_reactions );
      }
    }
    else if( TwoDGridPolicy<TwoDInterpPolicy>::name() == "Unit-base Correlated" || TwoDGridPolicy<TwoDInterpPolicy>::name() == "Correlated" )
    {
      if( TwoDInterpPolicy::name() == "LogLogLog" )
      {
        if( properties.getElasticElectronDistributionMode() == COUPLED_DISTRIBUTION ||
            ( properties.getElasticElectronDistributionMode() == HYBRID_DISTRIBUTION &&
              properties.getElasticCutoffAngleCosine() < 1.0 ) )
        {
          ThisType::createElasticPositronatomCore<Utility::LogNudgedLogCosLog,Utility::Correlated>(
                                                  raw_positronatom_data,
                                                  energy_grid,
                                                  grid_searcher,
                                                  properties,
                                                  scattering_reactions );
        }
        else
        {
          ThisType::createElasticPositronatomCore<Utility::LogLogCosLog,Utility::Correlated>(
                                                  raw_positronatom_data,
                                                  energy_grid,
                                                  grid_searcher,
                                                  properties,
                                                  scattering_reactions );
        }
      }
      else
      {
        ThisType::createElasticPositronatomCore<TwoDInterpPolicy,Utility::Correlated>(
                                                raw_positronatom_data,
                                                energy_grid,
                                                grid_searcher,
                                                properties,
                                                scattering_reactions );
      }
    }
    else
    {
      THROW_EXCEPTION( std::runtime_error, "Error: the bivariate grid policy "
                       << TwoDGridPolicy<TwoDInterpPolicy>::name() << " is not currently supported!" );
    }
  }

  // Create the bremsstrahlung scattering reaction
  if ( properties.isBremsstrahlungModeOn() )
  {
    Positronatom::ConstReactionMap::mapped_type& reaction_pointer =
      scattering_reactions[BREMSSTRAHLUNG_POSITRONATOMIC_REACTION];

    PositronatomicReactionNativeFactory::createBremsstrahlungReaction<TwoDInterpPolicy,TwoDGridPolicy>(
                  raw_positronatom_data,
                  energy_grid,
                  grid_searcher,
                  reaction_pointer,
                  properties.getBremsstrahlungAngularDistributionFunction(),
                  properties.getElectronEvaluationTolerance() );
  }

  // Create the atomic excitation scattering reaction
  if ( properties.isAtomicExcitationModeOn() )
  {
    Positronatom::ConstReactionMap::mapped_type& reaction_pointer =
      scattering_reactions[ATOMIC_EXCITATION_POSITRONATOMIC_REACTION];

    PositronatomicReactionNativeFactory::createAtomicExcitationReaction(
                  raw_positronatom_data,
                  energy_grid,
                  grid_searcher,
                  reaction_pointer );
  }

  // Create the subshell electroionization reactions
  if ( properties.isElectroionizationModeOn() )
  {
    std::vector<std::shared_ptr<const PositronatomicReaction> > reaction_pointers;

    PositronatomicReactionNativeFactory::createSubshellPositronionizationReactions<TwoDInterpPolicy,TwoDGridPolicy>(
                      raw_positronatom_data,
                      energy_grid,
                      grid_searcher,
                      reaction_pointers,
                      properties.getElectroionizationSamplingMode(),
                      properties.getElectronEvaluationTolerance() );

    for( unsigned i = 0; i < reaction_pointers.size(); ++i )
    {
      scattering_reactions[reaction_pointers[i]->getReactionType()] =
        reaction_pointers[i];
    }
  }

  // Create the positron-atom core
  positronatom_core.reset( new PositronatomCore( energy_grid,
                                               grid_searcher,
                                               scattering_reactions,
                                               absorption_reactions,
                                               atomic_relaxation_model,
                                               false,
                                               Utility::LogLog() ) );
}

// Create the elastic reaction for a positron-atom core
template <typename TwoDInterpPolicy,template<typename> class TwoDGridPolicy>
void PositronatomNativeFactory::createElasticPositronatomCore(
      const Data::ElectronPhotonRelaxationDataContainer& raw_positronatom_data,
      const std::shared_ptr<const std::vector<double> >& energy_grid,
      const std::shared_ptr<const Utility::HashBasedGridSearcher<double>>& grid_searcher,
      const SimulationElectronProperties& properties,
      Positronatom::ConstReactionMap& scattering_reactions )
{
  // Get the elastic distribution type
  ElasticElectronDistributionType distribution_type =
                            properties.getElasticElectronDistributionMode();

  if( distribution_type == COUPLED_DISTRIBUTION )
  {
    Positronatom::ConstReactionMap::mapped_type& reaction_pointer =
      scattering_reactions[COUPLED_ELASTIC_POSITRONATOMIC_REACTION];

    PositronatomicReactionNativeFactory::createCoupledElasticReaction<TwoDInterpPolicy,TwoDGridPolicy>(
                        raw_positronatom_data,
                        energy_grid,
                        grid_searcher,
                        reaction_pointer,
                        properties.getCoupledElasticSamplingMode(),
                        properties.getElectronEvaluationTolerance() );
  }
  else if( distribution_type == DECOUPLED_DISTRIBUTION )
  {
    Positronatom::ConstReactionMap::mapped_type& reaction_pointer =
      scattering_reactions[DECOUPLED_ELASTIC_POSITRONATOMIC_REACTION];

    PositronatomicReactionNativeFactory::createDecoupledElasticReaction<TwoDInterpPolicy,TwoDGridPolicy>(
                        raw_positronatom_data,
                        energy_grid,
                        grid_searcher,
                        reaction_pointer,
                        properties.getElectronEvaluationTolerance() );
  }
  else if( distribution_type == HYBRID_DISTRIBUTION )
  {
    // Create the coupled elastic scattering reaction (no moment preserving elastic scattering)
    if ( properties.getElasticCutoffAngleCosine() == 1.0 )
    {
      Positronatom::ConstReactionMap::mapped_type& reaction_pointer =
        scattering_reactions[DECOUPLED_ELASTIC_POSITRONATOMIC_REACTION];

      PositronatomicReactionNativeFactory::createDecoupledElasticReaction<TwoDInterpPolicy,TwoDGridPolicy>(
                        raw_positronatom_data,
                        energy_grid,
                        grid_searcher,
                        reaction_pointer,
                        properties.getElectronEvaluationTolerance() );
    }
    // Create the moment preserving elastic scattering reaction (no coupled elastic scattering)
    else if ( properties.getElasticCutoffAngleCosine() == -1.0 )
    {
      Positronatom::ConstReactionMap::mapped_type& reaction_pointer =
        scattering_reactions[MOMENT_PRESERVING_ELASTIC_POSITRONATOMIC_REACTION];

      PositronatomicReactionNativeFactory::createMomentPreservingElasticReaction<TwoDInterpPolicy,TwoDGridPolicy>(
                        raw_positronatom_data,
                        energy_grid,
                        grid_searcher,
                        reaction_pointer,
                        properties.getElasticCutoffAngleCosine(),
                        properties.getElectronEvaluationTolerance() );
    }
    // Create the hybrid elastic scattering reaction (if cutoff is within range)
    else
    {
      Positronatom::ConstReactionMap::mapped_type& reaction_pointer =
        scattering_reactions[HYBRID_ELASTIC_POSITRONATOMIC_REACTION];

      PositronatomicReactionNativeFactory::createHybridElasticReaction<TwoDInterpPolicy,TwoDGridPolicy>(
                        raw_positronatom_data,
                        energy_grid,
                        grid_searcher,
                        reaction_pointer,
                        properties.getElasticCutoffAngleCosine(),
                        properties.getElectronEvaluationTolerance() );
    }
  }
  else if( distribution_type == CUTOFF_DISTRIBUTION )
  {
    Positronatom::ConstReactionMap::mapped_type& reaction_pointer =
      scattering_reactions[CUTOFF_ELASTIC_POSITRONATOMIC_REACTION];

    PositronatomicReactionNativeFactory::createCutoffElasticReaction<TwoDInterpPolicy,TwoDGridPolicy>(
                        raw_positronatom_data,
                        energy_grid,
                        grid_searcher,
                        reaction_pointer,
                        properties.getElasticCutoffAngleCosine(),
                        properties.getElectronEvaluationTolerance() );
  }
  else
  {
    THROW_EXCEPTION( std::runtime_error,
                     "elastic distribution type "
                     << distribution_type <<
                     " is not currently supported!" );
  }
}

} // end MonteCarlo namespace

#endif // end MONTE_CARLO_POSITRONATOM_NATIVE_FACTORY_DEF_HPP

//---------------------------------------------------------------------------//
// end MonteCarlo_PositronatomNativeFactory_def.hpp
//---------------------------------------------------------------------------//

gha: C++, lang: cpp
/* -*- c-file-style:"stroustrup"; indent-tabs-mode: nil -*- */
#if !defined INC_PUBNUB_PARSE_IPV4_ADDR
#define INC_PUBNUB_PARSE_IPV4_ADDR
#include "core/pubnub_dns_servers.h"

/** Parses Ipv4 address string @p addr and, in case it succeeds, resolved value stores at @p p.
    @retval -1 on error
    @retval 0 on success
  */
int pubnub_parse_ipv4_addr(char const* addr, struct pubnub_ipv4_address* p);

#endif

gha: C, lang: assembly
﻿using DbFramework.DbCommands;
using DbFramework.Interfaces;

namespace SampleImplementation.TextCommands
{
	public class GetCitiesTextCommand : DbTextCommand, IManyResultsCommand<string>
    {
		private readonly long _communityId;

		public GetCitiesTextCommand(long communityId)
		{
			_communityId = communityId;
		}

		protected override string GetSqlString()
		{
			return @"
				SELECT [Name]
				FROM [dbo].[cities]
				WHERE Community_Id = @id";
		}

		protected override IDbParameters MapParameters()
		{
			return base.MapParameters()
				.Add("@id", _communityId);
		}

	    public string MapResult(IDbReader reader)
	    {
	        return reader.GetString("Name");
        }
	}
}

gha: C#, lang: c_sharp
﻿using System;
using System.Collections.Generic;
using System.Linq;
using System.Web;
using System.Data.SqlClient;
using SkyServer.Tools.Search;
using System.Data;

namespace SkyServer.Get
{
    /// <summary>
    /// Summary description for SpecByPF
    /// </summary>
    public class SpecByPF : IHttpHandler
    {

        public void ProcessRequest(HttpContext context)
        {
            context.Response.ContentType = "image/gif";
            Globals globals = (Globals)context.Application[Globals.PROPERTY_NAME];
            long? plateid = null;
            short? fiberid = null; 
            try
            {
                plateid = long.Parse(context.Request.QueryString["P"]);
                fiberid = short.Parse(context.Request.QueryString["F"]);
            }
            catch {  }

            ResponseREST rs = new ResponseREST();
            string URIparams = "?plateId=" + plateid.ToString() + "&fiber=" + fiberid.ToString() + "&query=SpecByPF&TaskName=Skyserver.SpecByPF";
            DataSet ds = rs.GetObjectInfoFromWebService(globals.ExploreWS, URIparams);

            using (DataTableReader reader = ds.Tables[0].CreateDataReader())
            {
                if (!reader.HasRows)
                {
                    context.Response.Redirect("noimage2.gif");
                }
                else
                {
                    reader.Read();
                    context.Response.BinaryWrite((byte[])reader.GetValue(0));
                }
            }
        }

        public bool IsReusable
        {
            get
            {
                return false;
            }
        }
    }
}
gha: ASP.NET, lang: c_sharp
#!/bin/bash
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=8
#SBATCH --time=96:00:00
#SBATCH --mem=64GB
#SBATCH --job-name=gridVOC
#SBATCH --gres=gpu:1
#SBATCH --mail-type=END
#SBATCH --mail-user=<netid>@nyu.edu
#SBATCH --output=<your log path>/batch-%j.log

RUNDIR=$HOME/translation/
cd $RUNDIR

export PATH="/home/xl2053/miniconda3/bin:$PATH"
. /home/xl2053/miniconda3/etc/profile.d/conda.sh
conda activate
conda activate nlpclass


for DROP in 0.0 0.1
do
    python grid_DROPOUT.py -c user_<netid> -m <your model> -d $DROP
done

gha: Jupyter Notebook, lang: shell
-- ========================================================
-- from VHDL producer:

-- Module ID: 3

-- Name of L1 Trigger Menu:
-- L1Menu_Collisions2023_v1_0_0

-- Unique ID of L1 Trigger Menu:
-- a15805e0-bc49-46d4-a2a2-b8ea093e069a

-- Unique ID of firmware implementation:
-- 7a1a9c0b-5e34-4c25-804f-2ae8094c4832

-- Scale set:
-- scales_2023_02_16

-- VHDL producer version
-- v2.14.0

-- tmEventSetup version
-- v0.11.2

-- HB 2016-09-16: constants for algo_mapping_rop.
type global_index_array is array (0 to NR_ALGOS-1) of integer;
constant global_index: global_index_array := (
        364, -- module_index: 0, name: L1_DoubleJet35_Mass_Min450_IsoTau45_RmOvlp
        258, -- module_index: 1, name: L1_LooseIsoEG24er2p1_IsoTau27er2p1_dR_Min0p3
        351, -- module_index: 2, name: L1_DoubleJet30er2p5_Mass_Min250_dEta_Max1p5
        274, -- module_index: 3, name: L1_DoubleIsoTau28er2p1_Mass_Max80
        356, -- module_index: 4, name: L1_DoubleJet_100_30_DoubleJet30_Mass_Min620
        355, -- module_index: 5, name: L1_DoubleJet_90_30_DoubleJet30_Mass_Min620
        137, -- module_index: 6, name: L1_Mu10er2p3_Jet32er2p3_dR_Max0p4_DoubleJet32er2p3_dEta_Max1p6
        123, -- module_index: 7, name: L1_DoubleJet16er2p5_Mu3_dR_Max0p4
        126, -- module_index: 8, name: L1_DoubleJet60er2p5_Mu3_dR_Max0p4
        125, -- module_index: 9, name: L1_Mu3_Jet60er2p5_dR_Max0p4
        213, -- module_index: 10, name: L1_DoubleEG10p5_er1p2_dR_Max0p6
        206, -- module_index: 11, name: L1_DoubleEG7_er1p2_dR_Max0p8
        211, -- module_index: 12, name: L1_DoubleEG9p5_er1p2_dR_Max0p6
         96, -- module_index: 13, name: L1_TripleMu_5SQ_3SQ_0OQ_DoubleMu_5_3_SQ_OS_Mass_Max9
         86, -- module_index: 14, name: L1_TripleMu_5SQ_3SQ_0OQ
         97, -- module_index: 15, name: L1_TripleMu_5SQ_3SQ_0_DoubleMu_5_3_SQ_OS_Mass_Max9
         54, -- module_index: 16, name: L1_DoubleMu0er2p0_SQ_dR_Max1p4
         53, -- module_index: 17, name: L1_DoubleMu0_Upt15_Upt7
        345, -- module_index: 18, name: L1_DoubleJet100er2p3_dEta_Max1p6
         67, -- module_index: 19, name: L1_DoubleMu0er1p4_OQ_OS_dEta_Max1p6
         64, -- module_index: 20, name: L1_DoubleMu0er1p5_SQ_OS_dEta_Max1p2
         58, -- module_index: 21, name: L1_DoubleMu0er2p0_SQ_OS_dEta_Max1p6
         56, -- module_index: 22, name: L1_DoubleMu0er2p0_SQ_dEta_Max1p6
        374, -- module_index: 23, name: L1_TripleJet_105_85_75_DoubleJet_85_75_er2p5
        232, -- module_index: 24, name: L1_TripleEG_16_12_8_er2p5
        234, -- module_index: 25, name: L1_TripleEG_18_17_8_er2p5
        225, -- module_index: 26, name: L1_DoubleEG_LooseIso16_LooseIso12_er1p5
        227, -- module_index: 27, name: L1_DoubleEG_LooseIso20_LooseIso12_er1p5
        268, -- module_index: 28, name: L1_DoubleIsoTau30er2p1
        272, -- module_index: 29, name: L1_DoubleIsoTau36er2p1
        177, -- module_index: 30, name: L1_SingleLooseIsoEG28_FWD2p5
        223, -- module_index: 31, name: L1_DoubleEG_LooseIso22_12_er2p5
        216, -- module_index: 32, name: L1_DoubleEG_20_10_er2p5
        219, -- module_index: 33, name: L1_DoubleEG_25_14_er2p5
        266, -- module_index: 34, name: L1_DoubleTau70er2p1
        320, -- module_index: 35, name: L1_SingleJet35_FWD2p5
        116, -- module_index: 36, name: L1_DoubleMu4_SQ_EG9er2p5
        117, -- module_index: 37, name: L1_DoubleMu5_SQ_EG9er2p5
         60, -- module_index: 38, name: L1_DoubleMu0er1p5_SQ
        330, -- module_index: 39, name: L1_SingleJet12erHE
        121, -- module_index: 40, name: L1_Mu3_Jet30er2p5
         12, -- module_index: 41, name: L1_SingleMu3
         79, -- module_index: 42, name: L1_TripleMu0_OQ
         83, -- module_index: 43, name: L1_TripleMu3_SQ
         89, -- module_index: 44, name: L1_TripleMu_5_3_3_SQ
        187, -- module_index: 45, name: L1_SingleIsoEG26er1p5
        190, -- module_index: 46, name: L1_SingleIsoEG28er2p1
        194, -- module_index: 47, name: L1_SingleIsoEG32er2p5
        178, -- module_index: 48, name: L1_SingleLooseIsoEG28er2p5
         18, -- module_index: 49, name: L1_SingleMu12_DQ_EMTF
        161, -- module_index: 50, name: L1_SingleEG15er2p5
        168, -- module_index: 51, name: L1_SingleEG36er2p5
        315, -- module_index: 52, name: L1_SingleJet120er2p5
        263, -- module_index: 53, name: L1_SingleTau120er2p1
         38, -- module_index: 54, name: L1_DoubleMu0_OQ
         48, -- module_index: 55, name: L1_DoubleMu_15_7_SQ
         36, -- module_index: 56, name: L1_SingleMu16er1p5
         32, -- module_index: 57, name: L1_SingleMu9er1p5
        173, -- module_index: 58, name: L1_SingleEG50
        310, -- module_index: 59, name: L1_SingleJet200
         20, -- module_index: 60, name: L1_SingleMu18
          0, -- module_index: 61, name: L1_SingleMuCosmics
        411, -- module_index: 62, name: L1_ETT1600
        486, -- module_index: 63, name: L1_BPTX_AND_Ref1_VME
        490, -- module_index: 64, name: L1_BPTX_BeamGas_Ref2_VME
        480, -- module_index: 65, name: L1_FirstCollisionInOrbit
        101, -- module_index: 66, name: L1_SingleMuShower_Nominal
        506, -- module_index: 67, name: L1_TOTEM_4
    others => 0
);

-- ========================================================
gha: HTML, lang: yaml
/*-------------------------------------------------------------------------
 *
 * globals.c
 *	  global variable declarations
 *
 * Portions Copyright (c) 1996-2023, PostgreSQL Global Development Group
 * Portions Copyright (c) 1994, Regents of the University of California
 *
 *
 * IDENTIFICATION
 *	  src/backend/utils/init/globals.c
 *
 * NOTES
 *	  Globals used all over the place should be declared here and not
 *	  in other modules.
 *
 *-------------------------------------------------------------------------
 */
#include "postgres.h"

#include "common/file_perm.h"
#include "libpq/libpq-be.h"
#include "libpq/pqcomm.h"
#include "miscadmin.h"
#include "storage/backendid.h"


ProtocolVersion FrontendProtocol;

volatile sig_atomic_t InterruptPending = false;
volatile sig_atomic_t QueryCancelPending = false;
volatile sig_atomic_t ProcDiePending = false;
volatile sig_atomic_t CheckClientConnectionPending = false;
volatile sig_atomic_t ClientConnectionLost = false;
volatile sig_atomic_t IdleInTransactionSessionTimeoutPending = false;
volatile sig_atomic_t IdleSessionTimeoutPending = false;
volatile sig_atomic_t ProcSignalBarrierPending = false;
volatile sig_atomic_t LogMemoryContextPending = false;
volatile sig_atomic_t IdleStatsUpdateTimeoutPending = false;
volatile uint32 InterruptHoldoffCount = 0;
volatile uint32 QueryCancelHoldoffCount = 0;
volatile uint32 CritSectionCount = 0;

int			MyProcPid;
pg_time_t	MyStartTime;
TimestampTz MyStartTimestamp;
struct Port *MyProcPort;
int32		MyCancelKey;
int			MyPMChildSlot;

/*
 * MyLatch points to the latch that should be used for signal handling by the
 * current process. It will either point to a process local latch if the
 * current process does not have a PGPROC entry in that moment, or to
 * PGPROC->procLatch if it has. Thus it can always be used in signal handlers,
 * without checking for its existence.
 */
struct Latch *MyLatch;

/*
 * DataDir is the absolute path to the top level of the PGDATA directory tree.
 * Except during early startup, this is also the server's working directory;
 * most code therefore can simply use relative paths and not reference DataDir
 * explicitly.
 */
char	   *DataDir = NULL;

/*
 * Mode of the data directory.  The default is 0700 but it may be changed in
 * checkDataDir() to 0750 if the data directory actually has that mode.
 */
int			data_directory_mode = PG_DIR_MODE_OWNER;

char		OutputFileName[MAXPGPATH];	/* debugging output file */

char		my_exec_path[MAXPGPATH];	/* full path to my executable */
char		pkglib_path[MAXPGPATH]; /* full path to lib directory */

#ifdef EXEC_BACKEND
char		postgres_exec_path[MAXPGPATH];	/* full path to backend */

/* note: currently this is not valid in backend processes */
#endif

BackendId	MyBackendId = InvalidBackendId;

BackendId	ParallelLeaderBackendId = InvalidBackendId;

Oid			MyDatabaseId = InvalidOid;

Oid			MyDatabaseTableSpace = InvalidOid;

/*
 * DatabasePath is the path (relative to DataDir) of my database's
 * primary directory, ie, its directory in the default tablespace.
 */
char	   *DatabasePath = NULL;

pid_t		PostmasterPid = 0;

/*
 * IsPostmasterEnvironment is true in a postmaster process and any postmaster
 * child process; it is false in a standalone process (bootstrap or
 * standalone backend).  IsUnderPostmaster is true in postmaster child
 * processes.  Note that "child process" includes all children, not only
 * regular backends.  These should be set correctly as early as possible
 * in the execution of a process, so that error handling will do the right
 * things if an error should occur during process initialization.
 *
 * These are initialized for the bootstrap/standalone case.
 */
bool		IsPostmasterEnvironment = false;
bool		IsUnderPostmaster = false;
bool		IsBinaryUpgrade = false;
bool		IsBackgroundWorker = false;

bool		ExitOnAnyError = false;

int			DateStyle = USE_ISO_DATES;
int			DateOrder = DATEORDER_MDY;
int			IntervalStyle = INTSTYLE_POSTGRES;

bool		enableFsync = true;
bool		allowSystemTableMods = false;
int			work_mem = 4096;
double		hash_mem_multiplier = 2.0;
int			maintenance_work_mem = 65536;
int			max_parallel_maintenance_workers = 2;

/*
 * Primary determinants of sizes of shared-memory structures.
 *
 * MaxBackends is computed by PostmasterMain after modules have had a chance to
 * register background workers.
 */
int			NBuffers = 16384;
int			MaxConnections = 100;
int			max_worker_processes = 8;
int			max_parallel_workers = 8;
int			MaxBackends = 0;

/* GUC parameters for vacuum */
int			VacuumBufferUsageLimit = 256;

int			VacuumCostPageHit = 1;
int			VacuumCostPageMiss = 2;
int			VacuumCostPageDirty = 20;
int			VacuumCostLimit = 200;
double		VacuumCostDelay = 0;

int64		VacuumPageHit = 0;
int64		VacuumPageMiss = 0;
int64		VacuumPageDirty = 0;

int			VacuumCostBalance = 0;	/* working state for vacuum */
bool		VacuumCostActive = false;

gha: C, lang: cpp
---
title: "It's good to be back, but I still don't know where I like it more"
description: ""
published: 2014-10-15
redirect_from:
  - /blog/its-good-to-be-back-but-i-still-dont-know-where-i-like-it-more/swizec/6610
categories: "City Lights Bookstore, Ljubljana, Ljubljana Castle, San Francisco, Slovenia, Travel + Events, United States"
hero: ./img/images-22489.jpg
---

![Ljubljana Castle at night](./img/images-22489.jpg "Ljubljana Castle at night")![]()

Today marks two weeks since I got back from a 6 month trip to [the US](<http://maps.google.com/maps?ll=38.8833333333,-77.0166666667&spn=10.0,10.0&q=38.8833333333,-77.0166666667 (United%20States)&t=h> "United States"). Strangely I'm still jetlagged, every morning feels like I got hit by a freight train.

Last time I wrote about reverse culture shock was in February when [I returned to Slovenia after 3 months and was culturally shocked](https://swizec.com/blog/i-returned-to-slovenia-after-3-months-and-i-am-culturally-shocked/)

My observations are different now. In six months I had time to settle down in [San Francisco](<http://maps.google.com/maps?ll=37.7833333333,-122.416666667&spn=0.1,0.1&q=37.7833333333,-122.416666667 (San%20Francisco)&t=h> "San Francisco"), establish some decent friendships, meet more of interesting people. Things.

## People are pretty much the same

![City Lights Bookstore](./img/images-22491.jpg "City Lights Bookstore")![]()

Some people are great. Some are a bag of dicks. It's got nothing to do with where they're from.

Yes, Americans are generally more open to conversations with strangers and on the outside they are polite to the point of nausea. But they are also backstabby, will never tell you what they _actually_ think, and will only express bad things behind your back.

But people in Slovenia are like that with acquaintances as well. The difference is that I've lived here for 27 years and there for a few months so more people are open with me here than there.

Makes sense.

And the overwhelming feeling of everyone being _extremely_ impolite the last time I came back? That's city vs. suburbia.

People in San Francisco are just as untalkative, brisk, and terse as they are in [Ljubljana](<http://maps.google.com/maps?ll=46.0555555556,14.5083333333&spn=0.1,0.1&q=46.0555555556,14.5083333333 (Ljubljana)&t=h> "Ljubljana"). Wham bam you're done. No time for pleasantries, you're holding up the line!

And don't think people in San Francisco will smile at you when they walk past, or give you a nod when you're both jogging. They won't even notice you exist.

## Slovenia complains about being expensive, but is kinda cheap

Comparing the cost of living is funny. I never have a good answer for this one.

The first time I rented a room in San Francisco my butt clenched and I didn't stop panicking until I got back. Yikes.

Prices for room sublets range from $1400 to $1800+. I found a happy medium for $1600.

That's $1600 for a room in an apartment with three other flatmates, sharing a single bathroom, everyone cooking in the same kitchen, rattling windows and everything looking kind of grimey. But the flatmates were nice because as a stranger in a strange town they're the first choice for someone to chat and make friends with.

But my posh fairly sizeable downtown studio here in Ljubljana only costs $700 a month, $800 with utilities. Nice apartment for half the price of a kind of crummy room ...

Yeah.

![A brunch](./img/images-22492.jpg "A brunch")

At the same time going to restaurants costs about the same here as it does there. A lunch menu will be around 10 euro. It's around $15 in SF - a euro or so pricier.

But then comes the tip. Since you're not a dick, you give 20%. It adds up and suddenly you're spending $30 per person on brunch.

Yikes.

Ok services (people, really) are cheaper in Ljubljana than they are in San Francisco. In restaurants the biggest difference comes from the tip, but everywhere else you get a better service for the price you're paying. Haircuts come to mind.

As far as groceries go ... I'm not sure. I eat like a beast so 4 or 5 days of groceries costs me 60 euro here, and a week's worth of groceries cost me $80 there. Technically I spend more on groceries here than there.

But meat, for example, is much cheaper here than there. Maybe I'm just not a very smart shopper.

## The infrastructure in SF sucks

![In front of Ferry Building](./img/images-22490.jpg "In front of Ferry Building")![]()

You know something's wrong when every company bigger than 10,000 starts running their own bus service. Something is broken. The city is _hurting_.

Muni is a cool enough system, nice and cheap. You pay $2 and you get a ride anywhere. Less than 50 cent more expensive than in Ljubljana!

But it only saves you 10 minutes compared to a brisk walk. A 2.5 mile ride from [Nob Hill](<http://maps.google.com/maps?ll=37.79323,-122.41448&spn=0.1,0.1&q=37.79323,-122.41448 (Nob%20Hill%2C%20San%20Francisco)&t=h> "Nob Hill, San Francisco") to The Mission takes between 32 and 48 minutes, a walk takes 53min, and a car ride is 10 minutes. (according to Google Maps)

Obviously you're going to Uber.

A comparative 3.5 mile ride from downtown Ljubljana to the big shopping mall takes 25min by bus, 55min to walk, and again just 10 minutes by car.

Obviously you're going to bus.

On top of being faster, our buses are also more predictable, run more regularly, and feel cleaner and more integrated into society. In SF it almost feels like you've lost at life if you ride the bus.

But maybe that's just prejudice because I didn't do it enough.

## Slovenia is missing half of the service industry

To get a cab, I have to make a _phone call_ to a dispatch center. Then I have to wait like a lost soul on a street corner. No feedback about how long it's going to take; sometimes it's a minute, sometimes it's ten. Sometimes you have to call again.

And you need cash to pay for a cab. No credit cards, no phone payments, just cash.

But it's looking up. Some companies have apps now, but you still have to pay cash.

When you want to get groceries ... well you'd better get off your arse and walk to a store. Only one chain offers delivery and the one time I tried it, you could tell it wasn't the core of their business. I'll try them again soon.

Alas, there's no Google Shopping Express here. I loved that thing. Oh you ran out of energy drinks and suck at planning, we'll bring you some by tonight. For cheaper than buying at a store.

In San Francisco there is even a service for cleaners (handy.

You sign up online, cleaners show up, cleaners keep coming regularly for as long as you want. Payment is invisible by credit card - no awkward moments.

When I asked on Twitter what my options were in Ljubljana, 14 people retweeted, 4 asked to be told when I find out, 1 told me I'm lazy, 1 sent me a sketchy phone number, and mum sent an email saying she'll do it.

No mum, I'm not paying you to clean my apartment.

Food delivery - in SF, app, in LJ, phone call.

Healthy food delivery - in SF, app, in LJ, nope.

Courier person for one thing - in SF, app, in LJ, nope.

Pay back friend for lunch - in SF, app, in LJ, cash.

Ship a few random items - in SF, app, in LJ, walk to post office and figure it out.

And let's not even get started on splitting the bill. Biggest killer feature of the US!

When many people dine, everyone throws their credit card on the table, each gets their own bill split exactly to the correct fraction.

We tried that in Ljubljana with a friend and surprisingly the server was up to it. But the approach he took was solving the knapsack problem by hand and making two separate bills with unique items in such a way that we both paid similar amounts.

Sigh.

## Life in general

![Powell Street](./img/images-22493.jpg "Powell Street")

Life in San Francisco is more care free. Whatever you want to get done, somebody is working on an app to solve your problem.

In Ljubljana a lot, if not most, things are manual. Ugh.

And you have to pay attention to opening hours too. The only time you ever care about what day it is in San Francisco is when you're dealing with banks or the post office. Everything else works all the time.

Want to do your groceries at 3am on your way home from the bars? Sure thing, Safeway. Or you've just run out of alcohols at a party and need more? Mosey along to the nearest corner store and they will sell you some.

In Slovenia you can't buy alcohol in a store after 9pm, but you can buy it at a bar at 5am and you can't buy it past 2am in San Francisco. Weird.

And Sundays still matter in Ljubljana. _Nothing_ is open. The city is dead. Good luck figuring out where to have lunch on a Sunday afternoon in downtown Ljubljana.

But I do love our coffee shop culture. It seems no matter the season, time of day, or the weather, coffee shops are full of people sitting down, relaxing, sipping their coffee and chatting. It's amazing.

Coffee culture in the US ... ugh, how about now? They always rush and never sit down. If they do sit down it's with a laptop to get some work done. It's not social at all.

How they ever do any business in such an environment I don't know. Actually I do, brunch.

Brunch in San Francisco is an institution. You _will_ wait up to an hour in line to sit down and you _will_ go out to lunch practically every weekend.

Whether it's with a girlfriend or a friend or even a potential business partner, brunch is the only truly social meal of the week in San Francisco. The only real time you can sit down and relax with a fellow person.

Dinner is doable, but it's always at least a bit rushed. Gotta get home, see the fam or whatev.

## The size

![Selfie from Twin Peaks](./img/images-22494.jpg "Selfie from Twin Peaks")

I guess most of the difference comes down to size.

Even though Ljubljana and San Francisco proper are roughly the same size - 7 miles across - SF _feels_ bigger. It's got 800,000 people packed into the same area Ljubljana's only got 300,000.

As a result, everything in SF takes foooreeeveeeer. Go out to eat? 30 minutes to get there, 20 minutes to wait in line.

And because it's so packed there are multiple "downtowns". It's not uncommon for a walk from one bar to the next to take 20 minutes because good bars are everywhere. Anywhere you go in San Francisco, there is something of interest. Something you're going to want to do and see.

In Ljubljana, even though it's nominally the same size, everything of interest lies in the small downtown area. You never have to walk more than 10 minutes to go anywhere. Twenty minutes tops.

Further out and you're essentially in suburbia. It's still the city, but it's more like San Francisco's Menlo Park in relevance and layout.

## The verdict?

I don't know.

Life in San Francisco feels easier, but it's a butt clenching exercise in making ends meet.

Life in Ljubljana is more relaxed, but you spend ungodly amounts of time running support systems.

The step counter is definitely chirpier in Ljubljana though.

_shrug_

gha: MDX, lang: markdown
# Számok WPF
Korábbi közismereti informatika érettségi programozás feladatsorának WPF-re átírta változata

## Feladat leírás és kiindó állomány
Feladat leírása: Számok - WPF.docx   
Induló állomány: felszam.txt 

## Kapcsolódó videó
https://youtu.be/fnUSQMOcUdc

gha: JavaScript, lang: ini
Experimental
============

C++ API
-------

.. note::
  **This feature is not officially supported and may change without notice**

The C++ API allows you to use DALI as a library from native applications. Refer to
the ``PipelineTest`` family of tests for more information about how to use this API.

gha: C++, lang: markdown
#pragma once
#include <string>
#include <vector>
#include <boost/optional.hpp>
#include "ctpl.h"
#include "Position.h"
#include "HistoryMap.h"

class Uci
{
public:
	Uci();
	~Uci();
	bool execute(std::string command);
private:
	boost::optional<Position> position_;
	HistoryMap history_;
	ctpl::thread_pool thread_pool_;
	std::future<void> searching_;
	void executeUci();
	void executeUciNewGame();
	void executeIsReady();
	void executePosition(const std::vector<std::string>& command_parts);
	void executeGo(const std::vector<std::string>& command_parts);
	void executeSetOption(const std::vector<std::string>& command_parts);
	void goDepth(const std::vector<std::string>& tokens);
	void goTime(const std::vector<std::string>& tokens);
	void goPerft(const std::vector<std::string>& tokens);
	void executeD();
};

gha: C++, lang: cpp
#include "../native/native_wiring.cpp"

gha: C++, lang: batchfile
# Congratulations and welcome to Computer engineering at Åbo Akademi University

This page will help you with the basics (who to contact etc.) and get you started with your studies.

## Tutors

These guys help you with any questions that you may come up with. The tutors help you throughout the first year.

You can contact them via [Telegram](COMMUNICATION.md#telegram) or by [email](COMMUNICATION.md#email).

| Tutors 2020               |
| ------------------------- |
| Hanna Liman               |
| Janina Heikkala           |
| Max Sirén                 |
| Odin Röblom               |
| Roope Paajanen            |

<!-- Full-blown tutor greeting: [greeting](http://datateknologerna.org/greeting) -->

## Intro-week

Time: **24.-28.8.2020**

During the introduction week, you will

* Meet the tutors
* Meet new people
* Become familiar with campus and the university
* Learn about [TEK and TFiF](TEKTFIF.md)
* Have fun!

**The schedule for the introduction week can be found SOOON (TODO) [here](https://www.abo.fi/studera-hos-oss/du-som-redan-studerar/studieinformation/studieorientering/).**

**Tutors and student associations will host evening activities for you. This is not mandatory but highly recommended.**

Here's a preliminary schedule for evening activities

| Monday   | Tuesday     | Wednesday         | Thursday   | Friday   | Weekend     |
| ---------|--------------|-------------------|------------|----------|-------------|
| TFiF GP  | Tour de Åbo  |ASK in Kuppisparken| TBA   | TBA     | -           |

## Courses

The courses can be found here in the [studienhandboken](https://studiehandboken.abo.fi/en/programme/17004). You need to open each course to see when it is actually held...

Also note: Some things are not great in life... This site should not be viewed from a phone, hopefully will be updated soon.

// TODO: add some cool parsing stuff here

gha: HTML, lang: markdown
from .geometa import get_meta, from_metadata

# I am a Researcher who wants to create a GeoMeta file for my dataset
get_meta('sample_data/subset_data_1/subset_data_1.tif', '10.5069/G9HT2M76',
         'doi.org/10.1002/esp.3884', 'myMeta.json')

# I have been given a GeoMeta file and want to recreate
from_metadata('myMeta.json', 'sample_data/full_data_1/full_data_1.tif')

gha: Python, lang: sql
﻿using Microsoft.EntityFrameworkCore;
using Microsoft.EntityFrameworkCore.Design;
using Microsoft.Extensions.Configuration;
using System;
using System.IO;

namespace Cms.Model.Context
{
    public class DataDbContextFactory : IDesignTimeDbContextFactory<DataDbContext>
    {
        public DataDbContext CreateDbContext(string[] args)
        {

            var environmentName = Environment.GetEnvironmentVariable("ASPNETCORE_ENVIRONMENT");

            IConfigurationRoot configuration = new ConfigurationBuilder()
                .SetBasePath(Directory.GetCurrentDirectory())
                .AddJsonFile("appsettings.json")
                .AddJsonFile($"appsettings.{environmentName}.json")
                .Build();


            var buider = new DbContextOptionsBuilder<DataDbContext>();
            var connectionString = configuration.GetConnectionString("DefaultConnection");
            buider.UseNpgsql(connectionString);
            return new DataDbContext(buider.Options);
        }
    }
}

gha: C#, lang: c_sharp
﻿namespace maestropanel.plesklib.Models
{
    using System.Xml.Serialization;

    [XmlRoot("packet")]
    public class SiteAddResult : IResponseResult
    {
        private ApiResponse _response;

        public SiteAddResult()
        {
            this._response = new ApiResponse();
            this.site = new SiteResult();
        }

        [XmlElement("site")]
        public SiteResult site { get; set; }

        public void SaveResult(ApiResponse response)
        {
            this._response = response;
        }

        public ResponseResult ToResult()
        {
            this.site.addResult.result.apiResponse = _response;
            return this.site.addResult.result;
        }
    }

    public class SiteResult
    {
        public SiteResult()
        {
            this.addResult = new AddResult();
        }

        [XmlElement("add")]
        public AddResult addResult { get; set; }
    }

    public class AddResult
    {
        public AddResult()
        {
            this.result = new ResponseResult();
        }

        [XmlElement("result")]
        public ResponseResult result { get; set; }
    }
}

gha: C#, lang: c_sharp
![ZumiHeader](ZumiHeader.png)

# Color Classifier

<font size=3> <span style="color:red">**Note!**</span> This activity requires the Color Training Wizard found in the "Explore" page.</font>

<font size =3> You can see colors and differentiate between them, but did you know computers can do this too? In this lesson, you will learn how to use a special **algorithm** to teach Zumi different colors. This is a very basic example of machine learning, which can be summarized in three steps:

* Gathering data
* Generating a model
* Making predictions

You will use Zumi's camera to take many pictures of your favorite colors, and then run code that will use the color information to label each color. In the final step, you will be able to test your model and write code for Zumi to react to each color differently! For now, let's teach Zumi about colors. You will need to have your activity color cards handy!</font>

![color_activity_cards](color_activity_cards.png)

***
# Color Classifier

# How do computers see and interpret colors?
<font size =3> Before getting started with training Zumi to recognize colors, you need to learn how Zumi sees colors. It is very different than how you see colors!

## What is an image?
<font size =3> An image is made up of an array of small dots called **pixels** (short for picture element). A pixel can be a single color or a combination of colors, and each of those colors is represented by a series of three numbers that tell you exactly how much red, green, and blue are in it. This is called the **RGB** value, which stands for red, green, and blue. For example, a beautiful shade of turquoise might look something like (27, 209, 197) since there isn’t a lot of red, but there is a lot of green and blue. Because each value of RGB can be between 0 and 255, there are 256 values to choose from for each color. That results in 256^3, or 16,777,216, different color combinations! </font>

***
# Color Classifier

## What is a matrix?
<font size =3> Since each pixel can be represented by numbers, a picture is a grid of numbers. This is where humans and computers start to see images a little differently. Humans see colors and shapes that we recognize as different objects, but computers only see these grids, also called **matrices**. Each number represents the RGB value of each pixel. They look a little like this: </font>

![matriceszumi](matriceszumi.png)


***
# Color Classifier

## Using HSV instead of RGB

<font size =3> 

Your program will convert each RGB image to the **HSV** colorspace. HSV stands for hue, saturation, and value.


* **Hue** normally ranges from 0-360 and represents the color (in this application however, it ranges from 0-180)
* **Saturation** is the color's intensity
* **Value** is how light or dark the color is

In computer vision applications, it is better to use the HSV colorspace since it separates values for colors and intensity. This is important because shadows, reflections, and other factors may cause certain colors to look very different. The HSV colorspace takes this into account for more accurate results. </font>

![HSV_cylinder](HSV_cylinder.png)


***
# Color Classifier

## Practice: Teach Zumi 3 Colors
<font size=3> Head on over to the KNN Color Training Wizard and select three of your favorite colors from the packet of color cards in your Zumi box. Pay attention to how Zumi plots each color as a 3D coordinate (for hue, saturation, and value). How do you think Zumi is predicting colors correctly?<br> When you are done, don't forget to save your model with a project name that is easy to remember. You will be using it in the next section, so make sure to write it down in addition to all of your label names.</font>

***
# Color Classifier

## Loading Model
<font size=3> The great thing about machine learning is that when you save a model, you can use it again! In the previous activity, you chose three of your favorite colors to teach to Zumi. Now you will use Python code to load the model and have Zumi react differently to each of the colors!</font>
    
### Import libraries
<font size=3> Import the following libraries to access the functions you need for driving, camera, and color classification.


```python 
from zumi.zumi import Zumi
from zumi.util.camera import Camera
from zumi.util.screen import Screen
from zumi.util.color_classifier import ColorClassifier
import time

camera = Camera()
screen = Screen()
zumi = Zumi()
````

***
# Color Classifier

### Loading a Model
<font size=3> To load the model, you will call a function from the ColorClassifier library: <font face="Courier">load_model()</font>. This function needs a parameter, which is your project name. Remember what you named your project? Insert your user name AND the project name within the quotes below. Check that your spelling and punctuation is correct. If it doesn't exist, you will get an error. 


```python 
user_name = ''
demo_name = ''

knn = ColorClassifier(user_name=user_name)
train = knn.load_model(demo_name)
knn.fit("hsv")
````

***
# Color Classifier

<font size=3> Once your model has been successfully loaded, you can test it. Run the code below and pick a color card to show to Zumi. When you are ready, press enter to see the results on the screen. If you press "q", the program will break out of the loop and turn off the camera.


```python 
camera.start_camera()

while True:
        user_input = input("Press 'enter' to predict or 'q to quit: ")

        if user_input == "q":
            break
            
        image = camera.capture()
        predict = knn.predict(image)
        screen.draw_text_center(predict)

camera.close()
````

***
# Color Classifier

## Traffic Light
<font size=3> You have trained Zumi to recognize the colors, but Zumi should probably make some decisions depending on the color she sees! Think about a traffic light. There are three colors on the traffic light. What do each of the colors mean? <br>
    
![traffic_light](traffic_light.png)

</font>

### Data collection
<font size=3> Go back to the Color Training Wizard and train the labels "red", "yellow", and "green". Next, save the model as "trafficlight".</font>

### Making Decisions
<font size=3> In this activity, you will make Zumi stop if she sees red, drive when she sees green, and drive at a slower speed if she sees yellow. Use the functions <font face="Courier">stop()</font>, <font face="Courier">forward(speed=30)</font>, and <font face="Courier">forward(speed=70)</font> for red, yellow, and green. For example:
    
<font face="Courier">
    
if predict == "yellow": <br>
<span style="margin-left: 40px;">zumi.forward(speed=30)</span> <br>
</font>
</font>
    
### Load the model
<font size=3> Load the "trafficlight" project here by providing the project name in the quotes.


```python 
knn = ColorClassifier()
train = knn.load_model("trafficlight")
knn.fit("hsv")
````

***
# Color Classifier

### Insert If statements
<font size=3> Fill in the code with the correct actions to go with the traffic light color. Then test it by showing Zumi a color card and pressing enter to see Zumi react!


```python 
camera.start_camera()

while True:
        user_input = input("Press 'enter' to predict or 'q to quit: ")

        if user_input == "q":
            break
            
        image = camera.capture()
        predict = knn.predict(image)
        screen.draw_text_center(predict)
        
        # Add your if statements here!
        
        Finish the code

camera.close()
````

***
# Color Classifier

## Design your own traffic light
<font size=3> Who said traffic lights always have to be red, yellow, and green? In the real world, these are universal symbols and we should keep them that way, but in Zumi world, you can create your own traffic lights that signal different behaviors. Maybe purple means "do a u-turn", or blue means "go left". It's your world so you get to decide! <br>
    
![trafficlight_custom](trafficlight_custom.png)

    
Go to the Color Training Wizard and train three (or more!) colors for your new traffic light. You can go beyond simply stopping and driving. Check out lesson 2.1 or the Zumi documentation for more ideas! Remember your project name and labels because you will need to load the model below when you are done.</font>

### Load model for custom traffic light


```python 
knn = ColorClassifier()
train = knn.load_model("PROJECT NAME HERE")
knn.fit("hsv")
````

***
# Color Classifier

### Fill in the labels
<font size=3> Just like in the normal traffic light example, include if statements to tell Zumi what to do when she sees each of your colors. When you're finished, build a small city and have someone be your traffic light by holding up the color cards you trained.


```python 
camera.start_camera()

while True:
        user_input = input("Press 'enter' to predict or 'q to quit: ")

        if user_input == "q":
            break
            
        image = camera.capture()
        predict = knn.predict(image)
        screen.draw_text_center(predict)
        
        # Add your if statements here!

camera.close()
````

gha: Jupyter Notebook, lang: markdown
const path = require('path');
const {
    DataTypes
} = require('sequelize');
const db = require(path.resolve(__dirname, '../connection'));

const User = db.define('user', {
            id: {
                type: DataTypes.INTEGER,
                allowNull: false,
                autoIncrement: true,
                primaryKey: true
            },
            firstName: {
                type: DataTypes.STRING,
            },
            surname: {
                type: DataTypes.STRING,
            },
            email: {
                type: DataTypes.STRING(100),
            },
            password: {
                type: DataTypes.STRING(156),
                allowNull: false,
            },
            img: {
                type: DataTypes.STRING
            },
            document: {
                type: DataTypes.STRING
            },
            admin: {
                type: DataTypes.BOOLEAN
            },
        });

module.exports = User;

gha: EJS, lang: javascript
ACLOCAL_AMFLAGS=-I m4 

lib_LTLIBRARIES = librouting_flooding_offgg.la

librouting_flooding_offgg_la_CFLAGS = $(CFLAGS) $(GLIB_FLAGS) $(GSL_FLAGS) -Wall

librouting_flooding_offgg_la_SOURCES = flooding+offgg.c

librouting_flooding_offgg_la_LDFLAGS = -module

gha: Roff, lang: makefile
#include <stdio.h>
#include <stdlib.h>
int arr0[200000] = {0};
int cmp(const void *a,const void *b)
{
	return *((int *)b) - (*(int *)a);
}
int main()
{
	int n,m,i;
	scanf("%d%d",&n,&m);
	for(i = 0; i < n; i++)
	{
		scanf("%d",arr0 + i);
	}
	qsort(arr0,n,sizeof(int),cmp);
	double s = 0;
	for(i = 0; i < m; i++)
	{
		s += arr0[i];
	}
	s /= m;
	if(s >= 60.0)
	{
		printf("%.3f\n",s);
	}
	else
	{
		puts("Jianglaoshi%%%");
	}
	return 0;
}
gha: Makefile, lang: cpp
root: ./content/tutorial

structure:  
    readme: _index.md  
    summary: summary.md

gha: HTML, lang: yaml
import { create, tsx } from '@dojo/framework/core/vdom';
import PasswordInput from '@dojo/widgets/password-input';
import Example from '../../Example';

const factory = create();

export default factory(function NoRules() {
	return (
		<Example>
			<PasswordInput required>{{ label: 'Enter Password' }}</PasswordInput>
		</Example>
	);
});

gha: TypeScript, lang: javascript
<template>
  <div class="buysoon">
    <!-- 收藏/添加到购物车 -->
    <div class="add-fav">
      <button>
        <img :src="require('../../assets/prodetail/gouwuche.png')" alt />
      </button>
      <!-- 分隔线 -->
      <img :src="require('../../assets/prodetail/split.png')" alt />
      <button @click="changeStar">
        <img :src="!isFav?starSrc:starAddedSrc" alt />
      </button>
    </div>
    <!-- 立即购买按钮 -->

    <button class="buy-btn">立即购买</button>
  </div>
</template>
<script>
export default {
  data() {
    return {
      isFav: false,
      starSrc: require("../../assets/prodetail/star.png"),
      starAddedSrc: require("../../assets/prodetail/star2.png")
    };
  },
  methods: {
    changeStar() {
      //是否收藏
      if (this.isFav) {
        this.isFav = false;
      } else {
        this.isFav = true;
      }
    }
  },
  created() {}
};
</script>
<style scoped>
.buysoon {
  width: 100%;
  height: 80px;
  position: fixed; /*固定在页面底部，不会随滚动条变化而变化*/
  left: 0;
  bottom: 0;
  z-index: 2;
  display: flex;
  align-items: center;
  justify-content: left;
}

.buysoon > .add-fav {
  width: 50%;
  height: 100%;
  background: #fff;
  display: flex;
  justify-content: left;
  align-items: center;
}
/* 添加到购物车/收藏按钮 */
.buysoon > .add-fav > button {
  width: 49%;
  height: 100%;
  outline: none;
  border: none;
  background-color: transparent;
  position: relative;
}

.add-fav > img {
  width: 2%;
  height: 50%;
}
/* 添加到购物车/收藏按钮-图片 */
.buysoon > .add-fav > button > img {
  width: 40px;
  height: 40px;
  position: absolute;
  top: 50%;
  left: 50%;
  transform: translate(-50%, -50%);
}

/* 立即购买按钮 */
.buysoon > .buy-btn {
  width: 50%;
  height: 100%;
  outline: none;
  border: none;
  background: rgba(43, 205, 221, 1);
  color: #fff;
  font-size: 16px;
  font-weight: bold;
}
</style>
gha: HTML, lang: javascript
# letsGetBuilding

A quick demonstration of the Restful gem. A google search is performed from the command line and the response code and response headers are outputted. Also, The number of searches performed during the session is tracked and outputted after every search.

# CONTRIBUTORS

> <a href="https://github.com/sanelca" target="_blank">Sanel Hodzic</a><br /><br />
> <a href="https://github.com/osinakayah/" target="_blank">Osinachi Ifeanyi</a>

gha: Ruby, lang: markdown
const appUrl = 'https://nuxt-i18n-demo.netlify.app'

export default {
  // See https://nuxtjs.org/api/configuration-mode
  ssr: false,

  // See https://nuxtjs.org/api/configuration-target
  target: 'server',

  /*
   ** Headers of the page
   */
  head: {
    title: process.env.npm_package_name || '',
    meta: [
      { charset: 'utf-8' },
      { name: 'viewport', content: 'width=device-width, initial-scale=1' },
      {
        hid: 'description',
        name: 'description',
        content: process.env.npm_package_description || '',
      },
    ],
    link: [{ rel: 'icon', type: 'image/x-icon', href: '/favicon.ico' }],
  },

  /*
   ** Customize the progress-bar color
   */
  loading: { color: '#fff' },

  /*
   ** Global CSS
   */
  css: [],

  /*
   ** Plugins to load before mounting the App
   */
  plugins: [],

  /*
   ** Nuxt.js modules
   */
  modules: [
    'nuxt-i18n',
    // sitemap should always come last
    '@nuxtjs/sitemap',
  ],

  /*
   ** Nuxt.js dev modules
   */
  buildModules: ['@nuxtjs/eslint-module'],

  /*
   ** i18n config
   */
  i18n: {
    baseUrl: appUrl,
    seo: true,
    locales: [
      {
        code: 'en',
        iso: 'en-AU',
        name: 'English',
      },
      {
        code: 'nl',
        iso: 'nl-BE',
        name: 'Nederlands',
      },
      {
        code: 'fr',
        iso: 'fr-BE',
        name: 'français',
      },
    ],
    defaultLocale: 'en',
    vueI18n: {
      fallbackLocale: 'en',
      messages: {
        en: require('./locales/en.json'),
        nl: require('./locales/nl.json'),
        fr: require('./locales/fr.json'),
      },
      dateTimeFormats: {
        en: {
          long: { year: 'numeric', month: 'long', day: 'numeric' },
        },
        nl: {
          long: { year: 'numeric', month: 'long', day: 'numeric' },
        },
        fr: {
          long: { year: 'numeric', month: 'long', day: 'numeric' },
        },
      },
    },
    // Netlify will do the language detection
    detectBrowserLanguage: false,
  },

  /*
   ** Sitemap config
   */
  sitemap: {
    hostname: appUrl,
    trailingSlash: true,
    i18n: true,
  },

  /*
   ** Build configuration
   */
  build: {},

  /*
   ** Router config
   */
  router: {
    // easily spot nuxt-link without a trailing slash, because they will return a 404
    trailingSlash: true,
  },

  /*
   ** Generate pages for static deploy
   */
  generate: {
    // See https://nuxtjs.org/faq/netlify-deployment/
    fallback: true,
    // the following would be an API call
    routes: ['/dynamic/1', '/dynamic/2', '/dynamic/3'],
  },
}

gha: Vue, lang: javascript
//
//  OracleDateFormatter.h
//  Oracle
//
//  Created by Tom Martin on 12/12/18.
/*
Copyright (C) 2018 Tom Martin

This library is free software; you can redistribute it and/or
modify it under the terms of the GNU Lesser General Public
License as published by the Free Software Foundation; either
version 2.1 of the License, or (at your option) any later version.

This library is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
Lesser General Public License for more details.

You should have received a copy of the GNU Lesser General Public
License along with this library; if not, write to the Free Software
Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA

Or, contact the author,

Tom Martin
Riemer Reporting Service
24600 Detoit Rd
Westlake OH 44145
mailto:tom.martin@riemer.com
*/
//

#import <EOAccess/EOAccess.h>

NS_ASSUME_NONNULL_BEGIN

@interface OracleDateFormatter : EOSQLFormatter

@end

NS_ASSUME_NONNULL_END

gha: Objective-C, lang: cpp
/*
 * ARX Data Anonymization Tool
 * Copyright 2012 - 2023 Fabian Prasser and contributors
 * 
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 * 
 * http://www.apache.org/licenses/LICENSE-2.0
 * 
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.deidentifier.arx.risk;

/**
 * Helper class containing approximations for the digamma and trigamma
 * functions.
 * 
 * @author Florian Kohlmayer
 * @author Fabian Prasser
 */
class Gamma {

    /** The Constant B10. */
    private final static double B10            = 5.0 / 66.0;

    /** The Constant B2. */
    private final static double B2             = 1.0 / 6.0;

    /** The Constant B4. */
    private final static double B4             = -1.0 / 30.0;

    /** The Constant B6. */
    private final static double B6             = 1.0 / 42.0;

    /** The Constant B8. */
    private final static double B8             = -1.0 / 30.0;

    /** The Constant DIGAMMA_1. <br>
     * -digamma(1) = Euler Mascheroni constant
     */
    private final static double DIGAMMA_1      = -0.57721566490153286060651209008240243104215933593992d;

    /** The Constant LARGE_DIGAMMA. */
    private final static double LARGE_DIGAMMA  = 12.0;

    /** The Constant LARGE_TRIGAMMA. */
    private final static double LARGE_TRIGAMMA = 8.0;

    /** The Constant S3. */
    private final static double S3             = 1.0 / 12.0;

    /** The Constant S4. */
    private final static double S4             = 1.0 / 120.0;

    /** The Constant S5. */
    private final static double S5             = 1.0 / 252.0;

    /** The Constant S6. */
    private final static double S6             = 1.0 / 240.0;

    /** The Constant S7. */
    private final static double S7             = 1.0 / 132.0;

    /** The Constant SMALL_DIGAMMA. */
    private final static double SMALL_DIGAMMA  = 1e-6;

    /** The Constant SMALL_TRIGAMMA. */
    private final static double SMALL_TRIGAMMA = 1e-4;

    /** The Constant TETRAGAMMA_1. <br>
     * -2 * Zeta(3) = -2 * Apry constant  
     */
    private final static double TETRAGAMMA_1   = -2.0d * 1.202056903159594285399738161511449990764986292d;

    /** The Constant TRIGAMMA_1. <br>
     * trigamma(1) = pi^2/6 = Zeta(2)
     */
    private final static double TRIGAMMA_1     = (StrictMath.PI * StrictMath.PI) / 6.0;                  

    /**
     * Approximates the digamma function. Java port of the
     * "The Lightspeed Matlab toolbox" version 2.7 by Tom Minka see:
     * http://research.microsoft.com/en-us/um/people/minka/software/lightspeed/
     * 
     * @param x
     *            input value
     * @return approximation of digamma for x
     */
    static double digamma(double x) {

        /* Illegal arguments */
        if (Double.isInfinite(x) || Double.isNaN(x)) { return Double.NaN; }

        /* Singularities */
        if (x == 0.0d) { return Double.NEGATIVE_INFINITY; }

        /* Negative values */
        /*
         * Use the reflection formula (Jeffrey 11.1.6): digamma(-x) =
         * digamma(x+1) + pi*cot(pi*x)
         * 
         * This is related to the identity digamma(-x) = digamma(x+1) -
         * digamma(z) + digamma(1-z) where z is the fractional part of x For
         * example: digamma(-3.1) = 1/3.1 + 1/2.1 + 1/1.1 + 1/0.1 +
         * digamma(1-0.1) = digamma(4.1) - digamma(0.1) + digamma(1-0.1) Then we
         * use digamma(1-z) - digamma(z) = pi*cot(pi*z)
         */
        if (x < 0.0d) { return digamma(1.0d - x) +
                               (StrictMath.PI / StrictMath.tan(-StrictMath.PI *
                                                               x)); }

        /* Use Taylor series if argument <= small */
        if (x <= SMALL_DIGAMMA) { return (DIGAMMA_1 - (1.0d / x)) +
                                         (TRIGAMMA_1 * x); }

        double result = 0.0d;
        /* Reduce to digamma(X + N) where (X + N) >= large */
        while (x < LARGE_DIGAMMA) {
            result -= 1.0d / x;
            x++;
        }

        /* Use de Moivre's expansion if argument >= C */
        /* This expansion can be computed in Maple via asympt(Psi(x),x) */
        if (x >= LARGE_DIGAMMA) {
            double r = 1.0d / x;
            result += StrictMath.log(x) - (0.5d * r);
            r *= r;
            result -= r *
                      (S3 - (r * (S4 - (r * (S5 - (r * (S6 - (r * S7))))))));
        }

        return result;
    }

    /**
     * TODO: Implement efficiently
     * 
     * @param x
     * @return
     */
    static double gamma(double x) {
        return org.apache.commons.math3.special.Gamma.gamma(x);
    }

    /**
     * TODO: Implement efficiently
     * 
     * @param x
     * @return
     */
    static double logGamma(double x) {
        return org.apache.commons.math3.special.Gamma.logGamma(x);
    }

    /**
     * Approximates the trigamma function. Java port of the
     * "The Lightspeed Matlab toolbox" version 2.7 by Tom Minka see:
     * http://research.microsoft.com/en-us/um/people/minka/software/lightspeed/
     * 
     * @param x
     *            input value
     * @return approximation of trigamma for x
     */
    static double trigamma(double x) {
        /* Illegal arguments */
        if (Double.isInfinite(x) || Double.isNaN(x)) { return Double.NaN; }

        /* Singularities */
        if (x == 0.0d) { return Double.NEGATIVE_INFINITY; }

        /* Negative values */
        /*
         * Use the derivative of the digamma reflection formula: -trigamma(-x) =
         * trigamma(x+1) - (pi*csc(pi*x))^2
         */
        if (x < 0.0d) {
            double r = StrictMath.PI / StrictMath.sin(-StrictMath.PI * x);
            return -trigamma(1.0d - x) + (r * r);
        }

        /* Use Taylor series if argument <= small */
        if (x <= SMALL_TRIGAMMA) { return (1.0d / (x * x)) + TRIGAMMA_1 +
                                          (TETRAGAMMA_1 * x); }

        double result = 0.0d;
        /* Reduce to trigamma(x+n) where ( X + N ) >= B */
        while (x < LARGE_TRIGAMMA) {
            result += 1.0d / (x * x);
            x++;
        }

        /* Apply asymptotic formula when X >= B */
        /* This expansion can be computed in Maple via asympt(Psi(1,x),x) */
        if (x >= LARGE_DIGAMMA) {
            double r = 1.0d / (x * x);
            result += (0.5d * r) +
                      ((1.0d + (r * (B2 + (r * (B4 + (r * (B6 + (r * (B8 + (r * B10)))))))))) / x);
        }
        return result;
    }

}

gha: Java, lang: groovy
﻿using System;
using System.Collections.Generic;
using System.Globalization;
using System.Linq;
using System.Text;
using ScheduleBot.AspHost.BotServices;
using ScheduleServices.Core.Models.ScheduleElems;

namespace ScheduleBot.AspHost.Helpers
{
    public class CustomSerializator
    {
        public static string ProcessSchedule(IEnumerable<Lesson> lessons, DayOfWeek day)
        {
            var answerMessage = new StringBuilder();
            var culture = new CultureInfo("ru-Ru");
            var dayOfWeek = culture.DateTimeFormat.GetDayName(day);
            answerMessage.AppendLine($"<b>{dayOfWeek.ToUpper()}</b>");
            if (lessons.Count() == 0)
            {
                answerMessage.AppendLine("Пар нет 😃");
                return answerMessage.ToString();
            }

            foreach (var lesson in lessons)
            {
                var teacherOrGroup = lesson is TeacherScheduleSelector.LessonWithGroup wg
                    ? (wg.RelatedGroup?.Name ?? "")
                    : lesson.Teacher;
                answerMessage.AppendLine(
                    $"{lesson.Discipline} {ConvertBoolToString(lesson.IsOnEvenWeek)} {lesson.Notation} \n{teacherOrGroup} \n{lesson.BeginTime.ToString("hh\\:mm")}-{(lesson.BeginTime + lesson.Duration).ToString("hh\\:mm")} \t ауд. {lesson.Place} \n---------------------------");
            }


            return answerMessage.ToString();
        }

        private static string ConvertBoolToString(bool? isEvenWeek)
        {
            if (isEvenWeek == null)
                return "";
            if ((bool) isEvenWeek)
                return "(ч.н.)";
            return "(н.н.)";
        }
    }
}
gha: C#, lang: c_sharp
# What is this Sample Application about?

**TripXpert** is a sample application built with
[Telerik&reg; UI for ASP.NET MVC][ui-for-mvc].
The app demonstrates how you can integrate some of the most popular server-side wrappers for the
[Kendo UI widgets][kendo-demos] in a progressive web app (PWA). A progressive web app is a mobile app delivered through the web. It functions like a native app, due to the use of an app shell that allows for app-style gestures and navigations. The main difference is that there is no need to download it from an app store. It runs, self-contained, right in a web browser. With the help of service workers, a progressive web app is able to load instantly, even in areas of low connectivity. With the help of pre-caching, the app stays up to date at all times, displaying the most recent version upon launching.

**TripXpert** is a trip-planning app that enables users to:

* Browse available trips
* Discover interesting information about destinations
* Browse images of trips and destinations
* View maps of the destinations’ locations
* View a calendar of accommodation availability
* Submit inquiries

## What was it built with?

* [ASP.NET MVC DropDownList][mvc-dropdownlist]
* [ASP.NET MVC MaskedTextBox][mvc-maskedtextbox]
* [ASP.NET MVC Window][mvc-window]
* [ASP.NET MVC Button][mvc-button]
* [ASP.NET MVC Map][mvc-map]
* [ASP.NET MVC Dialog][mvc-dialog]
* [ASP.NET MVC Menu][mvc-menu]
* [ASP.NET MVC ListView][mvc-listview]
* [ASP.NET MVC Calendar][mvc-calendar]
* [ASP.NET MVC TabStrip][mvc-tabstrip]
* [ASP.NET MVC ComboBox][mvc-combobox]
* [ASP.NET MVC ResponsivePanel][mvc-responsivepanel]
* [Kendo UI Validator][kendo-validator]

## What are the requirements to run this sample app locally?

If you'd like to take a look behind the curtain, download the source code. You can examine and modify it to meet your project requirements. To run the sample app locally, you’ll need the respective or later version of the following products:

* [UI for ASP.NET MVC](https://www.telerik.com/download-trial-file/v2/ui-for-asp.net-mvc)
* [Microsoft SQL Server Express 2012](https://www.microsoft.com/en-us/download/details.aspx?id=29062)
* [Microsoft .NET framework 4.0](http://www.microsoft.com/en-us/download/details.aspx?id=17851)


## Browser Support

Browser | Windows | Mac | Linux
--- | --- | --- | ---
Edge | 20+ | N/A
FireFox | Current, previous and ESR
Chrome | Current and previous
Opera | Current and previous

Mobile Browsers | Version
--- | ---
iOS Safari | iOS 8+
Chrome Mobile | Current and previous
Opera Mobile | Current and previous

---

### See more demos

* [Kendo UI&reg; &hearts; Bootstrap](https://demos.telerik.com/kendo-ui/bootstrap/)
* [Web Mail Application](https://demos.telerik.com/aspnet-mvc/webmail/)
* [Stock History Dashboard](https://demos.telerik.com/aspnet-mvc/financial/stock-history)
* [Olympic Games Stats](https://demos.telerik.com/aspnet-mvc/olympic-games/)


[ui-for-mvc]: https://demos.telerik.com/aspnet-mvc/
[kendo-demos]: https://demos.telerik.com/kendo-ui/
[mvc-dropdownlist]: https://demos.telerik.com/aspnet-mvc/dropdownlist/
[mvc-mediaplayer]: https://demos.telerik.com/aspnet-mvc/mediaplayer/index
[mvc-map]: https://demos.telerik.com/aspnet-mvc/map/index
[mvc-dialog]: https://demos.telerik.com/aspnet-mvc/dialog/index
[mvc-menu]: https://demos.telerik.com/aspnet-mvc/menu/index
[mvc-listview]: https://demos.telerik.com/aspnet-mvc/listview/index
[mvc-calendar]: https://demos.telerik.com/aspnet-mvc/calendar/index
[mvc-upload]: https://demos.telerik.com/aspnet-mvc/upload/index
[mvc-tabstrip]: https://demos.telerik.com/aspnet-mvc/tabstrip/index
[mvc-combobox]: https://demos.telerik.com/aspnet-mvc/combobox/index
[mvc-responsivepanel]: https://demos.telerik.com/aspnet-mvc/responsive-panel/index
[kendo-validator]: https://demos.telerik.com/kendo-ui/validator/index
[kendo-validator]: https://demos.telerik.com/kendo-ui/validator/index
[mvc-maskedtextbox]: https://demos.telerik.com/aspnet-mvc/maskedtextbox
[mvc-window]: https://demos.telerik.com/aspnet-mvc/window
[mvc-button]: https://demos.telerik.com/aspnet-mvc/button

gha: JavaScript, lang: markdown
<?php

namespace App\Transformers;

use App\Category;
use League\Fractal\TransformerAbstract;

class CategoryTransformer extends TransformerAbstract
{
    /**
     * List of resources to automatically include
     *
     * @var array
     */
    protected $defaultIncludes = [
        //
    ];
    
    /**
     * List of resources possible to include
     *
     * @var array
     */
    protected $availableIncludes = [
        //
    ];
    
    /**
     * A Fractal transformer.
     *
     * @return array
     */
    public function transform(Category $category)
    {
        return [
            'id' => (int)$category->id,
            'name' => (string)$category->name,
            'eng' => (string)$category->eng,
            'slug' => (string)$category->slug,
            'created_at' => (string)$category->created_at,
            'updated_at' => (string)$category->updated_at,
        ];
    }
}

gha: TypeScript, lang: php
/*
**  Oricutron
**  Copyright (C) 2009-2010 Peter Gordon
**
**  This program is free software; you can redistribute it and/or
**  modify it under the terms of the GNU General Public License
**  as published by the Free Software Foundation, version 2
**  of the License.
**
**  This program is distributed in the hope that it will be useful,
**  but WITHOUT ANY WARRANTY; without even the implied warranty of
**  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
**  GNU General Public License for more details.
**
**  You should have received a copy of the GNU General Public License
**  along with this program; if not, write to the Free Software
**  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
**
**  Mac OS X message box
*/

#include <stdlib.h>
#include <stdio.h>
#include <string.h>
#include <unistd.h>
#include <dirent.h>
#include <sys/stat.h>

#import <Cocoa/Cocoa.h>

#include "system.h"
#include "6502.h"
#include "via.h"
#include "8912.h"
#include "gui.h"
#include "disk.h"
#include "monitor.h"
#include "6551.h"
#include "machine.h"
#include "msgbox.h"

SDL_bool init_msgbox( struct machine *oric )
{
  return SDL_TRUE;
}

void shut_msgbox( struct machine *oric )
{
}

SDL_bool msgbox( struct machine *oric, int type, char *msg )
{
  NSAlert *alert;
  switch( type )
  {
    case MSGBOX_YES_NO:
	  alert = [NSAlert alertWithMessageText:@"Oricutron Request" defaultButton:@"Yes" alternateButton:@"No" otherButton:nil informativeTextWithFormat:@"%s", msg];
	  return ([alert runModal] == NSAlertDefaultReturn);

    case MSGBOX_OK_CANCEL:
	  alert = [NSAlert alertWithMessageText:@"Oricutron Request" defaultButton:@"Ok" alternateButton:@"Cancel" otherButton:nil informativeTextWithFormat:@"%s", msg];
	  return ([alert runModal] == NSAlertDefaultReturn);
    
    case MSGBOX_OK:
	  alert = [NSAlert alertWithMessageText:@"Oricutron Request" defaultButton:@"Ok" alternateButton:nil otherButton:nil informativeTextWithFormat:@"%s", msg];
	  [alert runModal];
      return SDL_TRUE;
  }

  return SDL_TRUE;
}

gha: C, lang: cpp
{"overlap": 0.1938501000404358, "von_neumann": 1.8402153253555298}
gha: Python, lang: ini
﻿using System.Collections.Generic;
using FelicitySecurity.Core.FelicitySecurityDataServiceReference;
using System.Linq;

namespace FelicitySecurity.Core.BusinessLogic
{
    /// <summary>
    /// Applies business logic before calling on any Repository data methods. 
    /// </summary>
    public class FelicitySecurityBusinessLogic
    {
        #region Declarations
        FelicitySecurityDataServiceSoapClient client = new FelicitySecurityDataServiceSoapClient("BasicHttpBinding_IFelicityDataService");
        #endregion

        #region Constructors
        #endregion
        #region Methods
        /// <summary>
        /// calls the Add Administrator Repository method
        /// </summary>
        /// <param name="item">Administrators_dto</param>
        public void AddAdministrator(Administrators_dto item)
        {
            client.AddAdministrator(item);
        }

        /// <summary>
        /// calls the Find All Administrator Repository method
        /// </summary>
        /// <param name="item">Administrators_dto</param>
        public List<Administrators_dto> FindAllAdministrators()
        {
            return client.FindAllAdministrators().ToList();
        }

        /// <summary>
        /// calls the Add Member Repository method
        /// </summary>
        /// <param name="item">Members_dto</param>
        public void AddMember(Members_dto item)
        {
            client.AddMember(item);
        }

        /// <summary>
        /// calls the Find All Members Repository method
        /// </summary>
        /// <param name="item">Members_dto</param>
        public List<Members_dto> FindAllMembers()
        {
            return client.FindAllMembers().ToList();
        }

        /// <summary>
        /// calls the Add Staff Repository method
        /// </summary>
        /// <param name="item">Staff_dto</param>
        public void AddStaff(Staff_dto item)
        {
            client.AddStaff(item);
        }

        /// <summary>
        /// calls the Find All Staff Repository method
        /// </summary>
        /// <param name="item">Staff_dto</param>
        public List<Staff_dto> FindAllStaff(Staff_dto item)
        {
            return client.FindAllStaff().ToList();
        }

        /// <summary>
        /// Calls the Remove Administrator Repository method
        /// </summary>
        /// <param name="administratorId"></param>
        public void DeleteAdministrator(Administrators_dto item)
        {
            client.RemoveAdministrator(item);
        }

        /// <summary>
        /// Calls the Update Administrator Repository method
        /// </summary>
        /// <param name="item"></param>
        public void UpdateAdministrator(Administrators_dto item)
        {
            client.UpdateAdministrator(item);
        }

        /// <summary>
        /// Calls the Update Administrator Repository method
        /// </summary>
        /// <param name="item"></param>
        public void UpdateMember(Members_dto item)
        {
            client.UpdateMember(item);
        }

        /// <summary>
        /// Calls the Delete Member Repository method supplies a given memberId
        /// </summary>
        /// <param name="memberId"></param>
        public void DeleteMember(Members_dto item)
        {
            client.DeleteMember(item);
        }
        #endregion
    }
}

gha: C#, lang: c_sharp
# i18n (국제화)

Vuesion에는 다국어 관리를 좀 더 쉽게 만들어 줄 유용한 도구들이 있습니다.

## 기본 로케일 및 지원되는 로케일

`./vuesion/config.json` 파일에서 기본 로케일을 지정할 수 있습니다.

지원하길 원하는 다른 로케일을 추가할 수도 있습니다.
`extract-i18n-messages` 스크립트를 사용하면 선택한 로케일의 번역본을 추가할 수 있습니다.

아래는 예시 설정값입니다.

```json
  "i18n": {
    "defaultLocale": "en",
    "locales": [
        {
          "code": "en",
          "file": "en.json"
        },
        {
          "code": "ru",
          "file": "ru.json"
        }
    ]
    }
```

## 메시지 설정 및 사용

파일을 수정합니다. (예: `./src/pages/index.vue`)

```html
<template>
  <div>
      <landing-page-header />
      ...
  </div>
</template>
```

`$t` 와 주석을 사용하여 번역을 추가합니다. (현재 기본 로케일: `en`)

```html
<template>
  <div>
      {{ $t('home.test' /* this is a test!!! */) }}
      <landing-page-header />
      ...
  </div>
</template>
```

이후 `npm run extract-i18n-messages` 를 실행한 뒤, [http://localhost:3000/](http://localhost:3000/) 로 이동합니다.
`this is a test!!!` 라는 메시지를 좌상단에서 확인할 수 있습니다.

`./i18n/en.json` 파일을 확인해 보면, 아래와 같은 값이 등록되어 있습니다.
```json
{
...
  "home.test": "this is a test!!!"
}
```
`./i18n/ko.json` 파일도 확인을 해 보면, 정확히 동일한 키와 값이 추가되어 있습니다.

해당 값을 한국어로 번역해 봅시다.

```json
{
...
  "home.test": "헬로월드는 테스트입니다."
}
```

이후 다시 `npm run extract-i18n-messages` 를 실행합니다.

**기본 로케일이 en(영문) 이므로 ko(한국어)로 번역한 값은 덮어쓰기 되지 않습니다.**

Vue 컴포넌트에서 기본값을 변경하길 원한다면, 주석을 변경하면 됩니다 

```html
<template>
  <div>
      {{ $t('home.test' /* this is not a test!!! */) }}
      <landing-page-header />
      ...
  </div>
</template>
```

`npm run extract-i18n-messages` 명령어를 실행 한 뒤 `./i18n/en.json` 파일을 확인해 보면 값이 덮어쓰기 되어 있습니다.

```json
{
...
  "home.test": "this is not a test!!!"
}
```

기본 로케일 파일이 아닌 `./i18n/ko.json` 은 변경되지 않습니다.

```json
{
...
  "home.test": "헬로월드는 테스트입니다."
}
```

## 제약사항

HTML 태그를 메시지로 등록하려면, `<>` 대신 `[]` 를 사용해야 합니다.

```html
<template>
  <div>
    <div v-html="$t('home.link' /* [a href='https://example.com' target='_blank']this is a link[/a] */)" />
    ...
  </div>
</template>
```

gha: JavaScript, lang: markdown
# Librar.io

## Live Site

https://mcraepv.github.io/librar.io/

## Description

Librar.io allows users to create and save book journals of their favorite
novels, and search the google books API to find new ones! Users can then keep a
reading journal to help them stay motivated. Users can also find links to where
to buy the books their search queries return.

![Home Page](./assets/librariopic.png)

## Installation

Clone our repository to check out the code, or visit the live site above to see
it deployed.

## Usage

Try out the search, or add a book you're currently reading to the journal
section.

## Credits

### Foundation

https://get.foundation/

### jQuery

https://jquery.com/

### Google Books API

https://developers.google.com/books

### Firebase

https://firebase.google.com/

### Font Awesome

https://fontawesome.com/

## License

MIT License

Copyright (c) 2020 Charles McRae Peavy & Mina Ghaffar

Permission is hereby granted, free of charge, to any person obtaining a copy of
this software and associated documentation files (the "Software"), to deal in
the Software without restriction, including without limitation the rights to
use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
the Software, and to permit persons to whom the Software is furnished to do so,
subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

## Developers

### Charles McRae Peavy

#### LinkedIn

https://www.linkedin.com/in/mcraepv/

#### Github

https://github.com/mcraepv

### Mariam Ghaffar

#### LinkedIn

https://www.linkedin.com/in/mariam-ghaffar-22852957/

#### Github

https://github.com/mghaffar89

gha: JavaScript, lang: markdown
﻿// Copyright © 2017 - 2021 Chocolatey Software, Inc
// Copyright © 2011 - 2017 RealDimensions Software, LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
//
// You may obtain a copy of the License at
//
// 	http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

namespace chocolatey.infrastructure.app.configuration
{
    using System;
    using System.Collections;
    using System.Collections.Generic;
    using System.ComponentModel;
    using System.Linq;
    using System.Reflection;
    using System.Security.Principal;
    using System.Text;
    using adapters;
    using logging;
    using nuget;
    using Environment = adapters.Environment;

    public static class EnvironmentSettings
    {
        private const string SET_ENVIRONMENT_METHOD = "SetEnvironment";
        private static Lazy<IEnvironment> _environmentInitializer = new Lazy<IEnvironment>(() => new Environment());

        [EditorBrowsable(EditorBrowsableState.Never)]
        public static void initialize_with(Lazy<IEnvironment> environment)
        {
            _environmentInitializer = environment;
        }

        private static IEnvironment Environment
        {
            get { return _environmentInitializer.Value; }
        }

        public static void reset_environment_variables(ChocolateyConfiguration config)
        {
            Environment.SetEnvironmentVariable(ApplicationParameters.Environment.ChocolateyPackageInstallLocation, null);
            Environment.SetEnvironmentVariable(ApplicationParameters.Environment.ChocolateyPackageInstallerType, null);
            Environment.SetEnvironmentVariable(ApplicationParameters.Environment.ChocolateyPackageExitCode, null);

            Environment.SetEnvironmentVariable(ApplicationParameters.Environment.ChocolateyIgnoreChecksums, null);
            Environment.SetEnvironmentVariable(ApplicationParameters.Environment.ChocolateyAllowEmptyChecksums, null);
            Environment.SetEnvironmentVariable(ApplicationParameters.Environment.ChocolateyAllowEmptyChecksumsSecure, null);
            Environment.SetEnvironmentVariable(ApplicationParameters.Environment.ChocolateyPowerShellHost, null);
            Environment.SetEnvironmentVariable(ApplicationParameters.Environment.ChocolateyForce, null);
            Environment.SetEnvironmentVariable(ApplicationParameters.Environment.ChocolateyExitOnRebootDetected, null);

            Environment.SetEnvironmentVariable("chocolateyProxyLocation", null);
            Environment.SetEnvironmentVariable("chocolateyProxyBypassList", null);
            Environment.SetEnvironmentVariable("chocolateyProxyBypassOnLocal", null);
        }

        public static void set_environment_variables(ChocolateyConfiguration config)
        {
            reset_environment_variables(config);

            Environment.SetEnvironmentVariable(ApplicationParameters.ChocolateyInstallEnvironmentVariableName, ApplicationParameters.InstallLocation);
            Environment.SetEnvironmentVariable("CHOCOLATEY_VERSION", config.Information.ChocolateyVersion);
            Environment.SetEnvironmentVariable("CHOCOLATEY_VERSION_PRODUCT", config.Information.ChocolateyProductVersion);
            Environment.SetEnvironmentVariable("OS_PLATFORM", config.Information.PlatformType.get_description_or_value());
            Environment.SetEnvironmentVariable("OS_VERSION", config.Information.PlatformVersion.to_string());
            Environment.SetEnvironmentVariable("OS_NAME", config.Information.PlatformName.to_string());
            // experimental until we know if this value returns correctly based on the OS and not the current process.
            Environment.SetEnvironmentVariable("OS_IS64BIT", config.Information.Is64BitOperatingSystem ? "true" : "false");
            Environment.SetEnvironmentVariable("PROCESS_IS64BIT", config.Information.Is64BitProcess ? "true" : "false");
            Environment.SetEnvironmentVariable("USER_NAME", config.Information.UserName);
            Environment.SetEnvironmentVariable("USER_DOMAIN", config.Information.UserDomainName);
            Environment.SetEnvironmentVariable("IS_ADMIN", config.Information.IsUserAdministrator ? "true" : "false");
            Environment.SetEnvironmentVariable("IS_SYSTEM", config.Information.IsUserSystemAccount ? "true" : "false");
            Environment.SetEnvironmentVariable("IS_REMOTEDESKTOP", config.Information.IsUserRemoteDesktop ? "true" : "false");
            Environment.SetEnvironmentVariable("IS_REMOTE", config.Information.IsUserRemote ? "true" : "false");
            Environment.SetEnvironmentVariable("IS_PROCESSELEVATED", config.Information.IsProcessElevated ? "true" : "false");
            Environment.SetEnvironmentVariable("TEMP", config.CacheLocation);
            Environment.SetEnvironmentVariable("TMP", config.CacheLocation);

            if (config.Debug) Environment.SetEnvironmentVariable("ChocolateyEnvironmentDebug", "true");
            if (config.Verbose) Environment.SetEnvironmentVariable("ChocolateyEnvironmentVerbose", "true");
            if (!config.Features.ChecksumFiles) Environment.SetEnvironmentVariable(ApplicationParameters.Environment.ChocolateyIgnoreChecksums, "true");
            if (config.Features.AllowEmptyChecksums) Environment.SetEnvironmentVariable(ApplicationParameters.Environment.ChocolateyAllowEmptyChecksums, "true");
            if (config.Features.AllowEmptyChecksumsSecure) Environment.SetEnvironmentVariable(ApplicationParameters.Environment.ChocolateyAllowEmptyChecksumsSecure, "true");

            Environment.SetEnvironmentVariable("chocolateyRequestTimeout", config.WebRequestTimeoutSeconds.to_string() + "000");

            if (config.CommandExecutionTimeoutSeconds != 0)
            {
                Environment.SetEnvironmentVariable("chocolateyResponseTimeout", config.CommandExecutionTimeoutSeconds.to_string() + "000");
            }

            if (!string.IsNullOrWhiteSpace(config.Proxy.Location))
            {
                var proxyCreds = string.Empty;
                if (!string.IsNullOrWhiteSpace(config.Proxy.User) &&
                    !string.IsNullOrWhiteSpace(config.Proxy.EncryptedPassword)
                    )
                {
                    proxyCreds = "{0}:{1}@".format_with(config.Proxy.User, NugetEncryptionUtility.DecryptString(config.Proxy.EncryptedPassword));

                    Environment.SetEnvironmentVariable("chocolateyProxyUser", config.Proxy.User);
                    Environment.SetEnvironmentVariable("chocolateyProxyPassword", NugetEncryptionUtility.DecryptString(config.Proxy.EncryptedPassword));
                }

                Environment.SetEnvironmentVariable("http_proxy", "{0}{1}".format_with(proxyCreds, config.Proxy.Location));
                Environment.SetEnvironmentVariable("https_proxy", "{0}{1}".format_with(proxyCreds, config.Proxy.Location));
                Environment.SetEnvironmentVariable("chocolateyProxyLocation", config.Proxy.Location);

                if (!string.IsNullOrWhiteSpace(config.Proxy.BypassList))
                {
                    Environment.SetEnvironmentVariable("chocolateyProxyBypassList", config.Proxy.BypassList);
                    Environment.SetEnvironmentVariable("no_proxy", config.Proxy.BypassList);

                }

                if (config.Proxy.BypassOnLocal) Environment.SetEnvironmentVariable("chocolateyProxyBypassOnLocal", "true");
            }

            if (config.Features.UsePowerShellHost) Environment.SetEnvironmentVariable(ApplicationParameters.Environment.ChocolateyPowerShellHost, "true");
            if (config.Force) Environment.SetEnvironmentVariable(ApplicationParameters.Environment.ChocolateyForce, "true");
            if (config.Features.ExitOnRebootDetected) Environment.SetEnvironmentVariable(ApplicationParameters.Environment.ChocolateyExitOnRebootDetected, "true");
            set_licensed_environment(config);
        }

        private static void set_licensed_environment(ChocolateyConfiguration config)
        {
            if (!config.Information.IsLicensedVersion) return;

            Environment.SetEnvironmentVariable("ChocolateyLicenseType", config.Information.LicenseType);

            var licenseAssembly = AppDomain.CurrentDomain.GetAssemblies().FirstOrDefault(a => a.GetName().Name.is_equal_to("chocolatey.licensed"));

            if (licenseAssembly != null)
            {
                Type licensedEnvironmentSettings = licenseAssembly.GetType(ApplicationParameters.LicensedEnvironmentSettings, throwOnError: false, ignoreCase: true);

                if (licensedEnvironmentSettings == null)
                {
                    if (config.RegularOutput) "chocolatey".Log().Warn(
                        ChocolateyLoggers.Important, @"Unable to set licensed environment settings. Please upgrade to a newer
 licensed version (choco upgrade chocolatey.extension).");
                    return;
                }
                try
                {
                    object componentClass = Activator.CreateInstance(licensedEnvironmentSettings);

                    licensedEnvironmentSettings.InvokeMember(
                        SET_ENVIRONMENT_METHOD,
                        BindingFlags.InvokeMethod,
                        null,
                        componentClass,
                        new Object[] { config }
                        );
                }
                catch (Exception ex)
                {
                    var isDebug = ApplicationParameters.is_debug_mode_cli_primitive();
                    if (config.Debug) isDebug = true;
                    var message = isDebug ? ex.ToString() : ex.Message;

                    if (isDebug && ex.InnerException != null)
                    {
                        message += "{0}{1}".format_with(Environment.NewLine, ex.InnerException.ToString());
                    }

                    "chocolatey".Log().Error(
                        ChocolateyLoggers.Important,
                        @"Error when setting environment for '{0}':{1} {2}".format_with(
                            licensedEnvironmentSettings.FullName,
                            Environment.NewLine,
                            message
                            ));
                }
            }
        }

        /// <summary>
        ///   Refreshes the current environment values with the updated values,
        ///   even if updated outside of the current process.
        /// </summary>
        /// <remarks>
        ///   This does not remove environment variables, but will ensure all updates are shown.
        ///   To see actual update with removed variables, one will need to restart a shell.
        /// </remarks>
        public static void update_environment_variables()
        {
            // grab original values
            var originalEnvironmentVariables = convert_to_case_insensitive_dictionary(Environment.GetEnvironmentVariables(EnvironmentVariableTarget.Process));
            var userName = originalEnvironmentVariables[ApplicationParameters.Environment.Username].to_string();
            var architecture = originalEnvironmentVariables[ApplicationParameters.Environment.ProcessorArchitecture].to_string();
            var originalPath = originalEnvironmentVariables[ApplicationParameters.Environment.Path]
                .to_string()
                .Split(new[] { ApplicationParameters.Environment.EnvironmentSeparator }, StringSplitOptions.RemoveEmptyEntries);
            var originalPathExt = originalEnvironmentVariables[ApplicationParameters.Environment.PathExtensions]
                .to_string()
                .Split(new[] { ApplicationParameters.Environment.EnvironmentSeparator }, StringSplitOptions.RemoveEmptyEntries);
            var originalPsModulePath = originalEnvironmentVariables[ApplicationParameters.Environment.PsModulePath]
                .to_string()
                .Split(new[] { ApplicationParameters.Environment.EnvironmentSeparator }, StringSplitOptions.RemoveEmptyEntries);

            // get updated values from the registry
            var machineVariables = convert_to_case_insensitive_dictionary(Environment.GetEnvironmentVariables(EnvironmentVariableTarget.Machine));
            var userVariables = convert_to_case_insensitive_dictionary(Environment.GetEnvironmentVariables(EnvironmentVariableTarget.User));

            // refresh current values with updated values, machine first
            refresh_environment_variables(machineVariables);

            //if the user is SYSTEM, we should not even look at user Variables
            var setUserEnvironmentVariables = true;
            try
            {
                var userIdentity = WindowsIdentity.GetCurrent();
                if (userIdentity != null && userIdentity.User == ApplicationParameters.LocalSystemSid)
                {
                    setUserEnvironmentVariables = false;
                }
            }
            catch (Exception ex)
            {
                "chocolatey".Log().Debug("Unable to determine current user to determine if LocalSystem account (to skip user env vars).{0} Reported error: {1}".format_with(Environment.NewLine, ex.Message));
            }

            if (setUserEnvironmentVariables) refresh_environment_variables(userVariables);

            // restore process overridden variables
            if (originalEnvironmentVariables.Contains(ApplicationParameters.Environment.Username)) Environment.SetEnvironmentVariable(ApplicationParameters.Environment.Username, userName);
            if (originalEnvironmentVariables.Contains(ApplicationParameters.Environment.ProcessorArchitecture)) Environment.SetEnvironmentVariable(ApplicationParameters.Environment.ProcessorArchitecture, architecture);

            // combine environment values that append together
            var updatedPath = "{0};{1};".format_with(
                machineVariables[ApplicationParameters.Environment.Path].to_string(),
                userVariables[ApplicationParameters.Environment.Path].to_string()
                ).Replace(";;", ";");
            var updatedPathExt = "{0};{1};".format_with(
                machineVariables[ApplicationParameters.Environment.PathExtensions].to_string(),
                userVariables[ApplicationParameters.Environment.PathExtensions].to_string()
                ).Replace(";;", ";");
            var updatedPsModulePath = "{0};{1};".format_with(
                userVariables[ApplicationParameters.Environment.PsModulePath].to_string(),
                machineVariables[ApplicationParameters.Environment.PsModulePath].to_string()
                ).Replace(";;", ";");

            // add back in process items
            updatedPath += gather_process_only_items(updatedPath, originalPath);
            updatedPathExt += gather_process_only_items(updatedPathExt, originalPathExt);
            updatedPsModulePath = "{0};{1}".format_with(gather_process_only_items(updatedPsModulePath, originalPsModulePath),updatedPsModulePath);

            if (!updatedPsModulePath.contains(ApplicationParameters.PowerShellModulePathProcessProgramFiles))
            {
                updatedPsModulePath = "{0};{1}".format_with(ApplicationParameters.PowerShellModulePathProcessProgramFiles, updatedPsModulePath).Replace(";;", ";");
            }

            if (!updatedPsModulePath.contains(ApplicationParameters.PowerShellModulePathProcessDocuments))
            {
                updatedPsModulePath = "{0};{1}".format_with(ApplicationParameters.PowerShellModulePathProcessDocuments, updatedPsModulePath).Replace(";;", ";");
            }

            if (updatedPsModulePath.StartsWith(";"))
            {
                updatedPsModulePath = updatedPsModulePath.Remove(0, 1);
            }

            Environment.SetEnvironmentVariable(ApplicationParameters.Environment.Path, updatedPath);
            Environment.SetEnvironmentVariable(ApplicationParameters.Environment.PathExtensions, updatedPathExt);
            Environment.SetEnvironmentVariable(ApplicationParameters.Environment.PsModulePath, updatedPsModulePath);
        }

        private static IDictionary convert_to_case_insensitive_dictionary(IDictionary originalDictionary)
        {
            if (originalDictionary == null) return new Hashtable(new Dictionary<string, string>(), StringComparer.OrdinalIgnoreCase);

            return new Hashtable(originalDictionary, StringComparer.OrdinalIgnoreCase);
        }

        private static void refresh_environment_variables(IDictionary environmentVariables)
        {
            foreach (DictionaryEntry variable in environmentVariables.or_empty_list_if_null())
            {
                Environment.SetEnvironmentVariable(variable.Key.to_string(), variable.Value.to_string());
            }
        }

        private static string gather_process_only_items(string currentValues, IEnumerable<string> originalValues)
        {
            var additionalItems = new StringBuilder();
            var items = currentValues.Split(
                new[] { ApplicationParameters.Environment.EnvironmentSeparator },
                StringSplitOptions.RemoveEmptyEntries
                );

            foreach (string originalValue in originalValues.or_empty_list_if_null())
            {
                if (!items.Contains(originalValue, StringComparer.InvariantCultureIgnoreCase))
                {
                    additionalItems.AppendFormat("{0};", originalValue);
                }
            }

            return additionalItems.to_string();
        }
    }
}

gha: C#, lang: groovy
function []=SCHISM_SLAB(icomb,base,varname,s_or_z,lev_or_zcor,ispher_nowrap,stacks,nspool,test)
% Authors: Joseph Zhang
% Date: Feb 2019
% Matlab function to visualize horizontal slabs at either a fix z level
% or at a fix sigma level. Works for node-centered variables only!
% For a fixed z level, nan is used for above surface/below bottom.
% Works for mixed grid.
% Requires get_global_info.m (in this dir)
% SCHISM_SLAB(icomb,base,varname,s_or_z,lev_or_zcor,stacks,nspool,test)
% Inputs: 
%         icomb: work with uncombined (0) or combined (1) nc 
%         base: base directory where base/outputs/ contains nc outputs schout_*.nc
%         varname = var names like 'salt' etc (node based only)
%         s_or_z = 'S' (along a fixed sigma level) or 'Z' (along a fix z level).
%                  This is not used for 2D variables.
%         lev_or_zcor = level index (1 to nvrt) if s_or_z='S'; z-coordinate value 
%                       (z<0 is below MSL) if s_or_z='Z'. 
%                       This is not used for 2D variables.
%         ispher_nowrap: for spherical grid only. 1: remove wrap-around elem's across dateline in scalar display. 0: original
%         stacks: array of stack numbers (e.g. [2 4 5]) in the output file names (related to time)
%         nspool: sub-sampling frequency within each stack (e.g. '1' - include all)
%         test: 'y' (only plot out 1st frame for test); 'n' (plot all frames)
%         May need to adjust some parameters inside (e.g. caxis) to get right appearance of images
% Outputs: images and slab.avi

close all; 
%scrsz(1:2)=1; scrsz(3)=width (pixels), scrsz(4)=height
scrsz = get(0,'ScreenSize'); 
%4 parameters of position: left bottom_coord width height
figure('Position',[1 scrsz(4)*0.2 scrsz(3)/2 scrsz(4)*0.7]); 

% Read the variable and the vertical grid
delete('slab.avi');
vidObj = VideoWriter('slab.avi');
vidObj.FrameRate = 30;  % Default 30; smaller ->slower
%vidObj.Quality = 50;    % Default 75
open(vidObj);

if(strcmp(test,'y'))
  stacks2=stacks(1); 
else
  stacks2=stacks; 
end

%Get basic info
[ne,np,nvrt,nm,xy00,i23d,ivs,vzcor,vid5,vdry_e,h0,dp,kbp00,vid_eta,nproc,np_lcl,ne_lcl,ns_lcl,iplg,ielg,iegl_rank]=get_global_info(icomb,base,varname,stacks);

%xy00(np,:)
%nm(:,end)
%vzcor

%Mark all nodes in wrap-around elements for scalar display later
if(ispher_nowrap==1)
  %If a node is on dateline, make it 180 deg
  xtmp=xy00(:,1);
  xtmp(find(xtmp==-180))=180;
  xy00(:,1)=xtmp;
  icolor_nd(1:np)=0;
  for i=1:ne
    lon_min=1.e10; lon_max=-1.e10;
    if(isnan(nm(4,i))) 
      i34=3;
    else
      i34=4;
    end
    lon_min=min(xy00(nm(1:i34,i),1));
    lon_max=max(xy00(nm(1:i34,i),1));
    if(lon_min<-100 && lon_max>100)
      icolor_nd(nm(1:i34,i))=1;
    end
  end %for i
end %ispher_nowrap==1

%For plotting vector scales
xmax=max(xy00(:,1)); 
xmin=min(xy00(:,1)); 
ymax=max(xy00(:,2));
ymin=min(xy00(:,2));

%Prep output array
if(strcmp(s_or_z,'S') || i23d==1)
  out5=zeros(ivs,np);
else
  out5=zeros(ivs,nvrt,np);
  %zcor=zeros(nvrt,np);
end

istep=0;
for day=stacks2
  istep=istep+1;

  if(icomb==0) 
    fname=[base,'/outputs/' 'schout_000000_' num2str(day) '.nc'];
  else
    fname=[base,'/outputs/' 'schout_' num2str(day) '.nc'];
  end
  disp(['doing ' fname]);
  ncid0 = netcdf.open(fname,'NC_NOWRITE');

  vid=netcdf.inqVarID(ncid0,'time');
  timeout0=double(netcdf.getVar(ncid0, vid)); %sec
  nrec=length(timeout0);

  if(strcmp(test,'y'))
    it2=1;
  else
    it2=nrec;
  end

  for it=1:nspool:it2;
    timeout=timeout0(it);
    time_d=fix(timeout/86400); %days
    time_h=fix((timeout-time_d*86400)/3600);
    time_m=fix((timeout-time_d*86400-time_h*3600)/60);
    time_s=timeout-time_d*86400-time_h*3600-time_m*60;

    %out5(ivs,np) if 2D or 'S'; otherwise out5(ivs,nvrt,np)
    if(icomb==0) 
      for irank=0:nproc-1
        fname3=[base '/outputs/schout_' num2str(irank,'%06.f') '_' num2str(day) '.nc'];
        ncid3 = netcdf.open(fname3,'NC_NOWRITE');
        
        clear tmp tmp2 tmp3;
        tmp3=double(netcdf.getVar(ncid3,vid_eta,[0 it-1],[np_lcl(irank+1) 1])); 
        eta2(iplg(irank+1,1:np_lcl(irank+1)))=tmp3;

        if(ivs==1) 
          if(i23d==1) %2D
            tmp=double(netcdf.getVar(ncid3,vid5,[0 it-1],[np_lcl(irank+1) 1])); %(np_lcl)
            out5(1,iplg(irank+1,1:np_lcl(irank+1)))=tmp;
          elseif(strcmp(s_or_z,'S'))
            tmp=double(netcdf.getVar(ncid3,vid5,[lev_or_zcor-1 0 it-1],[1 np_lcl(irank+1) 1])); %(np_lcl)
            out5(1,iplg(irank+1,1:np_lcl(irank+1)))=tmp;
          elseif(strcmp(s_or_z,'Z'))
            tmp=double(netcdf.getVar(ncid3,vid5,[0 0 it-1],[nvrt np_lcl(irank+1) 1])); %(nvrt,np_lcl)
            out5(1,:,iplg(irank+1,1:np_lcl(irank+1)))=tmp;
            tmp2=double(netcdf.getVar(ncid3,vzcor,[0 0 it-1],[nvrt np_lcl(irank+1) 1])); %(nvrt,np_lcl)
            zcor(:,iplg(irank+1,1:np_lcl(irank+1)))=tmp2;
          else
            error('Unknown s_or_z');
          end
        elseif(ivs==2)
          if(i23d==1) %2D
            tmp=double(netcdf.getVar(ncid3,vid5,[0 0 it-1],[2 np_lcl(irank+1) 1])); %(ivs,np_lcl)
            out5(1:2,iplg(irank+1,1:np_lcl(irank+1)))=tmp;
          elseif(strcmp(s_or_z,'S'))
            tmp=double(netcdf.getVar(ncid3,vid5,[0 lev_or_zcor-1 0 it-1],[2 1 np_lcl(irank+1) 1])); %(ivs,np_lcl)
            out5(1:2,iplg(irank+1,1:np_lcl(irank+1)))=tmp;
          elseif(strcmp(s_or_z,'Z'))
            tmp=double(netcdf.getVar(ncid3,vid5,[0 0 0 it-1],[2 nvrt np_lcl(irank+1) 1])); %(ivs,nvrt,np_lcl)
            out5(1:2,:,iplg(irank+1,1:np_lcl(irank+1)))=tmp;
            tmp2=double(netcdf.getVar(ncid3,vzcor,[0 0 it-1],[nvrt np_lcl(irank+1) 1])); %(nvrt,np_lcl)
            zcor(:,iplg(irank+1,1:np_lcl(irank+1)))=tmp2;
          else
            error('Unknown s_or_z');
          end
        else
          error('Unknown ivs');
        end %ivs

        netcdf.close(ncid3);
      end %for irank
    else %icomb=1 (combined)
      eta2=double(netcdf.getVar(ncid0,vid_eta,[0 it-1],[np 1]));
      if(ivs==1) 
        if(i23d==1) %2D
          out5(1,:)=double(netcdf.getVar(ncid0,vid5,[0 it-1],[np 1])); %(np)
        elseif(strcmp(s_or_z,'S'))
          out5(1,:)=double(netcdf.getVar(ncid0,vid5,[lev_or_zcor-1 0 it-1],[1 np 1])); %(np)
        elseif(strcmp(s_or_z,'Z'))
          out5(1,:,:)=double(netcdf.getVar(ncid0,vid5,[0 0 it-1],[nvrt np 1])); %(nvrt,np)
          zcor=double(netcdf.getVar(ncid0,vzcor,[0 0 it-1],[nvrt np 1])); %(nvrt,np)
        else
          error('Unknown s_or_z');
        end
      elseif(ivs==2)
        if(i23d==1) %2D
          out5=double(netcdf.getVar(ncid0,vid5,[0 0 it-1],[2 np 1])); %(ivs,np)
        elseif(strcmp(s_or_z,'S'))
          out5=double(netcdf.getVar(ncid0,vid5,[0 lev_or_zcor-1 0 it-1],[2 1 np 1])); %(ivs,np)
        elseif(strcmp(s_or_z,'Z'))
          out5=double(netcdf.getVar(ncid0,vid5,[0 0 0 it-1],[2 nvrt np 1])); %(ivs,nvrt,np)
          zcor=double(netcdf.getVar(ncid0,vzcor,[0 0 it-1],[nvrt np 1])); %(nvrt,np)
        else
          error('Unknown s_or_z');
        end
      else
        error('Unknown ivs');
      end %ivs
    end %icomb

    %Construct output uout(ivs,1:np) 
    if(i23d==1 || strcmp(s_or_z,'S'))
      uout=out5;
      %Mask dry nodes
      indx=find(eta2+dp<=h0);
      uout(:,indx)=nan;
    else
      %Interp in vertical @ wet spots only
      uout=NaN(ivs,np);
      for ii=1:np
        if(eta2(ii)+dp(ii)>h0)
%          indx=find(~isnan(zcor(:,ii)) & abs(zcor(:,ii))<1.e15);
%          indx2=indx(find(indx>=kbp00(ii)));
          for j=1:ivs
            uout(j,ii)=interp1(zcor(kbp00(ii):nvrt,ii),out5(j,kbp00(ii):nvrt,ii),lev_or_zcor,'linear',nan);
          end %j
        end %if
      end %ii
    end

    %Define junk
    uout(find(abs(uout)>1.e20))=nan;

    % plot uout
    % set axes
    v2=[xmin xmax ymin ymax]; %axis;
    % Write time stamp info
    loc_info_x=(v2(2)+v2(1))/2;
    loc_info_y=v2(4)*0.97+v2(3)*0.03;

    if(ivs==1) %scalar
      uout_p=uout(1,:);
      %Remove elem across dateline
      if(ispher_nowrap==1)
        uout_p(find(icolor_nd==1))=nan;
      end %ispher_nowrap

      h1=patch('Faces',nm','Vertices',xy00,'FaceVertexCData',uout_p','FaceColor','interp','EdgeColor','none');
      colormap(jet(40));
      % Set colormap range
      caxis([0 30]); colorbar;
    else %vector
      loc_scale_x=v2(2)*0.3+v2(1)*0.7;
      loc_scale_y=-v2(4)*0.02+v2(3)*1.02;
      x_aug=[xy00(:,1)' loc_scale_x];
      y_aug=[xy00(:,2)' loc_scale_y];
      quiver(x_aug,y_aug,[uout(1,:) 1],[uout(2,:) 0]);
      text(loc_scale_x,loc_scale_y,'1 m/s');

      %Alternatively, plot vector magnitude
%      h1=patch('Faces',nm','Vertices',xy00,'FaceVertexCData',sqrt(uout(1,:).^2+uout(2,:).^2)','FaceColor','interp','EdgeColor','none');
%      colormap(jet(40));
%      caxis([0 1]); colorbar;

    end %ivs

    axis([xmin xmax ymin ymax]);
    %axis([3.2e5 3.7e5 2.5e5 3.1e5]);
    text(loc_info_x,loc_info_y,{'Time (DD:HH:MM:SS)'; num2str([time_d time_h time_m time_s])});

    %axis off;

    % Add image to avi file
    set(gcf,'Color',[1 1 1]);
    set(gcf,'nextplot','replacechildren');
    currFrame = getframe(gcf);
    writeVideo(vidObj,currFrame);
    if(day ~= stacks2(end) || it ~=it2)
      clf; %clear figure to avoid overlay
    end

  end %it
  netcdf.close(ncid0);
end %for day=stacks2
close(vidObj);

gha: LLVM, lang: matlab
#
# Copyright (c) 2004-2005 The Trustees of Indiana University and Indiana
#                         University Research and Technology
#                         Corporation.  All rights reserved.
# Copyright (c) 2004-2005 The University of Tennessee and The University
#                         of Tennessee Research Foundation.  All rights
#                         reserved.
# Copyright (c) 2004-2005 High Performance Computing Center Stuttgart,
#                         University of Stuttgart.  All rights reserved.
# Copyright (c) 2004-2005 The Regents of the University of California.
#                         All rights reserved.
# $COPYRIGHT$
#
# Additional copyrights may follow
#
# $HEADER$
#



TESTS_ENVIRONMENT = $(SHELL) $(srcdir)/run_tests

check_PROGRAMS = \
	atomic_barrier \
	atomic_barrier_noinline \
	atomic_spinlock \
	atomic_spinlock_noinline \
	atomic_math \
	atomic_math_noinline \
	atomic_cmpset \
	atomic_cmpset_noinline

TESTS = \
	$(check_PROGRAMS)

EXTRA_DIST = run_tests
AM_CFLAGS = $(THREAD_CFLAGS)

######################################################################

atomic_barrier_SOURCES = atomic_barrier.c

atomic_barrier_noinline.c:
	ln -s $(top_srcdir)/test/asm/atomic_barrier.c atomic_barrier_noinline.c
atomic_barrier_noinline_SOURCES = atomic_barrier_noinline.c
atomic_barrier_noinline_CFLAGS = $(AM_CFLAGS) -DOMPI_DISABLE_INLINE_ASM

######################################################################

atomic_spinlock_SOURCES = atomic_spinlock.c
atomic_spinlock_CFLAGS = $(AM_CFLAGS)
atomic_spinlock_LDADD = $(libs)

atomic_spinlock_noinline.c:
	ln -s $(top_srcdir)/test/asm/atomic_spinlock.c atomic_spinlock_noinline.c
atomic_spinlock_noinline_SOURCES = atomic_spinlock_noinline.c
atomic_spinlock_noinline_CFLAGS = $(AM_CFLAGS) -DOMPI_DISABLE_INLINE_ASM
atomic_spinlock_noinline_LDADD = $(THREAD_LDFLAGS) $(THREAD_LIBS) $(libs)

######################################################################

atomic_math_SOURCES = atomic_math.c
atomic_math_CFLAGS = $(AM_CFLAGS)
atomic_math_LDADD = $(THREAD_LDFLAGS) $(THREAD_LIBS) $(libs)

atomic_math_noinline.c:
	ln -s $(top_srcdir)/test/asm/atomic_math.c atomic_math_noinline.c
atomic_math_noinline_SOURCES = atomic_math_noinline.c
atomic_math_noinline_CFLAGS = $(AM_CFLAGS) -DOMPI_DISABLE_INLINE_ASM
atomic_math_noinline_LDADD = $(THREAD_LDFLAGS) $(THREAD_LIBS) $(libs)

######################################################################

atomic_cmpset_SOURCES = atomic_cmpset.c
atomic_cmpset_CFLAGS = $(AM_CFLAGS)
atomic_cmpset_LDADD = $(THREAD_LDFLAGS) $(THREAD_LIBS) $(libs)

atomic_cmpset_noinline.c:
	ln -s $(top_srcdir)/test/asm/atomic_cmpset.c atomic_cmpset_noinline.c
atomic_cmpset_noinline_SOURCES = atomic_cmpset_noinline.c
atomic_cmpset_noinline_CFLAGS = $(AM_CFLAGS) -DOMPI_DISABLE_INLINE_ASM
atomic_cmpset_noinline_LDADD = $(THREAD_LDFLAGS) $(THREAD_LIBS) $(libs)

######################################################################


maintainer-clean-local:
	rm -f atomic_barrier_noinline.c \
	atomic_spinlock_noinline.c \
	atomic_math_noinline.c \
	atomic_cmpset_noinline.c

distclean-local:
	rm -rf *.dSYM .deps .libs *.log *.o *.trs $(check_PROGRAMS) Makefile

gha: C, lang: makefile
﻿using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Linq;
using System.Text;
using System.Threading.Tasks;
using System.Windows.Forms;
using System.IO;
using System.Diagnostics;

namespace ChordCadenza.Forms {
  internal partial class frmCalcKeys : Form, IFormStream, IFormProjectName, ITT {
    private ToolTip _TT;
    public ToolTip TT {
      get { return _TT; }
      set { _TT = value; }
    }

    //public bool HideOrShowForm { get { return true; } }
    public void FormStreamOnOff(bool on) {
      if (on) Close(); 
    }

    private void frmCalcKeys_Load(object sender, EventArgs e) {
      BackColor = Utils.SetBackColor(Forms.frmSC.Mtx, BackColor);
      clsTT.LoadToolTips(this);
      #if !ADVANCED
        grpProfile.Hide();
        grpMinorKeyType.Hide();
      #endif
    }

    //private clsFileStream CSVFileSummary;
    private clsTrks.Array<bool> TrkSelect;
    private List<clsKeysAlg> KeysList;
    private List<string> KeysLabels;
    internal clsCFPC CF = null;
    private clsKeysAlg.clsSegments Segments;
    private string FileName;
    //internal static bool FormShown = false;
    //private bool indTrace = false;

    internal frmCalcKeys(clsTrks.Array<bool> trkselect) {
      //* load and show frmCalcKeys
      InitializeComponent();
      Forms.frmSC.ZZZSetPCKBEvs(this);
      chkChordFile.Checked = false;
      FileName = P.F.Project.MidiPath;
      TrkSelect = trkselect;
      lblTracksSelected.Text = Forms.frmChordMap.UpdateTrksSelected(TrkSelect);
      //P.F.indCalcKeys = true;
      SetFormTitle();
      //////cmdDebugSegs.Hide();  //show if debugging needed
      //////chkTrace.Hide();  //show if debugging needed
      string msg = Calculate(null, null); 
      if (msg != "") {
        MessageBox.Show("Calc Keys failed: " + msg);
        return;  //don't show form
      }
      //if (showdialog) ShowDialog(); else Utils.FormAct(this);
      ShowDialog();
      EnableApply(true);
      WindowState = FormWindowState.Normal;
    }

    protected override bool ProcessCmdKey(ref Message msg, Keys keyData) {
      bool? ret = Forms.frmSC.StaticProcessCmdKey(ref msg, keyData);
      if (!ret.HasValue) return base.ProcessCmdKey(ref msg, keyData);
      return ret.Value;
    }

    //internal frmCalcKeys(clsFileStream fs, clsTrks.Array<bool> trkselect, int inertia) {
    //  //*  don't show the form - just calculate
    //  InitializeComponent();
    //  chkChordFile.Checked = false;
    //  TrkSelect = trkselect;
    //  lblTracksSelected.Text = Forms.frmChordMap.UpdateTrksSelected(TrkSelect);
    //  P.F.indCalcKeys = true;
    //  string msg = Calculate(fs, inertia);
    //  if (msg != "") {
    //    MessageBox.Show("CalcKeys failed: " + msg);
    //    return;
    //  }
    //  Apply();
    //}

    internal frmCalcKeys() {  //use ChordFile
      //* load and show frmCalcKeys
      InitializeComponent();
      chkChordFile.Checked = true;
      lblTracksSelected.Text = "";
      //P.F.indCalcKeys = false;
      SetFormTitle();
      string msg = Calculate(null, null);
      if (msg != "") {
        MessageBox.Show("Calc Keys failed: " + msg);
        return;  //don't show form
      }
      //ShowDialog();
      EnableApply(true);
      WindowState = FormWindowState.Normal;
      //Activate();
      Utils.FormAct(this);
    }

    public void SetFormTitle() {  //interface IFormProjectName
      SetFormTitle(P.F.Project);
    }

    public void SetFormTitle(clsProject project) {  //interface IFormProjectName

      Text = "Calculate Keys: " + FileName + " - Chord Cadenza";
    }

    private void cmdCalculate_Click(object sender, EventArgs e) {
      string msg = Calculate(null, null);
      if (msg != "") {
        MessageBox.Show("CalcKeys failed: " + msg);
        EnableApply(false);
      }
      EnableApply(true);
    }

    private void EnableApply(bool ena) {
      //cmdApply0.Enabled = ena;
      //cmdApply1.Enabled = ena;
      //cmdApply2.Enabled = ena;
      //cmdApply3.Enabled = ena;
      //cmdApply4.Enabled = ena;
      //cmdApply5.Enabled = ena;
      cmdApply.Enabled = ena;
      cmdOK.Enabled = ena;
    }

    private void CalcMinorScores() {
      //* calculate minor key scores for different minor key types
      //* use currently selected inertia(penalty), alg, profile 

      //* calculate totals of each pitchclass for segements(bars) in a minor key
      int[] pctots = new int[12];  //pitchclass totals
      for (int i = 0; i < 12; i++) pctots[i] = 0;
      int index = (KeysList.Count > 1) ? GetInertia() : 0;
      if (KeysList.Count == 0) {
        LogicError.Throw(eStopError.Y003);  //unable to reproduce this, but it did happen!
        return;
      }
      clsKeysAlg keysalg = KeysList[index];
      clsKeysAlg.clsSegments segs = clsKeysAlg.Segments;
      for (int segnum = 0; segnum < keysalg.Keys.Count; segnum++) {
        clsKeyTicks key = keysalg.Keys[segnum];
        if (key != null && key.Scale == "minor") {
          if (segnum != key.BBT.Bar) {
            LogicError.Throw(eLogicError.X094);
            break;
          }
          for (int pc = 0; pc < 12; pc++) pctots[pc] += segs.Segs[segnum][pc];
        }
      }

      //* calculate totals of l/l- t/t- combinations
      int totharmonic = pctots[8] + pctots[11];  //l- t
      int totmelup = pctots[9] + pctots[11];  //l t
      int totmeldown = pctots[8] + pctots[10];  //l- t-
      int totspecial = pctots[9] + pctots[10];  //l t-

      lblTotHarmonic.Text = totharmonic.ToString();
      lblTotMelUp.Text = totmelup.ToString();
      lblTotMelDown.Text = totmeldown.ToString();
      lblTotSpecial.Text = totspecial.ToString();

      eMinorKeyType maxtottype = eMinorKeyType.Harmonic;
      int maxtot = totharmonic;

      if (totmelup > maxtot) {
        maxtottype = eMinorKeyType.MelodicUp;
        maxtot = totmelup;
      }

      if (totmeldown > maxtot) {
        maxtottype = eMinorKeyType.MelodicDown;
        maxtot = totmeldown;
      }

      if (totspecial > maxtot) {
        maxtottype = eMinorKeyType.Special;
        maxtot = totspecial;
      }

      FontStyle fontstyle;

      fontstyle = (maxtottype == eMinorKeyType.Harmonic) ? FontStyle.Bold : FontStyle.Regular;
      lblTotHarmonic.Font = new Font(lblTotHarmonic.Font, fontstyle);

      fontstyle = (maxtottype == eMinorKeyType.MelodicUp) ? FontStyle.Bold : FontStyle.Regular;
      lblTotMelUp.Font = new Font(lblTotMelUp.Font, fontstyle);

      fontstyle = (maxtottype == eMinorKeyType.MelodicDown) ? FontStyle.Bold : FontStyle.Regular;
      lblTotMelDown.Font = new Font(lblTotMelDown.Font, fontstyle);

      fontstyle = (maxtottype == eMinorKeyType.Special) ? FontStyle.Bold : FontStyle.Regular;
      lblTotSpecial.Font = new Font(lblTotSpecial.Font, fontstyle);

      if (chkUseHighestMinorKeyType.Checked) P.frmStart.MinorKeyType = maxtottype;
    }


    private string Calculate(clsFileStream fs, int? inertia) {
      KeysList = new List<clsKeysAlg>();
      KeysLabels = new List<string>();
      clsKeysAlg.eAlg alg = clsKeysAlg.eAlg.Weighted;
      if (optAlgFlat.Checked) alg = clsKeysAlg.eAlg.Flat;
      //clsFileStream csvfileconv;
      clsNoteMap notemap;

      if (chkChordFile.Checked) {
        if (P.F.CF?.Evs == null || P.F.CF.Evs.Count == 0) return "Empty ChordFile"; 
        notemap = P.F.CF.NoteMap;
      } else {
        if (fs != null) notemap = fs.NoteMap;
        else {
          try {
            notemap = (new clsFileStream(FileName, TrkSelect, true, false, true)).NoteMap;
          }
          catch (MidiFileException exc) {
            return "MidiFileException: " + exc.Message;
          }
        }
      }

      clsKeysAlg.eProfile profile = clsKeysAlg.eProfile.Default;
      if (optProfileJazz.Checked) profile = clsKeysAlg.eProfile.Jazz;
      else if (optProfileSpecial.Checked) profile = clsKeysAlg.eProfile.Special;
      Segments = new clsKeysAlg.clsSegments(notemap);
      if (Segments.indEmpty) return "Empty Tracks";
      CF = (chkLoadTxt.Checked && P.F.CF != null) ? CF = P.F.CF : null;
      KeysLabels.Add("Txt");  //leave in, even if text not present
      clsKeysAlg.Alg = alg;
      //clsKeysAlg.Trace = indTrace;
      clsKeysAlg.Segments = Segments;

      if (inertia.HasValue) {
        AddToKeysList(alg, profile, inertia.Value);
      } else {
        AddToKeysList(alg, profile, 0);
        AddToKeysList(alg, profile, 30);
        AddToKeysList(alg, profile, 50);
        AddToKeysList(alg, profile, 70);
        AddToKeysList(alg, profile, 90);
        AddToKeysList(alg, profile, 110);
      }

      CalcMinorScores();

      PopulatelvMod(true);
      //cmdDebugSegs.Enabled = true;
      return "";
    }

    private void AddToKeysList(clsKeysAlg.eAlg alg, clsKeysAlg.eProfile profile, int penalty) {
      clsKeysAlg keysalg = new clsKeysAlg(profile, alg, penalty);
      KeysList.Add(keysalg);
      KeysLabels.Add(penalty.ToString());
    }

    private void PopulatelvMod(bool headers) {
      //* create table of key strings
      string[,] txt = new string[KeysList[0].Keys.Count, KeysList.Count + 1];
      string[,] txtx = new string[KeysList[0].Keys.Count, KeysList.Count + 1];
      for (int seg = 0; seg < KeysList[0].Keys.Count; seg++) {
        if (CF != null) {
          txt[seg, 0] = GetFileKey(seg).KeyStrShort;
          txtx[seg, 0] = GetFileKey(seg).KeyStrShort;
        }
        for (int i = 0; i < KeysList.Count; i++) {  //for each algorithm type 
          clsKeyTicks key = KeysList[i].Keys[seg];
          if (key != null) {
            if (seg != key.BBT.Bar) LogicError.Throw(eLogicError.X034);
            txt[seg, i + 1] = key.KeyStrShort;
            txtx[seg, i + 1] = key.KeyStrShort;
          }
        }
      }

      //* replace repeated keys with "*"
      for (int i = 0; i < KeysList.Count + 1; i++) {  //txtfile and each algorithm type
        //for (int seg = 1; seg < KeysList[0].Keys.Count - 1; seg++) {
        //  if (txtx[seg, i] == txtx[seg - 1, i] && txtx[seg, i] == txtx[seg + 1, i]) {
        //    txt[seg, i] = "*";
        //  }
        //}
        for (int seg = 1; seg < KeysList[0].Keys.Count; seg++) {
          if (txtx[seg, i] == txtx[seg - 1, i]) {
            txt[seg, i] = "*";
          }
        }
      }

      //* load lvmod
      lvMod.BeginUpdate();
      lvMod.Clear();
      if (headers) {
        lvMod.Columns.Add("Bar", 30);
        foreach (string lbl in KeysLabels) {
          lvMod.Columns.Add(lbl, 40);
        }
      }
      for (int seg = 0; seg < KeysList[0].Keys.Count; seg++) {
        List<string> lvstr = new List<string>();
        lvstr.Add((seg + 1).ToString());  //bar num
        lvstr.Add(txt[seg, 0]);  //txt file
        for (int i = 0; i < KeysList.Count; i++) {  //for each algorithm type
          lvstr.Add(txt[seg, i + 1]);
        }
        lvMod.Items.Add(new ListViewItem(lvstr.ToArray()));  //add segment
      }
      lvMod.EndUpdate();
    }

    //  for (int seg = 0; seg < KeysList[0].Keys.Count; seg++) {
    //    clsKey txtkey = null, key;
    //    string star = "";
    //    List<string> lvstr = new List<string>();
    //    string line = "";
    //    lvstr.Add((seg + 1).ToString());
    //    if (CF != null) {
    //      txtkey = GetFileKey(seg);
    //      lvstr.Add(txtkey.KeyStrShort);
    //      if (indTrace) {
    //        line += string.Format("{0, 4} {1, -4}", seg + 1, txtkey.KeyStrShort);
    //      }
    //    }
    //    for (int i = 0; i < KeysList.Count; i++) {  //for each algorithm type
    //      key = KeysList[i].Keys[seg];
    //      if (key == null) {
    //        lvstr.Add("");
    //      } else {
    //        if (seg != key.BBT.Bar) {
    //          LogicError.Throw(eLogicError.X034);
    //          lvstr.Add("");
    //        }
    //        if (CF != null) {
    //          if (!txtkey.Equiv(key)) star = " *"; else star = "";
    //        }
    //        lvstr.Add(key.KeyStrShort + star);
    //      }
    //      if (indTrace) {
    //        line += string.Format("{0, -4}", key.KeyStrShort + star);
    //      }
    //    }
    //    lvMod.Items.Add(new ListViewItem(lvstr.ToArray()));  //add segment
    //  }
    //  lvMod.EndUpdate();

    private clsKeyTicks GetFileKey(int seg) {
      clsKeyTicks txtkey;
      int ticks = (new clsMTime.clsBBT(seg, 0, 0)).Ticks;
      txtkey = P.F.Keys[ticks];
      return txtkey;
    }

    private void cmdApply_Click(object sender, EventArgs e) {
      Apply();
    }

    private void Apply() {
      if (KeysList == null) return;
      //if (P.F == null || P.F.CF == null) {
      //  MessageBox.Show("Apply failed - showchords/text file not loaded");
      //  return;
      //}
      if (P.F == null) {
        MessageBox.Show("Apply failed - no midifile or chordfile loaded");
        return;
      }

      //P.F.UndoRedoKeys.Update();

      clsKeysTicks keys = null;
      int index = (KeysList.Count > 1) ? GetInertia() : 0;
      clsKeyTicks prevkey = null;
      foreach (clsKeyTicks key in KeysList[index].Keys) {
        if (key == null) continue;
        if (key.IsEquiv(prevkey)) continue;  //same key, different BBT
        clsKeyTicks newkey = new clsKeyTicks(key);
        //if (P.F.CFTxt.Transpose_File != 0) newkey = newkey.Transpose(-P.F.CFTxt.Transpose_File);
        if (keys == null) {
          newkey.Ticks = 0;  //first key
          keys = new clsKeysTicks(newkey);
        } else {
          keys.Keys.Add(newkey);
        }
        prevkey = key;
      }
      //P.F.KeysAlt = keys;
      //SwitchKeys();
      P.F._CFKeys = keys;

      //P.F.CF.SyncEvsToKeys();
      //P.F.CF.UndoRedoCF.Update();
      //P.F.CF.TransposeMidi(0);  //to force enharmonic changes (spelling) 
      P.F.CF?.SetNoteMapFileChanged();

      if (P.frmSC != null) P.frmSC.Refresh();
      if (P.F.frmChordMap != null) P.F.frmChordMap.RefreshAll();
    }

    private int GetInertia() {
      if (optPenalty0.Checked) return 0;
      if (optPenalty30.Checked) return 1;
      if (optPenalty50.Checked) return 2;
      if (optPenalty70.Checked) return 3;
      if (optPenalty90.Checked) return 4;
      if (optPenalty110.Checked) return 5;
      LogicError.Throw(eLogicError.X083);
      return 0;
    }

    //internal static void SwitchKeys() {
    //  if (P.F.Keys == null || P.F.KeysAlt == null) return;
    //  clsKeys keys = P.F._CFKeys;
    //  P.F._CFKeys = P.F.KeysAlt;
    //  P.F.KeysAlt = keys;
    //  //indKeysCalc = !indKeysCalc;
    //  P.F.CF.SyncEvsToKeys();
    //  if (P.frmSC != null) P.frmSC.Refresh();
    //  if (P.F.frmNoteMap != null) P.F.frmNoteMap.ShowKeys();
    //}

    //private void cmdLoadChordFile_Click(object sender, EventArgs e) {
    //  string csvname = FileName;
    //  string filename = csvname.Substring(0, csvname.Length - 4) + ".chp";
    //  if (!File.Exists(filename)) return;
    //  //frmStart.CloseMidiWindows();
    //  P.CloseFrm(P.F.frmShowChords);
    //  P.F.frmShowChords = new frmShowChords(frmStart.frmShowChordsSettings);
    //  if (!P.F.frmShowChords.InitShowChordsTxt(filename)) {
    //    P.F.frmShowChords = null;
    //    return;
    //  }
    //  P.F.frmShowChords.cmdPlayCtl.Enabled = true;
    //  P.F.frmShowChords.cmdPlayCtlNoPerc.Enabled = true;
    //  P.F.frmShowChords.cmdStartPlay.Enabled = true;
    //}

    private void cmdDebug_Click(object sender, EventArgs e) {  
      //* not nornmally in use
      int seglo = 0; 
      int seghi = Segments.Segs.Count; 
      int[] tot = new int[12];
      for (int s = seglo; s < seghi; s++) {
        int[] seg = Segments.Segs[s];
        for (int pmidi = 0; pmidi < 12; pmidi++) {
          int p = pmidi;
          //if (CF != null && optKeysText.Checked) p = (pmidi - CF.Transpose_File + 12).Mod12();
          tot[p] += seg[pmidi];  //absolute pitch
        }
      }
      PrintSegs(seglo, seghi, tot);
    }

    private void PrintSegs(int seglo, int seghi, int[] tot) {
      int maxtot = tot.Max();
      Debug.WriteLine("SegCount for " + FileName
        + " From Seg:" + (seglo + 1)
        + " To Seg:" + (seghi + 1));
      string msg = "Abs: ";
      for (int p = 0; p < 12; p++) {
        tot[p] = (tot[p] * 100) / maxtot;
        msg += NoteName.ToSharpFlat(NoteName.GetNoteName(0, 0, p)) + ": " + tot[p] + "  ";
      }
      Debug.WriteLine(msg);
      if (CF != null) {  //print rel
        clsKeyTicks txtkey = GetFileKey(seglo);  //assume seglo is key for this range 
        msg = NoteName.ToSharpFlat(txtkey.KeyStrShort) + ": ";
        for (int p = 0; p < 12; p++) {
          int i = (p + txtkey.KeyNote).Mod12();
          msg += NoteName.Solfa.Substring(p * 2, 2) + ": " + tot[i] + "  ";
        }
        Debug.WriteLine(msg);
      }
    }

    private void frmCalcKeys_FormClosed(object sender, FormClosedEventArgs e) {
      P.F.frmCalcKeys = null;
    }

    private void cmdOK_Click(object sender, EventArgs e) {
      Apply();
      Close();
    }

    //private void cmdClose_Click(object sender, EventArgs e) {
    //  Close();
    //}

    private void optPenalty_CheckedChanged(object sender, EventArgs e) {
      RadioButton opt = (RadioButton)sender;
      if (opt.Checked) CalcMinorScores();  //no need to call if switched off
    }

    private void cmdHelp_Click(object sender, EventArgs e) {
      Utils.ShowHelp(this, Cfg.HelpFilePath, HelpNavigator.Topic, "Form_CalcKeys_Intro.htm");
    }

    private void chkChordFile_CheckedChanged(object sender, EventArgs e) {
      lblTracksSelected.Text = (chkChordFile.Checked) ? "" : Forms.frmChordMap.UpdateTrksSelected(TrkSelect);
    }
  }
}

gha: C#, lang: c_sharp
﻿DROP FUNCTION IF EXISTS finance.get_account_ids(root_account_id integer);

CREATE FUNCTION finance.get_account_ids(root_account_id integer)
RETURNS SETOF integer
STABLE
AS
$$
BEGIN
    RETURN QUERY 
    (
        WITH RECURSIVE account_cte(account_id, path) AS (
         SELECT
            tn.account_id,  tn.account_id::TEXT AS path
            FROM finance.accounts AS tn 
			WHERE tn.account_id =$1
			AND NOT tn.deleted
        UNION ALL
         SELECT
            c.account_id, (p.path || '->' || c.account_id::TEXT)
            FROM account_cte AS p, finance.accounts AS c WHERE parent_account_id = p.account_id
        )

        SELECT account_id FROM account_cte
    );
END
$$LANGUAGE plpgsql;


gha: JavaScript, lang: sql
/* eslint-disable react/prop-types */
import React, { useState, createContext, useEffect } from 'react';

const AuthContext = createContext({ signed: true, user: {}, token: '' });

export const AuthProvider = ({ children }) => {
  const [token, setToken] = useState(null);
  const [user, setUser] = useState({});

  useEffect(() => {
    const getStoragedData = () => {
      const storagedToken = localStorage.getItem('@dashw:token');
      const storagedUser = localStorage.getItem('@dashw:user');

      if (storagedToken && storagedUser) {
        setToken(storagedToken);
        setUser(storagedUser);
      }
    };
    getStoragedData();
  }, []);

  const signIn = (myToken, myUser) => {
    setToken(myToken);
    setUser(myUser);

    localStorage.setItem('@dashw:token', myToken);
    localStorage.setItem('@dashw:user', JSON.stringify(myUser));
  };

  const signOut = () => {
    setToken(null);
    setUser([]);

    localStorage.removeItem('@dashw:token');
    localStorage.removeItem('@dashw:user');
  };

  return (
    <AuthContext.Provider
      value={{
        signed: !!token,
        user,
        token,
        signIn,
        signOut
      }}
    >
      {children}
    </AuthContext.Provider>
  );
};

export default AuthContext;

gha: TypeScript, lang: javascript
<template>
    <li class="menu-item"
        :class="cssClasses">

        <a @click="linkClicked($event)"
           :href="item.url"
           :target="item.in_new_window ? '_blank' : '_self'"
           :class="{'is-active': isActive}">
            <b-icon v-if="item.icon" :icon="item.icon"></b-icon>
            <span class="item-label">{{ item.title }}</span>
            <b-icon v-if="hasItems" class="collapsible-icon" icon="angle-down"></b-icon>
        </a>

        <collapsible-menu-group ref="group"
                                v-if="hasItems"
                                v-show="isActive" :items="items"></collapsible-menu-group>
    </li>
</template>

<script>
    export default {

        name: 'collapsible-menu-item',

        props: ['item'],

        data() {
            return {
                isActive: false
            }
        },

        mounted() {
            this.isActive = this.item.is_active;

            if(this.isActive) {
                this.$emit('is-active');
            }

            if(this.$refs.group && ! this.isActive) {
                this.isActive = this.$refs.group.hasActive;
            }
        },

        methods: {
            linkClicked($event) {
                if(! this.hasItems) {
                    return true;
                }

                $event.preventDefault();
                this.isActive = ! this.isActive;
            }

        },

        computed: {
            hasItems() {
                return this.items && this.items.length > 0;
            },

            items() {
                return this.item.items;
            },

            cssClasses() {
                let classes = [];

                if(this.item.css_class) {
                    classes.push(this.item.css_class);
                }

                if(this.hasItems) {
                    classes.push('has-items');
                }

                return classes;
            }
        }

    }
</script>
gha: JavaScript, lang: groovy
CREATE TABLE wikidata_bots(
	user_id VARCHAR(265)
);
gha: Python, lang: sql
<!--
===============================================
vidgear library source-code is deployed under the Apache 2.0 License:

Copyright (c) 2019 Abhishek Thakur(@abhiTronix) <abhi.una12@gmail.com>

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
===============================================
-->

# Helping VidGear

<figure>
  <img src="../assets/images/help_us.png" loading="lazy" alt="Helping Vidgear" class="shadow" />
</figure>

> Liked VidGear? Would you like to help VidGear, other users, and the author?

There are many simple ways to help us:


&nbsp; 


## :material-star-settings: Star VidGear on GitHub

You can star :star2: VidGear on GitHub: [![GitHub Repo stars](https://img.shields.io/github/stars/abhiTronix/vidgear?label=stars%20%E2%9C%A8&logo=github&style=flat-square)](https://github.com/abhiTronix/vidgear/stargazers)

It helps us a lot by making it easier for others to find & trust this library. Thanks!


&nbsp; 


## :fontawesome-solid-handshake: Help others with issues on GitHub

You can see through any opened or pinned existing issues on our GitHub repository, and try helping others, wherever possible: [![GitHub issues](https://img.shields.io/github/issues-raw/abhiTronix/vidgear?label=open%20issues%20%20%F0%9F%94%A7&logo=github&style=flat-square)](https://github.com/abhiTronix/vidgear/issues)


&nbsp; 


## :fontawesome-solid-eye: Watch the GitHub repository

You can **watch 👀** VidGear Activities on GitHub: [![GitHub watchers](https://img.shields.io/github/watchers/abhiTronix/vidgear?label=watch%20%F0%9F%91%80&logo=github&style=flat-square)](https://github.com/abhiTronix/vidgear/subscription)

When you watch a repository, you will be notified of all conversations for that repository, including when someone creates a new issue, or pushes a new pull request.

You can try helping solving those issues, or give valuable feedback/review on new Pull Requests.


&nbsp; 


## :material-twitter: Tweet about VidGear

Tweet about VidGear and Spread the word 🗣:

<a href="https://twitter.com/intent/tweet?button_hashtag=vidgear&ref_src=twsrc%5Etfw" class="twitter-hashtag-button" data-size="large" data-text="Checkout VidGear - A High-Performance Video-Processing Python Framework." data-url="https://abhitronix.github.io/vidgear" data-related="abhi_una12" data-show-count="false">Tweet #vidgear</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

Let others know how you are using VidGear and why you like it!

&nbsp; 


## :fontawesome-solid-gift: Helping Author

> Donations help keep VidGear's development alive and motivate me _(as author)_. :heart:{ .heart }

It is something I am doing with my own free time. But so much more needs to be done, and I need your help to do this. For just the price of a cup of coffee, you can make a difference :slight_smile:

<script type='text/javascript' src='https://ko-fi.com/widgets/widget_2.js'></script><script type='text/javascript'>kofiwidget2.init('Support Me on Ko-fi', '#eba100', 'W7W8WTYO');kofiwidget2.draw();</script> 

Thanks a million! :blush:


&nbsp; 


## :material-connection: Connect with Author

You can connect with me, the author 👋:

![Author Image](https://avatars.githubusercontent.com/u/34266896?v=4){ align=left width="160" loading=lazy }

* Follow author on GitHub: [![GitHub follow](https://img.shields.io/github/followers/abhiTronix?label=Follow%20%40abhiTronix&logo=github&style=flat-square)](https://github.com/abhiTronix)
* Follow author on Twitter: <a href="https://twitter.com/abhi_una12?ref_src=twsrc%5Etfw" class="twitter-follow-button" data-show-count="false">Follow &commat;abhi_una12</a>
* Get in touch with author on Linkedin: [![Linkedin follow](https://img.shields.io/badge/Follow-&commat;Abhishek&nbsp;Thakur-orange.svg?logo=linkedin&style=flat-square)](https://in.linkedin.com/in/abhishek-abhitronix?trk=profile-badge)


<!-- scripts -->
<script async defer src="https://buttons.github.io/buttons.js"></script>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


&nbsp; 

gha: Python, lang: markdown
---
date: "2020-03-25T22:03:05-07:00"
description: 2020年初頭から3月の後半の現在でも猛威を振るうCovid-19と僕が住んでいるバンクーバーの現在を残しておこうと思います。
draft: false
eyecatch: /images/eyecatch/eye-covid-vancouver.jpg
lastmod: "2020-03-25T23:16:13-07:00"
tags:
- blog
- vancouver
title: COVID-19とバンクーバー
toc: false
---

# バンクーバーの現在
ロックダウンから一週間程度ですが、状況は一変しました。また日々状況は徐々にですが、悪化しています。例えば、

- スターバックスは一時全店閉鎖
- ティムホートンやその他のカフェはピックアップのみ
- レストランも店内で食事禁止でテイクアウトやデリバリーのみOK
- アジア人以外でもマスクをしている人をみるようになった

リモートワークが出来る会社はほぼ全てリモートに移行したり出来ない所は休業や従業員がレイオフされています。私の会社でも先週の月曜から急遽リモートワークに変更されました。

色んなお店が休業している事や物理的な距離を取るように忠告されている事もあり、外にはあまり人が歩いているのを見ません。バスや電車などは未だに運行していますが乗っている人はかなり少ないです。幸いスーパーなどは買い占めなどはロックダウン当初は少しありましたが今は場所にもよるとは思いますが普通にあります。

## さらなる悲劇
さらに先週の金曜に会社の売り上げがCOVID-19の影響で落ち、今後続けていくのが困難な状況だと言われました。ITは大丈夫と思われがちですが、会社はエージェンシーで基本的に受注ベースです。受注先がCOVID-19の影響で事業縮小や経営面の問題で、契約の遅延、キャンセルが相次いでいるといった状況です。おそらくバンクーバーにあるほとんどのエージェンシーは経営面で大きなダメージを負っていると思います。多分どこも似たような感じでプールは少ないと感じます。

## ビザについて
月曜のアナウンスでは、来月4月からフルタイムでは無くパートタイムの契約に変わると言われたので現在のビザやPRにも影響が出るかもしれないと思い、担当のコンサルに問い合わせた所自分のビザ(Bridge Open Work Permit)は仕事の影響を受けないと言われました。PR申請する前にレイオフされていた事もありクローズドでは無くオープンが絶対条件だったのが非常によかったです。

また今後PRに関しては記事を書こうと思いますが、**オープンのビザの取得を強くおすすめします。**(もしくはExpress Entryでさっさと取る)

月曜のアナウンスではパートタイムに切り替わると言われたのですが、火曜にはフルタイムで雇用し続けようと頑張っていると言われました。今は色々と交渉中ですが給料を一時的に下げる事になるので、自分が暮らしていける最低限の額をある程度で良いので出して欲しいと言われました。この状況でなんとか食いつないでくれようとしていることは非常に感謝していますが、フルタイムで雇用し続けたいのは少し疑問です。(引き抜き防止・・？)

# リモートワークについて
自分の会社は基本オフィス通勤推奨であった為、急遽フルリモートになったのですがなんとか回せているとは思います。ですが以前からタスクの振り分けが甘く、異常に忙しかったり急に何もする事が無い等が起きていました。個人的には多分プロジェクトマネージャーは自分が何しているか把握してないなーって思ってたんですが今回のフルリモートでそれが出てしまいました。

結構今は待ち時間が多く、この間は何してたらいいんだ・・・って感じになります。がなんとか健康に生きています。

アイキャッチの画像はリモートワークの様子です。みんなの自宅開発環境が見てみたい！

# その他の印象的な事
毎日首相のカナダ国内に対する情報のアップデートがTVやYouTubeで生放送+アーカイブ化されていつでもどこでも見れるようになっています。またそれとは別に僕が住んでいるBC州も感染者などのアップデートがこちらも毎日放送されています。メディアはウェブサイトやTwitterなどを使ってその日ごとのアップデートが配信されています。(カナダ全体や州ごとなど様々です)

COVID-19を受け、色んな会社が社会のために出来る事をしています。例えばインターネットプロバイダであるShawはWifiの無料開放を行っていたり、ケーブルテレビのサービスもニュースに限り無料開放などがされています。

これから日本もどうなっていくかわかりませんが、国全体、県ごとのアップデートは非常に良いと思ったので真似されると嬉しいなと思います。

gha: TypeScript, lang: markdown
header{
  position: relative;
  width: 100%;
  padding-top: 1%;
  padding-bottom: 1%;
  margin-bottom : 1.5%;
  background-color : #6F9CC7;
  font-family : 'Helvetica', sans-serif;
  text-align: center;
  color: white;
  box-shadow: $shadow;
  h1{
    font-size: 3em;
    margin: 0;
  }
  h2{
    line-height: 2em;
    font-size:1em;
    margin: 0;
    @media(max-width: $break-small){
      display: none;
    }
  }
}
gha: JavaScript, lang: css
region = "us-east-1"

amis = {
    amazon-linux-2017-09 = "ami-8c1be5f6"
    amazon-linux-2017-09.1 = "ami-1853ac65"
}

gha: Java, lang: toml
## 107. Binary Tree Level Order Traversal II

Just reverse the answer of 103.

gha: C++, lang: batchfile
﻿using FluentAssertions;
using Microsoft.Extensions.Logging;
using Microsoft.Extensions.Logging.Abstractions;
using Sfa.Tl.ResultsAndCertification.Application.Services;
using Sfa.Tl.ResultsAndCertification.Data.Repositories;
using Sfa.Tl.ResultsAndCertification.Domain.Models;
using Sfa.Tl.ResultsAndCertification.Models.Contracts.ProviderAddress;
using System;
using System.Collections.Generic;
using System.Linq;
using System.Threading.Tasks;
using Xunit;

namespace Sfa.Tl.ResultsAndCertification.IntegrationTests.Services.ProviderAddressTests
{
    public class When_GetAddress_IsCalled : ProviderAddressServiceBaseTest
    {
        private Address _actualResult;
        private TlProviderAddress _newAddress;

        public override void Given()
        {
            SeedTestData();            
            CreateMapper();

            SeedProviderAddress();

            _newAddress = new TlProviderAddress
            {
                TlProviderId = TlProviders.First().Id,
                DepartmentName = "New Dept",
                OrganisationName = "New Org",
                AddressLine1 = "New Line1",
                AddressLine2 = "New Line2",
                Town = "New town",
                Postcode = "A11, 7BB",
                IsActive = true,
                CreatedBy = "Test user",
                CreatedOn = DateTime.UtcNow
            };

            AddProviderAddress(_newAddress);

            TlProviderRepositoryLogger = new Logger<GenericRepository<TlProvider>>(new NullLoggerFactory());
            TlProviderRepository = new GenericRepository<TlProvider>(TlProviderRepositoryLogger, DbContext);

            TlProviderAddressLogger = new Logger<GenericRepository<TlProviderAddress>>(new NullLoggerFactory());
            TlProviderAddressRepository = new GenericRepository<TlProviderAddress>(TlProviderAddressLogger, DbContext);

            ProviderAddressServiceLogger = new Logger<ProviderAddressService>(new NullLoggerFactory());

            ProviderAddressService = new ProviderAddressService(TlProviderRepository, TlProviderAddressRepository, ProviderAddressMapper, ProviderAddressServiceLogger);
        }

        public override Task When()
        {
            return Task.CompletedTask;
        }

        public async Task WhenAsync(long providerUkprn)
        {
            _actualResult = await ProviderAddressService.GetAddressAsync(providerUkprn);
        }

        [Theory]
        [MemberData(nameof(Data))]
        public async Task Then_Returns_Expected_Results(long providerUkprn, bool expectedResult)
        {
            await WhenAsync(providerUkprn);            

            if (expectedResult)
            {
                _actualResult.Should().NotBeNull();
                _actualResult.DepartmentName.Should().Be(_newAddress.DepartmentName);
                _actualResult.OrganisationName.Should().Be(_newAddress.OrganisationName);
                _actualResult.AddressLine1.Should().Be(_newAddress.AddressLine1);
                _actualResult.AddressLine2.Should().Be(_newAddress.AddressLine2);
                _actualResult.Town.Should().Be(_newAddress.Town);
                _actualResult.Postcode.Should().Be(_newAddress.Postcode);
            }
            else
            {
                _actualResult.Should().BeNull();
            }
        }

        public static IEnumerable<object[]> Data
        {
            get
            {
                return new[]
                {
                    new object[] { (long)Provider.WalsallCollege, false },
                    new object[] { (long)Provider.BarsleyCollege, true }
                };
            }
        }
    }
}

gha: C#, lang: c_sharp
# SourceV30Rc2

## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**source_orcid** | [**SourceOrcidV30Rc2**](SourceOrcidV30Rc2.md) |  | [optional] 
**source_client_id** | [**SourceClientIdV30Rc2**](SourceClientIdV30Rc2.md) |  | [optional] 
**source_name** | [**SourceNameV30Rc2**](SourceNameV30Rc2.md) |  | [optional] 
**assertion_origin_orcid** | [**SourceOrcidV30Rc2**](SourceOrcidV30Rc2.md) |  | [optional] 
**assertion_origin_client_id** | [**SourceClientIdV30Rc2**](SourceClientIdV30Rc2.md) |  | [optional] 
**assertion_origin_name** | [**SourceNameV30Rc2**](SourceNameV30Rc2.md) |  | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)


gha: Python, lang: markdown
﻿using System;
using System.Collections.Generic;
using System.Linq;
using VL.NewAudio.Dsp;
using VL.NewAudio.Core;

namespace VL.NewAudio.Nodes
{
    /// <summary>
    /// Open and configures an audio device. 
    /// </summary>
    public class AudioStreamNode : AudioNode
    {
        public IAudioDevice? AudioDevice { get; set; }

        /// <summary>
        /// The sampling frequency to use. If nothing is selected or selected frequency is not available, the smallest above 44kHz is chosen.
        /// </summary>
        public SamplingFrequency SamplingFrequency { get; set; } = SamplingFrequency.Hz44100;

        /// <summary>
        /// The buffer size to use. If below min or above max, the default buffer size is chosen.
        /// </summary>
        public double BufferSize { get; set; } = 0;

        /// <summary>
        /// Input channels to use. You get the available channel names from the AudioDevice node.  
        /// </summary>
        public IEnumerable<string> InputChannels { get; set; }

        /// <summary>
        /// Output channels to use. You get the available channel names from the AudioDevice node.  
        /// </summary>
        public IEnumerable<string> OutputChannels { get; set; }

        public override bool IsEnabled => Config?.IsValid ?? false;

        public AudioStreamConfig? Config
        {
            get
            {
                if (AudioDevice != null)
                {
                    return new AudioStreamConfig(AudioDevice)
                    {
                        ActiveOutputChannels = AudioChannels.FromNames(AudioDevice, false, OutputChannels.ToArray()),
                        ActiveInputChannels = AudioChannels.FromNames(AudioDevice, true, InputChannels.ToArray()),
                        SampleRate = (int)SamplingFrequency,
                        BufferSize = BufferSize,
                        IsEnabled = IsEnable,
                        Interleaved = AudioDevice?.Caps?.Interleaved ?? true
                    }.Match();
                }

                return null;
            }
        }

        public AudioStreamNode()
        {
            OutputChannels = Array.Empty<string>();
            InputChannels = Array.Empty<string>();
        }
    }
}
gha: C#, lang: c_sharp
using System;
using System.ComponentModel;
using JetBrains.Annotations;

namespace AcManager.Tools.Managers.Presets {
    public interface ISavedPresetEntry : INotifyPropertyChanged, IEquatable<ISavedPresetEntry> {
        [NotNull]
        string DisplayName { get; }

        [NotNull]
        string VirtualFilename { get; }

        bool IsBuiltIn { get; }

        [NotNull]
        byte[] ReadBinaryData();

        void SetParent(string baseDirectory);
    }
}
gha: C#, lang: c_sharp
package dataStructure.enumerate;

public enum Enum {
    RED(1, "红色"),
    GREEN(2, "绿色"),
    BLUE(3, "蓝色");
    private int code;
    private String color;

    Enum(int code, String color) {
        this.code = code;
        this.color = color;
    }

    public String getColor() {
        return color;
    }

    public void setColor(String color) {
        this.color = color;
    }

    public int getCode() {
        return code;
    }

    public void setCode(int code) {
        this.code = code;
    }
}

gha: Scala, lang: java
# TOOL hisat2-paired-end-storage.R: "HISAT2 for paired end reads for large samples" (Use this special version of the tool when you have more than 100 million reads per sample. Aligns paired end RNA-seq reads to a reference genome.)
# INPUT reads{...}.fq: "Reads to align" TYPE GENERIC
# INPUT OPTIONAL reads1.txt: "List of read 1 files" TYPE GENERIC
# INPUT OPTIONAL reads2.txt: "List of read 2 files" TYPE GENERIC
# OUTPUT OPTIONAL hisat.bam
# OUTPUT OPTIONAL hisat.bam.bai
# OUTPUT OPTIONAL hisat.log
# PARAMETER organism: "Genome" TYPE ["FILES genomes/indexes/hisat2 .fa"] DEFAULT "SYMLINK_TARGET genomes/indexes/hisat2/default .fa" (Genome or transcriptome that you would like to align your reads against.)
# PARAMETER rna.strandness: "RNA-strandness" TYPE [unstranded, FR, RF] DEFAULT unstranded (Specify strand-specific information. FR means read 1 is always on the same strand as the gene. RF means read 2 is always on the same strand as the gene. The default is unstranded.)
# PARAMETER quality.format: "Base quality encoding used" TYPE [sanger: "Sanger - Phred+33", phred64: "Phred+64"] DEFAULT sanger (Quality encoding used in the fastq file.)
# PARAMETER OPTIONAL max.multihits: "How many hits to report per read" TYPE INTEGER FROM 1 TO 1000000 DEFAULT 5 (Instructs HISAT2 to report up to this many alignments to the reference for a given read.)
# PARAMETER OPTIONAL min.intron.length: "Minimum intron length" TYPE INTEGER FROM 1 TO 1000 DEFAULT 20 (Sets minimum intron length. Default: 20)
# PARAMETER OPTIONAL max.intron.length: "Maximum intron length" TYPE INTEGER FROM 1 TO 1000000 DEFAULT 500000 (Sets maximum intron length. Default: 500000)
# PARAMETER OPTIONAL no.softclip: "Disallow soft-clipping" TYPE [nosoft: "No soft-clipping", yessoft: "Use soft-clipping"] DEFAULT yessoft (Is soft-cliping used. By default HISAT2 may soft-clip reads near their 5' and 3' ends.)
# PARAMETER OPTIONAL dta: "Require long anchor lengths for subsequent assembly" TYPE [nodta: "Don't require", yesdta: "Require"] DEFAULT nodta (With this option, HISAT2 requires longer anchor lengths for de novo discovery of splice sites. This leads to fewer alignments with short-anchors, which helps transcript assemblers improve significantly in computation and memory usage.)
# PARAMETER OPTIONAL dta.cufflinks: "Tailor alignments for Cufflinks" TYPE [yes, no] DEFAULT no (Report alignments tailored specifically for Cufflinks transcript assembly. With this option, HISAT2 looks for novel splice sites with three signals, GT-AG, GC-AG, AT-AC, but all user-provided splice sites are used irrespective of their signals. HISAT2 produces an optional XS field for every spliced alignment.)
# STORAGE 500

# AO 30.05.2017 First version
# EK 18.10.2017 Polishing
# EK 29.11.2021 Add --dta-cufflinks option

## Source required functions
source(file.path(chipster.common.lib.path, "zip-utils.R"))
source(file.path(chipster.common.lib.path, "tool-utils.R"))
source(file.path(chipster.common.lib.path, "bam-utils.R"))

## Helper functions
# Unzips a list of files
unzipInputs <- function(names) {
  for (i in 1:nrow(names)) {
    unzipIfGZipFile(names[i, 1])
  }
}

# Echoes command in log file if debug == TRUE
debugPrint <- function(command) {
  if (debug) {
    system(paste("echo ", command, ">> debug.log"))
  }
}

## Options
# Prefer fixed representation over exponential
options(scipen = 10)
# Debug mode, change debug to TRUE or FALSE, depending do you want debug prints or not
debug <- FALSE
debugPrint("")
debugPrint("DEBUG MODE IS ON")

# Get input name
input.names <- read.table("chipster-inputs.tsv", header = FALSE, sep = "\t")

# check out if the file is compressed and if so unzip it
unzipInputs(input.names)

## Parse parameters and store them into hisat.parameters
hisat.parameters <- ""
# Reads to align
# Parse the read names from input files
if (file.exists("reads1.txt") && file.exists("reads2.txt")) {
  # Case: list files exist
  reads1.list <- make_input_list("reads1.txt")
  reads2.list <- make_input_list("reads2.txt")
  if (identical(intersect(reads1.list, reads2.list), character(0))) {
    reads1 <- paste(reads1.list, sep = "", collapse = ",")
    reads2 <- paste(reads2.list, sep = "", collapse = ",")
  } else {
    stop(paste("CHIPSTER-NOTE: ", "One or more files is listed in both lists."))
  }
} else if (file.exists("reads002.fq") && !file.exists("reads003.fq")) {
  # Case: no list file, but only two fastq inputs
  in.sorted <- input.names[order(input.names[, 2]), ]
  reads <- grep("reads", in.sorted[, 1], value = TRUE)
  reads1 <- reads[1]
  reads2 <- reads[2]
} else {
  # Case: no list files, more than two fastq inputs
  stop(paste("CHIPSTER-NOTE: ", "List file is missing. You need to provide a list of read files for both directions."))
}
hisat.parameters <- paste(hisat.parameters, "-1", reads1, "-2", reads2)
# Quality score format
if (quality.format == "phred64") {
  hisat.parameters <- paste(hisat.parameters, "--phred64")
} else {
  hisat.parameters <- paste(hisat.parameters, "--phred33")
}
# Intron length, defaluts are 20 and 500 000
hisat.parameters <- paste(hisat.parameters, "--min-intronlen", min.intron.length)
hisat.parameters <- paste(hisat.parameters, "--max-intronlen", max.intron.length)
# Specify strand-specific information: the default is unstranded
if (rna.strandness == "FR") {
  hisat.parameters <- paste(hisat.parameters, "--rna-strandness FR")
} else if (rna.strandness == "RF") {
  hisat.parameters <- paste(hisat.parameters, "--rna-strandness RF")
}
# Organism
# -x declares the basename of the index for reference genome
hisat.parameters <- paste(hisat.parameters, "-x", organism)
# Set environment variable that defines where indexes locate, HISAT2 requires this
Sys.setenv(HISAT2_INDEXES = "/opt/chipster/tools/genomes/indexes/hisat2")
# Known splice sites
if (file.exists("splicesites.txt")) {
  hisat.parameters <- paste(hisat.parameters, "--known-splicesite-infile", "splicesites.txt")
}
# How many hits is a read allowed to have
hisat.parameters <- paste(hisat.parameters, "-k", max.multihits)
# Allow soft-clipping, by default soft-clipping is used
if (no.softclip == "nosoft") {
  hisat.parameters <- paste(hisat.parameters, "--no-softclip")
}
# Is longer anchor lengths required
if (dta == "yesdta") {
  hisat.parameters <- paste(hisat.parameters, "--dta")
}

# Should alignments be trailored for Cufflinks
if (dta.cufflinks == "yes") {
  hisat.parameters <- paste(hisat.parameters, "--dta-cufflinks")
}

## Set parameters that are not mutable via Chipster
# Threads that hisat uses
hisat.parameters <- paste(hisat.parameters, "-p", chipster.threads.max)
# Name of the output file
hisat.parameters <- paste(hisat.parameters, "-S", "hisat.sam")
# Forward errors to hisat.log
hisat.parameters <- paste(hisat.parameters, "2>> hisat.log")
# Suppress SAM records for reads that failed to align
hisat.parameters <- paste(hisat.parameters, "--no-unal")

# Print the HISAT2_INDEXES into debug
debugPrint("")
debugPrint("HISAT2_INDEXES:")
debugPrint("$HISAT2_INDEXES")

# Print parameters into log
debugPrint("HISAT PARAMETERS")
debugPrint(toString(hisat.parameters))

# setting up HISAT binaries (and paths)
hisat.binary <- file.path(chipster.tools.path, "hisat2", "hisat2")
samtools.binary <- file.path(chipster.tools.path, "samtools", "samtools")

## Run HISAT
# Note a single ' at the beginning, it allows us to use special characters like >
command <- paste("bash -c '", hisat.binary)

# Add the parameters
command <- paste(command, hisat.parameters)

# Close the command with a ', because there is a opening ' also
command <- paste(command, "'")
# Print the command to the hisat.log file
debugPrint(command)

# Run command
system(command)

## Run samtools
# Convert SAM file into BAM file and index bam file
# Parameters:
#   -b Output in the BAM format.
#   -S Ignored for compatibility with previous samtools versions. Previously this option was required if input was in SAM format, but now the correct
#    format is automatically detected by examining the first few characters of input.
# Convert SAM to BAM
debugPrint("")
debugPrint("SAMTOOLS")
samtools.view.command <- paste(samtools.binary, "view -bS hisat.sam > hisat.tmp.bam")
debugPrint(samtools.view.command)
system(samtools.view.command)
# Index bam, this produces a "hisat.sorted.bam" file
samtools.sort.command <- paste(samtools.binary, "sort hisat.tmp.bam hisat.sorted")
debugPrint(samtools.sort.command)
system(samtools.sort.command)

# Do not return empty BAM files
if (fileOk("hisat.sorted.bam", minsize = 100)) {
  # Rename result files
  system("mv hisat.sorted.bam hisat.bam")
  # Change file names in BAM header to display names
  displayNamesToBAM("hisat.bam")
  # Index BAM
  system(paste(samtools.binary, "index hisat.bam > hisat.bam.bai"))
}


# Unset environmet variable
Sys.unsetenv("HISAT2_INDEX")

# Append the debug.log into hisat.log
system("cat debug.log >> hisat.log")

# Substitute display names to log for clarity
displayNamesToFile("hisat.log")

# Handle output names
#

# read input names
inputnames <- read_input_definitions()

# Determine base name
name1 <- unlist(strsplit(reads1, ","))
base1 <- strip_name(inputnames[[name1[1]]])

name2 <- unlist(strsplit(reads2, ","))
base2 <- strip_name(inputnames[[name2[1]]])

basename <- paired_name(base1, base2)

# Make a matrix of output names
outputnames <- matrix(NA, nrow = 2, ncol = 2)
outputnames[1, ] <- c("hisat.bam", paste(basename, ".bam", sep = ""))
outputnames[2, ] <- c("hisat.bam.bai", paste(basename, ".bam.bai", sep = ""))

# Write output definitions file
write_output_definitions(outputnames)

# EOF

gha: R, lang: cobol
using System.IO;
using Xunit;

#pragma warning disable xUnit1026 // Theory methods should use all of their parameters

namespace MSBuildProjectTools.LanguageServer.Tests
{
    using Utilities;

    /// <summary>
    ///     Tests for <see cref="DotNetRuntimeInfo"/>.
    /// </summary>
    public class DotNetRuntimeInfoTests
    {
        /// <summary>
        ///     Verify that <see cref="DotNetRuntimeInfo"/> can parse the output of "dotnet --info".
        /// </summary>
        [Theory(DisplayName = "Parse 'dotnet --info' output ")]
        [InlineData("English", "2.1.401", @"C:\Program Files\dotnet\sdk\2.1.401\", "win10-x64", Examples.English_2_1_401)]
        [InlineData("German", "2.1.403", @"C:\Program Files\dotnet\sdk\2.1.403\", "win10-x64", Examples.German_2_1_403)]
        [InlineData("Chinese", "2.1.403", @"C:\Program Files\dotnet\sdk\2.1.403\", "win10-x64", Examples.Chinese_2_1_403)]
        public void Parse(string language, string expectedVersion, string expectedBaseDirectory, string expectedRID, string dotnetInfoOutput)
        {
            DotNetRuntimeInfo parsedOutput;

            using (StringReader outputReader = new StringReader(dotnetInfoOutput))
            {
                parsedOutput = DotNetRuntimeInfo.ParseDotNetInfoOutput(outputReader);
            }

            Assert.NotNull(parsedOutput);
            Assert.Equal(expectedVersion, parsedOutput.SdkVersion);
            Assert.Equal(expectedBaseDirectory, parsedOutput.BaseDirectory);
        }

        /// <summary>
        ///     Output examples from "dotnet --info".
        /// </summary>
        static class Examples
        {
            /// <summary>
            ///     .NET Core SDK v2.1.401 (English)
            /// </summary>
            public const string English_2_1_401 = @"
.NET Core SDK (reflecting any global.json):
 Version:   2.1.401
 Commit:    91b1c13032

Runtime Environment:
 OS Name:     Windows
 OS Version:  10.0.17134
 OS Platform: Windows
 RID:         win10-x64
 Base Path:   C:\Program Files\dotnet\sdk\2.1.401\

Host (useful for support):
  Version: 2.1.3
  Commit:  124038c13e

.NET Core SDKs installed:
  1.1.7 [C:\Program Files\dotnet\sdk]
  1.1.8 [C:\Program Files\dotnet\sdk]
  1.1.9 [C:\Program Files\dotnet\sdk]
  1.1.10 [C:\Program Files\dotnet\sdk]
  2.1.4 [C:\Program Files\dotnet\sdk]
  2.1.100 [C:\Program Files\dotnet\sdk]
  2.1.103 [C:\Program Files\dotnet\sdk]
  2.1.104 [C:\Program Files\dotnet\sdk]
  2.1.200-preview-007474 [C:\Program Files\dotnet\sdk]
  2.1.200-preview-007576 [C:\Program Files\dotnet\sdk]
  2.1.200-preview-007597 [C:\Program Files\dotnet\sdk]
  2.1.200 [C:\Program Files\dotnet\sdk]
  2.1.201 [C:\Program Files\dotnet\sdk]
  2.1.202 [C:\Program Files\dotnet\sdk]
  2.1.300-preview1-008174 [C:\Program Files\dotnet\sdk]
  2.1.300-preview2-008530 [C:\Program Files\dotnet\sdk]
  2.1.300-preview2-008533 [C:\Program Files\dotnet\sdk]
  2.1.300-rc1-008673 [C:\Program Files\dotnet\sdk]
  2.1.300 [C:\Program Files\dotnet\sdk]
  2.1.401 [C:\Program Files\dotnet\sdk]

.NET Core runtimes installed:
  Microsoft.AspNetCore.All 2.1.0-preview1-final [C:\Program Files\dotnet\shared\Microsoft.AspNetCore.All]
  Microsoft.AspNetCore.All 2.1.0-preview2-final [C:\Program Files\dotnet\shared\Microsoft.AspNetCore.All]
  Microsoft.AspNetCore.All 2.1.0-rc1-final [C:\Program Files\dotnet\shared\Microsoft.AspNetCore.All]
  Microsoft.AspNetCore.All 2.1.0 [C:\Program Files\dotnet\shared\Microsoft.AspNetCore.All]
  Microsoft.AspNetCore.All 2.1.3 [C:\Program Files\dotnet\shared\Microsoft.AspNetCore.All]
  Microsoft.AspNetCore.App 2.1.0-preview1-final [C:\Program Files\dotnet\shared\Microsoft.AspNetCore.App]
  Microsoft.AspNetCore.App 2.1.0-preview2-final [C:\Program Files\dotnet\shared\Microsoft.AspNetCore.App]
  Microsoft.AspNetCore.App 2.1.0-rc1-final [C:\Program Files\dotnet\shared\Microsoft.AspNetCore.App]
  Microsoft.AspNetCore.App 2.1.0 [C:\Program Files\dotnet\shared\Microsoft.AspNetCore.App]
  Microsoft.AspNetCore.App 2.1.3 [C:\Program Files\dotnet\shared\Microsoft.AspNetCore.App]
  Microsoft.NETCore.App 1.0.9 [C:\Program Files\dotnet\shared\Microsoft.NETCore.App]
  Microsoft.NETCore.App 1.0.10 [C:\Program Files\dotnet\shared\Microsoft.NETCore.App]
  Microsoft.NETCore.App 1.0.11 [C:\Program Files\dotnet\shared\Microsoft.NETCore.App]
  Microsoft.NETCore.App 1.0.12 [C:\Program Files\dotnet\shared\Microsoft.NETCore.App]
  Microsoft.NETCore.App 1.1.6 [C:\Program Files\dotnet\shared\Microsoft.NETCore.App]
  Microsoft.NETCore.App 1.1.7 [C:\Program Files\dotnet\shared\Microsoft.NETCore.App]
  Microsoft.NETCore.App 1.1.8 [C:\Program Files\dotnet\shared\Microsoft.NETCore.App]
  Microsoft.NETCore.App 1.1.9 [C:\Program Files\dotnet\shared\Microsoft.NETCore.App]
  Microsoft.NETCore.App 2.0.5 [C:\Program Files\dotnet\shared\Microsoft.NETCore.App]
  Microsoft.NETCore.App 2.0.6 [C:\Program Files\dotnet\shared\Microsoft.NETCore.App]
  Microsoft.NETCore.App 2.0.7 [C:\Program Files\dotnet\shared\Microsoft.NETCore.App]
  Microsoft.NETCore.App 2.0.9 [C:\Program Files\dotnet\shared\Microsoft.NETCore.App]
  Microsoft.NETCore.App 2.1.0-preview1-26216-03 [C:\Program Files\dotnet\shared\Microsoft.NETCore.App]
  Microsoft.NETCore.App 2.1.0-preview2-26406-04 [C:\Program Files\dotnet\shared\Microsoft.NETCore.App]
  Microsoft.NETCore.App 2.1.0-rc1 [C:\Program Files\dotnet\shared\Microsoft.NETCore.App]
  Microsoft.NETCore.App 2.1.0 [C:\Program Files\dotnet\shared\Microsoft.NETCore.App]
  Microsoft.NETCore.App 2.1.3 [C:\Program Files\dotnet\shared\Microsoft.NETCore.App]

To install additional .NET Core runtimes or SDKs:
  https://aka.ms/dotnet-download
            ";

            /// <summary>
            ///     .NET Core SDK v2.1.401 (Chinese)
            /// </summary>
            public const string Chinese_2_1_403 = @"
.NET Core SDK（反映任何 global.json）:
 Version:   2.1.403
 Commit:    04e15494b6

运行时环境:
 OS Name:     Windows
 OS Version:  10.0.17134
 OS Platform: Windows
 RID:         win10-x64
 Base Path:   C:\Program Files\dotnet\sdk\2.1.403\

Host (useful for support):
  Version: 2.1.5
  Commit:  290303f510

.NET Core SDKs installed:
  2.1.202 [C:\Program Files\dotnet\sdk]
  2.1.401 [C:\Program Files\dotnet\sdk]
  2.1.402 [C:\Program Files\dotnet\sdk]
  2.1.403 [C:\Program Files\dotnet\sdk]

.NET Core runtimes installed:
  Microsoft.AspNetCore.All 2.1.0 [C:\Program Files\dotnet\shared\Microsoft.AspNetCore.All]
  Microsoft.AspNetCore.All 2.1.1 [C:\Program Files\dotnet\shared\Microsoft.AspNetCore.All]
  Microsoft.AspNetCore.All 2.1.2 [C:\Program Files\dotnet\shared\Microsoft.AspNetCore.All]
  Microsoft.AspNetCore.All 2.1.4 [C:\Program Files\dotnet\shared\Microsoft.AspNetCore.All]
  Microsoft.AspNetCore.All 2.1.5 [C:\Program Files\dotnet\shared\Microsoft.AspNetCore.All]
  Microsoft.AspNetCore.App 2.1.0 [C:\Program Files\dotnet\shared\Microsoft.AspNetCore.App]
  Microsoft.AspNetCore.App 2.1.1 [C:\Program Files\dotnet\shared\Microsoft.AspNetCore.App]
  Microsoft.AspNetCore.App 2.1.2 [C:\Program Files\dotnet\shared\Microsoft.AspNetCore.App]
  Microsoft.AspNetCore.App 2.1.4 [C:\Program Files\dotnet\shared\Microsoft.AspNetCore.App]
  Microsoft.AspNetCore.App 2.1.5 [C:\Program Files\dotnet\shared\Microsoft.AspNetCore.App]
  Microsoft.NETCore.App 2.0.9 [C:\Program Files\dotnet\shared\Microsoft.NETCore.App]
  Microsoft.NETCore.App 2.1.4 [C:\Program Files\dotnet\shared\Microsoft.NETCore.App]
  Microsoft.NETCore.App 2.1.5 [C:\Program Files\dotnet\shared\Microsoft.NETCore.App]

To install additional .NET Core runtimes or SDKs:
  https://aka.ms/dotnet-download
            ";

            /// <summary>
            ///     .NET Core SDK v2.1.403 (German)
            /// </summary>
            public const string German_2_1_403 = @"
.NET Core SDK (gemäß ""global.json""):
 Version:   2.1.403
 Commit:    04e15494b6

Laufzeitumgebung:
 OS Name:     Windows
 OS Version:  10.0.17763
 OS Platform: Windows
 RID:         win10-x64
 Base Path:   C:\Program Files\dotnet\sdk\2.1.403\

Host (useful for support):
  Version: 2.1.5
  Commit:  290303f510
            ";
        }
    }
}

gha: C#, lang: c_sharp
import React from 'react'
import PropTypes from 'prop-types'
import { Link } from 'wouter'
import HeaderHome from '../HeaderHome/index'
import { container, header, content, pill, call, btn } from './styles'

const CallToAction = ({ headerText, headerLinkPath, headerLinkClick, pillText, ctaText, btnPath, btnClick, btnText }) =>
	<div style={container}>
		<HeaderHome
			linkText={headerText}
			linkPath={headerLinkPath}
			linkClick={headerLinkClick}
			css={header}
			whiteText={true}
		/>
		<div style={content}>
			<span style={pill}>{pillText}</span>
			<div style={call}>{ctaText}</div>
			<Link to={btnPath} onClick={btnClick}>
				<a style={btn}>{btnText}</a>
			</Link>
		</div>
	</div>

CallToAction.propTypes = {
	headerText: PropTypes.string,
	headerLinkPath: PropTypes.string,
	headerLinkClick: PropTypes.func,
	pillText: PropTypes.string,
	ctaText: PropTypes.string,
	btnPath: PropTypes.string,
	btnClick: PropTypes.func,
	btnText: PropTypes.string
}

export default CallToAction
gha: JavaScript, lang: scala
"""
=======================================
Saving and loading sunpy Maps with asdf
=======================================

In this example we are going to look at how we can save and load a
`~sunpy.map.GenericMap` with `asdf <https://asdf.readthedocs.io/en/latest/>`__.

asdf is a modern file format designed to meet the needs of the astronomy
community. It has deep integration with Python, SunPy and Astropy as well as
implementations in other languages. It can be used to store known Python
objects in a portable, well defined file format. It is primarily useful for
storing complex Astropy and SunPy objects in a way that can be loaded back into
the same form as they were saved.

Here, even though we will be working with `~sunpy.map.sources.sdo.AIAMap`
specifically, the process can be extended to any `~sunpy.map.GenericMap`,
including ones created using custom FITS files.
"""
import asdf
import astropy.units as u

import sunpy.data.sample
import sunpy.map

################################################################################
# We begin by creating an `~sunpy.map.sources.sdo.AIAMap` object using the
# sample data.

aia_map = sunpy.map.Map(sunpy.data.sample.AIA_171_IMAGE)
aia_map.peek(clip_interval=(1, 99.99)*u.percent)

################################################################################
# We can now save this object to an asdf file to use later. Saving it like this
# allows us to preserve all of the metadata of the object along with the actual
# array data. When we load the asdf again, we get an identical
# `~sunpy.map.sources.sdo.AIAMap` object.
#
# asdf files work by saving a dictionary internally, so to save the object we
# need to put it into a dictionary. This becomes what asdf calls a "tree".

tree = {'aia_map': aia_map}

################################################################################
# We can now write the data to an asdf file like so:

with asdf.AsdfFile(tree) as asdf_file:
    asdf_file.write_to("sunpy_map.asdf")

################################################################################
# This asdf file is a portable file and can be safely loaded by anyone with
# Astropy, sunpy and asdf installed. We can reload it like so:

with asdf.open("sunpy_map.asdf") as asdf_file:
    reloaded_aia_map = asdf_file['aia_map']
    reloaded_aia_map.peek(clip_interval=(1, 99.99)*u.percent)

gha: Python, lang: markdown
.. _install-label:

Installation
============


How To Install
--------------

* Make sure you have `python3.6` or higher installed

  .. code-block:: none

    $ python3 --version
    Python 3.6.9


* Make sure you have `pip3` version 20.0 or higher installed

  .. code-block:: none

    $ python3 -m pip --version
    pip 20.0.2 from /home/gefux/.local/lib/python3.6/site-packages/pip (python 3.6)


* Install OQuPy via pip

  .. code-block:: none

    $ python3 -m pip install oqupy


Test Installation
-----------------

Open a interactive python3 session and type:

.. code-block:: python

  >>> import oqupy
  >>> oqupy.__version__

This should give you the following message:

.. code-block:: none

  '0.4.0'


Uninstall
---------

Uninstall OQuPy with pip:

.. code-block:: none

 $ python3 -m pip uninstall oqupy

gha: Jupyter Notebook, lang: markdown
/*
 *  File name:  lib_delay.h
 *  Date first: 11/05/2018
 *  Date last:  11/05/2018
 *
 *  Description: STM8 Library for short delays.
 *
 *  Author:     Richard Hodges
 *
 *  Copyright (C) 2018 Richard Hodges. All rights reserved.
 *  Permission is hereby granted for any use.
 *
 ******************************************************************************
 *
 * Delays
 */
void delay_500ns(void);		/* 500 microseconds */
void delay_usecs(char);		/* 1 to 255 microseconds */
void delay_50us(void);		/* 50 microseconds */
void delay_ms(unsigned char);	/* 1 to 255 milliseconds (setup code) */

gha: C, lang: cpp
SRC = jdiff_languages.cpp \
      jdiff_main.cpp \
      jdiff_parse_options.cpp \
      java_syntactic_diff.cpp \
      # Empty last line

OBJ += ../$(CPROVER_DIR)/src/ansi-c/ansi-c$(LIBEXT) \
      ..//java_bytecode/java_bytecode$(LIBEXT) \
      ../$(CPROVER_DIR)/src/linking/linking$(LIBEXT) \
      ../$(CPROVER_DIR)/src/big-int/big-int$(LIBEXT) \
      ../$(CPROVER_DIR)/src/goto-programs/goto-programs$(LIBEXT) \
      ../$(CPROVER_DIR)/src/pointer-analysis/pointer-analysis$(LIBEXT) \
      ../$(CPROVER_DIR)/src/goto-diff/syntactic_diff$(OBJEXT) \
      ../$(CPROVER_DIR)/src/goto-diff/unified_diff$(OBJEXT) \
      ../$(CPROVER_DIR)/src/goto-diff/change_impact$(OBJEXT) \
      ../$(CPROVER_DIR)/src/goto-diff/goto_diff_base$(OBJEXT) \
      ../$(CPROVER_DIR)/src/goto-instrument/source_lines$(OBJEXT) \
      ../$(CPROVER_DIR)/src/goto-instrument/cover$(OBJEXT) \
      ../$(CPROVER_DIR)/src/goto-instrument/cover_basic_blocks$(OBJEXT) \
      ../$(CPROVER_DIR)/src/goto-instrument/cover_filter$(OBJEXT) \
      ../$(CPROVER_DIR)/src/goto-instrument/cover_instrument_assume$(OBJEXT) \
      ../$(CPROVER_DIR)/src/goto-instrument/cover_instrument_branch$(OBJEXT) \
      ../$(CPROVER_DIR)/src/goto-instrument/cover_instrument_condition$(OBJEXT) \
      ../$(CPROVER_DIR)/src/goto-instrument/cover_instrument_decision$(OBJEXT) \
      ../$(CPROVER_DIR)/src/goto-instrument/cover_instrument_location$(OBJEXT) \
      ../$(CPROVER_DIR)/src/goto-instrument/cover_instrument_mcdc$(OBJEXT) \
      ../$(CPROVER_DIR)/src/goto-instrument/cover_instrument_other$(OBJEXT) \
      ../$(CPROVER_DIR)/src/goto-instrument/cover_util$(OBJEXT) \
      ../$(CPROVER_DIR)/src/analyses/analyses$(LIBEXT) \
      ../$(CPROVER_DIR)/src/langapi/langapi$(LIBEXT) \
      ../$(CPROVER_DIR)/src/xmllang/xmllang$(LIBEXT) \
      ../$(CPROVER_DIR)/src/solvers/solvers$(LIBEXT) \
      ../$(CPROVER_DIR)/src/util/util$(LIBEXT) \
      ../miniz/miniz$(OBJEXT) \
      ../$(CPROVER_DIR)/src/json/json$(LIBEXT) \
      # Empty last line

INCLUDES= -I .. -I ../$(CPROVER_DIR)/src

LIBS =

include ../config.inc
include ../$(CPROVER_DIR)/src/config.inc
include ../$(CPROVER_DIR)/src/common

CLEANFILES = jdiff$(EXEEXT)

all: jdiff$(EXEEXT)

###############################################################################

jdiff$(EXEEXT): $(OBJ)
	$(LINKBIN)

.PHONY: jdiff-mac-signed

jdiff-mac-signed: jdiff$(EXEEXT)
	strip jdiff$(EXEEXT) ; codesign -v -s $(OSX_IDENTITY) jdiff$(EXEEXT)

gha: C++, lang: makefile
import { test, credentials } from './utils/test'
import { arn } from './utils/mockAws'

test('deleteTopic', async (t) => {
  const { eventLog, fanout } = t.context

  const topicName = t.title

  await fanout.deleteTopic(credentials, topicName)

  t.deepEqual(eventLog, [
    ['sns.createTopic', { Name: topicName }],
    ['sns.deleteTopic', { TopicArn: arn.sns(topicName) }],
  ])
})

gha: TypeScript, lang: javascript
\hypertarget{classmtm__alignment__test_1_1mtm__aligner}{\section{mtm\-\_\-alignment\-\_\-test.\-mtm\-\_\-aligner Class Reference}
\label{classmtm__alignment__test_1_1mtm__aligner}\index{mtm\-\_\-alignment\-\_\-test.\-mtm\-\_\-aligner@{mtm\-\_\-alignment\-\_\-test.\-mtm\-\_\-aligner}}
}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
def \hyperlink{classmtm__alignment__test_1_1mtm__aligner_ae8bb0d4f0b12e149f1032b18ee13754f}{rotate}
\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_a356851f1dbf80bfdf88dd2be2375aadf}{def {\bfseries ecm\-\_\-joint\-\_\-cb}}\label{classmtm__alignment__test_1_1mtm__aligner_a356851f1dbf80bfdf88dd2be2375aadf}

\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_a86b062fc65be35830ad5239d1c453aca}{def {\bfseries \-\_\-\-\_\-init\-\_\-\-\_\-}}\label{classmtm__alignment__test_1_1mtm__aligner_a86b062fc65be35830ad5239d1c453aca}

\end{DoxyCompactItemize}
\subsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_a66fbb0a8962ef5b3b28fe1429315d5cc}{{\bfseries lets\-\_\-do\-\_\-it\-\_\-once}}\label{classmtm__alignment__test_1_1mtm__aligner_a66fbb0a8962ef5b3b28fe1429315d5cc}

\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_aa0457188df6f6daf8af6fc7ba9ba4242}{{\bfseries psm1\-\_\-kin}}\label{classmtm__alignment__test_1_1mtm__aligner_aa0457188df6f6daf8af6fc7ba9ba4242}

\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_ab10272a41958344050deb06e813cd82d}{{\bfseries psm1\-\_\-robot}}\label{classmtm__alignment__test_1_1mtm__aligner_ab10272a41958344050deb06e813cd82d}

\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_a41fa48a02c1b1a94d13058083c6fe6f4}{{\bfseries psm2\-\_\-kin}}\label{classmtm__alignment__test_1_1mtm__aligner_a41fa48a02c1b1a94d13058083c6fe6f4}

\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_a9b788a92a4b18e8740f90d9fd16c34c2}{{\bfseries psm2\-\_\-robot}}\label{classmtm__alignment__test_1_1mtm__aligner_a9b788a92a4b18e8740f90d9fd16c34c2}

\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_ab719e5232dcd65bdccb822165b231450}{{\bfseries ecm\-\_\-kin}}\label{classmtm__alignment__test_1_1mtm__aligner_ab719e5232dcd65bdccb822165b231450}

\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_a2172ccdef3463694da08c63704888fdc}{{\bfseries ecm\-\_\-robot}}\label{classmtm__alignment__test_1_1mtm__aligner_a2172ccdef3463694da08c63704888fdc}

\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_ab4698ffb0769df9a323b4fdf2ea6dd14}{{\bfseries mtmr\-\_\-robot}}\label{classmtm__alignment__test_1_1mtm__aligner_ab4698ffb0769df9a323b4fdf2ea6dd14}

\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_a681ac32ad367833eb3114fa3ddf133c9}{{\bfseries mtmr\-\_\-kin}}\label{classmtm__alignment__test_1_1mtm__aligner_a681ac32ad367833eb3114fa3ddf133c9}

\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_a2722555b351f9cd18b6c4c3203228117}{{\bfseries psm1\-\_\-pub}}\label{classmtm__alignment__test_1_1mtm__aligner_a2722555b351f9cd18b6c4c3203228117}

\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_ad8672e13dfd606b4a77b68403adc6e73}{{\bfseries psm2\-\_\-pub}}\label{classmtm__alignment__test_1_1mtm__aligner_ad8672e13dfd606b4a77b68403adc6e73}

\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_a261a2258c62f232c6f789d71e4d30de6}{{\bfseries ecm\-\_\-pub}}\label{classmtm__alignment__test_1_1mtm__aligner_a261a2258c62f232c6f789d71e4d30de6}

\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_a6b0f4eddab2fdafe95d7d6c916db58ee}{{\bfseries mtmr\-\_\-pub}}\label{classmtm__alignment__test_1_1mtm__aligner_a6b0f4eddab2fdafe95d7d6c916db58ee}

\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_a6e296d6faef8bbbef41f7a4fefefe6fb}{{\bfseries mtml\-\_\-pub}}\label{classmtm__alignment__test_1_1mtm__aligner_a6e296d6faef8bbbef41f7a4fefefe6fb}

\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_a3838fa4b092feb3f441472e006df6a93}{{\bfseries ecm\-\_\-base}}\label{classmtm__alignment__test_1_1mtm__aligner_a3838fa4b092feb3f441472e006df6a93}

\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_a83df974e499509163d717369caf24ef4}{{\bfseries tf\-\_\-new\-\_\-psm2\-\_\-base}}\label{classmtm__alignment__test_1_1mtm__aligner_a83df974e499509163d717369caf24ef4}

\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_a6cc554ce6b26af83da6867df9784821a}{{\bfseries tf\-\_\-new\-\_\-psm1\-\_\-base}}\label{classmtm__alignment__test_1_1mtm__aligner_a6cc554ce6b26af83da6867df9784821a}

\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_acb3f9429ac21c843a006489a202070a5}{{\bfseries mtmr\-\_\-base}}\label{classmtm__alignment__test_1_1mtm__aligner_acb3f9429ac21c843a006489a202070a5}

\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_a3c7cbcff7ef9b58a3d390f5f12d5273b}{{\bfseries mtmr\-\_\-hw}}\label{classmtm__alignment__test_1_1mtm__aligner_a3c7cbcff7ef9b58a3d390f5f12d5273b}

\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_abff688327c863eef627434bf191a1ced}{{\bfseries mtml\-\_\-hw}}\label{classmtm__alignment__test_1_1mtm__aligner_abff688327c863eef627434bf191a1ced}

\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_a87073e1b7a7361ae32ad98c018269438}{{\bfseries psm1\-\_\-hw}}\label{classmtm__alignment__test_1_1mtm__aligner_a87073e1b7a7361ae32ad98c018269438}

\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_ad095e8db3bc09f4f6a96187a4fda2cf9}{{\bfseries psm2\-\_\-hw}}\label{classmtm__alignment__test_1_1mtm__aligner_ad095e8db3bc09f4f6a96187a4fda2cf9}

\end{DoxyCompactItemize}
\subsection*{Static Public Attributes}
\begin{DoxyCompactItemize}
\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_a84768367a1e9952cd2be1f8bf6d77eb5}{{\bfseries q} = msg.\-position}\label{classmtm__alignment__test_1_1mtm__aligner_a84768367a1e9952cd2be1f8bf6d77eb5}

\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_a69769e0c07a10bac224ef50a9fd4070a}{tuple {\bfseries ecm\-\_\-ee} = self.\-ecm\-\_\-kin.\-forward(q)}\label{classmtm__alignment__test_1_1mtm__aligner_a69769e0c07a10bac224ef50a9fd4070a}

\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_a7cb6f99d5700f109f560cd6fa0dbc79f}{tuple {\bfseries ecm\-\_\-base\-\_\-frame} = self.\-ecm\-\_\-base.\-forward(\mbox{[}$\,$\mbox{]})}\label{classmtm__alignment__test_1_1mtm__aligner_a7cb6f99d5700f109f560cd6fa0dbc79f}

\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_ab41240ac9e3960dca058d464b7460874}{tuple {\bfseries r\-\_\-180\-\_\-x} = self.\-rotate('x', pi)}\label{classmtm__alignment__test_1_1mtm__aligner_ab41240ac9e3960dca058d464b7460874}

\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_a1353322b5bb40f0a5d8ef8ae6c644e95}{tuple {\bfseries r\-\_\-90\-\_\-z} = self.\-rotate('z', -\/pi/2)}\label{classmtm__alignment__test_1_1mtm__aligner_a1353322b5bb40f0a5d8ef8ae6c644e95}

\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_af550be8d65ace8a3e291ca55c19cbe41}{tuple {\bfseries psm1\-\_\-base\-\_\-frame} = (ecm\-\_\-ee $\ast$$\ast$ -\/1)}\label{classmtm__alignment__test_1_1mtm__aligner_af550be8d65ace8a3e291ca55c19cbe41}

\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_ab2bda5b0fb885d59bbc8d85226038db2}{tuple {\bfseries psm1\-\_\-message} = pose\-\_\-converter.\-Pose\-Conv.\-to\-\_\-pose\-\_\-msg(psm1\-\_\-base\-\_\-frame)}\label{classmtm__alignment__test_1_1mtm__aligner_ab2bda5b0fb885d59bbc8d85226038db2}

\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_a5ab5797fdbfebd015d215d9dbcb2929e}{tuple {\bfseries psm1\-\_\-message\-\_\-stamped} = pose\-\_\-converter.\-Pose\-Conv.\-to\-\_\-pose\-\_\-stamped\-\_\-msg(psm1\-\_\-base\-\_\-frame)}\label{classmtm__alignment__test_1_1mtm__aligner_a5ab5797fdbfebd015d215d9dbcb2929e}

\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_a3575f94b228b6d8998bb4c19f8f4cde9}{tuple {\bfseries psm2\-\_\-base\-\_\-frame} = (ecm\-\_\-ee $\ast$$\ast$ -\/1)}\label{classmtm__alignment__test_1_1mtm__aligner_a3575f94b228b6d8998bb4c19f8f4cde9}

\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_a08c8a821a4f07982873341c23fe4a09d}{tuple {\bfseries psm2\-\_\-message} = pose\-\_\-converter.\-Pose\-Conv.\-to\-\_\-pose\-\_\-msg(psm2\-\_\-base\-\_\-frame)}\label{classmtm__alignment__test_1_1mtm__aligner_a08c8a821a4f07982873341c23fe4a09d}

\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_a8c0374e589d2db89fd59e01dbfaef02f}{tuple {\bfseries psm2\-\_\-message\-\_\-stamped} = pose\-\_\-converter.\-Pose\-Conv.\-to\-\_\-pose\-\_\-stamped\-\_\-msg(psm2\-\_\-base\-\_\-frame)}\label{classmtm__alignment__test_1_1mtm__aligner_a8c0374e589d2db89fd59e01dbfaef02f}

\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_affd419c85a6756e4646051d811ac38ba}{tuple {\bfseries ecm\-\_\-message} = pose\-\_\-converter.\-Pose\-Conv.\-to\-\_\-pose\-\_\-msg(ecm\-\_\-base\-\_\-frame)}\label{classmtm__alignment__test_1_1mtm__aligner_affd419c85a6756e4646051d811ac38ba}

\item 
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_add6c43296672eb784ced99b9e224f58e}{tuple {\bfseries ecm\-\_\-ee\-\_\-message\-\_\-stamped} = pose\-\_\-converter.\-Pose\-Conv.\-to\-\_\-pose\-\_\-stamped\-\_\-msg(ecm\-\_\-ee)}\label{classmtm__alignment__test_1_1mtm__aligner_add6c43296672eb784ced99b9e224f58e}

\end{DoxyCompactItemize}


\subsection{Member Function Documentation}
\hypertarget{classmtm__alignment__test_1_1mtm__aligner_ae8bb0d4f0b12e149f1032b18ee13754f}{\index{mtm\-\_\-alignment\-\_\-test\-::mtm\-\_\-aligner@{mtm\-\_\-alignment\-\_\-test\-::mtm\-\_\-aligner}!rotate@{rotate}}
\index{rotate@{rotate}!mtm_alignment_test::mtm_aligner@{mtm\-\_\-alignment\-\_\-test\-::mtm\-\_\-aligner}}
\subsubsection[{rotate}]{\setlength{\rightskip}{0pt plus 5cm}def mtm\-\_\-alignment\-\_\-test.\-mtm\-\_\-aligner.\-rotate (
\begin{DoxyParamCaption}
\item[{}]{self, }
\item[{}]{axis, }
\item[{}]{angle}
\end{DoxyParamCaption}
)}}\label{classmtm__alignment__test_1_1mtm__aligner_ae8bb0d4f0b12e149f1032b18ee13754f}
\begin{DoxyVerb}Returns a rotation matrix
    axis : 'x','y' or 'z'
    angle : In radians
\end{DoxyVerb}
 

The documentation for this class was generated from the following file\-:\begin{DoxyCompactItemize}
\item 
mtm\-\_\-alignment\-\_\-test.\-py\end{DoxyCompactItemize}

gha: HTML, lang: tex
import app from 'flarum/admin/app';
import { SettingsPage } from './SettingsPage';

app.initializers.add('maicol07-sso', () => {
  app.extensionData
    .for('maicol07-sso')
    .registerSetting({
      setting: 'maicol07-sso.manage_account_btn_open_in_new_tab',
      label: app.translator.trans('maicol07-sso.admin.settings.manage_account_btn_open_in_new_tab'),
      type: 'boolean',
    })
    .registerSetting({
      setting: 'maicol07-sso.remove_login_btn',
      label: app.translator.trans('maicol07-sso.admin.settings.remove_login_btn'),
      type: 'boolean',
    })
    .registerSetting({
      setting: 'maicol07-sso.remove_signup_btn',
      label: app.translator.trans('maicol07-sso.admin.settings.remove_signup_btn'),
      type: 'boolean',
    })
    .registerPage(SettingsPage);
});

gha: PHP, lang: javascript
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE pkgmetadata SYSTEM "https://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>cyber+gentoo@sysrq.in</email>
		<name>Anna</name>
	</maintainer>
	<longdescription lang="en">
		Crystal is a programming language that resembles Ruby but compiles to
		native code and tries to be much more efficient, at the cost of
		disallowing certain dynamic aspects of Ruby.
	</longdescription>
	<upstream>
		<remote-id type="github">crystal-lang/crystal</remote-id>
	</upstream>
</pkgmetadata>

gha: Shell, lang: xml
---
import HeaderLink from './HeaderLink.astro';
import { SITE_TITLE } from '../config';
import HeaderInner from './HeaderInner.astro';
---

<header class="w-100 bg-gray-800 text-white">
	<HeaderInner />
</header>
gha: Astro, lang: javascript
BARUFER ; IHS/SD/TPF - UFMS ERROR RESOLUTION ; 10/24/2008
 ;;1.8;IHS ACCOUNTS RECEIVABLE;**3,7,8,23**;OCT 26, 2005
 Q
 ;
LKUP ;EP - LOOK UP ERROR REPORTED BY UFMS
 N SEARCH,TARGET,CHOICE,ITEM,MAX,LINE,ESC
 D ERRHDR
 S $P(LINE,"-",81)=""
 K DIR,DIC,DIE,DR,DA
 S DIR("?",1)="Enter an 'APPLY TO' value. This corresponds to the 3P invoice #,"
 S DIR("?",2)="or Enter a partial 'APPLY TO' value,"
 S DIR("?")="or enter a '*' to get a list of all 'APPLY TO' values on file"
 S DIR("A")="Enter an 'APPLY TO' value: "
 S DIR(0)="FO^1:20"
 D ^DIR
 Q:$D(DIRUT)!$D(DTOUT)!$D(DUOUT)!(Y="")
 ;
 S TARGET=Y
 K CHOICES
 I Y="*" S SEARCH="",TARGET=""
 E  S SEARCH=TARGET-1
 S (MAX,ESC,CHOICE)=0
 F ITEM=1:1 S SEARCH=$O(^BARSESS(DUZ(2),"E",SEARCH)) Q:SEARCH=""!($E(SEARCH,1,$L(TARGET))'=TARGET)!(ESC)!(CHOICE)  D  ;MRS:BAR*1.8*8 HEAT739
 .;F ITEM=1:1 S SEARCH=$O(^BARSESS(DUZ(2),"E",SEARCH)) Q:SEARCH=""!(ESC)!(CHOICE)  D  ;MRS:BAR*1.8*8 HEAT739
 .S CHOICES(ITEM)=SEARCH
 .S MAX=MAX+1
 .W !,ITEM_". "_CHOICES(ITEM)
 .I '(ITEM#10)!('$O(^BARSESS(DUZ(2),"E",SEARCH))) K DIR S DIR(0)="NO^1:"_MAX W ! D ^DIR Q:Y=""  S ESC=$D(DIRUT)!$D(DTOUT)!$D(DUOUT) Q:ESC  S CHOICE=CHOICES(+Y)
 I '$D(CHOICES) W "   ??" H 2 G LKUP
 I ITEM=2,$D(CHOICES) D ARTRAN(CHOICES(1)) G LKUP
 G:ESC!'(CHOICE) LKUP
 D ARTRAN(CHOICE)
 G LKUP
 Q
 ;
ARTRAN(APPLYTO) ;EP - PULL TRANSACTION DATA
 N TRDATE,EXDATE,BILL,BILLIEN,TPBIEN,TRANTYP,ADJCAT,ENTRYBY
 S PAGE=0
 D LKUPHDR(APPLYTO)
 D TRDETAIL
 S TRDATE="",ESC=0
 F  S TRDATE=$O(^BARSESS(DUZ(2),"E",APPLYTO,TRDATE)) Q:'TRDATE!(ESC)  D
 .S CREDIT=$$GET1^DIQ(90050.03,TRDATE_",",2)
 .S DEBIT=$$GET1^DIQ(90050.03,TRDATE_",",3)
 .S BILL=$$GET1^DIQ(90050.03,TRDATE_",",4)
 .S BLLIEN=$$GET1^DIQ(90050.03,TRDATE_",",4,"I")
 .S ENTRYBY=$$GET1^DIQ(90050.03,TRDATE_",",13,"E")
 .S TPBIEN=$$GET1^DIQ(90050.01,BLLIEN_",",17,"I")
 .S TRANTYP=$$GET1^DIQ(90050.03,TRDATE_",",101,"E")
 .S ADJCAT=$$GET1^DIQ(90050.03,TRDATE_",",102,"E")
 .S SESSID=$O(^BARSESS(DUZ(2),"E",APPLYTO,TRDATE,""))
 .S UDUZ=$O(^BARSESS(DUZ(2),"E",APPLYTO,TRDATE,SESSID,""))
 .W !,BILL
 .S Y=TRDATE X ^DD("DD") S EXDATE=Y
 .W ?18,EXDATE
 .W ?50,SESSID
 .;W ?65,$E($P($G(^VA(200,DUZ,0)),U),1,15)  ;MRS;BAR*1.8*7
 .W ?65,$E($P($G(^VA(200,UDUZ,0)),U),1,15)  ;MRS;BAR*1.8*7
 .W !?10,ENTRYBY
 .W ?30,$J(CREDIT,10,2)
 .W ?40,$J(DEBIT,10,2)
 .W ?52,$E(TRANTYP,1,15)
 .W ?70,$E(ADJCAT,1,10)
 .I $Y>(IOSL-4) W ! K DIR S DIR(0)="E" D ^DIR S ESC=$D(DIRUT)!$D(DTOUT)!$D(DUOUT) Q:ESC  D LKUPHDR(APPLYTO),TRDETAIL
 .S DELSEND=$$GET1^DIQ(90057.110102,TRDATE_","_SESSID_","_UDUZ_",",.08,"E")
 .I DELSEND'="" D
 ..W !?15,"FILE SENT IN DELAYED MODE:"
 ..W !?20,DELSEND
 .;SESSION TRANSMISSION DATES
 .S TRANSDT=0  ;TRANSMISSION DATE
 .F CNT=1:1 S TRANSDT=$O(^BARSESS(DUZ(2),UDUZ,11,SESSID,21,TRANSDT)) Q:'TRANSDT!ESC  D
 ..S IENS=TRANSDT_","_SESSID_","_UDUZ_","
 ..S EXTRANS=$$GET1^DIQ(90057.210101,IENS,.01,"E")
 ..W:CNT=1 !?15,"SESSION TRANSMISSION DATE: ",EXTRANS
 ..I $Y>(IOSL-4) W ! K DIR S DIR(0)="E" D ^DIR S ESC=$D(DIRUT)!$D(DTOUT)!$D(DUOUT) Q:ESC  D TRANSHDR
 ..S FILENAME=$$GET1^DIQ(90057.210101,IENS,.02,"E")
 ..S BY=$$GET1^DIQ(90057.210101,IENS,.03,"E")
 ..W !?15,"IN FILE: ",FILENAME
 ..W !?15,"     BY: ",BY
 Q:ESC
 K DIR
 S DIR(0)="E"
 W !
 D ^DIR
 Q
 ;
LKUPHDR(APPLYTO) ;
 N PARENT,SATELITE
 W @IOF
 S PAGE=$G(PAGE)+1
 S X="VIEWING TRANSACTIONS ASSOCIATED WITH 'APPLY TO'"
 S X=$J("",IOM-$L(X)\2-$X)_X
 W !,X
 W ?70,"PAGE ",PAGE
 W !
 W $$CJ^XLFSTR("FIELD OF "_APPLYTO,IOM)
 S PARENT=$E(APPLYTO,1,6)
 S SATELITE=$E(APPLYTO,7,12)
 K DIC,DIR,DIE,DA,DR
 S DIC="^AUTTLOC("
 S D="CTOO"
 S DIC(0)=""
 S X=PARENT
 D IX^DIC
 I Y<0 D
 .S D="C"
 .S DIC(0)=""
 .S X=PARENT
 .D IX^DIC
 I Y<0 S PARENTNM="CAN'T BE FOUND"
 E  S PARENTNM=$$GET1^DIQ(9999999.06,+Y_",",.01,"E")
 K DIC,DIR,DIE,DA,DR
 S DIC="^AUTTLOC("
 S D="CTOO"
 S DIC(0)=""
 S X=SATELITE
 D IX^DIC
 I Y<0 D
 .S D="C"
 .S DIC(0)=""
 .S X=SATELITE
 .D IX^DIC
 I Y<0 S SATNAME="CAN'T BE FOUND"
 E  S SATNAME=$$GET1^DIQ(9999999.06,+Y_",",.01,"E")
 K DIC,DIR,DIE,DA,DR
 W $$CJ^XLFSTR("PARENT:   "_PARENTNM,IOM)
 W $$CJ^XLFSTR("SATELLITE: "_SATNAME,IOM)
 Q
 ;
TRDETAIL ;
 W !!?3,"A/R BILL"
 W ?18,"TRAN. DATE"
 W ?50,"SESSION ID"
 W ?65,"SENT BY"
 W !?10,"ENTRY BY"
 W ?35,"CREDIT"
 W ?45,"DEBIT"
 W ?52,"TRANTYPE"
 W ?70,"ADJCAT"
 W !,LINE
 Q
 ;
ERRHDR ;EP - ERROR SCREEN HEADER
 W @IOF
 W !!,$$CJ^XLFSTR("TRANSACTION LOOKUP BY 'APPLY TO' FIELD",IOM)
 W !
 Q
 ;
TRANSHDR ;EP - TRANSMISSION HEADER
 W @IOF
 W !?15,"SESSION TRANSMISSION DATE: ",EXTRANS
 Q

gha: M, lang: assembly
{ lib, stdenv, symlinkJoin, fetchRFCBulk ? lib.fetchRFCBulk }:

stdenv.mkDerivation {
  name = "rfcs";
  src = symlinkJoin {
    name = "rfcs";
    paths = [
      (fetchRFCBulk {
        range = "0001-0500";
        hash = "sha256-sg0WED3hLhVkior4T7fj3aNYV53sxHCXFHr2TR0PVs8=";
      })
      (fetchRFCBulk {
        range = "0501-1000";
        hash = "sha256-oXQFaGWfpGz82ajK/lJ8tM/IcMFOx0dLhp8VqF7H3Ss=";
      })
      (fetchRFCBulk {
        range = "1001-1500";
        hash = "sha256-gu8Y+qwj+rhJB0zViMCE2BzgGEl0i95dbkPWJ/yHGpY=";
      })
      (fetchRFCBulk {
        range = "1501-2000";
        hash = "sha256-bfqBd8KO7AnvK4WKGw/GPg4XWdqq1fKq/qlAszv6dNU=";
      })
      (fetchRFCBulk {
        range = "2001-2500";
        hash = "sha256-FcYx+QcCFjUkA9k89W+nRygZySoaiIOg/HR5XtauVEc=";
      })
      (fetchRFCBulk {
        range = "2501-3000";
        hash = "sha256-ivngywGT5PMj6yQw3llKIkVEZixup7jtpxNzb7oZ/N8=";
      })
      (fetchRFCBulk {
        range = "3001-3500";
        hash = "sha256-efmPFtMBOhBFUjlNYODRY80dGh65Ar8LZjbJAUhrXyQ=";
      })
      (fetchRFCBulk {
        range = "3501-4000";
        hash = "sha256-SH1S7qAGx3RpI4q0SQfsqnoLVzgyxkBVBQJcAUfGTeQ=";
      })
      (fetchRFCBulk {
        range = "4001-4500";
        hash = "sha256-l61Y8ONNwlJ6YxxEjUellN3froh0DMkIBqthy5NTrw0=";
      })
      (fetchRFCBulk {
        range = "4501-5000";
        hash = "sha256-ROeg1yyYxwih3ew80UYMSFCyRIpUUUEm4XBywRbRP5M=";
      })
      (fetchRFCBulk {
        range = "5001-5500";
        hash = "sha256-xEMH5x9lzlZ18x/6NIhrXZjoACFY5EnQ5AXFIPqos3Y=";
      })
      (fetchRFCBulk {
        range = "5501-6000";
        hash = "sha256-pbX5rtABeJp7XkNj44sFgctY12QpkkN2SKXXersbjGo=";
      })
      (fetchRFCBulk {
        range = "6001-6500";
        hash = "sha256-z8dHZoACvzMSrBbaSnZsPeBuDlQvFLixR0ho4cS5who=";
      })
      (fetchRFCBulk {
        range = "6501-7000";
        hash = "sha256-FJRhoiHfbqSyM4CJd0qFPJa2n+Zs52CnyY1BlwV24WU=";
      })
      (fetchRFCBulk {
        range = "7001-7500";
        hash = "sha256-m4h7segOsuhGKxjY/pBJpHKGUZZhIB5CpTbGZ/lw8bU=";
      })
      (fetchRFCBulk {
        range = "7501-8000";
        hash = "sha256-OIFl7kXOiFZxKCp779vzr/RLN93nMpqAgdSCd8A6lVk=";
      })
      (fetchRFCBulk {
        range = "8001-8500";
        hash = "sha256-MWN0gQke+zes2o9JYgiGQAtYMaF1E70aupvVlsQ+YRg=";
      })
      (fetchRFCBulk {
        range = "8501-latest";
        # even though we download the "latest" file, after removing files, that
        # we dont know. we should end up with the same hash regardless of
        # upstream file changes.
        postFetch = ''
          find -not -regex ".*/rfc8[5-8][0-9][0-9]\\.txt" -delete
        '';
        hash = "sha256-5wKF5fwWuORSEfOvJuKHgRkZBOphJq4fr/kVQRNAfac=";
      })
    ];
  };
  buildPhase = ''
    install -Dt $out/share/rfc/ *.txt
    (cd $out/share/rfc; gzip -9 *.txt)
  '';
}

gha: Nix, lang: javascript
{% extends "_base_core.html" %}
{% load static %}
{% load common_tags %}
{% block page_title %} {{ viewParams.MON_VO }} PanDA ES tasks{% endblock %}
{% block title %} <a class="menu-link" href="{% url 'index' %}">{{ viewParams.MON_VO }} PanDA</a>{% endblock %}
{% block subtitle %}Event Service tasks{{viewParams.selection|safe }}
{% if vo %}     for VO {{ vo }}
{% endif %}
{% endblock %}

{% block subtitle_params %}
{% if tasksTotalCount %}<b> Total tasks found &#x7E; <a href="{{ request.session.urls_cut.nolimiturl }}limit={{ tasksTotalCount }}">{{ tasksTotalCount }}</a></b>{% endif %}
{% endblock %}

{% block css_page_library %}
  <!-- Load c3.css -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/c3/0.7.8/c3.min.css" rel="stylesheet">
{% endblock %}
{% block js_head_page_library %}
  <script src="{% static 'js/humanize.min.js' %}"></script>
  <script src="{% static 'js/jquery.shorten.1.0.js' %}"></script>
  <!-- Load d3.js and c3.js -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/d3/5.12.0/d3.min.js" charset="utf-8"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/c3/0.7.8/c3.min.js"></script>
{% endblock %}


{% block body %}
<div class="bp-selected-params">
{% if requestParams.statenotupdated %}<p><b>Tasks in <span class="{{ requestParams.status }}">{{ requestParams.status }}</span> state for more than {{ requestParams.statenotupdated }} hours</b></p> {% endif %}
{% if requestParams.workinggroup %}<p><b>Working group: {{ requestParams.workinggroup }}</b></p> {% endif %}
{% if requestParams.username %}<p><b>User: <a href="{% url 'userInfo' requestParams.username %}?display_limit=300">{{ requestParams.username }}</a>     <a href="{% url 'userInfo' requestParams.username %}?display_limit=300">Show user page</a></b></p> {% endif %}
{% if requestParams.tasktype %}<p><b>Task type: {{ requestParams.tasktype }}</b></p> {% endif %}

{% if requestParams.campaign %}<p><b>Campaign: {{ requestParams.campaign }}</b></p> {% endif %}
{% if requestParams.project %}<p><b>Project: {{ requestParams.project }}</b></p> {% endif %}
{% if requestParams.stream %}<p><b>Stream: {{ requestParams.stream }}</b></p> {% endif %}
{% if requestParams.tag %}<p><b>Tag: {{ requestParams.tag }}</b></p> {% endif %}

{% if requestParams.transpath %}<p><b>Transformation: {{ requestParams.transpath }}</b></p> {% endif %}
{% if requestParams.transuses %}<p><b>Release: {{ requestParams.transuses }}</b></p> {% endif %}
{% if requestParams.processingtype %}<p><b>Processing type: {{ requestParams.processingtype }}</b></p> {% endif %}
{% if requestParams.cloud %}<p><b>Cloud: {{ requestParams.cloud }}</b></p> {% endif %}
{% if requestParams.parent_tid %}<p><b>Parent task: {{ requestParams.parent_tid }}</b></p> {% endif %}
{% if requestParams.status %}<p><b>{% if viewParams.MON_VO == 'ATLAS' %}Detailed JEDI task status {% else %}Task status {% endif %}: <span class='{{requestParams.status}}'>{{ requestParams.status }}</span></b></p> {% endif %}
{% if requestParams.superstatus %}<p><b>{% if viewParams.MON_VO == 'ATLAS' %}Task status {% else %}Task status {% endif %}: <span class='{{requestParams.superstatus}}'>{{ requestParams.superstatus }}</span></b></p> {% endif %}
{% if requestParams.hashtag %}<p><b>Hashtag: {{ requestParams.hashtag }} </b></p> {% endif %}
</div>

{% if tasks %}

{% if sumd %}

<table>
<tr class='tablesection'><th colspan=20> Task attribute summary, {{ ntasks }} tasks </th></tr>
{% for fdict in sumd %}
<tr><th> {{ fdict.field }} ({{ fdict.list|length }}) </th><div class="comment more"><td>
{% for item in fdict.list %}
<span {% if fdict.field == 'status' or fdict.field == 'superstatus' %} class='{{item.kname}} bp_tooltip task_{{item.kname}}' {% endif %}> {{ item.kname }} </span>
{% if not request.session.xurls or fdict.field not in request.session.xurls %}
    <a href="{{ xurl }}{{ fdict.field }}={{ item.kname }}">({{ item.kvalue }})</a>
{% else %}
    <a href="{{ request.session.xurls|get_item:fdict.field }}{{ fdict.field }}={{ item.kname }}">({{ item.kvalue }})</a>
{% endif %}
{% endfor %}
</td></div></tr>
{% endfor %}
{% if hashtags and hashtags|length > 0 %}
    <tr>
        <th>hashtags ({{ hashtags|length }})</th>
        <td>{% for hashtag in hashtags %}
                {% if 'hashtag' in requestParams %}
                    <a href="{{ nohashtagurl }}hashtag={{ requestParams.hashtag }},{{ hashtag }}">{{ hashtag }}</a>
                {% else %}
                    <a href="{{ xurl }}hashtag={{ hashtag }}">{{ hashtag }}</a>
                {% endif %}
                {% if not forloop.last %}, {% endif %}
            {% endfor %}</td>
    </tr>
{% endif %}
</table>
{% endif %}
  
  
<div id="div-plot">
    <a href="#plots" class="button bluebutton" onclick="togglePlots();"><span class="tooltip-right">Show jobs consumption plots<span class="tooltip-text">It might be slow if number of tasks in current selection is big.</span></span></a>
</div>


<div id="plots" data-ng-controller="jobConsumptionPlotsController">
<div class="card bp-container-simple secondary ng-hide" ng-hide="tasklist.jc_plots.selection.is_hidden">
  <div class="card-divider"><p>Job consumption plots:</p></div>
  <div class="card-section">
    <p ng-bind-html="tasklist.jc_plots.message"></p>

    <fieldset class="inline">
      <legend>Job category:</legend>
      <label ng-repeat="option in tasklist.jc_plots.options.category"><input type="radio" ng-value="option" ng-model="tasklist.jc_plots.selection.category" ng-change="tasklist.jc_plots.rebuild()">{$ option $}</label>
    </fieldset>

    <div class="c3-chart-block" ng-repeat="plot in tasklist.jc_plots.plot_data" jcplot-directive plot="plot" parent="$parent"></div>
  </div>
</div>
</div>
  
  
  
<table>
<tr class='tablesection'>
  <th colspan=20> {{ tasks|length }} tasks, sorted by
    {% if 'sortby' in requestParams %} {{ requestParams.sortby }} {% else %} jeditaskid-desc {% endif %}
    {% if ntasks > tasks|length %}
      <a href="{{ request.session.urls_cut.nodisplaylimiturl }}display_limit={{ ntasks }}">, remove the limit</a>
    {% endif %}
  </th></tr>
<tr class='tablesection'>
	<th><a href="{{request.session.urls_cut.nosorturl}}">ID</a></th>
    {% if requestParams.tasktype == 'anal' %}<th>Jobset</th>{% endif %}
	<th>TaskType/ProcessingType     Group<br><font color='brown'>Logged status</font></th>

    <th>Site</th>

	<th>Task status</th>
	<th>Ninputfiles | <span class='finished'>finished</span> | <br><span class='failed'>failed</span></th>
	<th>Nevents | remaining</th>

	<th>Event dispatches</th>
	<th><a href="{{request.session.urls_cut.nosorturl}}">Created</a></th>
	<th><a href="{{request.session.urls_cut.nosorturl}}sortby=time-descending">Modified</a></th>
	<th><a href="{{request.session.urls_cut.nosorturl}}sortby=statetime-descending">State changed</a></th>
	<th><a href="{{request.session.urls_cut.nosorturl}}sortby=priority">Priority</a></th>
</tr>
{% for task in tasks %}
	<tr>
		<td><a href="{% url 'taskInfo' task.jeditaskid %}">{{ task.jeditaskid }}</a></td>
		{% if requestParams.tasktype == 'anal' %}<td>{{ task.reqid }}</td>{% endif %}
		<td>{{ task.tasktype }}{% if task.processingtype %}/{{ task.processingtype }} {% endif %}     {% if task.workinggroup %} <a href="{% url 'taskList' %}?workinggroup={{ task.workinggroup }}">{{ task.workinggroup }}</a>     {% endif %}  <a href="{% url 'taskList' %}?username={{ task.username }}">{{ task.username }}</a></font> {% if task.ticketid %}     <a href="https://its.cern.ch/jira/browse/{{ task.ticketid }}"> {% if task.ticketsystemtype %}{{ task.ticketsystemtype }} {% else %} JIRA {% endif %}</a> {% endif %}
{% if task.deftreqid and viewParams.MON_VO == 'ATLAS' %}     RequestID:<a href="https://prodtask-dev.cern.ch/prodtask/inputlist_with_request/{{task.deftreqid}}/">{{task.deftreqid}}</a> {% endif %}
		<br><span class="alert wrap-words">{{ task.errordialog|safe }}</span></td>

        <td> <a href="{% url 'siteInfo' task.site %}">{{ task.site }}</a> </td>

		<td  class='{{task.superstatus}}_fill'><a href="https://panda-wms.readthedocs.io/en/latest/terminology/terminology.html#task">{% if task.superstatus %} <span class="bp_tooltip task_{{ task.superstatus }}">{{ task.superstatus }}</span> {% else %} <span class="bp_tooltip task_{{ task.status }}">{{ task.status }} </span> {% endif %}</a></td>
        <td>
            {{ task.dsinfo.nfiles }} | <span class='finished'> {{ task.dsinfo.nfilesfinished }}</span> | <span class='failed'>{{ task.dsinfo.nfilesfailed }}</span>
        </td>

        <td>
        {% if task.eventsData %}
            {{ task.eventsData.totev }} | {{ task.eventsData.totevrem }}
        {% endif %}
        </td>

        <td> {{task.estaskstr}}

           <div id="div-{{ task.jeditaskid }}">
                <a onclick="javascript:loadESData('{{ task.jeditaskid }}');">Show</a>
            </div>
        </td>
		<td><font size=-1>{{ task.creationdate }}</font></td>
		<td><font size=-1>{{ task.modificationtime }}</font></td>
		<td><font size=-1>{{ task.statechangetime }}</font></td>
		<td>{{ task.taskpriority }}</td>
	</tr>
{% endfor %}
</table>

{% else %}
    <p>No matches to query.</p>
{% endif %}
{% endblock %}

{% block js_body_page %}
<script src="{% static 'js/draw-plots-c3.js' %}?{% cache_bust "js/draw-plots-c3.js" %}"></script>
<script type="text/javascript">

  app.controller('jobConsumptionPlotsController', function($scope, $http, $sce) {
    $scope.tasklist = {};
    $scope.tasklist.jc_plots = {
      message: $sce.trustAsHtml('<img src="{% static 'images/load.gif' %}"> Loading... '),
      selection: {
        category: '',
        is_hidden: true,
      },
      options: {
        category: []
      },
      url_path: '{% url 'tasksplots' %}?idtasks={{ idtasks }}',
      plot_data: [],
      charts: {}
    };

    $scope.tasklist.jc_plots.fetch = function () {
      $scope.tasklist.jc_plots.message = $sce.trustAsHtml('<img src="{% static 'images/load.gif' %}"> Loading... ');
      $http.get($scope.tasklist.jc_plots.url_path, {params:{}}).then(
        function success(response) {
          if (response.status === 200 && response.data.data.length > 0) {
              $scope.tasklist.jc_plots.plot_data = response.data.data;

              $scope.tasklist.jc_plots.options.category = [];
              Object.keys($scope.tasklist.jc_plots.plot_data[1].data.data).forEach((key) => {
                $scope.tasklist.jc_plots.options.category.push(key);
              });
              $scope.tasklist.jc_plots.options.category.sort();
              $scope.tasklist.jc_plots.selection.category = 'run';

              $scope.tasklist.jc_plots.message = '';
          }
          else {
            let message = '';
            (response.data.error && response.data.error.length > 0) ? message = response.data.error : message = 'No jobs found for this list of tasks.';
            $scope.tasklist.jc_plots.message = $sce.trustAsHtml(message);
          }
        },
        function error(response) {
          console.log(response);
          $scope.tasklist.jc_plots.message = $sce.trustAsHtml('Failed to load data :( Try to refresh page by link on the top right.');
        },
      );
    };

    $scope.tasklist.jc_plots.build = function () {
      $scope.tasklist.jc_plots.plot_data.forEach((item) => {
        if (item.data.details.type === 'pie') {
          $scope.tasklist.jc_plots.charts[item.name + "_chart"] = draw_donut(item.data.data[$scope.tasklist.jc_plots.selection.category]['columns'], item.name + "_chart", item.data.details.title, item.data.details)
        }
        else if (item.data.details.type === 'stack_bar') {
          $scope.tasklist.jc_plots.charts[item.name + "_chart"] = draw_stacked_bar_hist(item.data.data[$scope.tasklist.jc_plots.selection.category], item.data.details, item.name + "_chart");
        }
      })
    };

    $scope.tasklist.jc_plots.rebuild = function () {
      $scope.tasklist.jc_plots.destroy();
      $scope.tasklist.jc_plots.build();
    };

    $scope.tasklist.jc_plots.destroy = function () {
      let plot_names = Object.keys($scope.tasklist.jc_plots.charts);
      plot_names.forEach((item) => {
        if ($scope.tasklist.jc_plots.charts[item]) {
          $scope.tasklist.jc_plots.charts[item] = $scope.tasklist.jc_plots.charts[item].destroy();
        }
      });
    };

    $scope.tasklist.jc_plots.toggle = function () {
      if (Object.keys($scope.tasklist.jc_plots.charts).length === 0) {
        $scope.tasklist.jc_plots.fetch();
        $scope.tasklist.jc_plots.selection.is_hidden = false;
      }
      else {
        ($scope.tasklist.jc_plots.selection.is_hidden) ? $scope.tasklist.jc_plots.selection.is_hidden = false : $scope.tasklist.jc_plots.selection.is_hidden = true;
      }
    }

  })
  .directive('jcplotDirective', function ($timeout) {
      var template = '<div id="{$plot.name$}_chart"></div>';
      return {
          template: template,
          scope: {
              plot: '=',
              parent: '=',
          },
          link: function (scope, element, attrs) {
            $timeout(() => {
              element.ready(() => {
                if (scope.plot.data.details.type === 'pie') {
                  if ('size' in scope.plot.data.details) {scope.plot.data.details.size[0] = getWidth();}
                  scope.parent.tasklist.jc_plots.charts[scope.plot.name + "_chart"] = draw_donut(scope.plot.data.data[scope.parent.tasklist.jc_plots.selection.category]['columns'], scope.plot.name + "_chart", scope.plot.data.details.title, scope.plot.data.details)
                }
                else if (scope.plot.data.details.type === 'stack_bar') {
                  scope.parent.tasklist.jc_plots.charts[scope.plot.name + "_chart"] = draw_stacked_bar_hist(scope.plot.data.data[scope.parent.tasklist.jc_plots.selection.category], scope.plot.data.details, scope.plot.name + "_chart");
                }
              });
            });
          }
      };
  });

  function togglePlots() {
    let scope = angular.element(document.getElementById('plots')).scope();
    scope.tasklist.jc_plots.toggle();
  }  
  
  function loadESData(jeditaskid) {

      $('#div-'+jeditaskid).html("<img src='{% static "images/load.gif" %}'>  ");
      $.ajax({
          url: {% url 'taskESExtendedInfo' %},
          data: 'jeditaskid='+jeditaskid,
          async: true,
      }).done(function (response) {
          $('#div-'+jeditaskid).html(response);
      });
  }

  $(document).ready(function () {
    $(".comment").shorten({showChars: getNCharsShorten(), minHideChars: 250});
  });

</script>

{% endblock %}

{% block help %}
  {% include "taskListHelp.html" %}
  {% include "taskInfoHelp.html" with show="all" %}
{% endblock %}


gha: JavaScript, lang: html
{{- /*
A template for handling warning messages.
*/}}

{{- /* Warn about not setting salt and keys explicitly */}}
{{- define "mattermost.warnings" }}
{{- with .Values.configJSON }}
{{- if not (and (.EmailSettings.InviteSalt) (and .FileSettings.PublicLinkSalt .SqlSettings.AtRestEncryptKey)) }}
WARNING:
--------

Every `helm upgrade` will generate a new set of keys unless it is set manually like this:

configJSON:
  {{- if not .EmailSettings.InviteSalt }}
  EmailSettings:
    InviteSalt: {{ randAlphaNum 32 }}
  {{- end }}
  {{- if not .FileSettings.PublicLinkSalt }}
  FileSettings:
    PublicLinkSalt: {{ randAlphaNum 32 }}
  {{- end }}
  {{- if not .SqlSettings.AtRestEncryptKey }}
  SqlSettings:
    AtRestEncryptKey: {{ randAlphaNum 32 }}
  {{- end }}
{{- end }}
{{- end }}
{{- end }}

gha: Mustache, lang: yaml
### Package Import
import sys
import os
base_dir = os.environ['GEMS_HOME']
project_path = os.path.join(base_dir, 'python-refactor')
sys.path.insert(0, project_path)
from Code.utils import matlab

import numpy as np
from numba import njit
import time

### Setting path
#data_base_dir = os.path.join('/data2', 'sehyun', 'Data')
#path_omi_processed = os.path.join(data_base_dir, 'Preprocessed_raw', 'OMI')


### Setting path
#data_base_dir = os.path.join(project_path, 'Data')
#path_read = os.path.join(data_base_dir, 'Preprocessed_raw', 'OMI') 
data_base_dir = os.path.join('/', 'share', 'irisnas5', 'GEMS', 'GEMS_python')
path_read = os.path.join(data_base_dir, 'Preprocessed_raw', 'OMI_tempConv')

### Setting period
pname_list = ['OMNO2d_trop_CS','OMSO2e_m','OMDOAO3e_m','OMHCHOG']

mask = np.zeros((720, 1440))
mask[340:560, 1020:1320] = 1
mask = mask.ravel(order='F')

### Temporal convolution with gaussian
for pname in pname_list:

    print (pname)
    ### Load data
    YEARS = [2014,2015,2016,2017,2018,2019]
    def read_and_mask(yr):
        if os.path.isfile(os.path.join(path_read, f'{pname}_{yr}_DU.mat')):
            data_yr = matlab.loadmat(os.path.join(path_read, f'{pname}_{yr}_DU.mat'))['data_yr']
        elif os.path.isfile(os.path.join(path_read, f'{pname}_{yr}.mat')):
            data_yr = matlab.loadmat(os.path.join(path_read, f'{pname}_{yr}.mat'))['data_yr']
        else:
            raise ValueError(f'{pname}_{yr}.mat does not exists though variation tried.')
        data_subset = data_yr[mask==1, :]
        return data_subset
    data = np.concatenate([read_and_mask(yr) for yr in YEARS], axis=1)  # hstack
    data[data==-9999] = np.nan

    if pname=='OMSO2e_m':
        sigma = 2
    else:
        sigma = 1
    print (f' data shape : {data.shape}')
    
    @njit(error_model='numpy')
    def calculate(data):
        data_conv = np.full(data.shape, np.nan)
        for k in range(data.shape[0]):
            for t in range(data.shape[1]):
                t_ = t+1
                w_sum = 0; x_sum = 0;
                for n in range(data.shape[1]):
                    n_ = n+1
                    if np.isnan(data[k,n])==0:
                        w = np.exp((-(t_-n_)**2)/(2*sigma**2)) #  calcuate weights using t,n(days) with sigma # (k+1)-(n-1)=k-n
                        x = data[k, n]*w
                        w_sum += w
                        x_sum += x
                data_conv[k,t] = x_sum/w_sum
            print (k)
        return data_conv
    data_conv = calculate(data)
    matlab.savemat(os.path.join(path_read, f'tempConv_{pname}_sigma{sigma}_{YEARS[0]}_{YEARS[len(YEARS)-1]}.mat'), 
                   {'data_conv':data_conv, 'data':data})
    
gha: Jupyter Notebook, lang: python
﻿namespace MBrace.Flow.Internals.Consumers

open System
open System.IO
open System.Linq
open System.Collections.Generic
open System.Collections.Concurrent
open System.Threading

open Nessos.Streams
open Nessos.Streams.Internals

open MBrace.Core
open MBrace.Core.Internals
open MBrace.Flow
open MBrace.Flow.Internals

#nowarn "444"

module Distinct =

    /// <summary>Returns a flow that contains no duplicate entries according to the generic hash and equality comparisons on the keys returned by the given key-generating function. If an element occurs multiple times in the flow then only one is retained.</summary>
    /// <param name="projection">A function to transform items of the input flow into comparable keys.</param>
    /// <param name="source">The input flow.</param>
    /// <returns>A flow of elements distinct on their keys.</returns>
    let distinctBy (projection : 'T -> 'Key) (source : CloudFlow<'T>) : CloudFlow<'T> =
        // Stage 1: distinct and shuffle data to cluster
        let distinctAndShuffle () = cloud {
            let distinctCollectorF = local {
                let dict = new ConcurrentDictionary<'Key, 'T>()
                let! ct = Cloud.CancellationToken
                let cts = CancellationTokenSource.CreateLinkedTokenSource ct.LocalToken
                return
                    { new Collector<'T, ICollection<'Key * 'T>> with
                        member __.DegreeOfParallelism = source.DegreeOfParallelism
                        member __.Iterator() =
                            {   Func = fun v -> dict.TryAdd(projection v, v) |> ignore
                                Cts = cts }
                        member __.Result = dict |> Collection.map (fun kv -> kv.Key, kv.Value)
                    }
            }

            let! workers = Cloud.GetAvailableWorkers()
            let workers = workers |> Array.sortBy (fun w -> w.Id)
            let workers = 
                match source.DegreeOfParallelism with 
                | None -> workers
                | Some dp -> Array.init (min dp workers.Length) (fun i -> workers.[i % workers.Length])
            
            // local shuffle of grouped results
            let shuffleLocal (groupings : seq<'Key * 'T>) = local {
                return!
                    groupings
                    |> Seq.groupBy (fun (k,_) -> workers.[abs (hash k) % workers.Length])
                    |> Seq.map (fun (w,gps) -> local { let! ca = CloudValue.NewArray(gps |> Seq.map snd, storageLevel = StorageLevel.Disk) in return w, ca })
                    |> Local.Parallel
            }

            // top-level shuffled results combiner
            let combiner (gathered : (IWorkerRef * CloudArray<'T>) [] []) = local {
                return gathered |> Seq.concat |> Seq.sortBy fst |> Seq.toArray
            }

            let! shuffleResults = source.WithEvaluators distinctCollectorF shuffleLocal combiner
            return PersistedCloudFlow<'T>(shuffleResults) :> CloudFlow<'T>
        }

        // Stage 2 : Perform final distinction operation on shuffled data
        let reduceFlow (collectorf : LocalCloud<Collector<'T, 'S>>) 
                        (flowProjection : 'S -> LocalCloud<'R>) (flowCombiner : 'R [] -> LocalCloud<'R>)
                        (shuffled : CloudFlow<'T>) = cloud {

            let reduceCollectorF = local {
                let! ct = Cloud.CancellationToken
                let dict = new ConcurrentDictionary<'Key, 'T>()
                let cts = CancellationTokenSource.CreateLinkedTokenSource ct.LocalToken
                return 
                    { new Collector<'T, ICollection<'T>> with
                        member self.DegreeOfParallelism = source.DegreeOfParallelism
                        member self.Iterator() =
                            {   Func = fun t -> dict.TryAdd(projection t, t) |> ignore
                                Cts = cts }

                        member self.Result = dict |> Collection.map (fun kv -> kv.Value)
                    }
            }

            let reduceProjection (inputs : ICollection<'T>) = local {
                let! collector = collectorf
                let iterators = Array.init Environment.ProcessorCount (fun _ -> collector.Iterator())
                let! _ =
                    inputs
                    |> Collection.splitByPartitionCount iterators.Length
                    |> Seq.mapi (fun i ts -> local { let iter = iterators.[i] in return for t in ts do iter.Func t })
                    |> Local.Parallel

                return! flowProjection collector.Result
            }

            return! shuffled.WithEvaluators reduceCollectorF reduceProjection flowCombiner
        }

        { new CloudFlow<'T> with
            member __.DegreeOfParallelism = source.DegreeOfParallelism
            member __.WithEvaluators<'S, 'R> collectorF (projection : 'S -> LocalCloud<'R>) combiner = cloud {
                let! shuffledResult = distinctAndShuffle()
                return! reduceFlow collectorF projection combiner shuffledResult
            }
        }
gha: F#, lang: ocaml
= RDBMS Design

When you set out to build a new data-driven application that will use a
relational database, you might start by modeling the domain as a set of
properly normalized tables and use foreign keys to reference related
data in other tables.

The figure below shows how you might represent the data storage for your
application using a relational database model. The relational model
includes a couple of “join” tables in order to realize the many-to-many
relationships from the conceptual model of hotels-to-points of interest,
rooms-to-amenities, rooms-to-availability, and guests-to-rooms (via a
reservation).

image::data-modeling_hotel_relational.png[image]

== Design Differences Between RDBMS and Cassandra

Let's take a minute to highlight some of the key differences in doing
data modeling for Cassandra versus a relational database.

=== No joins

You cannot perform joins in Cassandra. If you have designed a data model
and find that you need something like a join, you'll have to either do
the work on the client side, or create a denormalized second table that
represents the join results for you. This latter option is preferred in
Cassandra data modeling. Performing joins on the client should be a very
rare case; you really want to duplicate (denormalize) the data instead.

=== No referential integrity

Although Cassandra supports features such as lightweight transactions
and batches, Cassandra itself has no concept of referential integrity
across tables. In a relational database, you could specify foreign keys
in a table to reference the primary key of a record in another table.
But Cassandra does not enforce this. It is still a common design
requirement to store IDs related to other entities in your tables, but
operations such as cascading deletes are not available.

=== Denormalization

In relational database design, you are often taught the importance of
normalization. This is not an advantage when working with Cassandra
because it performs best when the data model is denormalized. It is
often the case that companies end up denormalizing data in relational
databases as well. There are two common reasons for this. One is
performance. Companies simply can't get the performance they need when
they have to do so many joins on years' worth of data, so they
denormalize along the lines of known queries. This ends up working, but
goes against the grain of how relational databases are intended to be
designed, and ultimately makes one question whether using a relational
database is the best approach in these circumstances.

A second reason that relational databases get denormalized on purpose is
a business document structure that requires retention. That is, you have
an enclosing table that refers to a lot of external tables whose data
could change over time, but you need to preserve the enclosing document
as a snapshot in history. The common example here is with invoices. You
already have customer and product tables, and you'd think that you could
just make an invoice that refers to those tables. But this should never
be done in practice. Customer or price information could change, and
then you would lose the integrity of the invoice document as it was on
the invoice date, which could violate audits, reports, or laws, and
cause other problems.

In the relational world, denormalization violates Codd's normal forms,
and you try to avoid it. But in Cassandra, denormalization is, well,
perfectly normal. It's not required if your data model is simple. But
don't be afraid of it.

Historically, denormalization in Cassandra has required designing and
managing multiple tables using techniques described in this
documentation. Beginning with the 3.0 release, Cassandra provides a
feature known as `materialized views <materialized-views>` which allows
you to create multiple denormalized views of data based on a base table
design. Cassandra manages materialized views on the server, including
the work of keeping the views in sync with the table.

=== Query-first design

Relational modeling, in simple terms, means that you start from the
conceptual domain and then represent the nouns in the domain in tables.
You then assign primary keys and foreign keys to model relationships.
When you have a many-to-many relationship, you create the join tables
that represent just those keys. The join tables don't exist in the real
world, and are a necessary side effect of the way relational models
work. After you have all your tables laid out, you can start writing
queries that pull together disparate data using the relationships
defined by the keys. The queries in the relational world are very much
secondary. It is assumed that you can always get the data you want as
long as you have your tables modeled properly. Even if you have to use
several complex subqueries or join statements, this is usually true.

By contrast, in Cassandra you don't start with the data model; you start
with the query model. Instead of modeling the data first and then
writing queries, with Cassandra you model the queries and let the data
be organized around them. Think of the most common query paths your
application will use, and then create the tables that you need to
support them.

Detractors have suggested that designing the queries first is overly
constraining on application design, not to mention database modeling.
But it is perfectly reasonable to expect that you should think hard
about the queries in your application, just as you would, presumably,
think hard about your relational domain. You may get it wrong, and then
you'll have problems in either world. Or your query needs might change
over time, and then you'll have to work to update your data set. But
this is no different from defining the wrong tables, or needing
additional tables, in an RDBMS.

=== Designing for optimal storage

In a relational database, it is frequently transparent to the user how
tables are stored on disk, and it is rare to hear of recommendations
about data modeling based on how the RDBMS might store tables on disk.
However, that is an important consideration in Cassandra. Because
Cassandra tables are each stored in separate files on disk, it's
important to keep related columns defined together in the same table.

A key goal that you will see as you begin creating data models in
Cassandra is to minimize the number of partitions that must be searched
in order to satisfy a given query. Because the partition is a unit of
storage that does not get divided across nodes, a query that searches a
single partition will typically yield the best performance.

=== Sorting is a design decision

In an RDBMS, you can easily change the order in which records are
returned to you by using `ORDER BY` in your query. The default sort
order is not configurable; by default, records are returned in the order
in which they are written. If you want to change the order, you just
modify your query, and you can sort by any list of columns.

In Cassandra, however, sorting is treated differently; it is a design
decision. The sort order available on queries is fixed, and is
determined entirely by the selection of clustering columns you supply in
the `CREATE TABLE` command. The CQL `SELECT` statement does support
`ORDER BY` semantics, but only in the order specified by the clustering
columns.

_Material adapted from Cassandra, The Definitive Guide. Published by
O'Reilly Media, Inc. Copyright © 2020 Jeff Carpenter, Eben Hewitt. All
rights reserved. Used with permission._

gha: Java, lang: fortran
